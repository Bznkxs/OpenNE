actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76762'}; time used = 2.6439437866210938s
epoch 10: {'train_loss': '2.76077'}; time used = 2.8384575843811035s
epoch 15: {'train_loss': '2.74671'}; time used = 2.865800380706787s
epoch 20: {'train_loss': '2.72378'}; time used = 1.799863338470459s
epoch 25: {'train_loss': '2.68488'}; time used = 1.7303390502929688s
epoch 30: {'train_loss': '2.63936'}; time used = 1.532470464706421s
epoch 35: {'train_loss': '2.59493'}; time used = 1.5210504531860352s
epoch 40: {'train_loss': '2.53742'}; time used = 1.4911999702453613s
epoch 45: {'train_loss': '2.46866'}; time used = 1.5960330963134766s
epoch 50: {'train_loss': '2.39649'}; time used = 1.5752801895141602s
epoch 55: {'train_loss': '2.36520'}; time used = 1.6554598808288574s
epoch 60: {'train_loss': '2.31517'}; time used = 1.473862648010254s
epoch 65: {'train_loss': '2.38791'}; time used = 1.723156213760376s
epoch 70: {'train_loss': '2.32048'}; time used = 1.6775615215301514s
epoch 75: {'train_loss': '2.19692'}; time used = 2.004408121109009s
epoch 80: {'train_loss': '2.55152'}; time used = 2.977760076522827s
epoch 85: {'train_loss': '2.27419'}; time used = 2.682676076889038s
epoch 90: {'train_loss': '2.24716'}; time used = 2.8605055809020996s
epoch 95: {'train_loss': '2.12929'}; time used = 1.5440537929534912s
epoch 100: {'train_loss': '2.03966'}; time used = 1.5810692310333252s
epoch 105: {'train_loss': '2.02121'}; time used = 1.5422863960266113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.53506565093994.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86158'}; time used = 1.991994857788086s
epoch 10: {'train_loss': '2.77819'}; time used = 1.9006245136260986s
epoch 15: {'train_loss': '2.77561'}; time used = 3.6386117935180664s
epoch 20: {'train_loss': '2.78196'}; time used = 1.7432687282562256s
epoch 25: {'train_loss': '2.77369'}; time used = 1.8721261024475098s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.256359338760376.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39147'}; time used = 1.4873120784759521s
epoch 10: {'train_loss': '1.36318'}; time used = 1.2883658409118652s
epoch 15: {'train_loss': '1.30080'}; time used = 1.0845146179199219s
epoch 20: {'train_loss': '1.25396'}; time used = 1.0472297668457031s
epoch 25: {'train_loss': '1.16303'}; time used = 1.1016180515289307s
epoch 30: {'train_loss': '1.07216'}; time used = 1.0410051345825195s
epoch 35: {'train_loss': '1.09374'}; time used = 1.0898489952087402s
epoch 40: {'train_loss': '1.00020'}; time used = 1.0451524257659912s
epoch 45: {'train_loss': '0.91508'}; time used = 1.0500457286834717s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.799504518508911.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.240428686141968s
epoch 10: {'train_loss': '1.38629'}; time used = 4.640775203704834s
epoch 15: {'train_loss': '1.38629'}; time used = 4.009342908859253s
epoch 20: {'train_loss': '1.38629'}; time used = 3.9982151985168457s
epoch 25: {'train_loss': '1.38629'}; time used = 4.019011735916138s
epoch 30: {'train_loss': '1.38629'}; time used = 3.9882779121398926s
epoch 35: {'train_loss': '1.38629'}; time used = 3.9675517082214355s
epoch 40: {'train_loss': '1.38629'}; time used = 4.0071861743927s
epoch 45: {'train_loss': '1.38629'}; time used = 4.018179655075073s
epoch 50: {'train_loss': '1.38629'}; time used = 3.942049980163574s
epoch 55: {'train_loss': '1.38629'}; time used = 3.8847241401672363s
epoch 60: {'train_loss': '1.38629'}; time used = 4.437608242034912s
epoch 65: {'train_loss': '1.38629'}; time used = 4.817285537719727s
epoch 70: {'train_loss': '1.38629'}; time used = 4.714528560638428s
epoch 75: {'train_loss': '1.38629'}; time used = 4.663143634796143s
epoch 80: {'train_loss': '1.38629'}; time used = 4.671368598937988s
epoch 85: {'train_loss': '1.38629'}; time used = 5.006551265716553s
epoch 90: {'train_loss': '1.38629'}; time used = 4.97668194770813s
epoch 95: {'train_loss': '1.38629'}; time used = 7.290316343307495s
epoch 100: {'train_loss': '1.38629'}; time used = 5.151123285293579s
epoch 105: {'train_loss': '1.38629'}; time used = 4.749483585357666s
epoch 110: {'train_loss': '1.38629'}; time used = 4.616660118103027s
epoch 115: {'train_loss': '1.38629'}; time used = 4.547918796539307s
epoch 120: {'train_loss': '1.38629'}; time used = 4.475651741027832s
epoch 125: {'train_loss': '1.38629'}; time used = 3.8492884635925293s
epoch 130: {'train_loss': '1.38629'}; time used = 3.990325927734375s
epoch 135: {'train_loss': '1.38629'}; time used = 3.977285623550415s
epoch 140: {'train_loss': '1.38629'}; time used = 5.411811828613281s
epoch 145: {'train_loss': '1.38629'}; time used = 4.053877115249634s
epoch 150: {'train_loss': '1.38629'}; time used = 3.999140739440918s
epoch 155: {'train_loss': '1.38629'}; time used = 4.002682685852051s
epoch 160: {'train_loss': '1.38629'}; time used = 3.9859068393707275s
epoch 165: {'train_loss': '1.38629'}; time used = 4.146596193313599s
epoch 170: {'train_loss': '1.38629'}; time used = 4.06977915763855s
epoch 175: {'train_loss': '1.38629'}; time used = 5.542453765869141s
epoch 180: {'train_loss': '1.38629'}; time used = 4.5382080078125s
epoch 185: {'train_loss': '1.38629'}; time used = 5.572142839431763s
epoch 190: {'train_loss': '1.38629'}; time used = 6.307683229446411s
epoch 195: {'train_loss': '1.38629'}; time used = 4.2588841915130615s
epoch 200: {'train_loss': '1.38629'}; time used = 4.022768497467041s
epoch 205: {'train_loss': '1.38629'}; time used = 3.9798240661621094s
epoch 210: {'train_loss': '1.38629'}; time used = 3.9345414638519287s
epoch 215: {'train_loss': '1.38629'}; time used = 3.927363157272339s
epoch 220: {'train_loss': '1.38629'}; time used = 4.054409503936768s
epoch 225: {'train_loss': '1.38629'}; time used = 4.688823461532593s
epoch 230: {'train_loss': '1.38629'}; time used = 4.213423252105713s
epoch 235: {'train_loss': '1.38629'}; time used = 3.930295944213867s
epoch 240: {'train_loss': '1.38629'}; time used = 4.016826391220093s
epoch 245: {'train_loss': '1.38629'}; time used = 4.098515272140503s
epoch 250: {'train_loss': '1.38629'}; time used = 4.08082389831543s
epoch 255: {'train_loss': '1.38629'}; time used = 4.623899936676025s
epoch 260: {'train_loss': '1.38629'}; time used = 4.945054054260254s
epoch 265: {'train_loss': '1.38629'}; time used = 4.829319953918457s
epoch 270: {'train_loss': '1.38629'}; time used = 6.863692760467529s
epoch 275: {'train_loss': '1.38629'}; time used = 5.755063056945801s
epoch 280: {'train_loss': '1.38629'}; time used = 4.106148719787598s
epoch 285: {'train_loss': '1.38629'}; time used = 4.231842041015625s
epoch 290: {'train_loss': '1.38629'}; time used = 5.144609689712524s
epoch 295: {'train_loss': '1.38629'}; time used = 6.645646333694458s
epoch 300: {'train_loss': '1.38629'}; time used = 4.132747411727905s
epoch 305: {'train_loss': '1.38629'}; time used = 3.971891164779663s
epoch 310: {'train_loss': '1.38629'}; time used = 4.089047908782959s
epoch 315: {'train_loss': '1.38629'}; time used = 3.9990286827087402s
epoch 320: {'train_loss': '1.38629'}; time used = 4.05536413192749s
epoch 325: {'train_loss': '1.38629'}; time used = 4.024209022521973s
epoch 330: {'train_loss': '1.38629'}; time used = 3.8710732460021973s
epoch 335: {'train_loss': '1.38629'}; time used = 3.9690024852752686s
epoch 340: {'train_loss': '1.38629'}; time used = 4.12578010559082s
epoch 345: {'train_loss': '1.38629'}; time used = 4.808933734893799s
epoch 350: {'train_loss': '1.38629'}; time used = 4.002687931060791s
epoch 355: {'train_loss': '1.38629'}; time used = 3.971679925918579s
epoch 360: {'train_loss': '1.38629'}; time used = 4.047340154647827s
epoch 365: {'train_loss': '1.38629'}; time used = 4.014890193939209s
epoch 370: {'train_loss': '1.38629'}; time used = 3.9245097637176514s
epoch 375: {'train_loss': '1.38629'}; time used = 4.348137140274048s
epoch 380: {'train_loss': '1.38629'}; time used = 4.051483631134033s
epoch 385: {'train_loss': '1.38629'}; time used = 3.984966278076172s
epoch 390: {'train_loss': '1.38629'}; time used = 3.953230142593384s
epoch 395: {'train_loss': '1.38629'}; time used = 3.897956609725952s
epoch 400: {'train_loss': '1.38629'}; time used = 3.9563992023468018s
epoch 405: {'train_loss': '1.38629'}; time used = 4.74619197845459s
epoch 410: {'train_loss': '1.38629'}; time used = 3.9969067573547363s
epoch 415: {'train_loss': '1.38629'}; time used = 3.958239793777466s
epoch 420: {'train_loss': '1.38629'}; time used = 4.031153917312622s
epoch 425: {'train_loss': '1.38629'}; time used = 4.154398202896118s
epoch 430: {'train_loss': '1.38629'}; time used = 4.001979827880859s
epoch 435: {'train_loss': '1.38629'}; time used = 4.013789653778076s
epoch 440: {'train_loss': '1.38629'}; time used = 3.8958678245544434s
epoch 445: {'train_loss': '1.38629'}; time used = 4.032426357269287s
epoch 450: {'train_loss': '1.38629'}; time used = 4.05078387260437s
epoch 455: {'train_loss': '1.38629'}; time used = 4.150126695632935s
epoch 460: {'train_loss': '1.38629'}; time used = 4.113199472427368s
epoch 465: {'train_loss': '1.38629'}; time used = 4.042548656463623s
epoch 470: {'train_loss': '1.38629'}; time used = 3.9834203720092773s
epoch 475: {'train_loss': '1.38629'}; time used = 4.010968208312988s
epoch 480: {'train_loss': '1.38629'}; time used = 4.12699031829834s
epoch 485: {'train_loss': '1.38629'}; time used = 4.23954176902771s
epoch 490: {'train_loss': '1.38629'}; time used = 3.8755900859832764s
epoch 495: {'train_loss': '1.38629'}; time used = 3.98433518409729s
epoch 500: {'train_loss': '1.38629'}; time used = 3.9507036209106445s
Finished training. Time used = 443.6567029953003.
Training classifier using 80.00% nodes...
{'micro': 0.65, 'macro': 0.6457131288591963, 'samples': 0.65, 'weighted': 0.6449336977426864, 'accuracy': 0.65}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68889'}; time used = 1.9298036098480225s
epoch 10: {'train_loss': '2.63647'}; time used = 1.719266414642334s
epoch 15: {'train_loss': '2.61866'}; time used = 1.702307939529419s
epoch 20: {'train_loss': '2.58329'}; time used = 1.685326099395752s
epoch 25: {'train_loss': '2.56332'}; time used = 1.7508184909820557s
epoch 30: {'train_loss': '2.53356'}; time used = 1.76888108253479s
epoch 35: {'train_loss': '2.50958'}; time used = 1.71671462059021s
epoch 40: {'train_loss': '2.47382'}; time used = 1.6537880897521973s
epoch 45: {'train_loss': '2.44449'}; time used = 1.6519153118133545s
epoch 50: {'train_loss': '2.41279'}; time used = 1.7208940982818604s
epoch 55: {'train_loss': '2.41730'}; time used = 1.853743314743042s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.45618200302124.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.19730'}; time used = 2.027092218399048s
epoch 10: {'train_loss': '1.13556'}; time used = 1.6758708953857422s
epoch 15: {'train_loss': '1.11674'}; time used = 1.6427571773529053s
epoch 20: {'train_loss': '1.05524'}; time used = 1.666579008102417s
epoch 25: {'train_loss': '0.70409'}; time used = 1.7041454315185547s
epoch 30: {'train_loss': '0.45165'}; time used = 1.6505553722381592s
epoch 35: {'train_loss': '0.29033'}; time used = 1.7233147621154785s
epoch 40: {'train_loss': '0.34413'}; time used = 1.6396636962890625s
epoch 45: {'train_loss': '0.29507'}; time used = 1.7231411933898926s
epoch 50: {'train_loss': '0.30151'}; time used = 1.6713240146636963s
epoch 55: {'train_loss': '0.12387'}; time used = 1.7787976264953613s
epoch 60: {'train_loss': '0.22135'}; time used = 1.659877061843872s
epoch 65: {'train_loss': '0.02403'}; time used = 1.66984224319458s
epoch 70: {'train_loss': '0.10373'}; time used = 1.6565213203430176s
epoch 75: {'train_loss': '0.00619'}; time used = 1.7534737586975098s
epoch 80: {'train_loss': '0.00471'}; time used = 1.7682466506958008s
epoch 85: {'train_loss': '0.00376'}; time used = 2.2639405727386475s
epoch 90: {'train_loss': '0.09377'}; time used = 1.81319260597229s
epoch 95: {'train_loss': '0.17386'}; time used = 1.6614229679107666s
epoch 100: {'train_loss': '0.11884'}; time used = 1.6869080066680908s
epoch 105: {'train_loss': '0.09480'}; time used = 1.7760593891143799s
epoch 110: {'train_loss': '0.18491'}; time used = 1.6826090812683105s
epoch 115: {'train_loss': '0.17996'}; time used = 1.6923863887786865s
epoch 120: {'train_loss': '0.07794'}; time used = 1.920022964477539s
epoch 125: {'train_loss': '0.16712'}; time used = 2.9954211711883545s
epoch 130: {'train_loss': '0.25631'}; time used = 1.650451898574829s
epoch 135: {'train_loss': '0.01265'}; time used = 1.7717413902282715s
epoch 140: {'train_loss': '0.00976'}; time used = 1.551518201828003s
epoch 145: {'train_loss': '0.17748'}; time used = 1.9222888946533203s
epoch 150: {'train_loss': '0.00634'}; time used = 1.726595401763916s
epoch 155: {'train_loss': '0.09151'}; time used = 1.7412645816802979s
epoch 160: {'train_loss': '0.08937'}; time used = 1.7117903232574463s
epoch 165: {'train_loss': '0.09336'}; time used = 1.7137084007263184s
epoch 170: {'train_loss': '0.17064'}; time used = 3.071157217025757s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 65.02526950836182.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.1889448165893555s
epoch 10: {'train_loss': '1.38629'}; time used = 4.911541700363159s
epoch 15: {'train_loss': '1.38629'}; time used = 4.650942802429199s
epoch 20: {'train_loss': '1.38629'}; time used = 5.20897102355957s
epoch 25: {'train_loss': '1.38629'}; time used = 5.526867389678955s
epoch 30: {'train_loss': '1.38629'}; time used = 5.327081680297852s
epoch 35: {'train_loss': '1.38629'}; time used = 5.68945837020874s
epoch 40: {'train_loss': '1.38629'}; time used = 4.361783981323242s
epoch 45: {'train_loss': '1.38629'}; time used = 4.4953413009643555s
epoch 50: {'train_loss': '1.38629'}; time used = 4.391341686248779s
epoch 55: {'train_loss': '1.38629'}; time used = 4.5015411376953125s
epoch 60: {'train_loss': '1.38629'}; time used = 5.060620069503784s
epoch 65: {'train_loss': '1.38629'}; time used = 4.949294567108154s
epoch 70: {'train_loss': '1.38629'}; time used = 7.692133665084839s
epoch 75: {'train_loss': '1.38629'}; time used = 5.0917112827301025s
epoch 80: {'train_loss': '1.38629'}; time used = 4.620898246765137s
epoch 85: {'train_loss': '1.38629'}; time used = 5.91919207572937s
epoch 90: {'train_loss': '1.38629'}; time used = 4.912123441696167s
epoch 95: {'train_loss': '1.38629'}; time used = 4.538003444671631s
epoch 100: {'train_loss': '1.38629'}; time used = 4.3331077098846436s
epoch 105: {'train_loss': '1.38629'}; time used = 4.314924478530884s
epoch 110: {'train_loss': '1.38629'}; time used = 4.466559886932373s
epoch 115: {'train_loss': '1.38629'}; time used = 5.164546966552734s
epoch 120: {'train_loss': '1.38629'}; time used = 4.746097803115845s
epoch 125: {'train_loss': '1.38629'}; time used = 4.534977912902832s
epoch 130: {'train_loss': '1.38629'}; time used = 4.649321556091309s
epoch 135: {'train_loss': '1.38629'}; time used = 4.530066013336182s
epoch 140: {'train_loss': '1.38629'}; time used = 4.722270250320435s
epoch 145: {'train_loss': '1.38629'}; time used = 4.4958336353302s
epoch 150: {'train_loss': '1.38629'}; time used = 4.644923210144043s
epoch 155: {'train_loss': '1.38629'}; time used = 4.584678649902344s
epoch 160: {'train_loss': '1.38629'}; time used = 6.322700023651123s
epoch 165: {'train_loss': '1.38629'}; time used = 6.319970607757568s
epoch 170: {'train_loss': '1.38629'}; time used = 4.458070755004883s
epoch 175: {'train_loss': '1.38629'}; time used = 4.4675209522247314s
epoch 180: {'train_loss': '1.38629'}; time used = 6.054557800292969s
epoch 185: {'train_loss': '1.38629'}; time used = 6.20169472694397s
epoch 190: {'train_loss': '1.38629'}; time used = 4.9194629192352295s
epoch 195: {'train_loss': '1.38629'}; time used = 5.261399030685425s
epoch 200: {'train_loss': '1.38629'}; time used = 5.503751754760742s
epoch 205: {'train_loss': '1.38629'}; time used = 5.5790441036224365s
epoch 210: {'train_loss': '1.38629'}; time used = 5.001907110214233s
epoch 215: {'train_loss': '1.38629'}; time used = 4.868808746337891s
epoch 220: {'train_loss': '1.38629'}; time used = 4.908164978027344s
epoch 225: {'train_loss': '1.38629'}; time used = 4.940684080123901s
epoch 230: {'train_loss': '1.38629'}; time used = 6.579679250717163s
epoch 235: {'train_loss': '1.38629'}; time used = 5.460193872451782s
epoch 240: {'train_loss': '1.38629'}; time used = 4.851686716079712s
epoch 245: {'train_loss': '1.38629'}; time used = 4.67307186126709s
epoch 250: {'train_loss': '1.38629'}; time used = 4.979332208633423s
epoch 255: {'train_loss': '1.38629'}; time used = 4.268126010894775s
epoch 260: {'train_loss': '1.38629'}; time used = 4.415768623352051s
epoch 265: {'train_loss': '1.38629'}; time used = 4.9110331535339355s
epoch 270: {'train_loss': '1.38629'}; time used = 5.003816366195679s
epoch 275: {'train_loss': '1.38629'}; time used = 4.566478490829468s
epoch 280: {'train_loss': '1.38629'}; time used = 7.142449617385864s
epoch 285: {'train_loss': '1.38629'}; time used = 5.221762180328369s
epoch 290: {'train_loss': '1.38629'}; time used = 4.2236247062683105s
epoch 295: {'train_loss': '1.38629'}; time used = 4.337956428527832s
epoch 300: {'train_loss': '1.38629'}; time used = 6.8411688804626465s
epoch 305: {'train_loss': '1.38629'}; time used = 5.838077545166016s
epoch 310: {'train_loss': '1.38629'}; time used = 4.288745403289795s
epoch 315: {'train_loss': '1.38629'}; time used = 4.200068235397339s
epoch 320: {'train_loss': '1.38629'}; time used = 4.120884656906128s
epoch 325: {'train_loss': '1.38629'}; time used = 4.181044101715088s
epoch 330: {'train_loss': '1.38629'}; time used = 4.092498302459717s
epoch 335: {'train_loss': '1.38629'}; time used = 4.16995906829834s
epoch 340: {'train_loss': '1.38629'}; time used = 4.13015079498291s
epoch 345: {'train_loss': '1.38629'}; time used = 4.207951545715332s
epoch 350: {'train_loss': '1.38629'}; time used = 5.335409164428711s
epoch 355: {'train_loss': '1.38629'}; time used = 4.5779924392700195s
epoch 360: {'train_loss': '1.38629'}; time used = 4.3627684116363525s
epoch 365: {'train_loss': '1.38629'}; time used = 4.447508335113525s
epoch 370: {'train_loss': '1.38629'}; time used = 4.1137402057647705s
epoch 375: {'train_loss': '1.38629'}; time used = 4.185988187789917s
epoch 380: {'train_loss': '1.38629'}; time used = 4.247153997421265s
epoch 385: {'train_loss': '1.38629'}; time used = 4.159868478775024s
epoch 390: {'train_loss': '1.38629'}; time used = 4.153801679611206s
epoch 395: {'train_loss': '1.38629'}; time used = 4.984510183334351s
epoch 400: {'train_loss': '1.38629'}; time used = 4.94522500038147s
epoch 405: {'train_loss': '1.38629'}; time used = 4.556673049926758s
epoch 410: {'train_loss': '1.38629'}; time used = 4.2140514850616455s
epoch 415: {'train_loss': '1.38629'}; time used = 4.289307355880737s
epoch 420: {'train_loss': '1.38629'}; time used = 4.474247932434082s
epoch 425: {'train_loss': '1.38629'}; time used = 4.300824880599976s
epoch 430: {'train_loss': '1.38629'}; time used = 4.301690340042114s
epoch 435: {'train_loss': '1.38629'}; time used = 4.511080980300903s
epoch 440: {'train_loss': '1.38629'}; time used = 4.900794982910156s
epoch 445: {'train_loss': '1.38629'}; time used = 7.470425367355347s
epoch 450: {'train_loss': '1.38629'}; time used = 4.9713897705078125s
epoch 455: {'train_loss': '1.38629'}; time used = 4.419875621795654s
epoch 460: {'train_loss': '1.38629'}; time used = 4.183697462081909s
epoch 465: {'train_loss': '1.38629'}; time used = 4.28010892868042s
epoch 470: {'train_loss': '1.38629'}; time used = 4.34954571723938s
epoch 475: {'train_loss': '1.38629'}; time used = 4.313777923583984s
epoch 480: {'train_loss': '1.38629'}; time used = 6.478582859039307s
epoch 485: {'train_loss': '1.38629'}; time used = 6.533159494400024s
epoch 490: {'train_loss': '1.38629'}; time used = 4.369743347167969s
epoch 495: {'train_loss': '1.38629'}; time used = 4.561186790466309s
epoch 500: {'train_loss': '1.38629'}; time used = 4.3571085929870605s
Finished training. Time used = 496.7468161582947.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39428'}; time used = 1.299027919769287s
epoch 10: {'train_loss': '1.39513'}; time used = 1.192777156829834s
epoch 15: {'train_loss': '1.29281'}; time used = 1.173231840133667s
epoch 20: {'train_loss': '1.33984'}; time used = 1.213752031326294s
epoch 25: {'train_loss': '1.13473'}; time used = 1.1982030868530273s
epoch 30: {'train_loss': '1.23182'}; time used = 1.2369749546051025s
epoch 35: {'train_loss': '1.26600'}; time used = 1.1952621936798096s
epoch 40: {'train_loss': '1.17640'}; time used = 1.2155249118804932s
epoch 45: {'train_loss': '1.01820'}; time used = 1.1476125717163086s
epoch 50: {'train_loss': '1.14562'}; time used = 1.0837631225585938s
epoch 55: {'train_loss': '1.34888'}; time used = 1.05326247215271s
epoch 60: {'train_loss': '1.26393'}; time used = 1.0556366443634033s
epoch 65: {'train_loss': '1.19184'}; time used = 1.0985472202301025s
epoch 70: {'train_loss': '1.25925'}; time used = 1.0496032238006592s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.80751609802246.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77734'}; time used = 3.0368170738220215s
epoch 10: {'train_loss': '2.77314'}; time used = 3.623161554336548s
epoch 15: {'train_loss': '2.77377'}; time used = 3.5719244480133057s
epoch 20: {'train_loss': '2.77579'}; time used = 2.09317684173584s
epoch 25: {'train_loss': '2.77393'}; time used = 0.9971733093261719s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.494134187698364.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.66571'}; time used = 1.1535320281982422s
epoch 10: {'train_loss': '2.39960'}; time used = 0.9132108688354492s
epoch 15: {'train_loss': '2.09224'}; time used = 1.2408006191253662s
epoch 20: {'train_loss': '1.79857'}; time used = 1.1008656024932861s
epoch 25: {'train_loss': '1.76446'}; time used = 1.0453300476074219s
epoch 30: {'train_loss': '1.67559'}; time used = 1.1654918193817139s
epoch 35: {'train_loss': '1.60687'}; time used = 1.1201138496398926s
epoch 40: {'train_loss': '1.61908'}; time used = 0.9653284549713135s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.07300615310669.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.6041666666666666, 'samples': 0.631578947368421, 'weighted': 0.6206140350877193, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.35826'}; time used = 5.974006414413452s
epoch 10: {'train_loss': '1.35697'}; time used = 7.999008893966675s
epoch 15: {'train_loss': '1.17491'}; time used = 5.16083025932312s
epoch 20: {'train_loss': '1.14654'}; time used = 4.832215070724487s
epoch 25: {'train_loss': '1.02999'}; time used = 4.761857748031616s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.55373501777649.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7300000000000001, 'samples': 0.73, 'weighted': 0.73, 'accuracy': 0.73}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.50673'}; time used = 1.5126681327819824s
epoch 10: {'train_loss': '0.18653'}; time used = 1.2517836093902588s
epoch 15: {'train_loss': '0.08473'}; time used = 1.409252643585205s
epoch 20: {'train_loss': '0.01861'}; time used = 1.2887563705444336s
epoch 25: {'train_loss': '0.09167'}; time used = 1.4998517036437988s
epoch 30: {'train_loss': '0.02885'}; time used = 1.2959294319152832s
epoch 35: {'train_loss': '0.01624'}; time used = 1.3930542469024658s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.404185771942139.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78337'}; time used = 1.0201492309570312s
epoch 10: {'train_loss': '2.49296'}; time used = 0.8855466842651367s
epoch 15: {'train_loss': '2.08392'}; time used = 0.8887186050415039s
epoch 20: {'train_loss': '1.83465'}; time used = 0.8920533657073975s
epoch 25: {'train_loss': '1.83093'}; time used = 0.9113984107971191s
epoch 30: {'train_loss': '1.75923'}; time used = 0.9266371726989746s
epoch 35: {'train_loss': '1.64121'}; time used = 0.9185402393341064s
epoch 40: {'train_loss': '1.59391'}; time used = 1.0405638217926025s
epoch 45: {'train_loss': '1.66927'}; time used = 0.9139482975006104s
epoch 50: {'train_loss': '1.51924'}; time used = 0.8834488391876221s
epoch 55: {'train_loss': '1.47540'}; time used = 0.8841536045074463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.291162252426147.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.85466'}; time used = 1.2179241180419922s
epoch 10: {'train_loss': '0.76193'}; time used = 0.9681515693664551s
epoch 15: {'train_loss': '0.36955'}; time used = 1.0712270736694336s
epoch 20: {'train_loss': '0.22553'}; time used = 1.132047176361084s
epoch 25: {'train_loss': '0.19039'}; time used = 1.0133121013641357s
epoch 30: {'train_loss': '0.15155'}; time used = 0.961458683013916s
epoch 35: {'train_loss': '0.09072'}; time used = 0.9692888259887695s
epoch 40: {'train_loss': '0.06527'}; time used = 0.9817140102386475s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.978065967559814.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.25518'}; time used = 1.9642486572265625s
epoch 10: {'train_loss': '1.14682'}; time used = 3.123333692550659s
epoch 15: {'train_loss': '0.97169'}; time used = 2.0030734539031982s
epoch 20: {'train_loss': '0.81072'}; time used = 2.8544044494628906s
epoch 25: {'train_loss': '0.69000'}; time used = 3.213632345199585s
epoch 30: {'train_loss': '0.57310'}; time used = 2.894540309906006s
epoch 35: {'train_loss': '0.63225'}; time used = 1.9243664741516113s
epoch 40: {'train_loss': '0.50945'}; time used = 2.9103779792785645s
epoch 45: {'train_loss': '0.54666'}; time used = 2.9102683067321777s
epoch 50: {'train_loss': '0.57402'}; time used = 2.742325782775879s
epoch 55: {'train_loss': '0.55216'}; time used = 1.998905897140503s
epoch 60: {'train_loss': '0.49726'}; time used = 2.0228283405303955s
epoch 65: {'train_loss': '0.49893'}; time used = 2.2112233638763428s
epoch 70: {'train_loss': '0.49235'}; time used = 2.209672451019287s
epoch 75: {'train_loss': '0.37285'}; time used = 2.0711569786071777s
epoch 80: {'train_loss': '0.41104'}; time used = 2.8428285121917725s
epoch 85: {'train_loss': '0.42804'}; time used = 3.2455711364746094s
epoch 90: {'train_loss': '0.35262'}; time used = 3.25407338142395s
epoch 95: {'train_loss': '0.41648'}; time used = 1.9522392749786377s
epoch 100: {'train_loss': '0.33132'}; time used = 1.9924101829528809s
epoch 105: {'train_loss': '0.38710'}; time used = 2.004537343978882s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.94764018058777.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79344'}; time used = 2.997081756591797s
epoch 10: {'train_loss': '2.77192'}; time used = 1.7283167839050293s
epoch 15: {'train_loss': '2.75738'}; time used = 1.703432559967041s
epoch 20: {'train_loss': '2.73956'}; time used = 1.7666118144989014s
epoch 25: {'train_loss': '2.72268'}; time used = 2.0869500637054443s
epoch 30: {'train_loss': '2.70896'}; time used = 1.7167320251464844s
epoch 35: {'train_loss': '2.70097'}; time used = 1.656034231185913s
epoch 40: {'train_loss': '2.68867'}; time used = 1.6321637630462646s
epoch 45: {'train_loss': '2.68223'}; time used = 1.6439263820648193s
epoch 50: {'train_loss': '2.67659'}; time used = 1.6903624534606934s
epoch 55: {'train_loss': '2.67281'}; time used = 1.5863001346588135s
epoch 60: {'train_loss': '2.65592'}; time used = 1.6247656345367432s
epoch 65: {'train_loss': '2.64879'}; time used = 1.6356663703918457s
epoch 70: {'train_loss': '2.65638'}; time used = 1.7038447856903076s
epoch 75: {'train_loss': '2.63970'}; time used = 1.6876342296600342s
epoch 80: {'train_loss': '2.64315'}; time used = 1.6215808391571045s
epoch 85: {'train_loss': '2.64660'}; time used = 1.6208124160766602s
epoch 90: {'train_loss': '2.62973'}; time used = 1.616952657699585s
epoch 95: {'train_loss': '2.63511'}; time used = 1.630962610244751s
epoch 100: {'train_loss': '2.63192'}; time used = 1.761300802230835s
epoch 105: {'train_loss': '2.62001'}; time used = 1.638810157775879s
epoch 110: {'train_loss': '2.62148'}; time used = 1.772587537765503s
epoch 115: {'train_loss': '2.60156'}; time used = 1.6522679328918457s
epoch 120: {'train_loss': '2.61418'}; time used = 1.6617252826690674s
epoch 125: {'train_loss': '2.61150'}; time used = 1.6310389041900635s
epoch 130: {'train_loss': '2.61426'}; time used = 1.7002544403076172s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.90237545967102.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38898'}; time used = 1.1129100322723389s
epoch 10: {'train_loss': '1.35012'}; time used = 1.2414381504058838s
epoch 15: {'train_loss': '1.27881'}; time used = 1.302445411682129s
epoch 20: {'train_loss': '1.28217'}; time used = 1.2683556079864502s
epoch 25: {'train_loss': '1.16896'}; time used = 1.2504565715789795s
epoch 30: {'train_loss': '1.03601'}; time used = 1.2604284286499023s
epoch 35: {'train_loss': '0.94742'}; time used = 1.257451057434082s
epoch 40: {'train_loss': '0.87038'}; time used = 1.2421784400939941s
epoch 45: {'train_loss': '0.69521'}; time used = 1.2738525867462158s
epoch 50: {'train_loss': '0.83471'}; time used = 1.2521898746490479s
epoch 55: {'train_loss': '0.72847'}; time used = 1.2854115962982178s
epoch 60: {'train_loss': '0.73148'}; time used = 1.2388265132904053s
epoch 65: {'train_loss': '0.61672'}; time used = 1.060070276260376s
epoch 70: {'train_loss': '0.71089'}; time used = 1.0383729934692383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.783203125.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.68 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.09269'}; time used = 1.221517562866211s
epoch 10: {'train_loss': '0.80218'}; time used = 1.1058497428894043s
epoch 15: {'train_loss': '0.53760'}; time used = 1.0683958530426025s
epoch 20: {'train_loss': '0.39125'}; time used = 1.1066172122955322s
epoch 25: {'train_loss': '0.35448'}; time used = 1.1406316757202148s
epoch 30: {'train_loss': '0.16255'}; time used = 1.2456529140472412s
epoch 35: {'train_loss': '0.07849'}; time used = 1.2695534229278564s
epoch 40: {'train_loss': '0.06761'}; time used = 1.2729249000549316s
epoch 45: {'train_loss': '0.05063'}; time used = 1.0977425575256348s
epoch 50: {'train_loss': '0.04486'}; time used = 1.0605769157409668s
epoch 55: {'train_loss': '0.02220'}; time used = 1.0683634281158447s
epoch 60: {'train_loss': '0.15570'}; time used = 1.1219542026519775s
epoch 65: {'train_loss': '0.03724'}; time used = 1.0733263492584229s
epoch 70: {'train_loss': '0.04648'}; time used = 1.0795600414276123s
epoch 75: {'train_loss': '0.02930'}; time used = 1.0522964000701904s
epoch 80: {'train_loss': '0.11887'}; time used = 1.0835843086242676s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.0513699054718.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79690'}; time used = 2.5616395473480225s
epoch 10: {'train_loss': '2.83151'}; time used = 2.5364463329315186s
epoch 15: {'train_loss': '2.77503'}; time used = 2.436772346496582s
epoch 20: {'train_loss': '2.76498'}; time used = 2.488955497741699s
epoch 25: {'train_loss': '2.76308'}; time used = 2.6260643005371094s
epoch 30: {'train_loss': '2.74998'}; time used = 2.437455892562866s
epoch 35: {'train_loss': '2.72765'}; time used = 2.472492218017578s
epoch 40: {'train_loss': '2.72222'}; time used = 3.4796347618103027s
epoch 45: {'train_loss': '2.69295'}; time used = 3.418616771697998s
epoch 50: {'train_loss': '2.66702'}; time used = 3.2927749156951904s
epoch 55: {'train_loss': '2.61676'}; time used = 2.757849931716919s
epoch 60: {'train_loss': '2.63145'}; time used = 2.341174364089966s
epoch 65: {'train_loss': '2.52958'}; time used = 2.466522693634033s
epoch 70: {'train_loss': '2.50541'}; time used = 2.466252565383911s
epoch 75: {'train_loss': '2.46283'}; time used = 2.4555864334106445s
epoch 80: {'train_loss': '2.45522'}; time used = 3.464824914932251s
epoch 85: {'train_loss': '2.41101'}; time used = 3.3164169788360596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.38140273094177.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.13981'}; time used = 2.6993966102600098s
epoch 10: {'train_loss': '0.06406'}; time used = 1.6352975368499756s
epoch 15: {'train_loss': '0.09634'}; time used = 1.6853976249694824s
epoch 20: {'train_loss': '0.00476'}; time used = 1.7394838333129883s
epoch 25: {'train_loss': '0.02896'}; time used = 1.7123374938964844s
epoch 30: {'train_loss': '0.00760'}; time used = 1.694735050201416s
epoch 35: {'train_loss': '0.05533'}; time used = 1.5458202362060547s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.469361305236816.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.79541'}; time used = 1.1123037338256836s
epoch 10: {'train_loss': '0.52918'}; time used = 0.9999158382415771s
epoch 15: {'train_loss': '0.19796'}; time used = 1.1623518466949463s
epoch 20: {'train_loss': '0.24478'}; time used = 1.0016589164733887s
epoch 25: {'train_loss': '0.28027'}; time used = 1.0420820713043213s
epoch 30: {'train_loss': '0.16279'}; time used = 1.1206567287445068s
epoch 35: {'train_loss': '0.13500'}; time used = 1.2575898170471191s
epoch 40: {'train_loss': '0.12476'}; time used = 1.0698623657226562s
epoch 45: {'train_loss': '0.10238'}; time used = 1.1105561256408691s
epoch 50: {'train_loss': '0.09647'}; time used = 1.143693208694458s
epoch 55: {'train_loss': '0.08915'}; time used = 1.0800373554229736s
epoch 60: {'train_loss': '0.06339'}; time used = 1.1632661819458008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.07258152961731.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.86436'}; time used = 1.108689308166504s
epoch 10: {'train_loss': '2.80056'}; time used = 0.9805073738098145s
epoch 15: {'train_loss': '2.78697'}; time used = 1.0112721920013428s
epoch 20: {'train_loss': '2.77888'}; time used = 0.9800176620483398s
epoch 25: {'train_loss': '2.77275'}; time used = 0.9905233383178711s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.732578754425049.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31979'}; time used = 1.7941083908081055s
epoch 10: {'train_loss': '1.22630'}; time used = 1.9274969100952148s
epoch 15: {'train_loss': '1.14699'}; time used = 2.0359315872192383s
epoch 20: {'train_loss': '1.34946'}; time used = 1.7855772972106934s
epoch 25: {'train_loss': '1.25850'}; time used = 1.977766990661621s
epoch 30: {'train_loss': '1.15399'}; time used = 1.8321731090545654s
epoch 35: {'train_loss': '1.22916'}; time used = 1.979405403137207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.53674602508545.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.26486'}; time used = 1.229849100112915s
epoch 10: {'train_loss': '2.76476'}; time used = 1.0100793838500977s
epoch 15: {'train_loss': '2.75326'}; time used = 1.0037565231323242s
epoch 20: {'train_loss': '2.73155'}; time used = 1.0646400451660156s
epoch 25: {'train_loss': '2.63140'}; time used = 0.9345555305480957s
epoch 30: {'train_loss': '2.03148'}; time used = 0.9391379356384277s
epoch 35: {'train_loss': '1.45903'}; time used = 1.0161473751068115s
epoch 40: {'train_loss': '1.41015'}; time used = 0.8899335861206055s
epoch 45: {'train_loss': '1.40616'}; time used = 0.8813178539276123s
epoch 50: {'train_loss': '1.27451'}; time used = 0.9291515350341797s
epoch 55: {'train_loss': '1.25089'}; time used = 0.9338006973266602s
epoch 60: {'train_loss': '1.16905'}; time used = 0.980198860168457s
epoch 65: {'train_loss': '1.13405'}; time used = 0.9043576717376709s
epoch 70: {'train_loss': '1.06602'}; time used = 0.9078884124755859s
epoch 75: {'train_loss': '1.02535'}; time used = 1.0099849700927734s
epoch 80: {'train_loss': '1.05882'}; time used = 0.8884024620056152s
epoch 85: {'train_loss': '1.06306'}; time used = 0.8989782333374023s
epoch 90: {'train_loss': '1.00745'}; time used = 0.9028098583221436s
epoch 95: {'train_loss': '1.07633'}; time used = 1.6398253440856934s
epoch 100: {'train_loss': '1.03113'}; time used = 1.9296197891235352s
epoch 105: {'train_loss': '0.96096'}; time used = 2.209181070327759s
epoch 110: {'train_loss': '0.91438'}; time used = 1.8821437358856201s
epoch 115: {'train_loss': '0.90911'}; time used = 1.4701769351959229s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.391706705093384.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.18768'}; time used = 1.3920786380767822s
epoch 10: {'train_loss': '3.00816'}; time used = 1.2888922691345215s
epoch 15: {'train_loss': '2.87823'}; time used = 1.43717360496521s
epoch 20: {'train_loss': '2.79853'}; time used = 2.0618536472320557s
epoch 25: {'train_loss': '2.68152'}; time used = 2.7528278827667236s
epoch 30: {'train_loss': '2.57839'}; time used = 2.22702693939209s
epoch 35: {'train_loss': '2.46301'}; time used = 1.26651930809021s
epoch 40: {'train_loss': '2.35977'}; time used = 1.2436509132385254s
epoch 45: {'train_loss': '2.32555'}; time used = 1.2831270694732666s
epoch 50: {'train_loss': '2.33418'}; time used = 1.7204041481018066s
epoch 55: {'train_loss': '2.23923'}; time used = 1.381584644317627s
epoch 60: {'train_loss': '2.21781'}; time used = 1.1546454429626465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.085341691970825.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.21 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82502'}; time used = 1.7517971992492676s
epoch 10: {'train_loss': '2.78188'}; time used = 2.089085817337036s
epoch 15: {'train_loss': '2.76554'}; time used = 1.94743013381958s
epoch 20: {'train_loss': '2.76225'}; time used = 2.086104393005371s
epoch 25: {'train_loss': '2.75238'}; time used = 1.9126167297363281s
epoch 30: {'train_loss': '2.74459'}; time used = 1.899916648864746s
epoch 35: {'train_loss': '2.73912'}; time used = 1.957345962524414s
epoch 40: {'train_loss': '2.73133'}; time used = 1.920473337173462s
epoch 45: {'train_loss': '2.72193'}; time used = 1.9833950996398926s
epoch 50: {'train_loss': '2.71528'}; time used = 1.959193468093872s
epoch 55: {'train_loss': '2.71056'}; time used = 1.84059739112854s
epoch 60: {'train_loss': '2.69985'}; time used = 1.716594934463501s
epoch 65: {'train_loss': '2.69696'}; time used = 1.8508942127227783s
epoch 70: {'train_loss': '2.70328'}; time used = 1.8254098892211914s
epoch 75: {'train_loss': '2.68964'}; time used = 1.8725054264068604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.0329475402832.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.64 GiB already allocated; 1.25 GiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.34058'}; time used = 1.0013060569763184s
epoch 10: {'train_loss': '0.21998'}; time used = 0.8869979381561279s
epoch 15: {'train_loss': '0.19155'}; time used = 1.037367820739746s
epoch 20: {'train_loss': '0.12689'}; time used = 1.02976393699646s
epoch 25: {'train_loss': '0.11810'}; time used = 1.0392980575561523s
epoch 30: {'train_loss': '0.12205'}; time used = 1.0461268424987793s
epoch 35: {'train_loss': '0.10515'}; time used = 1.0519599914550781s
epoch 40: {'train_loss': '0.08648'}; time used = 1.0519230365753174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.505852460861206.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.35004'}; time used = 1.84425687789917s
epoch 10: {'train_loss': '1.08026'}; time used = 2.0291974544525146s
epoch 15: {'train_loss': '0.67850'}; time used = 1.8753602504730225s
epoch 20: {'train_loss': '0.31638'}; time used = 1.9239015579223633s
epoch 25: {'train_loss': '0.46017'}; time used = 2.851201057434082s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.341822624206543.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.79541'}; time used = 1.1942529678344727s
epoch 10: {'train_loss': '0.52918'}; time used = 1.1610889434814453s
epoch 15: {'train_loss': '0.19796'}; time used = 1.1391806602478027s
epoch 20: {'train_loss': '0.24478'}; time used = 1.1247782707214355s
epoch 25: {'train_loss': '0.28027'}; time used = 1.10984468460083s
epoch 30: {'train_loss': '0.16279'}; time used = 1.147209644317627s
epoch 35: {'train_loss': '0.13500'}; time used = 1.1434218883514404s
epoch 40: {'train_loss': '0.12476'}; time used = 0.9938979148864746s
epoch 45: {'train_loss': '0.10238'}; time used = 1.025895595550537s
epoch 50: {'train_loss': '0.09647'}; time used = 1.0330994129180908s
epoch 55: {'train_loss': '0.08915'}; time used = 1.0088932514190674s
epoch 60: {'train_loss': '0.06339'}; time used = 1.1203951835632324s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.935627222061157.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.22144'}; time used = 2.3991713523864746s
epoch 10: {'train_loss': '1.17821'}; time used = 2.342904567718506s
epoch 15: {'train_loss': '1.09368'}; time used = 2.403958559036255s
epoch 20: {'train_loss': '0.83537'}; time used = 2.4765381813049316s
epoch 25: {'train_loss': '0.51915'}; time used = 2.5553770065307617s
epoch 30: {'train_loss': '0.34601'}; time used = 2.448158025741577s
epoch 35: {'train_loss': '0.14287'}; time used = 2.488664388656616s
epoch 40: {'train_loss': '0.10995'}; time used = 2.7421369552612305s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.235190868377686.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39147'}; time used = 1.1763277053833008s
epoch 10: {'train_loss': '1.36318'}; time used = 1.1480028629302979s
epoch 15: {'train_loss': '1.30080'}; time used = 1.050915002822876s
epoch 20: {'train_loss': '1.25396'}; time used = 1.1287143230438232s
epoch 25: {'train_loss': '1.16303'}; time used = 1.053661584854126s
epoch 30: {'train_loss': '1.07216'}; time used = 1.0567495822906494s
epoch 35: {'train_loss': '1.09374'}; time used = 1.035292148590088s
epoch 40: {'train_loss': '1.00020'}; time used = 1.0837457180023193s
epoch 45: {'train_loss': '0.91508'}; time used = 1.0633552074432373s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.266186475753784.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.33978'}; time used = 2.459881067276001s
epoch 10: {'train_loss': '1.21379'}; time used = 2.2772724628448486s
epoch 15: {'train_loss': '1.17053'}; time used = 2.389228582382202s
epoch 20: {'train_loss': '1.17577'}; time used = 1.8926916122436523s
epoch 25: {'train_loss': '1.12283'}; time used = 2.2163503170013428s
epoch 30: {'train_loss': '1.01994'}; time used = 4.387484788894653s
epoch 35: {'train_loss': '0.96113'}; time used = 3.8698832988739014s
epoch 40: {'train_loss': '0.92867'}; time used = 3.868330955505371s
epoch 45: {'train_loss': '0.91964'}; time used = 2.0864953994750977s
epoch 50: {'train_loss': '0.75582'}; time used = 2.0708160400390625s
epoch 55: {'train_loss': '0.65620'}; time used = 1.933070182800293s
epoch 60: {'train_loss': '0.73388'}; time used = 2.0592596530914307s
epoch 65: {'train_loss': '0.80339'}; time used = 1.947406530380249s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.10965394973755.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6393728222996516, 'samples': 0.6521739130434783, 'weighted': 0.644296318739585, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.93812'}; time used = 1.0970394611358643s
epoch 10: {'train_loss': '2.80744'}; time used = 0.9781858921051025s
epoch 15: {'train_loss': '2.77881'}; time used = 1.13618803024292s
epoch 20: {'train_loss': '2.77289'}; time used = 1.0032036304473877s
epoch 25: {'train_loss': '2.77627'}; time used = 1.0514192581176758s
epoch 30: {'train_loss': '2.77159'}; time used = 1.0810370445251465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.765710830688477.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.3003315925598145s
epoch 10: {'train_loss': '1.38629'}; time used = 7.188812494277954s
epoch 15: {'train_loss': '1.38629'}; time used = 6.379813194274902s
epoch 20: {'train_loss': '1.38629'}; time used = 7.565288543701172s
epoch 25: {'train_loss': '1.38629'}; time used = 6.287651777267456s
epoch 30: {'train_loss': '1.38629'}; time used = 6.1907079219818115s
epoch 35: {'train_loss': '1.38629'}; time used = 6.242569923400879s
epoch 40: {'train_loss': '1.38629'}; time used = 6.139993906021118s
epoch 45: {'train_loss': '1.38629'}; time used = 6.535735130310059s
epoch 50: {'train_loss': '1.38629'}; time used = 6.099013090133667s
epoch 55: {'train_loss': '1.38629'}; time used = 9.239214658737183s
epoch 60: {'train_loss': '1.38629'}; time used = 6.280437231063843s
epoch 65: {'train_loss': '1.38629'}; time used = 6.152843952178955s
epoch 70: {'train_loss': '1.38629'}; time used = 6.10150408744812s
epoch 75: {'train_loss': '1.38629'}; time used = 6.2954394817352295s
epoch 80: {'train_loss': '1.38629'}; time used = 7.5161378383636475s
epoch 85: {'train_loss': '1.38629'}; time used = 8.365617513656616s
epoch 90: {'train_loss': '1.38629'}; time used = 6.067867040634155s
epoch 95: {'train_loss': '1.38629'}; time used = 5.945078611373901s
epoch 100: {'train_loss': '1.38629'}; time used = 6.22494101524353s
epoch 105: {'train_loss': '1.38629'}; time used = 6.0831263065338135s
epoch 110: {'train_loss': '1.38629'}; time used = 5.9282426834106445s
epoch 115: {'train_loss': '1.38629'}; time used = 8.59260606765747s
epoch 120: {'train_loss': '1.38629'}; time used = 8.196924686431885s
epoch 125: {'train_loss': '1.38629'}; time used = 7.082159042358398s
epoch 130: {'train_loss': '1.38629'}; time used = 7.126250982284546s
epoch 135: {'train_loss': '1.38629'}; time used = 6.161543846130371s
epoch 140: {'train_loss': '1.38629'}; time used = 5.864784002304077s
epoch 145: {'train_loss': '1.38629'}; time used = 5.92278265953064s
epoch 150: {'train_loss': '1.38629'}; time used = 5.885880708694458s
epoch 155: {'train_loss': '1.38629'}; time used = 5.858155012130737s
epoch 160: {'train_loss': '1.38629'}; time used = 5.873551368713379s
epoch 165: {'train_loss': '1.38629'}; time used = 5.828687906265259s
epoch 170: {'train_loss': '1.38629'}; time used = 5.8411805629730225s
epoch 175: {'train_loss': '1.38629'}; time used = 5.823451519012451s
epoch 180: {'train_loss': '1.38629'}; time used = 5.894490003585815s
epoch 185: {'train_loss': '1.38629'}; time used = 5.979212045669556s
epoch 190: {'train_loss': '1.38629'}; time used = 6.052170276641846s
epoch 195: {'train_loss': '1.38629'}; time used = 8.46443223953247s
epoch 200: {'train_loss': '1.38629'}; time used = 7.8733742237091064s
epoch 205: {'train_loss': '1.38629'}; time used = 7.0960373878479s
epoch 210: {'train_loss': '1.38629'}; time used = 6.929926872253418s
epoch 215: {'train_loss': '1.38629'}; time used = 7.255053997039795s
epoch 220: {'train_loss': '1.38629'}; time used = 6.20427942276001s
epoch 225: {'train_loss': '1.38629'}; time used = 5.782754421234131s
epoch 230: {'train_loss': '1.38629'}; time used = 6.0457375049591064s
epoch 235: {'train_loss': '1.38629'}; time used = 5.854296684265137s
epoch 240: {'train_loss': '1.38629'}; time used = 5.8266990184783936s
epoch 245: {'train_loss': '1.38629'}; time used = 5.830938100814819s
epoch 250: {'train_loss': '1.38629'}; time used = 5.8202009201049805s
epoch 255: {'train_loss': '1.38629'}; time used = 5.8886237144470215s
epoch 260: {'train_loss': '1.38629'}; time used = 6.1157238483428955s
epoch 265: {'train_loss': '1.38629'}; time used = 5.957051038742065s
epoch 270: {'train_loss': '1.38629'}; time used = 5.93606424331665s
epoch 275: {'train_loss': '1.38629'}; time used = 6.100221633911133s
epoch 280: {'train_loss': '1.38629'}; time used = 6.49383282661438s
epoch 285: {'train_loss': '1.38629'}; time used = 6.089637279510498s
epoch 290: {'train_loss': '1.38629'}; time used = 5.858238220214844s
epoch 295: {'train_loss': '1.38629'}; time used = 7.401233196258545s
epoch 300: {'train_loss': '1.38629'}; time used = 5.874723672866821s
epoch 305: {'train_loss': '1.38629'}; time used = 5.988863468170166s
epoch 310: {'train_loss': '1.38629'}; time used = 6.419494152069092s
epoch 315: {'train_loss': '1.38629'}; time used = 7.82276725769043s
epoch 320: {'train_loss': '1.38629'}; time used = 7.878586053848267s
epoch 325: {'train_loss': '1.38629'}; time used = 7.378398895263672s
epoch 330: {'train_loss': '1.38629'}; time used = 6.787404537200928s
epoch 335: {'train_loss': '1.38629'}; time used = 7.248348951339722s
epoch 340: {'train_loss': '1.38629'}; time used = 7.115986585617065s
epoch 345: {'train_loss': '1.38629'}; time used = 7.29315710067749s
epoch 350: {'train_loss': '1.38629'}; time used = 6.690358638763428s
epoch 355: {'train_loss': '1.38629'}; time used = 6.679725408554077s
epoch 360: {'train_loss': '1.38629'}; time used = 6.203293323516846s
epoch 365: {'train_loss': '1.38629'}; time used = 6.122689485549927s
epoch 370: {'train_loss': '1.38629'}; time used = 8.847826957702637s
epoch 375: {'train_loss': '1.38629'}; time used = 6.536811351776123s
epoch 380: {'train_loss': '1.38629'}; time used = 6.2243828773498535s
epoch 385: {'train_loss': '1.38629'}; time used = 8.168283224105835s
epoch 390: {'train_loss': '1.38629'}; time used = 6.7021324634552s
epoch 395: {'train_loss': '1.38629'}; time used = 5.885424613952637s
epoch 400: {'train_loss': '1.38629'}; time used = 5.827637672424316s
epoch 405: {'train_loss': '1.38629'}; time used = 5.756145000457764s
epoch 410: {'train_loss': '1.38629'}; time used = 6.303631067276001s
epoch 415: {'train_loss': '1.38629'}; time used = 6.006953239440918s
epoch 420: {'train_loss': '1.38629'}; time used = 6.012311697006226s
epoch 425: {'train_loss': '1.38629'}; time used = 7.021090030670166s
epoch 430: {'train_loss': '1.38629'}; time used = 8.618669033050537s
epoch 435: {'train_loss': '1.38629'}; time used = 5.927965402603149s
epoch 440: {'train_loss': '1.38629'}; time used = 5.8671252727508545s
epoch 445: {'train_loss': '1.38629'}; time used = 5.912375211715698s
epoch 450: {'train_loss': '1.38629'}; time used = 6.282152891159058s
epoch 455: {'train_loss': '1.38629'}; time used = 6.510445833206177s
epoch 460: {'train_loss': '1.38629'}; time used = 10.892854928970337s
epoch 465: {'train_loss': '1.38629'}; time used = 6.7661919593811035s
epoch 470: {'train_loss': '1.38629'}; time used = 6.7846410274505615s
epoch 475: {'train_loss': '1.38629'}; time used = 6.653681993484497s
epoch 480: {'train_loss': '1.38629'}; time used = 7.2942116260528564s
epoch 485: {'train_loss': '1.38629'}; time used = 7.197046756744385s
epoch 490: {'train_loss': '1.38629'}; time used = 6.724388360977173s
epoch 495: {'train_loss': '1.38629'}; time used = 6.074089765548706s
epoch 500: {'train_loss': '1.38629'}; time used = 6.087170124053955s
Finished training. Time used = 668.062497138977.
Training classifier using 80.00% nodes...
{'micro': 0.32666666666666666, 'macro': 0.18259451161005566, 'samples': 0.32666666666666666, 'weighted': 0.17711667626175395, 'accuracy': 0.32666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.360113859176636s
epoch 10: {'train_loss': '1.38629'}; time used = 4.120979309082031s
epoch 15: {'train_loss': '1.38629'}; time used = 4.869704961776733s
epoch 20: {'train_loss': '1.38629'}; time used = 4.6704652309417725s
epoch 25: {'train_loss': '1.38629'}; time used = 4.420669794082642s
epoch 30: {'train_loss': '1.38629'}; time used = 4.527280330657959s
epoch 35: {'train_loss': '1.38629'}; time used = 4.317593812942505s
epoch 40: {'train_loss': '1.38629'}; time used = 6.490420341491699s
epoch 45: {'train_loss': '1.38629'}; time used = 4.955633163452148s
epoch 50: {'train_loss': '1.38629'}; time used = 4.58020806312561s
epoch 55: {'train_loss': '1.38629'}; time used = 4.409832715988159s
epoch 60: {'train_loss': '1.38629'}; time used = 4.390859127044678s
epoch 65: {'train_loss': '1.38629'}; time used = 4.2124717235565186s
epoch 70: {'train_loss': '1.38629'}; time used = 4.012068033218384s
epoch 75: {'train_loss': '1.38629'}; time used = 4.022773265838623s
epoch 80: {'train_loss': '1.38629'}; time used = 4.404135465621948s
epoch 85: {'train_loss': '1.38629'}; time used = 4.211858034133911s
epoch 90: {'train_loss': '1.38629'}; time used = 4.439760684967041s
epoch 95: {'train_loss': '1.38629'}; time used = 4.059860467910767s
epoch 100: {'train_loss': '1.38629'}; time used = 4.064903736114502s
epoch 105: {'train_loss': '1.38629'}; time used = 3.9686853885650635s
epoch 110: {'train_loss': '1.38629'}; time used = 4.094482183456421s
epoch 115: {'train_loss': '1.38629'}; time used = 4.339514493942261s
epoch 120: {'train_loss': '1.38629'}; time used = 4.172326564788818s
epoch 125: {'train_loss': '1.38629'}; time used = 4.55634331703186s
epoch 130: {'train_loss': '1.38629'}; time used = 4.19655966758728s
epoch 135: {'train_loss': '1.38629'}; time used = 4.218968391418457s
epoch 140: {'train_loss': '1.38629'}; time used = 4.3067710399627686s
epoch 145: {'train_loss': '1.38629'}; time used = 4.185483455657959s
epoch 150: {'train_loss': '1.38629'}; time used = 4.396987676620483s
epoch 155: {'train_loss': '1.38629'}; time used = 4.150451898574829s
epoch 160: {'train_loss': '1.38629'}; time used = 4.231004476547241s
epoch 165: {'train_loss': '1.38629'}; time used = 4.238816261291504s
epoch 170: {'train_loss': '1.38629'}; time used = 4.305018663406372s
epoch 175: {'train_loss': '1.38629'}; time used = 4.277604103088379s
epoch 180: {'train_loss': '1.38629'}; time used = 5.118499994277954s
epoch 185: {'train_loss': '1.38629'}; time used = 6.8759777545928955s
epoch 190: {'train_loss': '1.38629'}; time used = 5.521838665008545s
epoch 195: {'train_loss': '1.38629'}; time used = 4.623024940490723s
epoch 200: {'train_loss': '1.38629'}; time used = 5.068936586380005s
epoch 205: {'train_loss': '1.38629'}; time used = 6.75873875617981s
epoch 210: {'train_loss': '1.38629'}; time used = 4.680782079696655s
epoch 215: {'train_loss': '1.38629'}; time used = 4.474528074264526s
epoch 220: {'train_loss': '1.38629'}; time used = 4.309155702590942s
epoch 225: {'train_loss': '1.38629'}; time used = 4.209491014480591s
epoch 230: {'train_loss': '1.38629'}; time used = 4.471817493438721s
epoch 235: {'train_loss': '1.38629'}; time used = 4.74284291267395s
epoch 240: {'train_loss': '1.38629'}; time used = 6.673466920852661s
epoch 245: {'train_loss': '1.38629'}; time used = 4.4654107093811035s
epoch 250: {'train_loss': '1.38629'}; time used = 4.359100818634033s
epoch 255: {'train_loss': '1.38629'}; time used = 4.235045671463013s
epoch 260: {'train_loss': '1.38629'}; time used = 6.727841854095459s
epoch 265: {'train_loss': '1.38629'}; time used = 5.2915496826171875s
epoch 270: {'train_loss': '1.38629'}; time used = 4.317014217376709s
epoch 275: {'train_loss': '1.38629'}; time used = 4.449777364730835s
epoch 280: {'train_loss': '1.38629'}; time used = 4.461323976516724s
epoch 285: {'train_loss': '1.38629'}; time used = 4.080177545547485s
epoch 290: {'train_loss': '1.38629'}; time used = 4.222652912139893s
epoch 295: {'train_loss': '1.38629'}; time used = 4.105315446853638s
epoch 300: {'train_loss': '1.38629'}; time used = 4.154055118560791s
epoch 305: {'train_loss': '1.38629'}; time used = 4.221893072128296s
epoch 310: {'train_loss': '1.38629'}; time used = 4.216865301132202s
epoch 315: {'train_loss': '1.38629'}; time used = 4.0851593017578125s
epoch 320: {'train_loss': '1.38629'}; time used = 4.041065216064453s
epoch 325: {'train_loss': '1.38629'}; time used = 4.698683261871338s
epoch 330: {'train_loss': '1.38629'}; time used = 3.9604296684265137s
epoch 335: {'train_loss': '1.38629'}; time used = 4.256955623626709s
epoch 340: {'train_loss': '1.38629'}; time used = 4.2838311195373535s
epoch 345: {'train_loss': '1.38629'}; time used = 4.014754056930542s
epoch 350: {'train_loss': '1.38629'}; time used = 4.146691799163818s
epoch 355: {'train_loss': '1.38629'}; time used = 5.130401372909546s
epoch 360: {'train_loss': '1.38629'}; time used = 4.313124418258667s
epoch 365: {'train_loss': '1.38629'}; time used = 4.441587209701538s
epoch 370: {'train_loss': '1.38629'}; time used = 3.8329644203186035s
epoch 375: {'train_loss': '1.38629'}; time used = 4.046403884887695s
epoch 380: {'train_loss': '1.38629'}; time used = 4.113370180130005s
epoch 385: {'train_loss': '1.38629'}; time used = 4.156402587890625s
epoch 390: {'train_loss': '1.38629'}; time used = 4.307164907455444s
epoch 395: {'train_loss': '1.38629'}; time used = 4.1371142864227295s
epoch 400: {'train_loss': '1.38629'}; time used = 4.123964071273804s
epoch 405: {'train_loss': '1.38629'}; time used = 4.260424613952637s
epoch 410: {'train_loss': '1.38629'}; time used = 4.19278883934021s
epoch 415: {'train_loss': '1.38629'}; time used = 4.875377416610718s
epoch 420: {'train_loss': '1.38629'}; time used = 6.769725799560547s
epoch 425: {'train_loss': '1.38629'}; time used = 4.71800684928894s
epoch 430: {'train_loss': '1.38629'}; time used = 4.57875394821167s
epoch 435: {'train_loss': '1.38629'}; time used = 4.034848928451538s
epoch 440: {'train_loss': '1.38629'}; time used = 3.9769463539123535s
epoch 445: {'train_loss': '1.38629'}; time used = 4.32068133354187s
epoch 450: {'train_loss': '1.38629'}; time used = 4.082478761672974s
epoch 455: {'train_loss': '1.38629'}; time used = 4.200912714004517s
epoch 460: {'train_loss': '1.38629'}; time used = 4.200896263122559s
epoch 465: {'train_loss': '1.38629'}; time used = 4.205384016036987s
epoch 470: {'train_loss': '1.38629'}; time used = 6.281427383422852s
epoch 475: {'train_loss': '1.38629'}; time used = 4.316836357116699s
epoch 480: {'train_loss': '1.38629'}; time used = 4.2857770919799805s
epoch 485: {'train_loss': '1.38629'}; time used = 7.1253578662872314s
epoch 490: {'train_loss': '1.38629'}; time used = 5.323891639709473s
epoch 495: {'train_loss': '1.38629'}; time used = 4.246453523635864s
epoch 500: {'train_loss': '1.38629'}; time used = 4.719639301300049s
Finished training. Time used = 464.2371816635132.
Training classifier using 80.00% nodes...
{'micro': 0.625, 'macro': 0.6190476190476191, 'samples': 0.625, 'weighted': 0.6180952380952381, 'accuracy': 0.625}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37637'}; time used = 1.2659621238708496s
epoch 10: {'train_loss': '1.35431'}; time used = 1.125568151473999s
epoch 15: {'train_loss': '1.27429'}; time used = 1.1224730014801025s
epoch 20: {'train_loss': '1.27044'}; time used = 1.130662441253662s
epoch 25: {'train_loss': '1.08872'}; time used = 1.1526963710784912s
epoch 30: {'train_loss': '1.23114'}; time used = 1.1025631427764893s
epoch 35: {'train_loss': '1.28043'}; time used = 1.1322143077850342s
epoch 40: {'train_loss': '1.23773'}; time used = 1.1935687065124512s
epoch 45: {'train_loss': '1.07266'}; time used = 1.1354100704193115s
epoch 50: {'train_loss': '1.18664'}; time used = 1.1650843620300293s
epoch 55: {'train_loss': '1.24351'}; time used = 1.1229748725891113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.80634832382202.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.28662'}; time used = 1.16011643409729s
epoch 10: {'train_loss': '1.47609'}; time used = 1.0258841514587402s
epoch 15: {'train_loss': '0.88482'}; time used = 1.0832087993621826s
epoch 20: {'train_loss': '0.73272'}; time used = 1.1902682781219482s
epoch 25: {'train_loss': '0.13307'}; time used = 0.9794418811798096s
epoch 30: {'train_loss': '0.24087'}; time used = 0.9903218746185303s
epoch 35: {'train_loss': '0.18772'}; time used = 1.0030920505523682s
epoch 40: {'train_loss': '0.16412'}; time used = 1.17171049118042s
epoch 45: {'train_loss': '0.04465'}; time used = 1.0301554203033447s
epoch 50: {'train_loss': '0.04283'}; time used = 1.0866773128509521s
epoch 55: {'train_loss': '0.00667'}; time used = 1.005401372909546s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.778622150421143.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92185'}; time used = 1.2583346366882324s
epoch 10: {'train_loss': '2.77940'}; time used = 0.8941094875335693s
epoch 15: {'train_loss': '2.66989'}; time used = 1.0241689682006836s
epoch 20: {'train_loss': '2.56077'}; time used = 0.9486987590789795s
epoch 25: {'train_loss': '2.38954'}; time used = 1.025644063949585s
epoch 30: {'train_loss': '2.14524'}; time used = 1.1071128845214844s
epoch 35: {'train_loss': '1.99034'}; time used = 0.9604861736297607s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.695986986160278.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.56159'}; time used = 1.287536859512329s
epoch 10: {'train_loss': '0.38356'}; time used = 1.1711010932922363s
epoch 15: {'train_loss': '0.22925'}; time used = 1.125408411026001s
epoch 20: {'train_loss': '0.11452'}; time used = 1.1493704319000244s
epoch 25: {'train_loss': '0.12714'}; time used = 1.1910150051116943s
epoch 30: {'train_loss': '0.07333'}; time used = 1.1867260932922363s
epoch 35: {'train_loss': '0.06975'}; time used = 1.2319366931915283s
epoch 40: {'train_loss': '0.07280'}; time used = 1.185720682144165s
epoch 45: {'train_loss': '0.05595'}; time used = 1.1686348915100098s
epoch 50: {'train_loss': '0.05480'}; time used = 1.3287861347198486s
epoch 55: {'train_loss': '0.03306'}; time used = 1.294600009918213s
epoch 60: {'train_loss': '0.00931'}; time used = 1.2107737064361572s
epoch 65: {'train_loss': '0.02619'}; time used = 1.040083408355713s
epoch 70: {'train_loss': '0.01868'}; time used = 1.1299619674682617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.267013788223267.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.92334'}; time used = 1.8523123264312744s
epoch 10: {'train_loss': '2.76998'}; time used = 1.7738409042358398s
epoch 15: {'train_loss': '2.76364'}; time used = 1.7730298042297363s
epoch 20: {'train_loss': '2.75545'}; time used = 1.8005869388580322s
epoch 25: {'train_loss': '2.73716'}; time used = 2.0666067600250244s
epoch 30: {'train_loss': '2.71490'}; time used = 1.9286019802093506s
epoch 35: {'train_loss': '2.67756'}; time used = 1.8125929832458496s
epoch 40: {'train_loss': '2.60332'}; time used = 1.9259727001190186s
epoch 45: {'train_loss': '2.50883'}; time used = 1.784409999847412s
epoch 50: {'train_loss': '2.47238'}; time used = 2.0617947578430176s
epoch 55: {'train_loss': '2.45007'}; time used = 3.197716236114502s
epoch 60: {'train_loss': '2.43912'}; time used = 3.1047189235687256s
epoch 65: {'train_loss': '2.44425'}; time used = 2.1813607215881348s
epoch 70: {'train_loss': '2.39077'}; time used = 1.8526654243469238s
epoch 75: {'train_loss': '2.38083'}; time used = 1.7290849685668945s
epoch 80: {'train_loss': '2.36379'}; time used = 1.8021225929260254s
epoch 85: {'train_loss': '2.44955'}; time used = 1.72222900390625s
epoch 90: {'train_loss': '2.42865'}; time used = 1.7141978740692139s
epoch 95: {'train_loss': '2.40752'}; time used = 1.7055087089538574s
epoch 100: {'train_loss': '2.38145'}; time used = 1.7817785739898682s
epoch 105: {'train_loss': '2.35814'}; time used = 1.792029857635498s
epoch 110: {'train_loss': '2.35666'}; time used = 1.9135112762451172s
epoch 115: {'train_loss': '2.36584'}; time used = 1.7706658840179443s
epoch 120: {'train_loss': '2.34197'}; time used = 1.9218146800994873s
epoch 125: {'train_loss': '2.34069'}; time used = 1.8822638988494873s
epoch 130: {'train_loss': '2.33722'}; time used = 1.8050520420074463s
epoch 135: {'train_loss': '2.35166'}; time used = 1.8310105800628662s
epoch 140: {'train_loss': '2.34160'}; time used = 2.0115437507629395s
epoch 145: {'train_loss': '2.33866'}; time used = 1.7902746200561523s
epoch 150: {'train_loss': '2.32427'}; time used = 2.7615649700164795s
epoch 155: {'train_loss': '2.31631'}; time used = 3.2597429752349854s
epoch 160: {'train_loss': '2.32742'}; time used = 3.2233383655548096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 69.95087695121765.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5871794871794872, 'samples': 0.5942028985507246, 'weighted': 0.5910813823857303, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84634'}; time used = 2.530266523361206s
epoch 10: {'train_loss': '2.77286'}; time used = 2.47619366645813s
epoch 15: {'train_loss': '2.78452'}; time used = 2.580272912979126s
epoch 20: {'train_loss': '2.78321'}; time used = 2.545748233795166s
epoch 25: {'train_loss': '2.77270'}; time used = 2.5572381019592285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.702362298965454.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6086956521739131, 'samples': 0.6521739130434783, 'weighted': 0.618147448015123, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90277'}; time used = 1.7526037693023682s
epoch 10: {'train_loss': '2.79521'}; time used = 1.5726430416107178s
epoch 15: {'train_loss': '2.77093'}; time used = 3.7044668197631836s
epoch 20: {'train_loss': '2.75614'}; time used = 1.7337141036987305s
epoch 25: {'train_loss': '2.75043'}; time used = 1.8087570667266846s
epoch 30: {'train_loss': '2.74652'}; time used = 1.5538806915283203s
epoch 35: {'train_loss': '2.74089'}; time used = 1.5891058444976807s
epoch 40: {'train_loss': '2.73098'}; time used = 1.6233727931976318s
epoch 45: {'train_loss': '2.72202'}; time used = 1.634068489074707s
epoch 50: {'train_loss': '2.71510'}; time used = 1.6346502304077148s
epoch 55: {'train_loss': '2.71506'}; time used = 1.7177913188934326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.949965476989746.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5473015873015873, 'samples': 0.5507246376811594, 'weighted': 0.550154129284564, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.26 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.355717658996582s
epoch 10: {'train_loss': '1.38629'}; time used = 6.102766036987305s
epoch 15: {'train_loss': '1.38629'}; time used = 8.0583016872406s
epoch 20: {'train_loss': '1.38629'}; time used = 7.789322137832642s
epoch 25: {'train_loss': '1.38629'}; time used = 6.265839338302612s
epoch 30: {'train_loss': '1.38629'}; time used = 9.93270206451416s
epoch 35: {'train_loss': '1.38629'}; time used = 6.543695688247681s
epoch 40: {'train_loss': '1.38629'}; time used = 6.389470100402832s
epoch 45: {'train_loss': '1.38629'}; time used = 7.852850914001465s
epoch 50: {'train_loss': '1.38629'}; time used = 6.387616157531738s
epoch 55: {'train_loss': '1.38629'}; time used = 6.086601972579956s
epoch 60: {'train_loss': '1.38629'}; time used = 6.23048996925354s
epoch 65: {'train_loss': '1.38629'}; time used = 6.631134748458862s
epoch 70: {'train_loss': '1.38629'}; time used = 6.408859968185425s
epoch 75: {'train_loss': '1.38629'}; time used = 6.2947728633880615s
epoch 80: {'train_loss': '1.38629'}; time used = 9.962386846542358s
epoch 85: {'train_loss': '1.38629'}; time used = 6.246721029281616s
epoch 90: {'train_loss': '1.38629'}; time used = 6.255706548690796s
epoch 95: {'train_loss': '1.38629'}; time used = 6.0950376987457275s
epoch 100: {'train_loss': '1.38629'}; time used = 6.43034553527832s
epoch 105: {'train_loss': '1.38629'}; time used = 6.232746362686157s
epoch 110: {'train_loss': '1.38629'}; time used = 6.2921061515808105s
epoch 115: {'train_loss': '1.38629'}; time used = 6.736323595046997s
epoch 120: {'train_loss': '1.38629'}; time used = 6.151045322418213s
epoch 125: {'train_loss': '1.38629'}; time used = 6.156662464141846s
epoch 130: {'train_loss': '1.38629'}; time used = 6.102730989456177s
epoch 135: {'train_loss': '1.38629'}; time used = 6.343029260635376s
epoch 140: {'train_loss': '1.38629'}; time used = 6.362884283065796s
epoch 145: {'train_loss': '1.38629'}; time used = 9.054816007614136s
epoch 150: {'train_loss': '1.38629'}; time used = 7.353694438934326s
epoch 155: {'train_loss': '1.38629'}; time used = 6.132232189178467s
epoch 160: {'train_loss': '1.38629'}; time used = 9.128051280975342s
epoch 165: {'train_loss': '1.38629'}; time used = 6.832427978515625s
epoch 170: {'train_loss': '1.38629'}; time used = 6.363550662994385s
epoch 175: {'train_loss': '1.38629'}; time used = 10.014271974563599s
epoch 180: {'train_loss': '1.38629'}; time used = 6.8413169384002686s
epoch 185: {'train_loss': '1.38629'}; time used = 6.201290607452393s
epoch 190: {'train_loss': '1.38629'}; time used = 6.447236776351929s
epoch 195: {'train_loss': '1.38629'}; time used = 6.194895029067993s
epoch 200: {'train_loss': '1.38629'}; time used = 7.304513692855835s
epoch 205: {'train_loss': '1.38629'}; time used = 6.517293214797974s
epoch 210: {'train_loss': '1.38629'}; time used = 6.179692029953003s
epoch 215: {'train_loss': '1.38629'}; time used = 6.223599195480347s
epoch 220: {'train_loss': '1.38629'}; time used = 6.411228895187378s
epoch 225: {'train_loss': '1.38629'}; time used = 6.191202163696289s
epoch 230: {'train_loss': '1.38629'}; time used = 6.2911696434021s
epoch 235: {'train_loss': '1.38629'}; time used = 6.102670907974243s
epoch 240: {'train_loss': '1.38629'}; time used = 6.1835081577301025s
epoch 245: {'train_loss': '1.38629'}; time used = 6.189797878265381s
epoch 250: {'train_loss': '1.38629'}; time used = 6.039937973022461s
epoch 255: {'train_loss': '1.38629'}; time used = 6.105343818664551s
epoch 260: {'train_loss': '1.38629'}; time used = 6.081221580505371s
epoch 265: {'train_loss': '1.38629'}; time used = 6.034667491912842s
epoch 270: {'train_loss': '1.38629'}; time used = 6.1824963092803955s
epoch 275: {'train_loss': '1.38629'}; time used = 6.934341669082642s
epoch 280: {'train_loss': '1.38629'}; time used = 6.128049373626709s
epoch 285: {'train_loss': '1.38629'}; time used = 6.157958745956421s
epoch 290: {'train_loss': '1.38629'}; time used = 6.157257556915283s
epoch 295: {'train_loss': '1.38629'}; time used = 6.1479692459106445s
epoch 300: {'train_loss': '1.38629'}; time used = 9.839356899261475s
epoch 305: {'train_loss': '1.38629'}; time used = 6.729264497756958s
epoch 310: {'train_loss': '1.38629'}; time used = 6.448268175125122s
epoch 315: {'train_loss': '1.38629'}; time used = 6.171954870223999s
epoch 320: {'train_loss': '1.38629'}; time used = 6.254437446594238s
epoch 325: {'train_loss': '1.38629'}; time used = 6.342151641845703s
epoch 330: {'train_loss': '1.38629'}; time used = 6.672479629516602s
epoch 335: {'train_loss': '1.38629'}; time used = 6.222347974777222s
epoch 340: {'train_loss': '1.38629'}; time used = 6.109501600265503s
epoch 345: {'train_loss': '1.38629'}; time used = 7.472926139831543s
epoch 350: {'train_loss': '1.38629'}; time used = 6.287236452102661s
epoch 355: {'train_loss': '1.38629'}; time used = 6.202357530593872s
epoch 360: {'train_loss': '1.38629'}; time used = 6.519298315048218s
epoch 365: {'train_loss': '1.38629'}; time used = 6.106676340103149s
epoch 370: {'train_loss': '1.38629'}; time used = 6.407300710678101s
epoch 375: {'train_loss': '1.38629'}; time used = 6.678384780883789s
epoch 380: {'train_loss': '1.38629'}; time used = 9.565598487854004s
epoch 385: {'train_loss': '1.38629'}; time used = 6.32261061668396s
epoch 390: {'train_loss': '1.38629'}; time used = 6.351215124130249s
epoch 395: {'train_loss': '1.38629'}; time used = 6.391075849533081s
epoch 400: {'train_loss': '1.38629'}; time used = 6.2684690952301025s
epoch 405: {'train_loss': '1.38629'}; time used = 6.151626348495483s
epoch 410: {'train_loss': '1.38629'}; time used = 6.114519834518433s
epoch 415: {'train_loss': '1.38629'}; time used = 6.1666553020477295s
epoch 420: {'train_loss': '1.38629'}; time used = 6.191250324249268s
epoch 425: {'train_loss': '1.38629'}; time used = 6.102057933807373s
epoch 430: {'train_loss': '1.38629'}; time used = 6.02715277671814s
epoch 435: {'train_loss': '1.38629'}; time used = 6.03202223777771s
epoch 440: {'train_loss': '1.38629'}; time used = 6.463369846343994s
epoch 445: {'train_loss': '1.38629'}; time used = 6.358666181564331s
epoch 450: {'train_loss': '1.38629'}; time used = 6.137152910232544s
epoch 455: {'train_loss': '1.38629'}; time used = 8.641650199890137s
epoch 460: {'train_loss': '1.38629'}; time used = 7.697066307067871s
epoch 465: {'train_loss': '1.38629'}; time used = 6.868983745574951s
epoch 470: {'train_loss': '1.38629'}; time used = 6.30320930480957s
epoch 475: {'train_loss': '1.38629'}; time used = 6.15821647644043s
epoch 480: {'train_loss': '1.38629'}; time used = 6.586361646652222s
epoch 485: {'train_loss': '1.38629'}; time used = 6.280241250991821s
epoch 490: {'train_loss': '1.38629'}; time used = 6.4422619342803955s
epoch 495: {'train_loss': '1.38629'}; time used = 6.144093751907349s
epoch 500: {'train_loss': '1.38629'}; time used = 6.122416019439697s
Finished training. Time used = 672.989529132843.
Training classifier using 80.00% nodes...
{'micro': 0.49, 'macro': 0.4512628096506092, 'samples': 0.49, 'weighted': 0.44390139594932615, 'accuracy': 0.49}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35200'}; time used = 1.4735157489776611s
epoch 10: {'train_loss': '1.28705'}; time used = 1.3135278224945068s
epoch 15: {'train_loss': '0.88087'}; time used = 1.4577383995056152s
epoch 20: {'train_loss': '0.92344'}; time used = 1.31736159324646s
epoch 25: {'train_loss': '0.22901'}; time used = 1.3071057796478271s
epoch 30: {'train_loss': '0.21444'}; time used = 1.4491479396820068s
epoch 35: {'train_loss': '0.17523'}; time used = 1.4238612651824951s
epoch 40: {'train_loss': '0.34534'}; time used = 1.3307528495788574s
epoch 45: {'train_loss': '0.03729'}; time used = 1.3769268989562988s
epoch 50: {'train_loss': '0.01849'}; time used = 1.3643639087677002s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.70071792602539.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.26327'}; time used = 1.6230964660644531s
epoch 10: {'train_loss': '1.13159'}; time used = 1.559044599533081s
epoch 15: {'train_loss': '0.98224'}; time used = 1.6182022094726562s
epoch 20: {'train_loss': '0.92522'}; time used = 1.6713132858276367s
epoch 25: {'train_loss': '0.85927'}; time used = 1.7339394092559814s
epoch 30: {'train_loss': '0.80303'}; time used = 1.4935510158538818s
epoch 35: {'train_loss': '0.77291'}; time used = 1.7081408500671387s
epoch 40: {'train_loss': '0.72248'}; time used = 1.5508527755737305s
epoch 45: {'train_loss': '0.63729'}; time used = 1.934493064880371s
epoch 50: {'train_loss': '0.37333'}; time used = 2.92901349067688s
epoch 55: {'train_loss': '0.16888'}; time used = 2.9909865856170654s
epoch 60: {'train_loss': '0.07770'}; time used = 2.902230978012085s
epoch 65: {'train_loss': '0.07173'}; time used = 1.5981097221374512s
epoch 70: {'train_loss': '0.04928'}; time used = 1.6968142986297607s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.906658411026.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81332'}; time used = 1.9491968154907227s
epoch 10: {'train_loss': '2.57135'}; time used = 2.5861856937408447s
epoch 15: {'train_loss': '1.96089'}; time used = 1.1756114959716797s
epoch 20: {'train_loss': '1.75094'}; time used = 1.1793551445007324s
epoch 25: {'train_loss': '1.56447'}; time used = 1.200885534286499s
epoch 30: {'train_loss': '1.47576'}; time used = 1.2353451251983643s
epoch 35: {'train_loss': '1.42951'}; time used = 1.1502296924591064s
epoch 40: {'train_loss': '1.68376'}; time used = 1.0750701427459717s
epoch 45: {'train_loss': '1.48240'}; time used = 1.0740203857421875s
epoch 50: {'train_loss': '1.27181'}; time used = 1.0501658916473389s
epoch 55: {'train_loss': '1.25471'}; time used = 1.2645108699798584s
epoch 60: {'train_loss': '1.19304'}; time used = 1.1471407413482666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.555447578430176.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36022'}; time used = 1.9699177742004395s
epoch 10: {'train_loss': '1.28608'}; time used = 1.9122629165649414s
epoch 15: {'train_loss': '1.28740'}; time used = 1.7776167392730713s
epoch 20: {'train_loss': '1.34145'}; time used = 1.8834195137023926s
epoch 25: {'train_loss': '1.30629'}; time used = 1.8345444202423096s
epoch 30: {'train_loss': '1.22176'}; time used = 1.71177339553833s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.42366051673889.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79972'}; time used = 2.4094855785369873s
epoch 10: {'train_loss': '2.76849'}; time used = 2.3592562675476074s
epoch 15: {'train_loss': '2.75878'}; time used = 2.24098539352417s
epoch 20: {'train_loss': '2.73918'}; time used = 2.4648261070251465s
epoch 25: {'train_loss': '2.71626'}; time used = 2.363295316696167s
epoch 30: {'train_loss': '2.68554'}; time used = 2.470620632171631s
epoch 35: {'train_loss': '2.64642'}; time used = 2.5284059047698975s
epoch 40: {'train_loss': '2.64693'}; time used = 2.256157159805298s
epoch 45: {'train_loss': '2.61682'}; time used = 2.397531270980835s
epoch 50: {'train_loss': '2.57892'}; time used = 2.3113150596618652s
epoch 55: {'train_loss': '2.53468'}; time used = 2.289097309112549s
epoch 60: {'train_loss': '2.52294'}; time used = 2.3050999641418457s
epoch 65: {'train_loss': '2.46268'}; time used = 2.3786540031433105s
epoch 70: {'train_loss': '2.44901'}; time used = 3.35319447517395s
epoch 75: {'train_loss': '2.43417'}; time used = 3.2546167373657227s
epoch 80: {'train_loss': '2.40934'}; time used = 3.158925771713257s
epoch 85: {'train_loss': '2.42718'}; time used = 3.0114071369171143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.649988651275635.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.15383'}; time used = 1.6641509532928467s
epoch 10: {'train_loss': '0.45288'}; time used = 1.5111842155456543s
epoch 15: {'train_loss': '0.22148'}; time used = 1.5156614780426025s
epoch 20: {'train_loss': '0.31599'}; time used = 1.7508766651153564s
epoch 25: {'train_loss': '0.86477'}; time used = 1.6211717128753662s
epoch 30: {'train_loss': '0.28723'}; time used = 1.684295415878296s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.852135419845581.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77907'}; time used = 2.2920963764190674s
epoch 10: {'train_loss': '2.77262'}; time used = 1.9645328521728516s
epoch 15: {'train_loss': '2.77893'}; time used = 0.9396932125091553s
epoch 20: {'train_loss': '2.78020'}; time used = 0.9540534019470215s
epoch 25: {'train_loss': '2.77352'}; time used = 0.9845418930053711s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.837708473205566.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05031'}; time used = 1.8599140644073486s
epoch 10: {'train_loss': '2.82101'}; time used = 1.7227153778076172s
epoch 15: {'train_loss': '2.74434'}; time used = 1.9302654266357422s
epoch 20: {'train_loss': '2.74756'}; time used = 1.6937251091003418s
epoch 25: {'train_loss': '2.73596'}; time used = 1.7806596755981445s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.02701997756958.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.43949'}; time used = 2.0594701766967773s
epoch 10: {'train_loss': '0.26965'}; time used = 1.7583904266357422s
epoch 15: {'train_loss': '0.28920'}; time used = 1.7321958541870117s
epoch 20: {'train_loss': '0.26665'}; time used = 1.1184077262878418s
epoch 25: {'train_loss': '0.30384'}; time used = 0.9113497734069824s
epoch 30: {'train_loss': '0.24368'}; time used = 0.9159667491912842s
epoch 35: {'train_loss': '0.27754'}; time used = 0.9066715240478516s
epoch 40: {'train_loss': '0.21971'}; time used = 0.9105045795440674s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.813037157058716.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83847'}; time used = 1.4795949459075928s
epoch 10: {'train_loss': '2.80269'}; time used = 1.3360378742218018s
epoch 15: {'train_loss': '2.78988'}; time used = 1.2571399211883545s
epoch 20: {'train_loss': '2.78275'}; time used = 1.4325556755065918s
epoch 25: {'train_loss': '2.77671'}; time used = 1.4832322597503662s
epoch 30: {'train_loss': '2.77198'}; time used = 1.2225725650787354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.787534236907959.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83427'}; time used = 1.8697497844696045s
epoch 10: {'train_loss': '2.76012'}; time used = 1.661365270614624s
epoch 15: {'train_loss': '2.75160'}; time used = 1.6650326251983643s
epoch 20: {'train_loss': '2.73749'}; time used = 1.6585116386413574s
epoch 25: {'train_loss': '2.71292'}; time used = 1.7794218063354492s
epoch 30: {'train_loss': '2.65667'}; time used = 1.7818574905395508s
epoch 35: {'train_loss': '2.59486'}; time used = 1.7385663986206055s
epoch 40: {'train_loss': '2.54101'}; time used = 1.8819475173950195s
epoch 45: {'train_loss': '2.51356'}; time used = 1.6622087955474854s
epoch 50: {'train_loss': '2.48693'}; time used = 1.6057837009429932s
epoch 55: {'train_loss': '2.47844'}; time used = 1.6963157653808594s
epoch 60: {'train_loss': '2.46261'}; time used = 1.6487205028533936s
epoch 65: {'train_loss': '2.44483'}; time used = 1.6461029052734375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.994903802871704.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39810'}; time used = 1.5365145206451416s
epoch 10: {'train_loss': '1.45842'}; time used = 1.3801405429840088s
epoch 15: {'train_loss': '1.27182'}; time used = 2.406578540802002s
epoch 20: {'train_loss': '1.47370'}; time used = 2.406341552734375s
epoch 25: {'train_loss': '1.36661'}; time used = 2.605015516281128s
epoch 30: {'train_loss': '1.38829'}; time used = 2.2132961750030518s
epoch 35: {'train_loss': '1.38871'}; time used = 1.381251573562622s
epoch 40: {'train_loss': '1.35746'}; time used = 1.3704988956451416s
epoch 45: {'train_loss': '1.32204'}; time used = 1.401803970336914s
epoch 50: {'train_loss': '1.36186'}; time used = 1.5004422664642334s
epoch 55: {'train_loss': '1.35256'}; time used = 1.3201560974121094s
epoch 60: {'train_loss': '1.25258'}; time used = 1.327120065689087s
epoch 65: {'train_loss': '0.71657'}; time used = 1.3392925262451172s
epoch 70: {'train_loss': '0.75805'}; time used = 1.398542881011963s
epoch 75: {'train_loss': '0.17467'}; time used = 1.4297261238098145s
epoch 80: {'train_loss': '0.23451'}; time used = 1.4445669651031494s
epoch 85: {'train_loss': '0.29720'}; time used = 1.4314608573913574s
epoch 90: {'train_loss': '0.75433'}; time used = 1.3435559272766113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.949915647506714.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.483592510223389s
epoch 10: {'train_loss': '1.38629'}; time used = 4.428795099258423s
epoch 15: {'train_loss': '1.38629'}; time used = 7.241298675537109s
epoch 20: {'train_loss': '1.38629'}; time used = 5.618011236190796s
epoch 25: {'train_loss': '1.38629'}; time used = 4.517089128494263s
epoch 30: {'train_loss': '1.38629'}; time used = 5.145390033721924s
epoch 35: {'train_loss': '1.38629'}; time used = 8.062238454818726s
epoch 40: {'train_loss': '1.38629'}; time used = 4.473032474517822s
epoch 45: {'train_loss': '1.38629'}; time used = 4.165410280227661s
epoch 50: {'train_loss': '1.38629'}; time used = 4.500582695007324s
epoch 55: {'train_loss': '1.38629'}; time used = 4.419193744659424s
epoch 60: {'train_loss': '1.38629'}; time used = 4.55193305015564s
epoch 65: {'train_loss': '1.38629'}; time used = 4.479566812515259s
epoch 70: {'train_loss': '1.38629'}; time used = 4.459470272064209s
epoch 75: {'train_loss': '1.38629'}; time used = 4.597862243652344s
epoch 80: {'train_loss': '1.38629'}; time used = 4.586037635803223s
epoch 85: {'train_loss': '1.38629'}; time used = 4.510444641113281s
epoch 90: {'train_loss': '1.38629'}; time used = 4.5361199378967285s
epoch 95: {'train_loss': '1.38629'}; time used = 4.570242643356323s
epoch 100: {'train_loss': '1.38629'}; time used = 4.606990814208984s
epoch 105: {'train_loss': '1.38629'}; time used = 4.499411106109619s
epoch 110: {'train_loss': '1.38629'}; time used = 4.510323762893677s
epoch 115: {'train_loss': '1.38629'}; time used = 4.375356912612915s
epoch 120: {'train_loss': '1.38629'}; time used = 4.902495384216309s
epoch 125: {'train_loss': '1.38629'}; time used = 4.478574991226196s
epoch 130: {'train_loss': '1.38629'}; time used = 4.524080514907837s
epoch 135: {'train_loss': '1.38629'}; time used = 4.195637226104736s
epoch 140: {'train_loss': '1.38629'}; time used = 4.5666773319244385s
epoch 145: {'train_loss': '1.38629'}; time used = 4.908099174499512s
epoch 150: {'train_loss': '1.38629'}; time used = 4.0307581424713135s
epoch 155: {'train_loss': '1.38629'}; time used = 4.087102890014648s
epoch 160: {'train_loss': '1.38629'}; time used = 4.037125587463379s
epoch 165: {'train_loss': '1.38629'}; time used = 4.088136434555054s
epoch 170: {'train_loss': '1.38629'}; time used = 4.87825870513916s
epoch 175: {'train_loss': '1.38629'}; time used = 4.667762994766235s
epoch 180: {'train_loss': '1.38629'}; time used = 4.184250831604004s
epoch 185: {'train_loss': '1.38629'}; time used = 4.240569591522217s
epoch 190: {'train_loss': '1.38629'}; time used = 4.09216570854187s
epoch 195: {'train_loss': '1.38629'}; time used = 3.9440534114837646s
epoch 200: {'train_loss': '1.38629'}; time used = 4.0698065757751465s
epoch 205: {'train_loss': '1.38629'}; time used = 4.057888746261597s
epoch 210: {'train_loss': '1.38629'}; time used = 4.039360523223877s
epoch 215: {'train_loss': '1.38629'}; time used = 3.9886653423309326s
epoch 220: {'train_loss': '1.38629'}; time used = 4.022196054458618s
epoch 225: {'train_loss': '1.38629'}; time used = 4.980247974395752s
epoch 230: {'train_loss': '1.38629'}; time used = 4.499913454055786s
epoch 235: {'train_loss': '1.38629'}; time used = 4.087298631668091s
epoch 240: {'train_loss': '1.38629'}; time used = 4.148046493530273s
epoch 245: {'train_loss': '1.38629'}; time used = 4.126986742019653s
epoch 250: {'train_loss': '1.38629'}; time used = 3.980792284011841s
epoch 255: {'train_loss': '1.38629'}; time used = 3.954010248184204s
epoch 260: {'train_loss': '1.38629'}; time used = 4.035588979721069s
epoch 265: {'train_loss': '1.38629'}; time used = 4.049347639083862s
epoch 270: {'train_loss': '1.38629'}; time used = 4.121737241744995s
epoch 275: {'train_loss': '1.38629'}; time used = 4.024004220962524s
epoch 280: {'train_loss': '1.38629'}; time used = 3.976562738418579s
epoch 285: {'train_loss': '1.38629'}; time used = 4.078319787979126s
epoch 290: {'train_loss': '1.38629'}; time used = 3.9653520584106445s
epoch 295: {'train_loss': '1.38629'}; time used = 4.08962082862854s
epoch 300: {'train_loss': '1.38629'}; time used = 4.141772747039795s
epoch 305: {'train_loss': '1.38629'}; time used = 4.015131950378418s
epoch 310: {'train_loss': '1.38629'}; time used = 4.1551642417907715s
epoch 315: {'train_loss': '1.38629'}; time used = 4.051501274108887s
epoch 320: {'train_loss': '1.38629'}; time used = 4.007206439971924s
epoch 325: {'train_loss': '1.38629'}; time used = 4.126176357269287s
epoch 330: {'train_loss': '1.38629'}; time used = 4.00365948677063s
epoch 335: {'train_loss': '1.38629'}; time used = 4.033265829086304s
epoch 340: {'train_loss': '1.38629'}; time used = 4.0432658195495605s
epoch 345: {'train_loss': '1.38629'}; time used = 4.0227460861206055s
epoch 350: {'train_loss': '1.38629'}; time used = 4.126340627670288s
epoch 355: {'train_loss': '1.38629'}; time used = 3.9688496589660645s
epoch 360: {'train_loss': '1.38629'}; time used = 4.05773138999939s
epoch 365: {'train_loss': '1.38629'}; time used = 4.0879223346710205s
epoch 370: {'train_loss': '1.38629'}; time used = 3.974001407623291s
epoch 375: {'train_loss': '1.38629'}; time used = 4.978985071182251s
epoch 380: {'train_loss': '1.38629'}; time used = 4.365740060806274s
epoch 385: {'train_loss': '1.38629'}; time used = 4.045713663101196s
epoch 390: {'train_loss': '1.38629'}; time used = 4.077796220779419s
epoch 395: {'train_loss': '1.38629'}; time used = 4.124643802642822s
epoch 400: {'train_loss': '1.38629'}; time used = 4.044867515563965s
epoch 405: {'train_loss': '1.38629'}; time used = 4.144277095794678s
epoch 410: {'train_loss': '1.38629'}; time used = 4.058026313781738s
epoch 415: {'train_loss': '1.38629'}; time used = 4.106796026229858s
epoch 420: {'train_loss': '1.38629'}; time used = 4.010394334793091s
epoch 425: {'train_loss': '1.38629'}; time used = 3.9576127529144287s
epoch 430: {'train_loss': '1.38629'}; time used = 4.054670810699463s
epoch 435: {'train_loss': '1.38629'}; time used = 4.078796625137329s
epoch 440: {'train_loss': '1.38629'}; time used = 3.951390266418457s
epoch 445: {'train_loss': '1.38629'}; time used = 4.003226280212402s
epoch 450: {'train_loss': '1.38629'}; time used = 3.9857497215270996s
epoch 455: {'train_loss': '1.38629'}; time used = 4.184232234954834s
epoch 460: {'train_loss': '1.38629'}; time used = 4.19737982749939s
epoch 465: {'train_loss': '1.38629'}; time used = 4.015822172164917s
epoch 470: {'train_loss': '1.38629'}; time used = 4.054647207260132s
epoch 475: {'train_loss': '1.38629'}; time used = 4.002629041671753s
epoch 480: {'train_loss': '1.38629'}; time used = 4.097871541976929s
epoch 485: {'train_loss': '1.38629'}; time used = 4.143092393875122s
epoch 490: {'train_loss': '1.38629'}; time used = 4.251017093658447s
epoch 495: {'train_loss': '1.38629'}; time used = 6.823807716369629s
epoch 500: {'train_loss': '1.38629'}; time used = 5.271517515182495s
Finished training. Time used = 443.06621289253235.
Training classifier using 80.00% nodes...
{'micro': 0.63, 'macro': 0.6262626262626263, 'samples': 0.63, 'weighted': 0.6255151515151515, 'accuracy': 0.63}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.24207'}; time used = 1.1474943161010742s
epoch 10: {'train_loss': '2.77308'}; time used = 1.2825212478637695s
epoch 15: {'train_loss': '2.76376'}; time used = 1.4203839302062988s
epoch 20: {'train_loss': '2.73999'}; time used = 1.8098177909851074s
epoch 25: {'train_loss': '2.69393'}; time used = 1.8599271774291992s
epoch 30: {'train_loss': '2.58740'}; time used = 2.0166032314300537s
epoch 35: {'train_loss': '2.32533'}; time used = 1.909120798110962s
epoch 40: {'train_loss': '2.25445'}; time used = 1.8826000690460205s
epoch 45: {'train_loss': '2.04637'}; time used = 1.3475935459136963s
epoch 50: {'train_loss': '2.06652'}; time used = 0.995800256729126s
epoch 55: {'train_loss': '2.11464'}; time used = 1.0067322254180908s
epoch 60: {'train_loss': '1.95763'}; time used = 1.0388433933258057s
epoch 65: {'train_loss': '1.89745'}; time used = 0.9216980934143066s
epoch 70: {'train_loss': '1.88560'}; time used = 1.0250742435455322s
epoch 75: {'train_loss': '1.80520'}; time used = 0.9880917072296143s
epoch 80: {'train_loss': '1.89146'}; time used = 0.9186053276062012s
epoch 85: {'train_loss': '1.88539'}; time used = 1.1307728290557861s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.917218446731567.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.75859'}; time used = 2.212850570678711s
epoch 10: {'train_loss': '2.73691'}; time used = 2.021977186203003s
epoch 15: {'train_loss': '2.71328'}; time used = 2.0568552017211914s
epoch 20: {'train_loss': '2.68204'}; time used = 1.7664830684661865s
epoch 25: {'train_loss': '2.64347'}; time used = 1.96506929397583s
epoch 30: {'train_loss': '2.62288'}; time used = 1.6933107376098633s
epoch 35: {'train_loss': '2.60346'}; time used = 1.7431974411010742s
epoch 40: {'train_loss': '2.57612'}; time used = 1.866464376449585s
epoch 45: {'train_loss': '2.54246'}; time used = 1.7136571407318115s
epoch 50: {'train_loss': '2.49807'}; time used = 1.73172926902771s
epoch 55: {'train_loss': '2.52719'}; time used = 1.9844794273376465s
epoch 60: {'train_loss': '2.48937'}; time used = 1.7081224918365479s
epoch 65: {'train_loss': '2.45026'}; time used = 1.787243366241455s
epoch 70: {'train_loss': '2.40065'}; time used = 2.0496959686279297s
epoch 75: {'train_loss': '2.39236'}; time used = 1.9036035537719727s
epoch 80: {'train_loss': '2.36968'}; time used = 1.917137622833252s
epoch 85: {'train_loss': '2.38041'}; time used = 1.8670907020568848s
epoch 90: {'train_loss': '2.38858'}; time used = 1.6996164321899414s
epoch 95: {'train_loss': '2.37201'}; time used = 1.7666451930999756s
epoch 100: {'train_loss': '2.34659'}; time used = 1.9000968933105469s
epoch 105: {'train_loss': '2.35825'}; time used = 1.80401611328125s
epoch 110: {'train_loss': '2.33842'}; time used = 1.7447376251220703s
epoch 115: {'train_loss': '2.34315'}; time used = 1.8396096229553223s
epoch 120: {'train_loss': '2.34175'}; time used = 1.8171708583831787s
epoch 125: {'train_loss': '2.32216'}; time used = 1.6947143077850342s
epoch 130: {'train_loss': '2.31927'}; time used = 1.7234132289886475s
epoch 135: {'train_loss': '2.33864'}; time used = 2.1475348472595215s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.5072603225708.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92585'}; time used = 2.2639918327331543s
epoch 10: {'train_loss': '2.80833'}; time used = 2.239880084991455s
epoch 15: {'train_loss': '2.78952'}; time used = 2.2924067974090576s
epoch 20: {'train_loss': '2.77763'}; time used = 2.214247703552246s
epoch 25: {'train_loss': '2.76432'}; time used = 2.499056816101074s
epoch 30: {'train_loss': '2.75096'}; time used = 2.3761918544769287s
epoch 35: {'train_loss': '2.74012'}; time used = 2.128289222717285s
epoch 40: {'train_loss': '2.72527'}; time used = 3.0064871311187744s
epoch 45: {'train_loss': '2.71027'}; time used = 2.2043426036834717s
epoch 50: {'train_loss': '2.69108'}; time used = 2.226029396057129s
epoch 55: {'train_loss': '2.69006'}; time used = 2.1013307571411133s
epoch 60: {'train_loss': '2.65320'}; time used = 2.1239659786224365s
epoch 65: {'train_loss': '2.62162'}; time used = 2.130180597305298s
epoch 70: {'train_loss': '2.61333'}; time used = 2.1077582836151123s
epoch 75: {'train_loss': '2.55375'}; time used = 2.494019031524658s
epoch 80: {'train_loss': '2.56149'}; time used = 2.5141489505767822s
epoch 85: {'train_loss': '2.58841'}; time used = 2.643678665161133s
epoch 90: {'train_loss': '2.52337'}; time used = 2.6396100521087646s
epoch 95: {'train_loss': '2.52868'}; time used = 2.6873300075531006s
epoch 100: {'train_loss': '2.51159'}; time used = 2.6296133995056152s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.15680003166199.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27002'}; time used = 1.4698364734649658s
epoch 10: {'train_loss': '2.95787'}; time used = 1.3558464050292969s
epoch 15: {'train_loss': '2.87804'}; time used = 1.3425366878509521s
epoch 20: {'train_loss': '2.80224'}; time used = 1.3956665992736816s
epoch 25: {'train_loss': '2.81210'}; time used = 1.5159969329833984s
epoch 30: {'train_loss': '2.80054'}; time used = 1.4457316398620605s
epoch 35: {'train_loss': '2.79318'}; time used = 1.505131483078003s
epoch 40: {'train_loss': '2.79020'}; time used = 1.4699716567993164s
epoch 45: {'train_loss': '2.79118'}; time used = 1.4695420265197754s
epoch 50: {'train_loss': '2.78719'}; time used = 1.3916661739349365s
epoch 55: {'train_loss': '2.78174'}; time used = 1.50836181640625s
epoch 60: {'train_loss': '2.78173'}; time used = 1.4865608215332031s
epoch 65: {'train_loss': '2.77783'}; time used = 1.4820315837860107s
epoch 70: {'train_loss': '2.77594'}; time used = 2.9115078449249268s
epoch 75: {'train_loss': '2.78583'}; time used = 2.1637680530548096s
epoch 80: {'train_loss': '2.78014'}; time used = 1.3314828872680664s
epoch 85: {'train_loss': '2.78066'}; time used = 1.4595446586608887s
epoch 90: {'train_loss': '2.78029'}; time used = 1.3317749500274658s
epoch 95: {'train_loss': '2.77585'}; time used = 1.3365809917449951s
epoch 100: {'train_loss': '2.77358'}; time used = 1.4859020709991455s
epoch 105: {'train_loss': '2.77254'}; time used = 1.3873846530914307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.82769775390625.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.80808'}; time used = 2.4805681705474854s
epoch 10: {'train_loss': '2.77654'}; time used = 3.664759397506714s
epoch 15: {'train_loss': '2.77527'}; time used = 2.117318630218506s
epoch 20: {'train_loss': '2.78097'}; time used = 1.3321647644042969s
epoch 25: {'train_loss': '2.77707'}; time used = 1.3718655109405518s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.98452353477478.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.95757'}; time used = 1.78609037399292s
epoch 10: {'train_loss': '0.86366'}; time used = 1.719780683517456s
epoch 15: {'train_loss': '0.30816'}; time used = 1.7597620487213135s
epoch 20: {'train_loss': '0.05425'}; time used = 1.7242307662963867s
epoch 25: {'train_loss': '0.00209'}; time used = 1.9668543338775635s
epoch 30: {'train_loss': '0.00212'}; time used = 2.4261372089385986s
epoch 35: {'train_loss': '0.00003'}; time used = 2.1957006454467773s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.156490325927734.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92382'}; time used = 1.7880055904388428s
epoch 10: {'train_loss': '2.86475'}; time used = 1.8590655326843262s
epoch 15: {'train_loss': '2.84683'}; time used = 1.7895936965942383s
epoch 20: {'train_loss': '2.81633'}; time used = 1.8356916904449463s
epoch 25: {'train_loss': '2.79725'}; time used = 1.813981533050537s
epoch 30: {'train_loss': '2.78654'}; time used = 3.4810140132904053s
epoch 35: {'train_loss': '2.78016'}; time used = 3.2533140182495117s
epoch 40: {'train_loss': '2.77629'}; time used = 3.520340919494629s
epoch 45: {'train_loss': '2.77375'}; time used = 1.8070902824401855s
epoch 50: {'train_loss': '2.77235'}; time used = 1.8633434772491455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.032335996627808.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37465'}; time used = 3.0473971366882324s
epoch 10: {'train_loss': '1.34538'}; time used = 2.646164655685425s
epoch 15: {'train_loss': '1.36919'}; time used = 2.8439671993255615s
epoch 20: {'train_loss': '1.38557'}; time used = 2.7066569328308105s
epoch 25: {'train_loss': '1.24574'}; time used = 2.7364165782928467s
epoch 30: {'train_loss': '1.04726'}; time used = 2.69092059135437s
epoch 35: {'train_loss': '0.93427'}; time used = 2.6869382858276367s
epoch 40: {'train_loss': '0.88178'}; time used = 2.6598691940307617s
epoch 45: {'train_loss': '0.67201'}; time used = 2.7890076637268066s
epoch 50: {'train_loss': '0.75978'}; time used = 2.89388108253479s
epoch 55: {'train_loss': '0.67540'}; time used = 2.679708242416382s
epoch 60: {'train_loss': '0.47825'}; time used = 2.6436140537261963s
epoch 65: {'train_loss': '0.43630'}; time used = 2.6779396533966064s
epoch 70: {'train_loss': '0.67534'}; time used = 2.5813114643096924s
epoch 75: {'train_loss': '0.55167'}; time used = 2.6818649768829346s
epoch 80: {'train_loss': '0.57175'}; time used = 2.72678542137146s
epoch 85: {'train_loss': '0.72795'}; time used = 2.5988826751708984s
epoch 90: {'train_loss': '0.60275'}; time used = 2.5970706939697266s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.63878846168518.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78896'}; time used = 1.0848703384399414s
epoch 10: {'train_loss': '2.80994'}; time used = 1.0762355327606201s
epoch 15: {'train_loss': '2.78940'}; time used = 0.9921064376831055s
epoch 20: {'train_loss': '2.77469'}; time used = 0.990931510925293s
epoch 25: {'train_loss': '2.77286'}; time used = 1.0027837753295898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.181782007217407.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.65962'}; time used = 1.9684689044952393s
epoch 10: {'train_loss': '0.47020'}; time used = 1.8427021503448486s
epoch 15: {'train_loss': '0.37761'}; time used = 2.104353666305542s
epoch 20: {'train_loss': '0.25676'}; time used = 1.7952265739440918s
epoch 25: {'train_loss': '0.07554'}; time used = 1.8514113426208496s
epoch 30: {'train_loss': '0.03359'}; time used = 1.0689964294433594s
epoch 35: {'train_loss': '0.05563'}; time used = 0.9804472923278809s
epoch 40: {'train_loss': '0.05469'}; time used = 1.1961135864257812s
epoch 45: {'train_loss': '0.04564'}; time used = 1.2351505756378174s
epoch 50: {'train_loss': '0.04301'}; time used = 1.1720285415649414s
epoch 55: {'train_loss': '0.03063'}; time used = 1.1672861576080322s
epoch 60: {'train_loss': '0.00728'}; time used = 1.9421017169952393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.779993057250977.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.75178'}; time used = 1.635575294494629s
epoch 10: {'train_loss': '2.70868'}; time used = 1.591914415359497s
epoch 15: {'train_loss': '2.69641'}; time used = 1.5615298748016357s
epoch 20: {'train_loss': '2.66593'}; time used = 1.6026389598846436s
epoch 25: {'train_loss': '2.65313'}; time used = 1.6878743171691895s
epoch 30: {'train_loss': '2.64406'}; time used = 1.587815284729004s
epoch 35: {'train_loss': '2.63883'}; time used = 1.5904316902160645s
epoch 40: {'train_loss': '2.63706'}; time used = 1.5866422653198242s
epoch 45: {'train_loss': '2.63089'}; time used = 1.606149673461914s
epoch 50: {'train_loss': '2.61788'}; time used = 1.7389700412750244s
epoch 55: {'train_loss': '2.61625'}; time used = 1.722761631011963s
epoch 60: {'train_loss': '2.61839'}; time used = 1.6117665767669678s
epoch 65: {'train_loss': '2.60113'}; time used = 1.5894851684570312s
epoch 70: {'train_loss': '2.59104'}; time used = 1.6292424201965332s
epoch 75: {'train_loss': '2.58223'}; time used = 1.7270286083221436s
epoch 80: {'train_loss': '2.57768'}; time used = 1.6650032997131348s
epoch 85: {'train_loss': '2.57747'}; time used = 1.5860610008239746s
epoch 90: {'train_loss': '2.58006'}; time used = 1.6092097759246826s
epoch 95: {'train_loss': '2.57878'}; time used = 1.5950427055358887s
epoch 100: {'train_loss': '2.56572'}; time used = 1.6226646900177002s
epoch 105: {'train_loss': '2.56749'}; time used = 1.6577301025390625s
epoch 110: {'train_loss': '2.56484'}; time used = 1.5984020233154297s
epoch 115: {'train_loss': '2.56104'}; time used = 1.6236937046051025s
epoch 120: {'train_loss': '2.56067'}; time used = 1.5671324729919434s
epoch 125: {'train_loss': '2.55451'}; time used = 1.7688095569610596s
epoch 130: {'train_loss': '2.55841'}; time used = 1.7126343250274658s
epoch 135: {'train_loss': '2.55755'}; time used = 1.9573462009429932s
epoch 140: {'train_loss': '2.55672'}; time used = 1.596395492553711s
epoch 145: {'train_loss': '2.54964'}; time used = 1.7455031871795654s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.34096074104309.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5446029380455609, 'samples': 0.5507246376811594, 'weighted': 0.5484290003178098, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86923'}; time used = 1.4868195056915283s
epoch 10: {'train_loss': '2.79428'}; time used = 1.296288013458252s
epoch 15: {'train_loss': '2.77385'}; time used = 1.2867348194122314s
epoch 20: {'train_loss': '2.77958'}; time used = 1.2694694995880127s
epoch 25: {'train_loss': '2.77819'}; time used = 1.2758913040161133s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.976869106292725.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33256'}; time used = 1.1658961772918701s
epoch 10: {'train_loss': '1.67490'}; time used = 1.1554956436157227s
epoch 15: {'train_loss': '1.12562'}; time used = 1.1686830520629883s
epoch 20: {'train_loss': '1.66817'}; time used = 1.0636794567108154s
epoch 25: {'train_loss': '0.75449'}; time used = 1.053877353668213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.350914239883423.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.88829'}; time used = 1.471632957458496s
epoch 10: {'train_loss': '2.80343'}; time used = 1.0677480697631836s
epoch 15: {'train_loss': '2.76009'}; time used = 1.117696762084961s
epoch 20: {'train_loss': '2.72996'}; time used = 1.036269187927246s
epoch 25: {'train_loss': '2.67484'}; time used = 1.0545151233673096s
epoch 30: {'train_loss': '2.52745'}; time used = 1.0485930442810059s
epoch 35: {'train_loss': '2.31511'}; time used = 1.0251407623291016s
epoch 40: {'train_loss': '2.39001'}; time used = 1.051171064376831s
epoch 45: {'train_loss': '2.27762'}; time used = 1.023249864578247s
epoch 50: {'train_loss': '2.24621'}; time used = 1.0509519577026367s
epoch 55: {'train_loss': '2.19691'}; time used = 1.0280206203460693s
epoch 60: {'train_loss': '2.18709'}; time used = 1.1196646690368652s
epoch 65: {'train_loss': '2.16003'}; time used = 1.073169231414795s
epoch 70: {'train_loss': '2.17505'}; time used = 1.026667594909668s
epoch 75: {'train_loss': '2.10819'}; time used = 1.0135712623596191s
epoch 80: {'train_loss': '2.09634'}; time used = 1.0324034690856934s
epoch 85: {'train_loss': '2.12113'}; time used = 1.0480122566223145s
epoch 90: {'train_loss': '2.09013'}; time used = 1.239025592803955s
epoch 95: {'train_loss': '2.13115'}; time used = 1.079892873764038s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.22419786453247.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80643'}; time used = 1.149721622467041s
epoch 10: {'train_loss': '2.66815'}; time used = 1.0490944385528564s
epoch 15: {'train_loss': '2.58287'}; time used = 1.0337669849395752s
epoch 20: {'train_loss': '2.48571'}; time used = 1.0438032150268555s
epoch 25: {'train_loss': '2.34622'}; time used = 1.0414533615112305s
epoch 30: {'train_loss': '2.19689'}; time used = 1.0566368103027344s
epoch 35: {'train_loss': '2.06657'}; time used = 1.024129867553711s
epoch 40: {'train_loss': '2.01237'}; time used = 0.9724898338317871s
epoch 45: {'train_loss': '1.87461'}; time used = 0.9961254596710205s
epoch 50: {'train_loss': '2.14025'}; time used = 1.060591697692871s
epoch 55: {'train_loss': '2.02199'}; time used = 0.8878085613250732s
epoch 60: {'train_loss': '1.92862'}; time used = 0.935600757598877s
epoch 65: {'train_loss': '1.90544'}; time used = 0.9169604778289795s
epoch 70: {'train_loss': '1.83653'}; time used = 1.090183973312378s
epoch 75: {'train_loss': '1.77885'}; time used = 0.8665776252746582s
epoch 80: {'train_loss': '1.82993'}; time used = 0.8897178173065186s
epoch 85: {'train_loss': '1.82008'}; time used = 0.8886864185333252s
epoch 90: {'train_loss': '1.77811'}; time used = 0.8816497325897217s
epoch 95: {'train_loss': '1.80491'}; time used = 0.9015047550201416s
epoch 100: {'train_loss': '1.80197'}; time used = 0.8596467971801758s
epoch 105: {'train_loss': '1.77936'}; time used = 0.9620087146759033s
epoch 110: {'train_loss': '1.76375'}; time used = 0.8765914440155029s
epoch 115: {'train_loss': '1.73480'}; time used = 0.910170316696167s
epoch 120: {'train_loss': '1.75254'}; time used = 0.8722946643829346s
epoch 125: {'train_loss': '1.82728'}; time used = 0.8543641567230225s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.737183332443237.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38065'}; time used = 1.7790837287902832s
epoch 10: {'train_loss': '1.33833'}; time used = 1.9643831253051758s
epoch 15: {'train_loss': '1.35206'}; time used = 1.9949431419372559s
epoch 20: {'train_loss': '1.37426'}; time used = 1.9651422500610352s
epoch 25: {'train_loss': '1.20091'}; time used = 1.935314655303955s
epoch 30: {'train_loss': '1.39744'}; time used = 1.6893820762634277s
epoch 35: {'train_loss': '1.36984'}; time used = 1.6580665111541748s
epoch 40: {'train_loss': '1.33129'}; time used = 1.6106371879577637s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.105385303497314.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36730'}; time used = 2.687222480773926s
epoch 10: {'train_loss': '1.34330'}; time used = 2.618994951248169s
epoch 15: {'train_loss': '1.37551'}; time used = 2.649787425994873s
epoch 20: {'train_loss': '1.42177'}; time used = 2.389056921005249s
epoch 25: {'train_loss': '1.39237'}; time used = 2.4938862323760986s
epoch 30: {'train_loss': '1.26325'}; time used = 2.2176501750946045s
epoch 35: {'train_loss': '1.21466'}; time used = 2.1953601837158203s
epoch 40: {'train_loss': '1.07995'}; time used = 2.3236703872680664s
epoch 45: {'train_loss': '0.92279'}; time used = 2.3079209327697754s
epoch 50: {'train_loss': '0.72723'}; time used = 2.378387212753296s
epoch 55: {'train_loss': '0.51641'}; time used = 2.2009406089782715s
epoch 60: {'train_loss': '0.63865'}; time used = 2.6084539890289307s
epoch 65: {'train_loss': '0.78134'}; time used = 2.613878011703491s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.14751744270325.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6423258958755915, 'samples': 0.6666666666666666, 'weighted': 0.6490872210953347, 'accuracy': 0.6666666666666666}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79015'}; time used = 1.8392491340637207s
epoch 10: {'train_loss': '2.77602'}; time used = 1.8102755546569824s
epoch 15: {'train_loss': '2.77137'}; time used = 1.8386285305023193s
epoch 20: {'train_loss': '2.76710'}; time used = 1.879044771194458s
epoch 25: {'train_loss': '2.76095'}; time used = 1.8056306838989258s
epoch 30: {'train_loss': '2.75667'}; time used = 1.7365474700927734s
epoch 35: {'train_loss': '2.74970'}; time used = 1.747143268585205s
epoch 40: {'train_loss': '2.74920'}; time used = 1.7435243129730225s
epoch 45: {'train_loss': '2.74364'}; time used = 1.7326600551605225s
epoch 50: {'train_loss': '2.73512'}; time used = 1.886521577835083s
epoch 55: {'train_loss': '2.71792'}; time used = 1.7562673091888428s
epoch 60: {'train_loss': '2.66965'}; time used = 1.7526938915252686s
epoch 65: {'train_loss': '2.64299'}; time used = 1.7720885276794434s
epoch 70: {'train_loss': '2.63398'}; time used = 2.230947732925415s
epoch 75: {'train_loss': '2.61443'}; time used = 2.4803709983825684s
epoch 80: {'train_loss': '2.60906'}; time used = 1.9493701457977295s
epoch 85: {'train_loss': '2.61446'}; time used = 1.889265775680542s
epoch 90: {'train_loss': '2.59962'}; time used = 1.8296120166778564s
epoch 95: {'train_loss': '2.61556'}; time used = 2.121742010116577s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.42432689666748.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85293'}; time used = 1.0898289680480957s
epoch 10: {'train_loss': '2.80898'}; time used = 0.999535083770752s
epoch 15: {'train_loss': '2.78677'}; time used = 0.9682209491729736s
epoch 20: {'train_loss': '2.77282'}; time used = 1.0494403839111328s
epoch 25: {'train_loss': '2.77342'}; time used = 1.1387615203857422s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.207748889923096.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36879'}; time used = 1.7578661441802979s
epoch 10: {'train_loss': '1.31844'}; time used = 1.860792636871338s
epoch 15: {'train_loss': '1.28446'}; time used = 1.6771600246429443s
epoch 20: {'train_loss': '1.28024'}; time used = 1.6606121063232422s
epoch 25: {'train_loss': '1.12698'}; time used = 1.7607929706573486s
epoch 30: {'train_loss': '0.90786'}; time used = 1.654033899307251s
epoch 35: {'train_loss': '1.02106'}; time used = 1.661792516708374s
epoch 40: {'train_loss': '0.83597'}; time used = 1.6520085334777832s
epoch 45: {'train_loss': '0.71130'}; time used = 1.675666093826294s
epoch 50: {'train_loss': '0.70483'}; time used = 1.7342205047607422s
epoch 55: {'train_loss': '0.48304'}; time used = 1.6769633293151855s
epoch 60: {'train_loss': '0.55060'}; time used = 1.6679420471191406s
epoch 65: {'train_loss': '0.60769'}; time used = 1.6691927909851074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.893052101135254.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5527777777777778, 'samples': 0.5942028985507246, 'weighted': 0.5626409017713365, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05539'}; time used = 2.100701332092285s
epoch 10: {'train_loss': '0.93304'}; time used = 1.715479850769043s
epoch 15: {'train_loss': '0.88725'}; time used = 1.6266565322875977s
epoch 20: {'train_loss': '0.93834'}; time used = 1.8457458019256592s
epoch 25: {'train_loss': '0.84692'}; time used = 1.7561452388763428s
epoch 30: {'train_loss': '0.72921'}; time used = 1.6560511589050293s
epoch 35: {'train_loss': '0.48981'}; time used = 1.6517632007598877s
epoch 40: {'train_loss': '0.47402'}; time used = 1.6289548873901367s
epoch 45: {'train_loss': '0.50790'}; time used = 1.606811285018921s
epoch 50: {'train_loss': '0.40378'}; time used = 1.6008858680725098s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.887407064437866.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.38268398268398274, 'samples': 0.5507246376811594, 'weighted': 0.40602296254470177, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.37059'}; time used = 1.1927778720855713s
epoch 10: {'train_loss': '1.49165'}; time used = 1.2274997234344482s
epoch 15: {'train_loss': '1.16142'}; time used = 1.1051154136657715s
epoch 20: {'train_loss': '1.23903'}; time used = 1.1552813053131104s
epoch 25: {'train_loss': '0.83761'}; time used = 1.133422613143921s
epoch 30: {'train_loss': '0.94551'}; time used = 1.0618951320648193s
epoch 35: {'train_loss': '0.86698'}; time used = 1.171496868133545s
epoch 40: {'train_loss': '0.81250'}; time used = 1.035219669342041s
epoch 45: {'train_loss': '0.54695'}; time used = 1.1681413650512695s
epoch 50: {'train_loss': '0.44530'}; time used = 1.0278213024139404s
epoch 55: {'train_loss': '0.36628'}; time used = 1.0886282920837402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.08903741836548.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.30969'}; time used = 3.264665365219116s
epoch 10: {'train_loss': '0.33798'}; time used = 3.0005176067352295s
epoch 15: {'train_loss': '0.15200'}; time used = 1.9987053871154785s
epoch 20: {'train_loss': '0.09520'}; time used = 1.7022788524627686s
epoch 25: {'train_loss': '0.12461'}; time used = 1.8275961875915527s
epoch 30: {'train_loss': '0.08897'}; time used = 1.9985766410827637s
epoch 35: {'train_loss': '0.08576'}; time used = 2.2105185985565186s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.5350124835968.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78366'}; time used = 1.2192411422729492s
epoch 10: {'train_loss': '2.78356'}; time used = 1.1061391830444336s
epoch 15: {'train_loss': '2.78080'}; time used = 1.1499249935150146s
epoch 20: {'train_loss': '2.77423'}; time used = 1.0994179248809814s
epoch 25: {'train_loss': '2.77280'}; time used = 1.1098229885101318s
epoch 30: {'train_loss': '2.77332'}; time used = 1.327237844467163s
epoch 35: {'train_loss': '2.77341'}; time used = 1.0807018280029297s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.309748411178589.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38430'}; time used = 1.9451544284820557s
epoch 10: {'train_loss': '1.31526'}; time used = 2.2644598484039307s
epoch 15: {'train_loss': '1.25461'}; time used = 2.102263927459717s
epoch 20: {'train_loss': '1.33173'}; time used = 1.8290791511535645s
epoch 25: {'train_loss': '1.20726'}; time used = 2.9129507541656494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.575383186340332.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5179175118323192, 'samples': 0.5507246376811594, 'weighted': 0.5270306023458858, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.78437'}; time used = 2.171043872833252s
epoch 10: {'train_loss': '2.72946'}; time used = 1.8640947341918945s
epoch 15: {'train_loss': '2.70004'}; time used = 1.8601362705230713s
epoch 20: {'train_loss': '2.68697'}; time used = 1.8830499649047852s
epoch 25: {'train_loss': '2.67678'}; time used = 2.0236051082611084s
epoch 30: {'train_loss': '2.66696'}; time used = 1.7869248390197754s
epoch 35: {'train_loss': '2.66252'}; time used = 1.8693881034851074s
epoch 40: {'train_loss': '2.65682'}; time used = 1.822232723236084s
epoch 45: {'train_loss': '2.65035'}; time used = 1.7654526233673096s
epoch 50: {'train_loss': '2.63820'}; time used = 1.7304837703704834s
epoch 55: {'train_loss': '2.63375'}; time used = 1.7648711204528809s
epoch 60: {'train_loss': '2.63754'}; time used = 1.679292917251587s
epoch 65: {'train_loss': '2.62171'}; time used = 1.6726317405700684s
epoch 70: {'train_loss': '2.61019'}; time used = 1.666003704071045s
epoch 75: {'train_loss': '2.59868'}; time used = 1.9829185009002686s
epoch 80: {'train_loss': '2.59358'}; time used = 1.7900943756103516s
epoch 85: {'train_loss': '2.59141'}; time used = 1.6844406127929688s
epoch 90: {'train_loss': '2.59606'}; time used = 1.6734869480133057s
epoch 95: {'train_loss': '2.59195'}; time used = 1.6878392696380615s
epoch 100: {'train_loss': '2.58538'}; time used = 1.7547335624694824s
epoch 105: {'train_loss': '2.58371'}; time used = 1.8522446155548096s
epoch 110: {'train_loss': '2.58277'}; time used = 1.7298858165740967s
epoch 115: {'train_loss': '2.58067'}; time used = 1.693293809890747s
epoch 120: {'train_loss': '2.58265'}; time used = 1.6689865589141846s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.66869306564331.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.47787204769548264, 'samples': 0.5217391304347826, 'weighted': 0.4888388183803076, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.62580'}; time used = 1.4177274703979492s
epoch 10: {'train_loss': '2.44501'}; time used = 1.7910106182098389s
epoch 15: {'train_loss': '2.34887'}; time used = 1.809739589691162s
epoch 20: {'train_loss': '2.28786'}; time used = 1.029287576675415s
epoch 25: {'train_loss': '2.11246'}; time used = 0.9059364795684814s
epoch 30: {'train_loss': '2.00634'}; time used = 0.9227449893951416s
epoch 35: {'train_loss': '1.88121'}; time used = 1.5575530529022217s
epoch 40: {'train_loss': '1.79118'}; time used = 2.267720937728882s
epoch 45: {'train_loss': '1.69188'}; time used = 2.2601258754730225s
epoch 50: {'train_loss': '1.65815'}; time used = 1.791977882385254s
epoch 55: {'train_loss': '1.57348'}; time used = 1.8557114601135254s
epoch 60: {'train_loss': '1.54828'}; time used = 1.8602495193481445s
epoch 65: {'train_loss': '1.50768'}; time used = 1.6792922019958496s
epoch 70: {'train_loss': '1.51799'}; time used = 0.9526169300079346s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.695096731185913.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.93004'}; time used = 1.8841516971588135s
epoch 10: {'train_loss': '2.81447'}; time used = 1.8069534301757812s
epoch 15: {'train_loss': '2.78392'}; time used = 1.8213212490081787s
epoch 20: {'train_loss': '2.77147'}; time used = 1.836369276046753s
epoch 25: {'train_loss': '2.77563'}; time used = 1.812758445739746s
epoch 30: {'train_loss': '2.77506'}; time used = 1.7034924030303955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.609178066253662.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77835'}; time used = 1.797799825668335s
epoch 10: {'train_loss': '2.76130'}; time used = 1.6125178337097168s
epoch 15: {'train_loss': '2.75038'}; time used = 1.6275198459625244s
epoch 20: {'train_loss': '2.72940'}; time used = 1.583219289779663s
epoch 25: {'train_loss': '2.68933'}; time used = 1.665550708770752s
epoch 30: {'train_loss': '2.65237'}; time used = 1.6009180545806885s
epoch 35: {'train_loss': '2.60096'}; time used = 1.5686192512512207s
epoch 40: {'train_loss': '2.51891'}; time used = 1.7367901802062988s
epoch 45: {'train_loss': '2.48048'}; time used = 1.7692313194274902s
epoch 50: {'train_loss': '2.50325'}; time used = 1.8077971935272217s
epoch 55: {'train_loss': '2.45863'}; time used = 1.8622465133666992s
epoch 60: {'train_loss': '2.42076'}; time used = 1.7883765697479248s
epoch 65: {'train_loss': '2.34508'}; time used = 1.5978448390960693s
epoch 70: {'train_loss': '2.29469'}; time used = 1.569638729095459s
epoch 75: {'train_loss': '2.27827'}; time used = 1.5070726871490479s
epoch 80: {'train_loss': '2.29581'}; time used = 2.0534605979919434s
epoch 85: {'train_loss': '2.31226'}; time used = 1.8210582733154297s
epoch 90: {'train_loss': '2.24067'}; time used = 1.8059043884277344s
epoch 95: {'train_loss': '2.20841'}; time used = 1.5667428970336914s
epoch 100: {'train_loss': '2.17124'}; time used = 1.7424380779266357s
epoch 105: {'train_loss': '2.21677'}; time used = 1.7485535144805908s
epoch 110: {'train_loss': '2.12805'}; time used = 1.7728867530822754s
epoch 115: {'train_loss': '2.16738'}; time used = 1.7420151233673096s
epoch 120: {'train_loss': '2.12959'}; time used = 1.7476787567138672s
epoch 125: {'train_loss': '2.10225'}; time used = 1.7549536228179932s
epoch 130: {'train_loss': '2.06616'}; time used = 1.713975191116333s
epoch 135: {'train_loss': '2.14396'}; time used = 1.8105263710021973s
epoch 140: {'train_loss': '2.02829'}; time used = 1.779484510421753s
epoch 145: {'train_loss': '1.98148'}; time used = 1.7475078105926514s
epoch 150: {'train_loss': '1.98877'}; time used = 1.7200932502746582s
epoch 155: {'train_loss': '1.94482'}; time used = 1.7388916015625s
epoch 160: {'train_loss': '1.99758'}; time used = 1.740741491317749s
epoch 165: {'train_loss': '2.06075'}; time used = 1.7030677795410156s
epoch 170: {'train_loss': '2.01984'}; time used = 1.7697269916534424s
epoch 175: {'train_loss': '1.93611'}; time used = 1.544403314590454s
epoch 180: {'train_loss': '1.88878'}; time used = 1.6339199542999268s
epoch 185: {'train_loss': '1.91260'}; time used = 1.7265987396240234s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 67.11075973510742.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.600300364728599, 'samples': 0.6086956521739131, 'weighted': 0.6044980084512561, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.15224'}; time used = 1.1076180934906006s
epoch 10: {'train_loss': '2.80111'}; time used = 1.0147697925567627s
epoch 15: {'train_loss': '2.82097'}; time used = 0.9975073337554932s
epoch 20: {'train_loss': '2.81323'}; time used = 0.992009162902832s
epoch 25: {'train_loss': '2.79821'}; time used = 1.0229856967926025s
epoch 30: {'train_loss': '2.78960'}; time used = 0.984921932220459s
epoch 35: {'train_loss': '2.78359'}; time used = 0.9733541011810303s
epoch 40: {'train_loss': '2.78102'}; time used = 1.0663580894470215s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.436177253723145.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.45 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77665'}; time used = 1.8793809413909912s
epoch 10: {'train_loss': '2.65845'}; time used = 1.772953748703003s
epoch 15: {'train_loss': '2.63574'}; time used = 1.7566819190979004s
epoch 20: {'train_loss': '2.61070'}; time used = 1.7488384246826172s
epoch 25: {'train_loss': '2.58411'}; time used = 2.0805110931396484s
epoch 30: {'train_loss': '2.55819'}; time used = 1.7702417373657227s
epoch 35: {'train_loss': '2.52184'}; time used = 1.8261630535125732s
epoch 40: {'train_loss': '2.48288'}; time used = 1.9237709045410156s
epoch 45: {'train_loss': '2.43084'}; time used = 1.8639466762542725s
epoch 50: {'train_loss': '2.35485'}; time used = 1.8865227699279785s
epoch 55: {'train_loss': '2.37964'}; time used = 1.996330738067627s
epoch 60: {'train_loss': '2.38017'}; time used = 1.881795883178711s
epoch 65: {'train_loss': '2.33831'}; time used = 1.7415502071380615s
epoch 70: {'train_loss': '2.41740'}; time used = 2.027034044265747s
epoch 75: {'train_loss': '2.35856'}; time used = 1.8269362449645996s
epoch 80: {'train_loss': '2.32150'}; time used = 1.7124595642089844s
epoch 85: {'train_loss': '2.31364'}; time used = 1.6994493007659912s
epoch 90: {'train_loss': '2.29655'}; time used = 1.8600430488586426s
epoch 95: {'train_loss': '2.27080'}; time used = 1.6201233863830566s
epoch 100: {'train_loss': '2.22257'}; time used = 1.643909215927124s
epoch 105: {'train_loss': '2.22799'}; time used = 1.7013587951660156s
epoch 110: {'train_loss': '2.20109'}; time used = 1.6611824035644531s
epoch 115: {'train_loss': '2.17716'}; time used = 1.7438850402832031s
epoch 120: {'train_loss': '2.21622'}; time used = 1.793973445892334s
epoch 125: {'train_loss': '2.18086'}; time used = 1.7161250114440918s
epoch 130: {'train_loss': '2.18492'}; time used = 1.6661033630371094s
epoch 135: {'train_loss': '2.15146'}; time used = 1.9860374927520752s
epoch 140: {'train_loss': '2.25511'}; time used = 1.6774566173553467s
epoch 145: {'train_loss': '2.31671'}; time used = 1.6312711238861084s
epoch 150: {'train_loss': '2.24668'}; time used = 1.6374351978302002s
epoch 155: {'train_loss': '2.18660'}; time used = 1.6573197841644287s
epoch 160: {'train_loss': '2.21598'}; time used = 1.720432996749878s
epoch 165: {'train_loss': '2.16819'}; time used = 1.6697869300842285s
epoch 170: {'train_loss': '2.13650'}; time used = 1.6576743125915527s
epoch 175: {'train_loss': '2.11364'}; time used = 1.6435837745666504s
epoch 180: {'train_loss': '2.11406'}; time used = 1.6637089252471924s
epoch 185: {'train_loss': '2.12147'}; time used = 1.7627296447753906s
epoch 190: {'train_loss': '2.07026'}; time used = 1.6657495498657227s
epoch 195: {'train_loss': '2.13221'}; time used = 1.72788667678833s
epoch 200: {'train_loss': '2.07450'}; time used = 1.9886095523834229s
epoch 205: {'train_loss': '2.06888'}; time used = 1.678746223449707s
epoch 210: {'train_loss': '2.03414'}; time used = 1.7036879062652588s
epoch 215: {'train_loss': '2.04934'}; time used = 1.8781914710998535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 80.57741689682007.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5282051282051283, 'samples': 0.5362318840579711, 'weighted': 0.5326644370122631, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86519'}; time used = 1.9383361339569092s
epoch 10: {'train_loss': '2.77937'}; time used = 1.8926682472229004s
epoch 15: {'train_loss': '2.74082'}; time used = 2.005669593811035s
epoch 20: {'train_loss': '2.72254'}; time used = 1.9149770736694336s
epoch 25: {'train_loss': '2.69430'}; time used = 2.588700771331787s
epoch 30: {'train_loss': '2.67126'}; time used = 2.4662857055664062s
epoch 35: {'train_loss': '2.64400'}; time used = 2.079056978225708s
epoch 40: {'train_loss': '2.59905'}; time used = 2.013052463531494s
epoch 45: {'train_loss': '2.58936'}; time used = 2.034290313720703s
epoch 50: {'train_loss': '2.56761'}; time used = 2.017305374145508s
epoch 55: {'train_loss': '2.55491'}; time used = 2.1489038467407227s
epoch 60: {'train_loss': '2.53705'}; time used = 2.021373748779297s
epoch 65: {'train_loss': '2.50770'}; time used = 2.020078659057617s
epoch 70: {'train_loss': '2.48219'}; time used = 2.0238394737243652s
epoch 75: {'train_loss': '2.45807'}; time used = 2.0276877880096436s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.43027448654175.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51984'}; time used = 1.5003199577331543s
epoch 10: {'train_loss': '0.23069'}; time used = 1.2105140686035156s
epoch 15: {'train_loss': '0.11155'}; time used = 1.2379369735717773s
epoch 20: {'train_loss': '0.07026'}; time used = 1.2566430568695068s
epoch 25: {'train_loss': '0.20907'}; time used = 1.2571871280670166s
epoch 30: {'train_loss': '0.27845'}; time used = 1.2056562900543213s
epoch 35: {'train_loss': '0.20067'}; time used = 1.1041226387023926s
epoch 40: {'train_loss': '0.07057'}; time used = 1.2178623676300049s
epoch 45: {'train_loss': '0.03747'}; time used = 1.1172664165496826s
epoch 50: {'train_loss': '0.01677'}; time used = 1.2336406707763672s
epoch 55: {'train_loss': '0.01091'}; time used = 1.1330609321594238s
epoch 60: {'train_loss': '0.01071'}; time used = 1.2087011337280273s
epoch 65: {'train_loss': '0.01918'}; time used = 1.4090876579284668s
epoch 70: {'train_loss': '0.01852'}; time used = 1.9960949420928955s
epoch 75: {'train_loss': '0.02683'}; time used = 2.1870481967926025s
epoch 80: {'train_loss': '0.00627'}; time used = 2.1597752571105957s
epoch 85: {'train_loss': '0.02909'}; time used = 1.9366462230682373s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.227113485336304.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.28257'}; time used = 1.9832584857940674s
epoch 10: {'train_loss': '1.17331'}; time used = 2.0507020950317383s
epoch 15: {'train_loss': '1.10404'}; time used = 1.7651755809783936s
epoch 20: {'train_loss': '1.11482'}; time used = 2.1550185680389404s
epoch 25: {'train_loss': '1.07740'}; time used = 3.56657075881958s
epoch 30: {'train_loss': '0.94495'}; time used = 3.5580663681030273s
epoch 35: {'train_loss': '0.87408'}; time used = 2.2009267807006836s
epoch 40: {'train_loss': '0.86272'}; time used = 1.8249635696411133s
epoch 45: {'train_loss': '0.82050'}; time used = 1.8098504543304443s
epoch 50: {'train_loss': '0.65527'}; time used = 2.226893663406372s
epoch 55: {'train_loss': '0.57603'}; time used = 2.2648680210113525s
epoch 60: {'train_loss': '0.36132'}; time used = 3.947625160217285s
epoch 65: {'train_loss': '1.01588'}; time used = 1.87735915184021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.507922410964966.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.34225'}; time used = 1.2958316802978516s
epoch 10: {'train_loss': '0.22058'}; time used = 0.956477165222168s
epoch 15: {'train_loss': '0.18609'}; time used = 1.1038601398468018s
epoch 20: {'train_loss': '0.12009'}; time used = 0.9589474201202393s
epoch 25: {'train_loss': '0.11671'}; time used = 1.1317360401153564s
epoch 30: {'train_loss': '0.12084'}; time used = 1.0212328433990479s
epoch 35: {'train_loss': '0.10569'}; time used = 1.34761381149292s
epoch 40: {'train_loss': '0.08616'}; time used = 1.3404109477996826s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.964348077774048.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37801'}; time used = 3.156632661819458s
epoch 10: {'train_loss': '1.35158'}; time used = 3.9115543365478516s
epoch 15: {'train_loss': '1.38082'}; time used = 4.05251932144165s
epoch 20: {'train_loss': '1.44612'}; time used = 2.7776947021484375s
epoch 25: {'train_loss': '1.42444'}; time used = 2.511593818664551s
epoch 30: {'train_loss': '1.36374'}; time used = 2.536989450454712s
epoch 35: {'train_loss': '1.23277'}; time used = 2.49920916557312s
epoch 40: {'train_loss': '1.10923'}; time used = 2.7042529582977295s
epoch 45: {'train_loss': '1.05806'}; time used = 3.8955817222595215s
epoch 50: {'train_loss': '0.86066'}; time used = 4.147192001342773s
epoch 55: {'train_loss': '0.73505'}; time used = 2.852567672729492s
epoch 60: {'train_loss': '0.93493'}; time used = 2.4738729000091553s
epoch 65: {'train_loss': '0.94542'}; time used = 2.439098358154297s
epoch 70: {'train_loss': '0.88603'}; time used = 2.442619562149048s
epoch 75: {'train_loss': '0.82350'}; time used = 2.5666263103485107s
epoch 80: {'train_loss': '0.70743'}; time used = 2.4595532417297363s
epoch 85: {'train_loss': '0.77968'}; time used = 2.474391222000122s
epoch 90: {'train_loss': '0.65859'}; time used = 2.5053350925445557s
epoch 95: {'train_loss': '0.59237'}; time used = 2.448286294937134s
epoch 100: {'train_loss': '0.75581'}; time used = 2.568751573562622s
epoch 105: {'train_loss': '0.43189'}; time used = 3.6496083736419678s
epoch 110: {'train_loss': '0.66636'}; time used = 3.77553129196167s
epoch 115: {'train_loss': '0.51356'}; time used = 3.5864908695220947s
epoch 120: {'train_loss': '0.46274'}; time used = 3.106489658355713s
epoch 125: {'train_loss': '0.15865'}; time used = 3.8990988731384277s
epoch 130: {'train_loss': '0.20977'}; time used = 3.6980268955230713s
epoch 135: {'train_loss': '0.23670'}; time used = 2.5839624404907227s
epoch 140: {'train_loss': '0.32108'}; time used = 2.9637012481689453s
epoch 145: {'train_loss': '0.21288'}; time used = 3.987513780593872s
epoch 150: {'train_loss': '0.32556'}; time used = 3.8211448192596436s
epoch 155: {'train_loss': '0.08617'}; time used = 2.9150607585906982s
epoch 160: {'train_loss': '1.65610'}; time used = 2.4937753677368164s
epoch 165: {'train_loss': '1.15766'}; time used = 2.4044549465179443s
epoch 170: {'train_loss': '1.32207'}; time used = 2.420753240585327s
epoch 175: {'train_loss': '1.42244'}; time used = 2.3736379146575928s
epoch 180: {'train_loss': '1.36353'}; time used = 2.4306905269622803s
epoch 185: {'train_loss': '1.37844'}; time used = 2.3843748569488525s
epoch 190: {'train_loss': '1.41382'}; time used = 2.415358543395996s
epoch 195: {'train_loss': '1.36328'}; time used = 2.4081943035125732s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 121.25111317634583.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34936'}; time used = 5.009515762329102s
epoch 10: {'train_loss': '1.33867'}; time used = 6.495582580566406s
epoch 15: {'train_loss': '1.31032'}; time used = 7.178225755691528s
epoch 20: {'train_loss': '1.29284'}; time used = 4.7700395584106445s
epoch 25: {'train_loss': '1.23314'}; time used = 4.881422758102417s
epoch 30: {'train_loss': '1.14887'}; time used = 6.984459400177002s
epoch 35: {'train_loss': '1.10404'}; time used = 4.6550984382629395s
epoch 40: {'train_loss': '0.96033'}; time used = 4.549901008605957s
epoch 45: {'train_loss': '0.85188'}; time used = 4.734980583190918s
epoch 50: {'train_loss': '0.88447'}; time used = 4.949926376342773s
epoch 55: {'train_loss': '0.81088'}; time used = 7.553419828414917s
epoch 60: {'train_loss': '0.85587'}; time used = 9.834778070449829s
epoch 65: {'train_loss': '0.78356'}; time used = 4.848872184753418s
epoch 70: {'train_loss': '0.50769'}; time used = 5.092618465423584s
epoch 75: {'train_loss': '0.59299'}; time used = 7.33678936958313s
epoch 80: {'train_loss': '0.88110'}; time used = 7.26667857170105s
epoch 85: {'train_loss': '0.65511'}; time used = 4.690530776977539s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 121.91204237937927.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77114'}; time used = 2.0427870750427246s
epoch 10: {'train_loss': '2.74921'}; time used = 2.1212127208709717s
epoch 15: {'train_loss': '2.72577'}; time used = 2.1573305130004883s
epoch 20: {'train_loss': '2.68679'}; time used = 2.253293514251709s
epoch 25: {'train_loss': '2.69394'}; time used = 2.483630895614624s
epoch 30: {'train_loss': '2.68459'}; time used = 2.3032495975494385s
epoch 35: {'train_loss': '2.68752'}; time used = 2.056394338607788s
epoch 40: {'train_loss': '2.68576'}; time used = 2.0804858207702637s
epoch 45: {'train_loss': '2.68282'}; time used = 2.0346388816833496s
epoch 50: {'train_loss': '2.68291'}; time used = 4.084536075592041s
epoch 55: {'train_loss': '2.69218'}; time used = 4.01127028465271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.187286615371704.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.07778'}; time used = 1.261584997177124s
epoch 10: {'train_loss': '2.89350'}; time used = 1.1246063709259033s
epoch 15: {'train_loss': '2.83916'}; time used = 1.0787525177001953s
epoch 20: {'train_loss': '2.78973'}; time used = 1.1484410762786865s
epoch 25: {'train_loss': '2.70586'}; time used = 1.107313871383667s
epoch 30: {'train_loss': '2.59645'}; time used = 1.0973432064056396s
epoch 35: {'train_loss': '2.43229'}; time used = 1.1159238815307617s
epoch 40: {'train_loss': '2.30321'}; time used = 1.1071081161499023s
epoch 45: {'train_loss': '2.26830'}; time used = 1.1089622974395752s
epoch 50: {'train_loss': '2.25419'}; time used = 1.115166425704956s
epoch 55: {'train_loss': '2.19954'}; time used = 1.1163537502288818s
epoch 60: {'train_loss': '2.19164'}; time used = 1.213176965713501s
epoch 65: {'train_loss': '2.21993'}; time used = 1.1082634925842285s
epoch 70: {'train_loss': '2.21677'}; time used = 1.1740200519561768s
epoch 75: {'train_loss': '2.15685'}; time used = 1.3202581405639648s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.639227390289307.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.08639'}; time used = 1.5471720695495605s
epoch 10: {'train_loss': '0.42005'}; time used = 1.0138523578643799s
epoch 15: {'train_loss': '0.34355'}; time used = 1.1442174911499023s
epoch 20: {'train_loss': '0.30984'}; time used = 0.9926433563232422s
epoch 25: {'train_loss': '0.35629'}; time used = 1.0239784717559814s
epoch 30: {'train_loss': '0.28549'}; time used = 0.9609982967376709s
epoch 35: {'train_loss': '0.31699'}; time used = 0.9645330905914307s
epoch 40: {'train_loss': '0.28446'}; time used = 0.9846627712249756s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.404139041900635.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68638'}; time used = 0.9783036708831787s
epoch 10: {'train_loss': '2.30409'}; time used = 0.9104669094085693s
epoch 15: {'train_loss': '1.71634'}; time used = 1.0397276878356934s
epoch 20: {'train_loss': '1.50358'}; time used = 1.1401827335357666s
epoch 25: {'train_loss': '1.48431'}; time used = 1.1454036235809326s
epoch 30: {'train_loss': '1.33714'}; time used = 0.9870724678039551s
epoch 35: {'train_loss': '1.27850'}; time used = 0.94407057762146s
epoch 40: {'train_loss': '1.23985'}; time used = 1.0869803428649902s
epoch 45: {'train_loss': '1.17744'}; time used = 1.1775109767913818s
epoch 50: {'train_loss': '1.03336'}; time used = 0.9435350894927979s
epoch 55: {'train_loss': '1.16005'}; time used = 1.079930067062378s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.173543214797974.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.64279'}; time used = 1.7910757064819336s
epoch 10: {'train_loss': '2.44709'}; time used = 1.395742654800415s
epoch 15: {'train_loss': '2.39500'}; time used = 0.9488131999969482s
epoch 20: {'train_loss': '2.34729'}; time used = 0.9766438007354736s
epoch 25: {'train_loss': '2.25441'}; time used = 0.9455265998840332s
epoch 30: {'train_loss': '2.04039'}; time used = 1.1428284645080566s
epoch 35: {'train_loss': '2.47443'}; time used = 1.1756298542022705s
epoch 40: {'train_loss': '1.97988'}; time used = 1.1328456401824951s
epoch 45: {'train_loss': '1.80982'}; time used = 1.140831470489502s
epoch 50: {'train_loss': '1.92144'}; time used = 1.053231954574585s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.849052906036377.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36076'}; time used = 5.501770973205566s
epoch 10: {'train_loss': '1.30063'}; time used = 1.808992862701416s
epoch 15: {'train_loss': '1.24125'}; time used = 1.7353086471557617s
epoch 20: {'train_loss': '1.14359'}; time used = 1.7660326957702637s
epoch 25: {'train_loss': '0.91346'}; time used = 1.8517136573791504s
epoch 30: {'train_loss': '0.75315'}; time used = 1.6890625953674316s
epoch 35: {'train_loss': '0.53139'}; time used = 2.0357284545898438s
epoch 40: {'train_loss': '0.48088'}; time used = 3.5158939361572266s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.04489254951477.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.44454'}; time used = 7.881808280944824s
epoch 10: {'train_loss': '2.85409'}; time used = 7.343246936798096s
epoch 15: {'train_loss': '2.85009'}; time used = 7.379962682723999s
epoch 20: {'train_loss': '2.85170'}; time used = 7.679116487503052s
epoch 25: {'train_loss': '2.82460'}; time used = 10.009462356567383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.45954251289368.
Training classifier using 80.00% nodes...
{'micro': 0.49, 'macro': 0.46680100649921413, 'samples': 0.49, 'weighted': 0.46103227042188477, 'accuracy': 0.49}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.43949'}; time used = 1.2569043636322021s
epoch 10: {'train_loss': '0.26965'}; time used = 0.9701247215270996s
epoch 15: {'train_loss': '0.28920'}; time used = 1.295875072479248s
epoch 20: {'train_loss': '0.26665'}; time used = 1.8014178276062012s
epoch 25: {'train_loss': '0.30384'}; time used = 0.9498751163482666s
epoch 30: {'train_loss': '0.24368'}; time used = 1.0264902114868164s
epoch 35: {'train_loss': '0.27754'}; time used = 1.215698480606079s
epoch 40: {'train_loss': '0.21971'}; time used = 1.156879186630249s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.439600944519043.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.15109'}; time used = 1.1798644065856934s
epoch 10: {'train_loss': '2.81316'}; time used = 0.9309139251708984s
epoch 15: {'train_loss': '2.67057'}; time used = 0.9348580837249756s
epoch 20: {'train_loss': '2.49759'}; time used = 0.8989441394805908s
epoch 25: {'train_loss': '2.06840'}; time used = 0.9583935737609863s
epoch 30: {'train_loss': '1.57022'}; time used = 0.9526941776275635s
epoch 35: {'train_loss': '1.42054'}; time used = 1.094956874847412s
epoch 40: {'train_loss': '1.32235'}; time used = 1.009139060974121s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.474515438079834.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84171'}; time used = 1.962165355682373s
epoch 10: {'train_loss': '2.77201'}; time used = 1.9990451335906982s
epoch 15: {'train_loss': '2.79398'}; time used = 1.943915843963623s
epoch 20: {'train_loss': '2.78252'}; time used = 3.1739537715911865s
epoch 25: {'train_loss': '2.77055'}; time used = 3.3209798336029053s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.006579399108887.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.26285'}; time used = 8.71321153640747s
epoch 10: {'train_loss': '0.98495'}; time used = 7.794489860534668s
epoch 15: {'train_loss': '0.49483'}; time used = 7.30355167388916s
epoch 20: {'train_loss': '0.21029'}; time used = 8.974713802337646s
epoch 25: {'train_loss': '0.19382'}; time used = 8.730700969696045s
epoch 30: {'train_loss': '0.31061'}; time used = 7.395714044570923s
epoch 35: {'train_loss': '0.03786'}; time used = 8.861992597579956s
epoch 40: {'train_loss': '0.06400'}; time used = 7.792877197265625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 97.0406756401062.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44062727286437714, 'samples': 0.5066666666666667, 'weighted': 0.43096777671234404, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.20592'}; time used = 1.018183946609497s
epoch 10: {'train_loss': '0.54686'}; time used = 0.9625084400177002s
epoch 15: {'train_loss': '0.19122'}; time used = 0.9969074726104736s
epoch 20: {'train_loss': '0.07863'}; time used = 0.9654285907745361s
epoch 25: {'train_loss': '0.03969'}; time used = 1.0423376560211182s
epoch 30: {'train_loss': '0.03526'}; time used = 0.9391591548919678s
epoch 35: {'train_loss': '0.02553'}; time used = 0.9950723648071289s
epoch 40: {'train_loss': '0.01936'}; time used = 0.9394783973693848s
epoch 45: {'train_loss': '0.01135'}; time used = 0.9613838195800781s
epoch 50: {'train_loss': '0.00437'}; time used = 0.9440889358520508s
epoch 55: {'train_loss': '0.00237'}; time used = 1.1639344692230225s
epoch 60: {'train_loss': '0.00236'}; time used = 0.9606797695159912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.533891677856445.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.28102'}; time used = 9.385803937911987s
epoch 10: {'train_loss': '1.08024'}; time used = 7.092859745025635s
epoch 15: {'train_loss': '0.54303'}; time used = 7.49148964881897s
epoch 20: {'train_loss': '0.48067'}; time used = 7.7820844650268555s
epoch 25: {'train_loss': '0.25754'}; time used = 8.273504972457886s
epoch 30: {'train_loss': '0.11256'}; time used = 7.043917894363403s
epoch 35: {'train_loss': '0.01606'}; time used = 7.075496435165405s
epoch 40: {'train_loss': '0.02386'}; time used = 7.325811386108398s
epoch 45: {'train_loss': '0.87383'}; time used = 8.939380168914795s
epoch 50: {'train_loss': '0.20077'}; time used = 7.324742317199707s
epoch 55: {'train_loss': '0.24892'}; time used = 8.066869258880615s
epoch 60: {'train_loss': '0.10955'}; time used = 7.349827289581299s
epoch 65: {'train_loss': '0.50105'}; time used = 8.31204342842102s
epoch 70: {'train_loss': '0.16726'}; time used = 7.240686655044556s
epoch 75: {'train_loss': '0.20318'}; time used = 7.386483907699585s
epoch 80: {'train_loss': '0.26409'}; time used = 7.87335467338562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 140.21288013458252.
Training classifier using 80.00% nodes...
{'micro': 0.5, 'macro': 0.4900246181442129, 'samples': 0.5, 'weighted': 0.48585019538936025, 'accuracy': 0.5}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36988'}; time used = 1.1916797161102295s
epoch 10: {'train_loss': '1.35673'}; time used = 2.351088285446167s
epoch 15: {'train_loss': '1.26974'}; time used = 2.9080970287323s
epoch 20: {'train_loss': '1.32844'}; time used = 1.2346599102020264s
epoch 25: {'train_loss': '1.15661'}; time used = 0.9999022483825684s
epoch 30: {'train_loss': '1.27402'}; time used = 1.2467269897460938s
epoch 35: {'train_loss': '1.28551'}; time used = 1.042626142501831s
epoch 40: {'train_loss': '1.22245'}; time used = 1.2792820930480957s
epoch 45: {'train_loss': '1.09085'}; time used = 1.888167381286621s
epoch 50: {'train_loss': '1.13583'}; time used = 1.00881028175354s
epoch 55: {'train_loss': '1.31007'}; time used = 0.9875383377075195s
epoch 60: {'train_loss': '1.25936'}; time used = 1.140214443206787s
epoch 65: {'train_loss': '1.17574'}; time used = 1.0180118083953857s
epoch 70: {'train_loss': '1.24496'}; time used = 0.9647970199584961s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.758129119873047.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38919'}; time used = 1.8003795146942139s
epoch 10: {'train_loss': '1.31047'}; time used = 1.7720892429351807s
epoch 15: {'train_loss': '1.26423'}; time used = 1.9582066535949707s
epoch 20: {'train_loss': '1.29330'}; time used = 1.855449914932251s
epoch 25: {'train_loss': '1.17484'}; time used = 1.8612453937530518s
epoch 30: {'train_loss': '1.07679'}; time used = 1.8171045780181885s
epoch 35: {'train_loss': '1.21238'}; time used = 1.7131292819976807s
epoch 40: {'train_loss': '1.10214'}; time used = 1.7353427410125732s
epoch 45: {'train_loss': '1.18542'}; time used = 1.7839179039001465s
epoch 50: {'train_loss': '1.14039'}; time used = 1.8129162788391113s
epoch 55: {'train_loss': '1.01561'}; time used = 1.7563371658325195s
epoch 60: {'train_loss': '1.06376'}; time used = 1.8089594841003418s
epoch 65: {'train_loss': '1.21080'}; time used = 1.882585048675537s
epoch 70: {'train_loss': '1.12662'}; time used = 1.7436912059783936s
epoch 75: {'train_loss': '1.36662'}; time used = 2.1359949111938477s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.16820502281189.
Training classifier using 80.00% nodes...
{'micro': 0.4492753623188406, 'macro': 0.4349137931034483, 'samples': 0.4492753623188406, 'weighted': 0.4414417791104448, 'accuracy': 0.4492753623188406}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80997'}; time used = 2.303727865219116s
epoch 10: {'train_loss': '2.78055'}; time used = 1.9260892868041992s
epoch 15: {'train_loss': '2.77634'}; time used = 1.852245807647705s
epoch 20: {'train_loss': '2.77140'}; time used = 1.7838075160980225s
epoch 25: {'train_loss': '2.76572'}; time used = 1.8771755695343018s
epoch 30: {'train_loss': '2.75888'}; time used = 2.0373311042785645s
epoch 35: {'train_loss': '2.75934'}; time used = 1.9286963939666748s
epoch 40: {'train_loss': '2.75559'}; time used = 1.981651782989502s
epoch 45: {'train_loss': '2.75006'}; time used = 1.8949317932128906s
epoch 50: {'train_loss': '2.75154'}; time used = 1.8957912921905518s
epoch 55: {'train_loss': '2.75078'}; time used = 1.8535823822021484s
epoch 60: {'train_loss': '2.74607'}; time used = 2.278169870376587s
epoch 65: {'train_loss': '2.74274'}; time used = 2.0323657989501953s
epoch 70: {'train_loss': '2.73505'}; time used = 1.849588394165039s
epoch 75: {'train_loss': '2.73119'}; time used = 1.970200538635254s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.93739461898804.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83281'}; time used = 5.954755544662476s
epoch 10: {'train_loss': '2.80258'}; time used = 6.284147500991821s
epoch 15: {'train_loss': '2.78871'}; time used = 6.668524265289307s
epoch 20: {'train_loss': '2.78033'}; time used = 9.271406650543213s
epoch 25: {'train_loss': '2.77541'}; time used = 6.043632745742798s
epoch 30: {'train_loss': '2.77317'}; time used = 6.51096248626709s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.95729899406433.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.45356186651367375, 'samples': 0.46, 'weighted': 0.45224072480397787, 'accuracy': 0.46}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78244'}; time used = 1.4529790878295898s
epoch 10: {'train_loss': '2.67641'}; time used = 1.9618427753448486s
epoch 15: {'train_loss': '2.53617'}; time used = 1.691507339477539s
epoch 20: {'train_loss': '2.35353'}; time used = 1.7830638885498047s
epoch 25: {'train_loss': '2.24056'}; time used = 1.752126932144165s
epoch 30: {'train_loss': '2.12600'}; time used = 1.8455240726470947s
epoch 35: {'train_loss': '2.04446'}; time used = 1.4573354721069336s
epoch 40: {'train_loss': '2.20147'}; time used = 0.9861397743225098s
epoch 45: {'train_loss': '2.19829'}; time used = 1.0125727653503418s
epoch 50: {'train_loss': '2.05453'}; time used = 0.9665601253509521s
epoch 55: {'train_loss': '1.96463'}; time used = 1.0169322490692139s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.31513214111328.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.24717'}; time used = 2.4062340259552s
epoch 10: {'train_loss': '1.17426'}; time used = 1.6976397037506104s
epoch 15: {'train_loss': '1.14437'}; time used = 1.528028964996338s
epoch 20: {'train_loss': '1.09879'}; time used = 1.611961841583252s
epoch 25: {'train_loss': '1.04810'}; time used = 1.5965559482574463s
epoch 30: {'train_loss': '1.01622'}; time used = 1.69289231300354s
epoch 35: {'train_loss': '0.98549'}; time used = 1.587402105331421s
epoch 40: {'train_loss': '0.74950'}; time used = 1.6084434986114502s
epoch 45: {'train_loss': '0.48018'}; time used = 1.9579260349273682s
epoch 50: {'train_loss': '0.45961'}; time used = 1.7744865417480469s
epoch 55: {'train_loss': '0.29787'}; time used = 1.9787192344665527s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.086827993392944.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.12543'}; time used = 2.351802349090576s
epoch 10: {'train_loss': '0.19978'}; time used = 1.7433147430419922s
epoch 15: {'train_loss': '0.00599'}; time used = 1.7693228721618652s
epoch 20: {'train_loss': '0.04477'}; time used = 1.7450754642486572s
epoch 25: {'train_loss': '0.04610'}; time used = 2.0030171871185303s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.009574890136719.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84101'}; time used = 1.3285715579986572s
epoch 10: {'train_loss': '2.71585'}; time used = 1.0473437309265137s
epoch 15: {'train_loss': '2.62508'}; time used = 1.0450704097747803s
epoch 20: {'train_loss': '2.56273'}; time used = 1.0621140003204346s
epoch 25: {'train_loss': '2.49246'}; time used = 1.624230146408081s
epoch 30: {'train_loss': '2.43201'}; time used = 1.38319730758667s
epoch 35: {'train_loss': '2.39683'}; time used = 1.0444254875183105s
epoch 40: {'train_loss': '2.35278'}; time used = 1.0056893825531006s
epoch 45: {'train_loss': '2.30498'}; time used = 1.0173625946044922s
epoch 50: {'train_loss': '2.26612'}; time used = 1.1331307888031006s
epoch 55: {'train_loss': '2.28221'}; time used = 1.1018764972686768s
epoch 60: {'train_loss': '2.23946'}; time used = 1.1387901306152344s
epoch 65: {'train_loss': '2.18459'}; time used = 1.0382795333862305s
epoch 70: {'train_loss': '2.18865'}; time used = 1.042881727218628s
epoch 75: {'train_loss': '2.15002'}; time used = 1.0473597049713135s
epoch 80: {'train_loss': '2.22176'}; time used = 1.0102717876434326s
epoch 85: {'train_loss': '2.19295'}; time used = 1.0534873008728027s
epoch 90: {'train_loss': '2.17943'}; time used = 1.1498134136199951s
epoch 95: {'train_loss': '2.11234'}; time used = 1.185361385345459s
epoch 100: {'train_loss': '2.12202'}; time used = 1.1554038524627686s
epoch 105: {'train_loss': '2.10061'}; time used = 1.1899001598358154s
epoch 110: {'train_loss': '2.07397'}; time used = 1.1707065105438232s
epoch 115: {'train_loss': '2.03950'}; time used = 1.882727861404419s
epoch 120: {'train_loss': '2.05294'}; time used = 1.9780144691467285s
epoch 125: {'train_loss': '2.07949'}; time used = 1.0452790260314941s
epoch 130: {'train_loss': '2.02342'}; time used = 0.9582638740539551s
epoch 135: {'train_loss': '2.05273'}; time used = 0.9376325607299805s
epoch 140: {'train_loss': '2.03445'}; time used = 1.1005163192749023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.6629433631897.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05402'}; time used = 6.88528037071228s
epoch 10: {'train_loss': '2.78257'}; time used = 6.57932448387146s
epoch 15: {'train_loss': '2.80728'}; time used = 6.686633586883545s
epoch 20: {'train_loss': '2.79384'}; time used = 6.829943895339966s
epoch 25: {'train_loss': '2.77301'}; time used = 7.327033281326294s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.94687509536743.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.45661375661375664, 'samples': 0.4633333333333333, 'weighted': 0.45258201058201064, 'accuracy': 0.4633333333333333}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02360'}; time used = 1.7744224071502686s
epoch 10: {'train_loss': '0.99432'}; time used = 1.9575796127319336s
epoch 15: {'train_loss': '1.00324'}; time used = 1.716914176940918s
epoch 20: {'train_loss': '0.97274'}; time used = 1.6602191925048828s
epoch 25: {'train_loss': '0.86243'}; time used = 1.6739706993103027s
epoch 30: {'train_loss': '0.86893'}; time used = 1.5394749641418457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.592133522033691.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.623109243697479, 'samples': 0.6231884057971014, 'weighted': 0.6227134331993668, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.36122'}; time used = 1.946751356124878s
epoch 10: {'train_loss': '1.30033'}; time used = 1.9208588600158691s
epoch 15: {'train_loss': '1.33895'}; time used = 1.88161301612854s
epoch 20: {'train_loss': '1.37711'}; time used = 1.8512568473815918s
epoch 25: {'train_loss': '1.28491'}; time used = 1.9168689250946045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.476115942001343.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5446029380455609, 'samples': 0.5507246376811594, 'weighted': 0.5484290003178098, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76895'}; time used = 1.8425474166870117s
epoch 10: {'train_loss': '2.74339'}; time used = 1.6629209518432617s
epoch 15: {'train_loss': '2.72106'}; time used = 2.398942708969116s
epoch 20: {'train_loss': '2.69925'}; time used = 2.874488592147827s
epoch 25: {'train_loss': '2.67149'}; time used = 1.62461256980896s
epoch 30: {'train_loss': '2.65129'}; time used = 1.6463706493377686s
epoch 35: {'train_loss': '2.64308'}; time used = 1.5250473022460938s
epoch 40: {'train_loss': '2.62733'}; time used = 1.5281634330749512s
epoch 45: {'train_loss': '2.60506'}; time used = 1.7428784370422363s
epoch 50: {'train_loss': '2.57822'}; time used = 1.6455631256103516s
epoch 55: {'train_loss': '2.57227'}; time used = 1.594113826751709s
epoch 60: {'train_loss': '2.55666'}; time used = 1.6083409786224365s
epoch 65: {'train_loss': '2.52314'}; time used = 1.5519115924835205s
epoch 70: {'train_loss': '2.48454'}; time used = 1.6136815547943115s
epoch 75: {'train_loss': '2.46328'}; time used = 2.375230073928833s
epoch 80: {'train_loss': '2.42216'}; time used = 1.6125061511993408s
epoch 85: {'train_loss': '2.42562'}; time used = 1.5470821857452393s
epoch 90: {'train_loss': '2.41790'}; time used = 1.5308895111083984s
epoch 95: {'train_loss': '2.40551'}; time used = 1.5275492668151855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.323320388793945.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77051'}; time used = 1.2365782260894775s
epoch 10: {'train_loss': '2.79333'}; time used = 1.0455937385559082s
epoch 15: {'train_loss': '2.71861'}; time used = 1.0329539775848389s
epoch 20: {'train_loss': '2.42166'}; time used = 1.073575735092163s
epoch 25: {'train_loss': '1.85531'}; time used = 1.1367578506469727s
epoch 30: {'train_loss': '1.92331'}; time used = 1.000396728515625s
epoch 35: {'train_loss': '1.70951'}; time used = 1.0274345874786377s
epoch 40: {'train_loss': '1.64813'}; time used = 0.9919040203094482s
epoch 45: {'train_loss': '1.57795'}; time used = 1.004371166229248s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.051573276519775.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.92953'}; time used = 1.6440668106079102s
epoch 10: {'train_loss': '2.80842'}; time used = 1.586395263671875s
epoch 15: {'train_loss': '2.76153'}; time used = 1.641334056854248s
epoch 20: {'train_loss': '2.71295'}; time used = 2.7345569133758545s
epoch 25: {'train_loss': '2.66646'}; time used = 2.4668383598327637s
epoch 30: {'train_loss': '2.62971'}; time used = 1.8443706035614014s
epoch 35: {'train_loss': '2.61171'}; time used = 1.5834989547729492s
epoch 40: {'train_loss': '2.58896'}; time used = 1.7822868824005127s
epoch 45: {'train_loss': '2.55581'}; time used = 1.7225923538208008s
epoch 50: {'train_loss': '2.52016'}; time used = 1.6669254302978516s
epoch 55: {'train_loss': '2.52282'}; time used = 1.657485008239746s
epoch 60: {'train_loss': '2.51826'}; time used = 1.550769329071045s
epoch 65: {'train_loss': '2.49128'}; time used = 1.5229477882385254s
epoch 70: {'train_loss': '2.45635'}; time used = 1.5294625759124756s
epoch 75: {'train_loss': '2.43265'}; time used = 1.5249245166778564s
epoch 80: {'train_loss': '2.40407'}; time used = 1.5776658058166504s
epoch 85: {'train_loss': '2.41133'}; time used = 1.549027919769287s
epoch 90: {'train_loss': '2.39321'}; time used = 1.5465130805969238s
epoch 95: {'train_loss': '2.38779'}; time used = 1.6623561382293701s
epoch 100: {'train_loss': '2.36647'}; time used = 1.613405466079712s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.54218006134033.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.18480'}; time used = 1.1662960052490234s
epoch 10: {'train_loss': '2.77633'}; time used = 1.021000623703003s
epoch 15: {'train_loss': '2.62467'}; time used = 1.1508665084838867s
epoch 20: {'train_loss': '2.49339'}; time used = 1.1867787837982178s
epoch 25: {'train_loss': '2.40229'}; time used = 1.0517330169677734s
epoch 30: {'train_loss': '2.33781'}; time used = 1.022712230682373s
epoch 35: {'train_loss': '2.28785'}; time used = 1.0227453708648682s
epoch 40: {'train_loss': '2.24698'}; time used = 1.0226199626922607s
epoch 45: {'train_loss': '2.19859'}; time used = 1.0290443897247314s
epoch 50: {'train_loss': '2.19199'}; time used = 1.0369880199432373s
epoch 55: {'train_loss': '2.12088'}; time used = 1.0371496677398682s
epoch 60: {'train_loss': '2.01833'}; time used = 1.171617031097412s
epoch 65: {'train_loss': '2.30139'}; time used = 1.0248558521270752s
epoch 70: {'train_loss': '1.90247'}; time used = 1.0083506107330322s
epoch 75: {'train_loss': '1.61577'}; time used = 1.0116891860961914s
epoch 80: {'train_loss': '1.61341'}; time used = 1.0161511898040771s
epoch 85: {'train_loss': '1.71444'}; time used = 1.0288796424865723s
epoch 90: {'train_loss': '1.69716'}; time used = 1.022667646408081s
epoch 95: {'train_loss': '1.61917'}; time used = 1.0379629135131836s
epoch 100: {'train_loss': '1.61318'}; time used = 0.9843316078186035s
epoch 105: {'train_loss': '1.66615'}; time used = 1.0554559230804443s
epoch 110: {'train_loss': '1.50713'}; time used = 1.1652510166168213s
epoch 115: {'train_loss': '1.76998'}; time used = 1.1889846324920654s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.351531267166138.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.15962'}; time used = 2.049417734146118s
epoch 10: {'train_loss': '2.88797'}; time used = 1.9122908115386963s
epoch 15: {'train_loss': '2.79712'}; time used = 1.817716360092163s
epoch 20: {'train_loss': '2.77436'}; time used = 2.143012523651123s
epoch 25: {'train_loss': '2.78510'}; time used = 1.9202179908752441s
epoch 30: {'train_loss': '2.77329'}; time used = 1.8460559844970703s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.12407946586609.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5063131313131313, 'samples': 0.5072463768115942, 'weighted': 0.5078685404772362, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33809'}; time used = 2.1298153400421143s
epoch 10: {'train_loss': '1.26638'}; time used = 1.9903829097747803s
epoch 15: {'train_loss': '1.23918'}; time used = 2.0174620151519775s
epoch 20: {'train_loss': '1.18003'}; time used = 2.168834686279297s
epoch 25: {'train_loss': '1.04870'}; time used = 2.099882125854492s
epoch 30: {'train_loss': '0.76546'}; time used = 1.9809930324554443s
epoch 35: {'train_loss': '0.68985'}; time used = 1.9746534824371338s
epoch 40: {'train_loss': '0.68255'}; time used = 1.9474942684173584s
epoch 45: {'train_loss': '0.50846'}; time used = 1.9161906242370605s
epoch 50: {'train_loss': '0.41127'}; time used = 2.0153791904449463s
epoch 55: {'train_loss': '0.23317'}; time used = 2.0537116527557373s
epoch 60: {'train_loss': '0.30163'}; time used = 1.9379451274871826s
epoch 65: {'train_loss': '0.19642'}; time used = 2.03371262550354s
epoch 70: {'train_loss': '0.39257'}; time used = 2.0511651039123535s
epoch 75: {'train_loss': '0.14882'}; time used = 2.324301242828369s
epoch 80: {'train_loss': '0.06986'}; time used = 3.42885422706604s
epoch 85: {'train_loss': '0.03927'}; time used = 3.391376256942749s
epoch 90: {'train_loss': '0.02518'}; time used = 2.7356019020080566s
epoch 95: {'train_loss': '0.03940'}; time used = 2.0049757957458496s
epoch 100: {'train_loss': '0.11150'}; time used = 1.954075813293457s
epoch 105: {'train_loss': '0.00803'}; time used = 2.1500282287597656s
epoch 110: {'train_loss': '0.03265'}; time used = 1.9343044757843018s
epoch 115: {'train_loss': '0.00530'}; time used = 1.9402077198028564s
epoch 120: {'train_loss': '0.00561'}; time used = 1.9397783279418945s
epoch 125: {'train_loss': '0.01424'}; time used = 1.9211483001708984s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 57.09041714668274.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.34561'}; time used = 1.061816692352295s
epoch 10: {'train_loss': '1.33175'}; time used = 0.9371674060821533s
epoch 15: {'train_loss': '1.16629'}; time used = 0.9540205001831055s
epoch 20: {'train_loss': '1.02726'}; time used = 0.9352753162384033s
epoch 25: {'train_loss': '0.81883'}; time used = 0.9714767932891846s
epoch 30: {'train_loss': '0.83625'}; time used = 0.9480865001678467s
epoch 35: {'train_loss': '0.73176'}; time used = 0.9564056396484375s
epoch 40: {'train_loss': '0.65280'}; time used = 0.9413895606994629s
epoch 45: {'train_loss': '0.45527'}; time used = 0.9612016677856445s
epoch 50: {'train_loss': '0.67085'}; time used = 0.979111909866333s
epoch 55: {'train_loss': '0.31496'}; time used = 0.9487009048461914s
epoch 60: {'train_loss': '0.41956'}; time used = 0.962960958480835s
epoch 65: {'train_loss': '1.15563'}; time used = 1.0480797290802002s
epoch 70: {'train_loss': '0.62061'}; time used = 0.9439914226531982s
epoch 75: {'train_loss': '0.68915'}; time used = 0.9430880546569824s
epoch 80: {'train_loss': '0.50059'}; time used = 0.9371316432952881s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.697319507598877.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.23635'}; time used = 1.4368245601654053s
epoch 10: {'train_loss': '1.76339'}; time used = 1.326070785522461s
epoch 15: {'train_loss': '1.37960'}; time used = 1.309432029724121s
epoch 20: {'train_loss': '1.40762'}; time used = 1.2930545806884766s
epoch 25: {'train_loss': '1.37758'}; time used = 1.313584804534912s
epoch 30: {'train_loss': '1.49641'}; time used = 1.5409038066864014s
epoch 35: {'train_loss': '1.36253'}; time used = 2.748074531555176s
epoch 40: {'train_loss': '1.36068'}; time used = 1.134495735168457s
epoch 45: {'train_loss': '1.22136'}; time used = 1.0896251201629639s
epoch 50: {'train_loss': '1.13295'}; time used = 1.142488956451416s
epoch 55: {'train_loss': '1.38834'}; time used = 1.3253498077392578s
epoch 60: {'train_loss': '1.37867'}; time used = 1.3204131126403809s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.95734167098999.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5438596491228069, 'samples': 0.6578947368421053, 'weighted': 0.579870729455217, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83427'}; time used = 1.8596763610839844s
epoch 10: {'train_loss': '2.76012'}; time used = 1.7092740535736084s
epoch 15: {'train_loss': '2.75160'}; time used = 1.5876591205596924s
epoch 20: {'train_loss': '2.73749'}; time used = 1.6555299758911133s
epoch 25: {'train_loss': '2.71292'}; time used = 1.7557094097137451s
epoch 30: {'train_loss': '2.65667'}; time used = 1.7712388038635254s
epoch 35: {'train_loss': '2.59486'}; time used = 1.7885043621063232s
epoch 40: {'train_loss': '2.54101'}; time used = 1.8415050506591797s
epoch 45: {'train_loss': '2.51356'}; time used = 1.6644489765167236s
epoch 50: {'train_loss': '2.48693'}; time used = 1.6627318859100342s
epoch 55: {'train_loss': '2.47844'}; time used = 1.8004734516143799s
epoch 60: {'train_loss': '2.46261'}; time used = 1.9186458587646484s
epoch 65: {'train_loss': '2.44483'}; time used = 1.9128518104553223s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.81052017211914.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.38258'}; time used = 1.2417988777160645s
epoch 10: {'train_loss': '1.38953'}; time used = 1.022559404373169s
epoch 15: {'train_loss': '1.32397'}; time used = 0.9863066673278809s
epoch 20: {'train_loss': '1.34949'}; time used = 1.0941457748413086s
epoch 25: {'train_loss': '1.28711'}; time used = 0.991863489151001s
epoch 30: {'train_loss': '1.26874'}; time used = 0.9906342029571533s
epoch 35: {'train_loss': '1.19288'}; time used = 1.0904009342193604s
epoch 40: {'train_loss': '1.04312'}; time used = 1.0151631832122803s
epoch 45: {'train_loss': '0.93490'}; time used = 1.007725477218628s
epoch 50: {'train_loss': '1.09181'}; time used = 1.0330088138580322s
epoch 55: {'train_loss': '1.17681'}; time used = 1.0409197807312012s
epoch 60: {'train_loss': '0.97543'}; time used = 1.0394790172576904s
epoch 65: {'train_loss': '0.76948'}; time used = 1.0985181331634521s
epoch 70: {'train_loss': '0.68660'}; time used = 1.0868384838104248s
epoch 75: {'train_loss': '0.80486'}; time used = 1.1456220149993896s
epoch 80: {'train_loss': '0.61606'}; time used = 0.9771323204040527s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.53828501701355.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78006'}; time used = 1.165802240371704s
epoch 10: {'train_loss': '2.77293'}; time used = 1.0641355514526367s
epoch 15: {'train_loss': '2.77939'}; time used = 1.0756194591522217s
epoch 20: {'train_loss': '2.78122'}; time used = 1.1125526428222656s
epoch 25: {'train_loss': '2.77513'}; time used = 1.060427188873291s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.910924196243286.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83360'}; time used = 5.159897089004517s
epoch 10: {'train_loss': '2.80314'}; time used = 4.963230848312378s
epoch 15: {'train_loss': '2.78897'}; time used = 5.170504093170166s
epoch 20: {'train_loss': '2.77956'}; time used = 4.904439210891724s
epoch 25: {'train_loss': '2.77405'}; time used = 5.036584138870239s
epoch 30: {'train_loss': '2.77181'}; time used = 4.913464546203613s
epoch 35: {'train_loss': '2.77119'}; time used = 4.882764101028442s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.2870090007782.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.72997299729973, 'samples': 0.73, 'weighted': 0.72991899189919, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.69714'}; time used = 1.62483549118042s
epoch 10: {'train_loss': '2.63683'}; time used = 1.7276747226715088s
epoch 15: {'train_loss': '2.63180'}; time used = 1.6837821006774902s
epoch 20: {'train_loss': '2.59617'}; time used = 1.6642014980316162s
epoch 25: {'train_loss': '2.57458'}; time used = 1.729038953781128s
epoch 30: {'train_loss': '2.54241'}; time used = 1.6923701763153076s
epoch 35: {'train_loss': '2.51222'}; time used = 1.6714980602264404s
epoch 40: {'train_loss': '2.47209'}; time used = 1.6689527034759521s
epoch 45: {'train_loss': '2.46425'}; time used = 1.6661195755004883s
epoch 50: {'train_loss': '2.44956'}; time used = 1.671025276184082s
epoch 55: {'train_loss': '2.41645'}; time used = 1.7549238204956055s
epoch 60: {'train_loss': '2.40494'}; time used = 1.7188830375671387s
epoch 65: {'train_loss': '2.39865'}; time used = 1.6519830226898193s
epoch 70: {'train_loss': '2.32276'}; time used = 1.6767067909240723s
epoch 75: {'train_loss': '2.31542'}; time used = 1.6790502071380615s
epoch 80: {'train_loss': '2.31043'}; time used = 1.8377668857574463s
epoch 85: {'train_loss': '2.29378'}; time used = 1.6586782932281494s
epoch 90: {'train_loss': '2.29170'}; time used = 1.6987953186035156s
epoch 95: {'train_loss': '2.40818'}; time used = 1.6896045207977295s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.08351254463196.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87262'}; time used = 1.8643245697021484s
epoch 10: {'train_loss': '2.82200'}; time used = 1.9147419929504395s
epoch 15: {'train_loss': '2.78814'}; time used = 1.83367919921875s
epoch 20: {'train_loss': '2.77074'}; time used = 1.8337082862854004s
epoch 25: {'train_loss': '2.77031'}; time used = 1.866598129272461s
epoch 30: {'train_loss': '2.76924'}; time used = 1.9723200798034668s
epoch 35: {'train_loss': '2.76511'}; time used = 1.8453736305236816s
epoch 40: {'train_loss': '2.76486'}; time used = 1.8353259563446045s
epoch 45: {'train_loss': '2.76368'}; time used = 2.0506529808044434s
epoch 50: {'train_loss': '2.76081'}; time used = 2.05316162109375s
epoch 55: {'train_loss': '2.75997'}; time used = 1.7611420154571533s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.5253427028656.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.47550675675675674, 'samples': 0.4782608695652174, 'weighted': 0.4782608695652174, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05935'}; time used = 1.7036757469177246s
epoch 10: {'train_loss': '2.81804'}; time used = 1.6181504726409912s
epoch 15: {'train_loss': '2.74370'}; time used = 1.6809296607971191s
epoch 20: {'train_loss': '2.75128'}; time used = 1.737877607345581s
epoch 25: {'train_loss': '2.73684'}; time used = 2.0213370323181152s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.830652713775635.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.35826'}; time used = 4.724855661392212s
epoch 10: {'train_loss': '1.35697'}; time used = 4.532527446746826s
epoch 15: {'train_loss': '1.17491'}; time used = 4.618678569793701s
epoch 20: {'train_loss': '1.14654'}; time used = 4.414666175842285s
epoch 25: {'train_loss': '1.02999'}; time used = 4.759005308151245s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.20506978034973.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7300000000000001, 'samples': 0.73, 'weighted': 0.73, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05782'}; time used = 1.5218584537506104s
epoch 10: {'train_loss': '0.47206'}; time used = 1.50654935836792s
epoch 15: {'train_loss': '0.30918'}; time used = 1.7243123054504395s
epoch 20: {'train_loss': '0.28501'}; time used = 1.7819793224334717s
epoch 25: {'train_loss': '0.30347'}; time used = 1.749727725982666s
epoch 30: {'train_loss': '0.31210'}; time used = 1.622131109237671s
epoch 35: {'train_loss': '0.29449'}; time used = 1.6346514225006104s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.035181999206543.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86531'}; time used = 2.3796920776367188s
epoch 10: {'train_loss': '2.81687'}; time used = 2.094714403152466s
epoch 15: {'train_loss': '2.79006'}; time used = 2.3235580921173096s
epoch 20: {'train_loss': '2.77328'}; time used = 1.9693653583526611s
epoch 25: {'train_loss': '2.77227'}; time used = 0.9822900295257568s
epoch 30: {'train_loss': '2.77291'}; time used = 0.9773383140563965s
epoch 35: {'train_loss': '2.77111'}; time used = 1.0360314846038818s
epoch 40: {'train_loss': '2.76897'}; time used = 0.9529025554656982s
epoch 45: {'train_loss': '2.76673'}; time used = 0.9630298614501953s
epoch 50: {'train_loss': '2.76058'}; time used = 1.1164579391479492s
epoch 55: {'train_loss': '2.75010'}; time used = 0.9267072677612305s
epoch 60: {'train_loss': '2.73779'}; time used = 0.9475159645080566s
epoch 65: {'train_loss': '2.71067'}; time used = 1.1132197380065918s
epoch 70: {'train_loss': '2.64526'}; time used = 0.9735939502716064s
epoch 75: {'train_loss': '2.61161'}; time used = 0.9707796573638916s
epoch 80: {'train_loss': '2.53968'}; time used = 0.9663982391357422s
epoch 85: {'train_loss': '2.57008'}; time used = 0.9559588432312012s
epoch 90: {'train_loss': '2.53950'}; time used = 0.9984726905822754s
epoch 95: {'train_loss': '2.50882'}; time used = 1.0365567207336426s
epoch 100: {'train_loss': '2.47232'}; time used = 0.9809885025024414s
epoch 105: {'train_loss': '2.48036'}; time used = 0.9895365238189697s
epoch 110: {'train_loss': '2.39998'}; time used = 0.948314905166626s
epoch 115: {'train_loss': '2.43106'}; time used = 1.037804365158081s
epoch 120: {'train_loss': '2.45606'}; time used = 0.9449152946472168s
epoch 125: {'train_loss': '2.43056'}; time used = 0.9491062164306641s
epoch 130: {'train_loss': '2.44727'}; time used = 0.9701700210571289s
epoch 135: {'train_loss': '2.41142'}; time used = 0.9872825145721436s
epoch 140: {'train_loss': '2.39703'}; time used = 0.9471323490142822s
epoch 145: {'train_loss': '2.36459'}; time used = 0.9503481388092041s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.51109600067139.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31412'}; time used = 2.2537975311279297s
epoch 10: {'train_loss': '1.06080'}; time used = 2.296715497970581s
epoch 15: {'train_loss': '0.77012'}; time used = 2.326887607574463s
epoch 20: {'train_loss': '0.47989'}; time used = 2.3611366748809814s
epoch 25: {'train_loss': '0.55198'}; time used = 2.450171947479248s
epoch 30: {'train_loss': '0.27356'}; time used = 2.2727103233337402s
epoch 35: {'train_loss': '0.39029'}; time used = 2.220752477645874s
epoch 40: {'train_loss': '0.24256'}; time used = 2.278568744659424s
epoch 45: {'train_loss': '0.60699'}; time used = 2.1348142623901367s
epoch 50: {'train_loss': '0.46014'}; time used = 2.6338467597961426s
epoch 55: {'train_loss': '0.48425'}; time used = 2.246002197265625s
epoch 60: {'train_loss': '0.32286'}; time used = 2.1323812007904053s
epoch 65: {'train_loss': '0.19001'}; time used = 2.1675522327423096s
epoch 70: {'train_loss': '0.34685'}; time used = 2.132906436920166s
epoch 75: {'train_loss': '0.25650'}; time used = 2.219285488128662s
epoch 80: {'train_loss': '0.30207'}; time used = 2.372710704803467s
epoch 85: {'train_loss': '0.16664'}; time used = 2.1647255420684814s
epoch 90: {'train_loss': '0.35770'}; time used = 2.032153844833374s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.243515729904175.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.27971'}; time used = 2.0851268768310547s
epoch 10: {'train_loss': '1.18899'}; time used = 2.022037982940674s
epoch 15: {'train_loss': '1.12310'}; time used = 2.173537492752075s
epoch 20: {'train_loss': '1.11898'}; time used = 3.3300623893737793s
epoch 25: {'train_loss': '1.03041'}; time used = 2.7288405895233154s
epoch 30: {'train_loss': '0.86407'}; time used = 2.0680477619171143s
epoch 35: {'train_loss': '0.93068'}; time used = 2.2802772521972656s
epoch 40: {'train_loss': '0.75308'}; time used = 2.0614607334136963s
epoch 45: {'train_loss': '0.76075'}; time used = 1.9977390766143799s
epoch 50: {'train_loss': '0.68938'}; time used = 2.071558952331543s
epoch 55: {'train_loss': '0.44588'}; time used = 2.1669418811798096s
epoch 60: {'train_loss': '0.46566'}; time used = 4.579298257827759s
epoch 65: {'train_loss': '0.54749'}; time used = 2.52213978767395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.99618220329285.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6805555555555556, 'samples': 0.6811594202898551, 'weighted': 0.6815619967793881, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37833'}; time used = 2.099083423614502s
epoch 10: {'train_loss': '1.29321'}; time used = 1.9810817241668701s
epoch 15: {'train_loss': '1.18576'}; time used = 2.0392377376556396s
epoch 20: {'train_loss': '1.07595'}; time used = 2.0115182399749756s
epoch 25: {'train_loss': '0.70363'}; time used = 1.9516713619232178s
epoch 30: {'train_loss': '0.51999'}; time used = 1.9202899932861328s
epoch 35: {'train_loss': '0.69582'}; time used = 1.791022777557373s
epoch 40: {'train_loss': '0.66543'}; time used = 1.761098861694336s
epoch 45: {'train_loss': '0.68158'}; time used = 1.7697832584381104s
epoch 50: {'train_loss': '0.57951'}; time used = 1.8319485187530518s
epoch 55: {'train_loss': '0.43911'}; time used = 1.7293965816497803s
epoch 60: {'train_loss': '0.13690'}; time used = 1.7163300514221191s
epoch 65: {'train_loss': '0.19674'}; time used = 3.680793046951294s
epoch 70: {'train_loss': '0.11582'}; time used = 1.8629062175750732s
epoch 75: {'train_loss': '0.04255'}; time used = 2.0756232738494873s
epoch 80: {'train_loss': '0.03941'}; time used = 1.9880785942077637s
epoch 85: {'train_loss': '0.02006'}; time used = 1.9066860675811768s
epoch 90: {'train_loss': '0.02966'}; time used = 1.9376521110534668s
epoch 95: {'train_loss': '0.02008'}; time used = 1.8542473316192627s
epoch 100: {'train_loss': '0.01903'}; time used = 1.926605224609375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.263615131378174.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75571'}; time used = 1.4355831146240234s
epoch 10: {'train_loss': '2.74266'}; time used = 1.2644498348236084s
epoch 15: {'train_loss': '2.70106'}; time used = 1.261491060256958s
epoch 20: {'train_loss': '2.62702'}; time used = 1.3321447372436523s
epoch 25: {'train_loss': '2.50522'}; time used = 1.1252458095550537s
epoch 30: {'train_loss': '2.36089'}; time used = 1.2625391483306885s
epoch 35: {'train_loss': '2.31346'}; time used = 1.3141536712646484s
epoch 40: {'train_loss': '2.23857'}; time used = 1.3315653800964355s
epoch 45: {'train_loss': '2.19777'}; time used = 1.274134635925293s
epoch 50: {'train_loss': '2.18622'}; time used = 1.5457067489624023s
epoch 55: {'train_loss': '2.13804'}; time used = 1.1844861507415771s
epoch 60: {'train_loss': '2.22415'}; time used = 1.2267696857452393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.232943058013916.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.22332'}; time used = 2.1446614265441895s
epoch 10: {'train_loss': '3.08184'}; time used = 2.936066150665283s
epoch 15: {'train_loss': '2.93734'}; time used = 2.9587016105651855s
epoch 20: {'train_loss': '2.82886'}; time used = 3.261432647705078s
epoch 25: {'train_loss': '2.75491'}; time used = 2.01932954788208s
epoch 30: {'train_loss': '2.69459'}; time used = 2.0923619270324707s
epoch 35: {'train_loss': '2.66039'}; time used = 1.8300988674163818s
epoch 40: {'train_loss': '2.60799'}; time used = 1.7918908596038818s
epoch 45: {'train_loss': '2.56905'}; time used = 1.8133628368377686s
epoch 50: {'train_loss': '2.52276'}; time used = 1.8118321895599365s
epoch 55: {'train_loss': '2.51252'}; time used = 1.8564505577087402s
epoch 60: {'train_loss': '2.49985'}; time used = 2.355330467224121s
epoch 65: {'train_loss': '2.47811'}; time used = 1.7809150218963623s
epoch 70: {'train_loss': '2.46197'}; time used = 1.6734325885772705s
epoch 75: {'train_loss': '2.46734'}; time used = 1.679652214050293s
epoch 80: {'train_loss': '2.43961'}; time used = 1.749121904373169s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.20998430252075.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34175'}; time used = 7.929980039596558s
epoch 10: {'train_loss': '1.31182'}; time used = 11.90253758430481s
epoch 15: {'train_loss': '1.22845'}; time used = 8.122502565383911s
epoch 20: {'train_loss': '1.16647'}; time used = 7.578096389770508s
epoch 25: {'train_loss': '0.99447'}; time used = 7.524091482162476s
epoch 30: {'train_loss': '0.92273'}; time used = 9.632908821105957s
epoch 35: {'train_loss': '0.65979'}; time used = 9.100502729415894s
epoch 40: {'train_loss': '0.65878'}; time used = 7.080297231674194s
epoch 45: {'train_loss': '0.77951'}; time used = 7.445434093475342s
epoch 50: {'train_loss': '0.74438'}; time used = 8.491180181503296s
epoch 55: {'train_loss': '0.70819'}; time used = 10.355082273483276s
epoch 60: {'train_loss': '0.57687'}; time used = 12.138131380081177s
epoch 65: {'train_loss': '0.56876'}; time used = 7.24656867980957s
epoch 70: {'train_loss': '0.40916'}; time used = 9.882226943969727s
epoch 75: {'train_loss': '0.33778'}; time used = 9.031970500946045s
epoch 80: {'train_loss': '0.37640'}; time used = 7.164597034454346s
epoch 85: {'train_loss': '0.31902'}; time used = 7.502957105636597s
epoch 90: {'train_loss': '0.30754'}; time used = 7.368808031082153s
epoch 95: {'train_loss': '0.22408'}; time used = 7.610281705856323s
epoch 100: {'train_loss': '0.29779'}; time used = 8.495746612548828s
epoch 105: {'train_loss': '0.20704'}; time used = 9.116084575653076s
epoch 110: {'train_loss': '0.20743'}; time used = 7.768368482589722s
epoch 115: {'train_loss': '0.19781'}; time used = 7.311632394790649s
epoch 120: {'train_loss': '0.09114'}; time used = 7.218679904937744s
epoch 125: {'train_loss': '0.08678'}; time used = 7.236799001693726s
epoch 130: {'train_loss': '0.08220'}; time used = 7.102381944656372s
epoch 135: {'train_loss': '0.15874'}; time used = 7.599912643432617s
epoch 140: {'train_loss': '0.41483'}; time used = 7.591327905654907s
epoch 145: {'train_loss': '0.24868'}; time used = 9.600740194320679s
epoch 150: {'train_loss': '0.14059'}; time used = 8.779878616333008s
epoch 155: {'train_loss': '0.29933'}; time used = 7.273205280303955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 275.44966220855713.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.41875076073007217, 'samples': 0.5066666666666667, 'weighted': 0.4072993490192811, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.84522'}; time used = 0.9631986618041992s
epoch 10: {'train_loss': '0.57955'}; time used = 0.8694047927856445s
epoch 15: {'train_loss': '0.36531'}; time used = 0.8605966567993164s
epoch 20: {'train_loss': '0.27277'}; time used = 0.8923399448394775s
epoch 25: {'train_loss': '0.25718'}; time used = 0.8724281787872314s
epoch 30: {'train_loss': '0.20049'}; time used = 0.9457118511199951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.962447166442871.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.75387'}; time used = 1.9986176490783691s
epoch 10: {'train_loss': '2.70450'}; time used = 2.0860822200775146s
epoch 15: {'train_loss': '2.68465'}; time used = 1.7604384422302246s
epoch 20: {'train_loss': '2.67600'}; time used = 1.872345209121704s
epoch 25: {'train_loss': '2.66542'}; time used = 1.749819040298462s
epoch 30: {'train_loss': '2.65697'}; time used = 1.8032557964324951s
epoch 35: {'train_loss': '2.65355'}; time used = 1.6999993324279785s
epoch 40: {'train_loss': '2.64865'}; time used = 1.7476558685302734s
epoch 45: {'train_loss': '2.64044'}; time used = 1.6912891864776611s
epoch 50: {'train_loss': '2.62456'}; time used = 1.6583514213562012s
epoch 55: {'train_loss': '2.62067'}; time used = 1.835925817489624s
epoch 60: {'train_loss': '2.61959'}; time used = 1.7928640842437744s
epoch 65: {'train_loss': '2.60124'}; time used = 1.9831695556640625s
epoch 70: {'train_loss': '2.58912'}; time used = 1.7114675045013428s
epoch 75: {'train_loss': '2.58160'}; time used = 1.8280408382415771s
epoch 80: {'train_loss': '2.57710'}; time used = 1.970334768295288s
epoch 85: {'train_loss': '2.57831'}; time used = 1.7550017833709717s
epoch 90: {'train_loss': '2.58290'}; time used = 1.835160493850708s
epoch 95: {'train_loss': '2.57871'}; time used = 1.8333113193511963s
epoch 100: {'train_loss': '2.56996'}; time used = 1.9186363220214844s
epoch 105: {'train_loss': '2.57153'}; time used = 1.9058620929718018s
epoch 110: {'train_loss': '2.56856'}; time used = 1.9602324962615967s
epoch 115: {'train_loss': '2.56603'}; time used = 1.720686435699463s
epoch 120: {'train_loss': '2.56692'}; time used = 1.8821778297424316s
epoch 125: {'train_loss': '2.56057'}; time used = 1.8265650272369385s
epoch 130: {'train_loss': '2.56549'}; time used = 1.8551979064941406s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.1706268787384.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39621'}; time used = 1.0468199253082275s
epoch 10: {'train_loss': '1.36565'}; time used = 0.9364430904388428s
epoch 15: {'train_loss': '1.29215'}; time used = 0.9727599620819092s
epoch 20: {'train_loss': '1.30354'}; time used = 1.070707082748413s
epoch 25: {'train_loss': '1.19172'}; time used = 0.9490618705749512s
epoch 30: {'train_loss': '1.01932'}; time used = 0.9515891075134277s
epoch 35: {'train_loss': '1.09721'}; time used = 1.3551111221313477s
epoch 40: {'train_loss': '0.93424'}; time used = 2.184976100921631s
epoch 45: {'train_loss': '0.79866'}; time used = 2.178511381149292s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.265500783920288.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40305'}; time used = 2.354151725769043s
epoch 10: {'train_loss': '0.93079'}; time used = 2.2350361347198486s
epoch 15: {'train_loss': '0.00001'}; time used = 2.262037992477417s
epoch 20: {'train_loss': '0.00000'}; time used = 2.2182321548461914s
epoch 25: {'train_loss': '0.00000'}; time used = 2.3460001945495605s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.050870180130005.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34908'}; time used = 1.0659563541412354s
epoch 10: {'train_loss': '1.39204'}; time used = 0.8830416202545166s
epoch 15: {'train_loss': '1.38579'}; time used = 1.1868138313293457s
epoch 20: {'train_loss': '1.38921'}; time used = 0.8822662830352783s
epoch 25: {'train_loss': '1.38917'}; time used = 0.9112699031829834s
epoch 30: {'train_loss': '1.38570'}; time used = 0.9847514629364014s
epoch 35: {'train_loss': '1.39394'}; time used = 0.9038951396942139s
epoch 40: {'train_loss': '1.37467'}; time used = 0.926142692565918s
epoch 45: {'train_loss': '1.34336'}; time used = 0.9185585975646973s
epoch 50: {'train_loss': '1.40997'}; time used = 0.8993642330169678s
epoch 55: {'train_loss': '1.38000'}; time used = 0.9070174694061279s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.925241708755493.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37958'}; time used = 2.973527193069458s
epoch 10: {'train_loss': '1.34871'}; time used = 2.7028956413269043s
epoch 15: {'train_loss': '1.38300'}; time used = 2.649705410003662s
epoch 20: {'train_loss': '1.44533'}; time used = 2.7890830039978027s
epoch 25: {'train_loss': '1.42444'}; time used = 2.672123432159424s
epoch 30: {'train_loss': '1.38978'}; time used = 2.5640509128570557s
epoch 35: {'train_loss': '1.38220'}; time used = 2.5399649143218994s
epoch 40: {'train_loss': '1.35850'}; time used = 2.55983567237854s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.745739698410034.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.23468'}; time used = 1.7497880458831787s
epoch 10: {'train_loss': '1.14349'}; time used = 1.5087275505065918s
epoch 15: {'train_loss': '1.13727'}; time used = 1.6188063621520996s
epoch 20: {'train_loss': '1.01717'}; time used = 1.6647930145263672s
epoch 25: {'train_loss': '0.81724'}; time used = 1.9218652248382568s
epoch 30: {'train_loss': '0.73276'}; time used = 1.7735130786895752s
epoch 35: {'train_loss': '0.54845'}; time used = 2.379897356033325s
epoch 40: {'train_loss': '0.37877'}; time used = 2.7546634674072266s
epoch 45: {'train_loss': '0.33053'}; time used = 2.7703959941864014s
epoch 50: {'train_loss': '0.26638'}; time used = 2.6479625701904297s
epoch 55: {'train_loss': '0.15043'}; time used = 1.814270257949829s
epoch 60: {'train_loss': '0.21682'}; time used = 1.8480949401855469s
epoch 65: {'train_loss': '0.29031'}; time used = 1.7361173629760742s
epoch 70: {'train_loss': '0.29077'}; time used = 1.7137136459350586s
epoch 75: {'train_loss': '0.16469'}; time used = 1.7085447311401367s
epoch 80: {'train_loss': '0.02962'}; time used = 1.7749824523925781s
epoch 85: {'train_loss': '0.01664'}; time used = 1.7243599891662598s
epoch 90: {'train_loss': '0.05898'}; time used = 1.7606444358825684s
epoch 95: {'train_loss': '0.13836'}; time used = 1.7785987854003906s
epoch 100: {'train_loss': '0.01587'}; time used = 1.7584903240203857s
epoch 105: {'train_loss': '0.01447'}; time used = 1.842156171798706s
epoch 110: {'train_loss': '0.05669'}; time used = 1.7800118923187256s
epoch 115: {'train_loss': '0.00732'}; time used = 1.7591192722320557s
epoch 120: {'train_loss': '0.01945'}; time used = 1.7256534099578857s
epoch 125: {'train_loss': '0.00492'}; time used = 1.7713618278503418s
epoch 130: {'train_loss': '0.02383'}; time used = 1.8027167320251465s
epoch 135: {'train_loss': '0.00415'}; time used = 1.6296107769012451s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.389222860336304.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.13645'}; time used = 1.8841462135314941s
epoch 10: {'train_loss': '1.05720'}; time used = 1.8007161617279053s
epoch 15: {'train_loss': '1.01594'}; time used = 1.8809261322021484s
epoch 20: {'train_loss': '0.84184'}; time used = 1.822359323501587s
epoch 25: {'train_loss': '1.24697'}; time used = 1.869279384613037s
epoch 30: {'train_loss': '0.63177'}; time used = 1.696335792541504s
epoch 35: {'train_loss': '0.43920'}; time used = 1.6800143718719482s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.297026872634888.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02257'}; time used = 1.846846580505371s
epoch 10: {'train_loss': '0.50533'}; time used = 1.7682044506072998s
epoch 15: {'train_loss': '0.00019'}; time used = 1.7412974834442139s
epoch 20: {'train_loss': '0.00009'}; time used = 1.754481554031372s
epoch 25: {'train_loss': '0.00006'}; time used = 1.8460750579833984s
epoch 30: {'train_loss': '0.02103'}; time used = 1.7480480670928955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.972930908203125.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85126'}; time used = 4.5720055103302s
epoch 10: {'train_loss': '2.77772'}; time used = 4.329291105270386s
epoch 15: {'train_loss': '2.77997'}; time used = 4.49567985534668s
epoch 20: {'train_loss': '2.78611'}; time used = 4.568584203720093s
epoch 25: {'train_loss': '2.77357'}; time used = 4.534379959106445s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.021679401397705.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03275'}; time used = 3.413527727127075s
epoch 10: {'train_loss': '2.90455'}; time used = 2.6137115955352783s
epoch 15: {'train_loss': '2.85705'}; time used = 2.736199140548706s
epoch 20: {'train_loss': '2.82895'}; time used = 2.6691086292266846s
epoch 25: {'train_loss': '2.80675'}; time used = 2.7117860317230225s
epoch 30: {'train_loss': '2.79805'}; time used = 2.6340651512145996s
epoch 35: {'train_loss': '2.80471'}; time used = 2.696669816970825s
epoch 40: {'train_loss': '2.79777'}; time used = 2.736886978149414s
epoch 45: {'train_loss': '2.79612'}; time used = 2.629499673843384s
epoch 50: {'train_loss': '2.79168'}; time used = 2.7345378398895264s
epoch 55: {'train_loss': '2.78973'}; time used = 2.625394582748413s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.15823721885681.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29606'}; time used = 2.445871114730835s
epoch 10: {'train_loss': '1.20465'}; time used = 2.33499813079834s
epoch 15: {'train_loss': '1.14098'}; time used = 2.499105930328369s
epoch 20: {'train_loss': '1.11837'}; time used = 2.5752625465393066s
epoch 25: {'train_loss': '1.12045'}; time used = 2.484039783477783s
epoch 30: {'train_loss': '0.94450'}; time used = 2.3878087997436523s
epoch 35: {'train_loss': '0.82109'}; time used = 2.347066879272461s
epoch 40: {'train_loss': '0.80005'}; time used = 2.3614087104797363s
epoch 45: {'train_loss': '0.75912'}; time used = 2.345435857772827s
epoch 50: {'train_loss': '0.59759'}; time used = 2.4023125171661377s
epoch 55: {'train_loss': '0.51298'}; time used = 2.36079740524292s
epoch 60: {'train_loss': '0.54944'}; time used = 2.43337345123291s
epoch 65: {'train_loss': '0.66544'}; time used = 2.3527886867523193s
epoch 70: {'train_loss': '0.65573'}; time used = 2.3592233657836914s
epoch 75: {'train_loss': '0.59723'}; time used = 2.4760072231292725s
epoch 80: {'train_loss': '0.41569'}; time used = 2.4054205417633057s
epoch 85: {'train_loss': '0.35789'}; time used = 2.398747682571411s
epoch 90: {'train_loss': '0.46881'}; time used = 2.352121114730835s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.40029764175415.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88360'}; time used = 1.0376033782958984s
epoch 10: {'train_loss': '2.80493'}; time used = 0.9475307464599609s
epoch 15: {'train_loss': '2.79124'}; time used = 1.004711627960205s
epoch 20: {'train_loss': '2.78297'}; time used = 0.9950642585754395s
epoch 25: {'train_loss': '2.77711'}; time used = 0.9731495380401611s
epoch 30: {'train_loss': '2.77238'}; time used = 1.0263903141021729s
epoch 35: {'train_loss': '2.77002'}; time used = 0.9977536201477051s
epoch 40: {'train_loss': '2.76919'}; time used = 1.0143609046936035s
epoch 45: {'train_loss': '2.76897'}; time used = 0.9964869022369385s
epoch 50: {'train_loss': '2.76564'}; time used = 0.8923852443695068s
epoch 55: {'train_loss': '2.76276'}; time used = 0.9269795417785645s
epoch 60: {'train_loss': '2.76000'}; time used = 0.9003703594207764s
epoch 65: {'train_loss': '2.75362'}; time used = 0.8931055068969727s
epoch 70: {'train_loss': '2.72743'}; time used = 0.9379446506500244s
epoch 75: {'train_loss': '2.69693'}; time used = 0.9072616100311279s
epoch 80: {'train_loss': '2.63395'}; time used = 1.1226284503936768s
epoch 85: {'train_loss': '2.63470'}; time used = 0.8915379047393799s
epoch 90: {'train_loss': '2.59131'}; time used = 0.9106519222259521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.03430461883545.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.30710'}; time used = 1.873751163482666s
epoch 10: {'train_loss': '1.17157'}; time used = 1.850464105606079s
epoch 15: {'train_loss': '1.08234'}; time used = 1.8284378051757812s
epoch 20: {'train_loss': '1.13119'}; time used = 1.773775339126587s
epoch 25: {'train_loss': '1.02530'}; time used = 1.95501708984375s
epoch 30: {'train_loss': '0.87370'}; time used = 1.7823612689971924s
epoch 35: {'train_loss': '0.88888'}; time used = 1.9248161315917969s
epoch 40: {'train_loss': '0.79794'}; time used = 1.7822213172912598s
epoch 45: {'train_loss': '0.78906'}; time used = 1.8541886806488037s
epoch 50: {'train_loss': '0.97411'}; time used = 2.1459271907806396s
epoch 55: {'train_loss': '0.16540'}; time used = 1.7818646430969238s
epoch 60: {'train_loss': '0.28058'}; time used = 1.8677523136138916s
epoch 65: {'train_loss': '0.10337'}; time used = 1.9024052619934082s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.941045999526978.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5899830220713073, 'samples': 0.5942028985507246, 'weighted': 0.5929972195566053, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.26010'}; time used = 1.6737141609191895s
epoch 10: {'train_loss': '1.04748'}; time used = 1.7487215995788574s
epoch 15: {'train_loss': '0.95499'}; time used = 1.6617002487182617s
epoch 20: {'train_loss': '0.85569'}; time used = 1.6557574272155762s
epoch 25: {'train_loss': '0.45081'}; time used = 1.7436466217041016s
epoch 30: {'train_loss': '0.32744'}; time used = 1.677335262298584s
epoch 35: {'train_loss': '0.15215'}; time used = 1.696096420288086s
epoch 40: {'train_loss': '0.24519'}; time used = 1.6997895240783691s
epoch 45: {'train_loss': '0.24734'}; time used = 1.6972649097442627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.529289484024048.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05935'}; time used = 1.7025387287139893s
epoch 10: {'train_loss': '2.81804'}; time used = 1.6323883533477783s
epoch 15: {'train_loss': '2.74370'}; time used = 1.6267719268798828s
epoch 20: {'train_loss': '2.75128'}; time used = 1.6159813404083252s
epoch 25: {'train_loss': '2.73684'}; time used = 1.7004597187042236s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.208625793457031.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83887'}; time used = 1.0530738830566406s
epoch 10: {'train_loss': '2.78095'}; time used = 0.9206058979034424s
epoch 15: {'train_loss': '2.77338'}; time used = 0.9787764549255371s
epoch 20: {'train_loss': '2.77995'}; time used = 0.9556550979614258s
epoch 25: {'train_loss': '2.77583'}; time used = 0.9482908248901367s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.12397575378418.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.88521'}; time used = 1.7928218841552734s
epoch 10: {'train_loss': '2.83284'}; time used = 2.053335666656494s
epoch 15: {'train_loss': '2.77521'}; time used = 1.7534871101379395s
epoch 20: {'train_loss': '2.78328'}; time used = 1.6715092658996582s
epoch 25: {'train_loss': '2.77080'}; time used = 1.7591514587402344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.7081139087677.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.89612'}; time used = 1.8196063041687012s
epoch 10: {'train_loss': '2.82318'}; time used = 1.688032627105713s
epoch 15: {'train_loss': '2.76793'}; time used = 1.6805672645568848s
epoch 20: {'train_loss': '2.77268'}; time used = 1.6635105609893799s
epoch 25: {'train_loss': '2.75496'}; time used = 1.7427527904510498s
epoch 30: {'train_loss': '2.75112'}; time used = 1.6805856227874756s
epoch 35: {'train_loss': '2.74548'}; time used = 1.667755126953125s
epoch 40: {'train_loss': '2.73779'}; time used = 1.7790753841400146s
epoch 45: {'train_loss': '2.72260'}; time used = 1.638679027557373s
epoch 50: {'train_loss': '2.71672'}; time used = 1.7128381729125977s
epoch 55: {'train_loss': '2.71525'}; time used = 1.7128071784973145s
epoch 60: {'train_loss': '2.69979'}; time used = 1.7062184810638428s
epoch 65: {'train_loss': '2.68943'}; time used = 1.7034738063812256s
epoch 70: {'train_loss': '2.69455'}; time used = 1.6528048515319824s
epoch 75: {'train_loss': '2.67961'}; time used = 1.635124683380127s
epoch 80: {'train_loss': '2.68685'}; time used = 1.739344596862793s
epoch 85: {'train_loss': '2.68536'}; time used = 1.6350576877593994s
epoch 90: {'train_loss': '2.66982'}; time used = 1.6427218914031982s
epoch 95: {'train_loss': '2.67167'}; time used = 1.612076997756958s
epoch 100: {'train_loss': '2.67065'}; time used = 1.6423907279968262s
epoch 105: {'train_loss': '2.66221'}; time used = 1.714792251586914s
epoch 110: {'train_loss': '2.66075'}; time used = 1.6309785842895508s
epoch 115: {'train_loss': '2.63977'}; time used = 1.764641284942627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.279170989990234.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.48187084316670237, 'samples': 0.4927536231884058, 'weighted': 0.48731223317755407, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84638'}; time used = 8.29580569267273s
epoch 10: {'train_loss': '2.77651'}; time used = 8.07621455192566s
epoch 15: {'train_loss': '2.77959'}; time used = 9.517940521240234s
epoch 20: {'train_loss': '2.77642'}; time used = 9.391208410263062s
epoch 25: {'train_loss': '2.77055'}; time used = 9.113880634307861s
epoch 30: {'train_loss': '2.76952'}; time used = 10.806908369064331s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 72.10795164108276.
Training classifier using 80.00% nodes...
{'micro': 0.4666666666666667, 'macro': 0.4603738103428506, 'samples': 0.4666666666666667, 'weighted': 0.4589155372090357, 'accuracy': 0.4666666666666667}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.743847131729126s
epoch 10: {'train_loss': '1.38629'}; time used = 4.150116920471191s
epoch 15: {'train_loss': '1.38629'}; time used = 4.246492147445679s
epoch 20: {'train_loss': '1.38629'}; time used = 4.08896017074585s
epoch 25: {'train_loss': '1.38629'}; time used = 4.093464136123657s
epoch 30: {'train_loss': '1.38629'}; time used = 4.163902521133423s
epoch 35: {'train_loss': '1.38629'}; time used = 4.090347528457642s
epoch 40: {'train_loss': '1.38629'}; time used = 4.061860084533691s
epoch 45: {'train_loss': '1.38629'}; time used = 4.1725218296051025s
epoch 50: {'train_loss': '1.38629'}; time used = 4.075507640838623s
epoch 55: {'train_loss': '1.38629'}; time used = 4.035830736160278s
epoch 60: {'train_loss': '1.38629'}; time used = 4.186558485031128s
epoch 65: {'train_loss': '1.38629'}; time used = 4.167457818984985s
epoch 70: {'train_loss': '1.38629'}; time used = 4.077352523803711s
epoch 75: {'train_loss': '1.38629'}; time used = 4.045689582824707s
epoch 80: {'train_loss': '1.38629'}; time used = 4.235809087753296s
epoch 85: {'train_loss': '1.38629'}; time used = 4.053642749786377s
epoch 90: {'train_loss': '1.38629'}; time used = 4.185546159744263s
epoch 95: {'train_loss': '1.38629'}; time used = 4.057030916213989s
epoch 100: {'train_loss': '1.38629'}; time used = 4.35864520072937s
epoch 105: {'train_loss': '1.38629'}; time used = 3.991802215576172s
epoch 110: {'train_loss': '1.38629'}; time used = 4.061141729354858s
epoch 115: {'train_loss': '1.38629'}; time used = 4.123030662536621s
epoch 120: {'train_loss': '1.38629'}; time used = 4.074372291564941s
epoch 125: {'train_loss': '1.38629'}; time used = 4.032908201217651s
epoch 130: {'train_loss': '1.38629'}; time used = 4.0826263427734375s
epoch 135: {'train_loss': '1.38629'}; time used = 4.154032945632935s
epoch 140: {'train_loss': '1.38629'}; time used = 4.6752636432647705s
epoch 145: {'train_loss': '1.38629'}; time used = 4.171735525131226s
epoch 150: {'train_loss': '1.38629'}; time used = 4.106726884841919s
epoch 155: {'train_loss': '1.38629'}; time used = 4.070388078689575s
epoch 160: {'train_loss': '1.38629'}; time used = 4.091768026351929s
epoch 165: {'train_loss': '1.38629'}; time used = 4.053359508514404s
epoch 170: {'train_loss': '1.38629'}; time used = 4.008518218994141s
epoch 175: {'train_loss': '1.38629'}; time used = 4.299152851104736s
epoch 180: {'train_loss': '1.38629'}; time used = 4.339694976806641s
epoch 185: {'train_loss': '1.38629'}; time used = 4.224191188812256s
epoch 190: {'train_loss': '1.38629'}; time used = 4.2329511642456055s
epoch 195: {'train_loss': '1.38629'}; time used = 4.076562404632568s
epoch 200: {'train_loss': '1.38629'}; time used = 4.404896974563599s
epoch 205: {'train_loss': '1.38629'}; time used = 4.293025016784668s
epoch 210: {'train_loss': '1.38629'}; time used = 4.177938461303711s
epoch 215: {'train_loss': '1.38629'}; time used = 5.899493932723999s
epoch 220: {'train_loss': '1.38629'}; time used = 6.423240661621094s
epoch 225: {'train_loss': '1.38629'}; time used = 4.270825386047363s
epoch 230: {'train_loss': '1.38629'}; time used = 4.461986780166626s
epoch 235: {'train_loss': '1.38629'}; time used = 5.380385398864746s
epoch 240: {'train_loss': '1.38629'}; time used = 7.070544004440308s
epoch 245: {'train_loss': '1.38629'}; time used = 4.610511779785156s
epoch 250: {'train_loss': '1.38629'}; time used = 4.304704666137695s
epoch 255: {'train_loss': '1.38629'}; time used = 4.242779493331909s
epoch 260: {'train_loss': '1.38629'}; time used = 7.124781131744385s
epoch 265: {'train_loss': '1.38629'}; time used = 4.567289352416992s
epoch 270: {'train_loss': '1.38629'}; time used = 4.1439433097839355s
epoch 275: {'train_loss': '1.38629'}; time used = 4.0764501094818115s
epoch 280: {'train_loss': '1.38629'}; time used = 3.9974658489227295s
epoch 285: {'train_loss': '1.38629'}; time used = 4.177105665206909s
epoch 290: {'train_loss': '1.38629'}; time used = 4.144791841506958s
epoch 295: {'train_loss': '1.38629'}; time used = 4.471660614013672s
epoch 300: {'train_loss': '1.38629'}; time used = 4.351941347122192s
epoch 305: {'train_loss': '1.38629'}; time used = 4.171416521072388s
epoch 310: {'train_loss': '1.38629'}; time used = 4.886139869689941s
epoch 315: {'train_loss': '1.38629'}; time used = 4.2646803855896s
epoch 320: {'train_loss': '1.38629'}; time used = 4.1508119106292725s
epoch 325: {'train_loss': '1.38629'}; time used = 4.167203664779663s
epoch 330: {'train_loss': '1.38629'}; time used = 4.157948017120361s
epoch 335: {'train_loss': '1.38629'}; time used = 4.201307773590088s
epoch 340: {'train_loss': '1.38629'}; time used = 4.151671648025513s
epoch 345: {'train_loss': '1.38629'}; time used = 4.295825242996216s
epoch 350: {'train_loss': '1.38629'}; time used = 4.161836385726929s
epoch 355: {'train_loss': '1.38629'}; time used = 4.119085073471069s
epoch 360: {'train_loss': '1.38629'}; time used = 5.561809301376343s
epoch 365: {'train_loss': '1.38629'}; time used = 4.891545295715332s
epoch 370: {'train_loss': '1.38629'}; time used = 4.087456464767456s
epoch 375: {'train_loss': '1.38629'}; time used = 4.135124444961548s
epoch 380: {'train_loss': '1.38629'}; time used = 7.421532392501831s
epoch 385: {'train_loss': '1.38629'}; time used = 5.11083197593689s
epoch 390: {'train_loss': '1.38629'}; time used = 4.878455400466919s
epoch 395: {'train_loss': '1.38629'}; time used = 4.110308408737183s
epoch 400: {'train_loss': '1.38629'}; time used = 4.31324028968811s
epoch 405: {'train_loss': '1.38629'}; time used = 5.5685296058654785s
epoch 410: {'train_loss': '1.38629'}; time used = 4.442934513092041s
epoch 415: {'train_loss': '1.38629'}; time used = 4.370737075805664s
epoch 420: {'train_loss': '1.38629'}; time used = 4.325746059417725s
epoch 425: {'train_loss': '1.38629'}; time used = 4.292320966720581s
epoch 430: {'train_loss': '1.38629'}; time used = 5.516811370849609s
epoch 435: {'train_loss': '1.38629'}; time used = 4.23116135597229s
epoch 440: {'train_loss': '1.38629'}; time used = 4.064758539199829s
epoch 445: {'train_loss': '1.38629'}; time used = 5.882461071014404s
epoch 450: {'train_loss': '1.38629'}; time used = 4.216247320175171s
epoch 455: {'train_loss': '1.38629'}; time used = 4.163624048233032s
epoch 460: {'train_loss': '1.38629'}; time used = 5.108928442001343s
epoch 465: {'train_loss': '1.38629'}; time used = 4.946498870849609s
epoch 470: {'train_loss': '1.38629'}; time used = 4.134322166442871s
epoch 475: {'train_loss': '1.38629'}; time used = 4.081905841827393s
epoch 480: {'train_loss': '1.38629'}; time used = 4.2706403732299805s
epoch 485: {'train_loss': '1.38629'}; time used = 4.119996547698975s
epoch 490: {'train_loss': '1.38629'}; time used = 4.316367864608765s
epoch 495: {'train_loss': '1.38629'}; time used = 4.339382648468018s
epoch 500: {'train_loss': '1.38629'}; time used = 6.6027092933654785s
Finished training. Time used = 455.45431327819824.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93770'}; time used = 1.1006410121917725s
epoch 10: {'train_loss': '2.70391'}; time used = 0.9799301624298096s
epoch 15: {'train_loss': '2.58729'}; time used = 0.967393159866333s
epoch 20: {'train_loss': '2.39983'}; time used = 0.9704492092132568s
epoch 25: {'train_loss': '2.10169'}; time used = 1.0420160293579102s
epoch 30: {'train_loss': '1.81028'}; time used = 0.9640767574310303s
epoch 35: {'train_loss': '1.61307'}; time used = 0.9517695903778076s
epoch 40: {'train_loss': '1.57032'}; time used = 0.963270902633667s
epoch 45: {'train_loss': '1.60950'}; time used = 0.9625687599182129s
epoch 50: {'train_loss': '1.43565'}; time used = 1.1715960502624512s
epoch 55: {'train_loss': '1.47354'}; time used = 1.0724623203277588s
epoch 60: {'train_loss': '1.41626'}; time used = 1.0390691757202148s
epoch 65: {'train_loss': '1.38205'}; time used = 1.1198091506958008s
epoch 70: {'train_loss': '1.37414'}; time used = 1.307624101638794s
epoch 75: {'train_loss': '1.27917'}; time used = 0.9619359970092773s
epoch 80: {'train_loss': '1.34558'}; time used = 1.3175384998321533s
epoch 85: {'train_loss': '1.36059'}; time used = 1.21891188621521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.816859245300293.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29606'}; time used = 2.5792715549468994s
epoch 10: {'train_loss': '1.20465'}; time used = 2.5110840797424316s
epoch 15: {'train_loss': '1.14098'}; time used = 2.654066324234009s
epoch 20: {'train_loss': '1.11837'}; time used = 2.767883777618408s
epoch 25: {'train_loss': '1.12045'}; time used = 2.7109715938568115s
epoch 30: {'train_loss': '0.94450'}; time used = 3.9759597778320312s
epoch 35: {'train_loss': '0.82109'}; time used = 4.725621461868286s
epoch 40: {'train_loss': '0.80005'}; time used = 2.58123779296875s
epoch 45: {'train_loss': '0.75912'}; time used = 2.6158149242401123s
epoch 50: {'train_loss': '0.59759'}; time used = 2.5383031368255615s
epoch 55: {'train_loss': '0.51298'}; time used = 2.637002468109131s
epoch 60: {'train_loss': '0.54944'}; time used = 2.7099833488464355s
epoch 65: {'train_loss': '0.66544'}; time used = 2.6096224784851074s
epoch 70: {'train_loss': '0.65573'}; time used = 2.6721363067626953s
epoch 75: {'train_loss': '0.59723'}; time used = 2.6732163429260254s
epoch 80: {'train_loss': '0.41569'}; time used = 2.6120738983154297s
epoch 85: {'train_loss': '0.35789'}; time used = 2.54939866065979s
epoch 90: {'train_loss': '0.46881'}; time used = 2.602917432785034s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.06410598754883.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.44 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.72367'}; time used = 1.3518502712249756s
epoch 10: {'train_loss': '2.65552'}; time used = 1.136003017425537s
epoch 15: {'train_loss': '2.61933'}; time used = 1.1537549495697021s
epoch 20: {'train_loss': '2.57044'}; time used = 1.0488882064819336s
epoch 25: {'train_loss': '2.51230'}; time used = 1.036994218826294s
epoch 30: {'train_loss': '2.42982'}; time used = 1.0349457263946533s
epoch 35: {'train_loss': '2.35362'}; time used = 1.0338099002838135s
epoch 40: {'train_loss': '2.30672'}; time used = 1.014902114868164s
epoch 45: {'train_loss': '2.25711'}; time used = 1.0346400737762451s
epoch 50: {'train_loss': '2.23820'}; time used = 1.0228054523468018s
epoch 55: {'train_loss': '2.20648'}; time used = 1.0054981708526611s
epoch 60: {'train_loss': '2.15134'}; time used = 1.1037580966949463s
epoch 65: {'train_loss': '2.12164'}; time used = 1.0342376232147217s
epoch 70: {'train_loss': '2.14360'}; time used = 1.0403048992156982s
epoch 75: {'train_loss': '2.11470'}; time used = 1.0387685298919678s
epoch 80: {'train_loss': '2.12011'}; time used = 1.0184948444366455s
epoch 85: {'train_loss': '2.15931'}; time used = 1.0434634685516357s
epoch 90: {'train_loss': '2.12012'}; time used = 1.037466287612915s
epoch 95: {'train_loss': '2.31167'}; time used = 1.0421175956726074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.97439980506897.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.61781'}; time used = 1.2941577434539795s
epoch 10: {'train_loss': '2.44129'}; time used = 1.0027897357940674s
epoch 15: {'train_loss': '2.32789'}; time used = 1.0041518211364746s
epoch 20: {'train_loss': '2.22533'}; time used = 0.9902963638305664s
epoch 25: {'train_loss': '2.17048'}; time used = 1.0262253284454346s
epoch 30: {'train_loss': '2.11830'}; time used = 1.005542278289795s
epoch 35: {'train_loss': '2.11061'}; time used = 1.0702061653137207s
epoch 40: {'train_loss': '2.12154'}; time used = 1.1088263988494873s
epoch 45: {'train_loss': '2.11607'}; time used = 1.0460457801818848s
epoch 50: {'train_loss': '2.13388'}; time used = 1.0509998798370361s
epoch 55: {'train_loss': '2.11428'}; time used = 1.0016076564788818s
epoch 60: {'train_loss': '2.09740'}; time used = 1.0817608833312988s
epoch 65: {'train_loss': '2.10756'}; time used = 1.123311996459961s
epoch 70: {'train_loss': '2.11283'}; time used = 1.1234409809112549s
epoch 75: {'train_loss': '2.08592'}; time used = 1.1845703125s
epoch 80: {'train_loss': '2.09988'}; time used = 1.0301551818847656s
epoch 85: {'train_loss': '2.11179'}; time used = 1.1749184131622314s
epoch 90: {'train_loss': '2.11656'}; time used = 1.0334641933441162s
epoch 95: {'train_loss': '2.11759'}; time used = 1.0113248825073242s
epoch 100: {'train_loss': '2.14728'}; time used = 1.0280652046203613s
epoch 105: {'train_loss': '2.10989'}; time used = 1.0720634460449219s
epoch 110: {'train_loss': '2.08587'}; time used = 1.0212428569793701s
epoch 115: {'train_loss': '2.07981'}; time used = 1.013169527053833s
epoch 120: {'train_loss': '2.07415'}; time used = 1.012763261795044s
epoch 125: {'train_loss': '2.09627'}; time used = 1.1696670055389404s
epoch 130: {'train_loss': '2.08235'}; time used = 0.9795663356781006s
epoch 135: {'train_loss': '2.06108'}; time used = 1.0050792694091797s
epoch 140: {'train_loss': '2.09358'}; time used = 1.0096540451049805s
epoch 145: {'train_loss': '2.08853'}; time used = 1.0362317562103271s
epoch 150: {'train_loss': '2.07108'}; time used = 1.0418989658355713s
epoch 155: {'train_loss': '2.10606'}; time used = 1.0188803672790527s
epoch 160: {'train_loss': '2.09174'}; time used = 1.0051355361938477s
epoch 165: {'train_loss': '2.11243'}; time used = 1.0332562923431396s
epoch 170: {'train_loss': '2.11790'}; time used = 0.9986972808837891s
epoch 175: {'train_loss': '2.06126'}; time used = 1.023078203201294s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.4746778011322.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.72010'}; time used = 2.459977865219116s
epoch 10: {'train_loss': '2.64433'}; time used = 1.6159379482269287s
epoch 15: {'train_loss': '2.63450'}; time used = 1.6217968463897705s
epoch 20: {'train_loss': '2.60990'}; time used = 1.6316301822662354s
epoch 25: {'train_loss': '2.59379'}; time used = 1.7131602764129639s
epoch 30: {'train_loss': '2.56228'}; time used = 1.6033782958984375s
epoch 35: {'train_loss': '2.53128'}; time used = 1.641662359237671s
epoch 40: {'train_loss': '2.49378'}; time used = 2.475971221923828s
epoch 45: {'train_loss': '2.49968'}; time used = 1.9825387001037598s
epoch 50: {'train_loss': '2.37487'}; time used = 1.6566708087921143s
epoch 55: {'train_loss': '2.38991'}; time used = 1.8273940086364746s
epoch 60: {'train_loss': '2.36288'}; time used = 1.6538159847259521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.866225719451904.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17021'}; time used = 1.112076997756958s
epoch 10: {'train_loss': '2.83463'}; time used = 0.9732253551483154s
epoch 15: {'train_loss': '2.68806'}; time used = 1.010058879852295s
epoch 20: {'train_loss': '2.42839'}; time used = 0.9889533519744873s
epoch 25: {'train_loss': '1.84738'}; time used = 0.9855031967163086s
epoch 30: {'train_loss': '1.46755'}; time used = 1.0077118873596191s
epoch 35: {'train_loss': '1.38517'}; time used = 1.0173630714416504s
epoch 40: {'train_loss': '1.32043'}; time used = 0.9904661178588867s
epoch 45: {'train_loss': '1.23965'}; time used = 0.9964549541473389s
epoch 50: {'train_loss': '1.13769'}; time used = 1.1542532444000244s
epoch 55: {'train_loss': '1.54216'}; time used = 0.9709386825561523s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.94971776008606.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.63030'}; time used = 1.1424803733825684s
epoch 10: {'train_loss': '0.43721'}; time used = 1.0490334033966064s
epoch 15: {'train_loss': '0.30247'}; time used = 1.5073599815368652s
epoch 20: {'train_loss': '0.21032'}; time used = 1.676405906677246s
epoch 25: {'train_loss': '0.18059'}; time used = 1.9320306777954102s
epoch 30: {'train_loss': '0.14936'}; time used = 1.6982660293579102s
epoch 35: {'train_loss': '0.05593'}; time used = 1.7297062873840332s
epoch 40: {'train_loss': '0.13740'}; time used = 1.5895941257476807s
epoch 45: {'train_loss': '0.10892'}; time used = 0.9124047756195068s
epoch 50: {'train_loss': '0.13871'}; time used = 0.9043653011322021s
epoch 55: {'train_loss': '0.15067'}; time used = 1.1028945446014404s
epoch 60: {'train_loss': '0.10417'}; time used = 0.9787282943725586s
epoch 65: {'train_loss': '0.08571'}; time used = 0.9414727687835693s
epoch 70: {'train_loss': '0.04951'}; time used = 2.3405921459198s
epoch 75: {'train_loss': '0.10604'}; time used = 1.783386468887329s
epoch 80: {'train_loss': '0.15426'}; time used = 1.1606776714324951s
epoch 85: {'train_loss': '0.24255'}; time used = 1.1010034084320068s
epoch 90: {'train_loss': '0.05430'}; time used = 1.0490906238555908s
epoch 95: {'train_loss': '0.10722'}; time used = 1.0911767482757568s
epoch 100: {'train_loss': '0.22446'}; time used = 1.9405996799468994s
epoch 105: {'train_loss': '0.15639'}; time used = 1.8923566341400146s
epoch 110: {'train_loss': '0.15488'}; time used = 1.7760062217712402s
epoch 115: {'train_loss': '0.10953'}; time used = 1.9945664405822754s
epoch 120: {'train_loss': '0.02773'}; time used = 1.7663357257843018s
epoch 125: {'train_loss': '0.11634'}; time used = 1.7325782775878906s
epoch 130: {'train_loss': '0.13345'}; time used = 0.9027824401855469s
epoch 135: {'train_loss': '0.12968'}; time used = 1.041316032409668s
epoch 140: {'train_loss': '0.15205'}; time used = 1.0719249248504639s
epoch 145: {'train_loss': '0.14036'}; time used = 1.0658290386199951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.60962414741516.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.80808'}; time used = 2.714353561401367s
epoch 10: {'train_loss': '2.77654'}; time used = 2.422480821609497s
epoch 15: {'train_loss': '2.77527'}; time used = 1.2115871906280518s
epoch 20: {'train_loss': '2.78097'}; time used = 1.040351390838623s
epoch 25: {'train_loss': '2.77707'}; time used = 1.1900999546051025s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.356110095977783.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.04187'}; time used = 1.2750191688537598s
epoch 10: {'train_loss': '2.79966'}; time used = 1.0328271389007568s
epoch 15: {'train_loss': '2.78163'}; time used = 1.0540344715118408s
epoch 20: {'train_loss': '2.79801'}; time used = 1.065424919128418s
epoch 25: {'train_loss': '2.77417'}; time used = 1.154930830001831s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.27728533744812.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.26010'}; time used = 1.8875021934509277s
epoch 10: {'train_loss': '1.04748'}; time used = 1.6729331016540527s
epoch 15: {'train_loss': '0.95499'}; time used = 1.6520800590515137s
epoch 20: {'train_loss': '0.85569'}; time used = 1.6432561874389648s
epoch 25: {'train_loss': '0.45081'}; time used = 1.6684818267822266s
epoch 30: {'train_loss': '0.32744'}; time used = 1.6609609127044678s
epoch 35: {'train_loss': '0.15215'}; time used = 1.6035106182098389s
epoch 40: {'train_loss': '0.24519'}; time used = 1.7314553260803223s
epoch 45: {'train_loss': '0.24734'}; time used = 1.7272710800170898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.770739555358887.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.39684'}; time used = 1.126725196838379s
epoch 10: {'train_loss': '1.40259'}; time used = 1.0262396335601807s
epoch 15: {'train_loss': '1.38492'}; time used = 1.0088555812835693s
epoch 20: {'train_loss': '1.39332'}; time used = 1.01798677444458s
epoch 25: {'train_loss': '1.37584'}; time used = 1.044433355331421s
epoch 30: {'train_loss': '1.33833'}; time used = 1.016059398651123s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.794363021850586.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83103'}; time used = 1.4756176471710205s
epoch 10: {'train_loss': '2.78753'}; time used = 1.4279050827026367s
epoch 15: {'train_loss': '2.66319'}; time used = 1.3232481479644775s
epoch 20: {'train_loss': '2.50664'}; time used = 1.313413381576538s
epoch 25: {'train_loss': '2.30436'}; time used = 1.2668366432189941s
epoch 30: {'train_loss': '2.18422'}; time used = 1.2834093570709229s
epoch 35: {'train_loss': '2.05701'}; time used = 1.4535043239593506s
epoch 40: {'train_loss': '2.14162'}; time used = 1.4001173973083496s
epoch 45: {'train_loss': '2.06206'}; time used = 1.3026447296142578s
epoch 50: {'train_loss': '2.02029'}; time used = 1.267254114151001s
epoch 55: {'train_loss': '2.00697'}; time used = 1.2717442512512207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.8773992061615.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03631'}; time used = 1.4171240329742432s
epoch 10: {'train_loss': '0.64686'}; time used = 1.2738666534423828s
epoch 15: {'train_loss': '0.44683'}; time used = 1.277331829071045s
epoch 20: {'train_loss': '0.27608'}; time used = 1.3658218383789062s
epoch 25: {'train_loss': '0.26307'}; time used = 1.3839850425720215s
epoch 30: {'train_loss': '0.17975'}; time used = 1.3366234302520752s
epoch 35: {'train_loss': '0.14593'}; time used = 1.2597107887268066s
epoch 40: {'train_loss': '0.12357'}; time used = 1.2801690101623535s
epoch 45: {'train_loss': '0.17317'}; time used = 1.320232629776001s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.177500486373901.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37414'}; time used = 1.8008432388305664s
epoch 10: {'train_loss': '1.27046'}; time used = 1.764103651046753s
epoch 15: {'train_loss': '1.04917'}; time used = 1.7496345043182373s
epoch 20: {'train_loss': '0.84263'}; time used = 1.7726526260375977s
epoch 25: {'train_loss': '0.64813'}; time used = 1.8820164203643799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.692294120788574.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35025'}; time used = 1.6991991996765137s
epoch 10: {'train_loss': '1.40196'}; time used = 1.609004259109497s
epoch 15: {'train_loss': '0.87848'}; time used = 1.0813744068145752s
epoch 20: {'train_loss': '0.80770'}; time used = 1.160776138305664s
epoch 25: {'train_loss': '0.28304'}; time used = 1.1879127025604248s
epoch 30: {'train_loss': '0.15900'}; time used = 1.1618943214416504s
epoch 35: {'train_loss': '1.04074'}; time used = 1.088383436203003s
epoch 40: {'train_loss': '0.02973'}; time used = 1.0722763538360596s
epoch 45: {'train_loss': '0.01209'}; time used = 1.1145317554473877s
epoch 50: {'train_loss': '0.00328'}; time used = 1.0661096572875977s
epoch 55: {'train_loss': '0.00054'}; time used = 1.0864474773406982s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.051323413848877.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91540'}; time used = 2.025775671005249s
epoch 10: {'train_loss': '2.76849'}; time used = 1.7946617603302002s
epoch 15: {'train_loss': '2.75950'}; time used = 2.3412585258483887s
epoch 20: {'train_loss': '2.74922'}; time used = 2.966338872909546s
epoch 25: {'train_loss': '2.73317'}; time used = 3.2471678256988525s
epoch 30: {'train_loss': '2.71020'}; time used = 2.1541569232940674s
epoch 35: {'train_loss': '2.68103'}; time used = 1.900972604751587s
epoch 40: {'train_loss': '2.63798'}; time used = 1.8105003833770752s
epoch 45: {'train_loss': '2.57399'}; time used = 1.8013389110565186s
epoch 50: {'train_loss': '2.49128'}; time used = 1.6946122646331787s
epoch 55: {'train_loss': '2.47790'}; time used = 1.766087293624878s
epoch 60: {'train_loss': '2.45271'}; time used = 1.6717047691345215s
epoch 65: {'train_loss': '2.42852'}; time used = 1.7481803894042969s
epoch 70: {'train_loss': '2.39361'}; time used = 1.8227968215942383s
epoch 75: {'train_loss': '2.38480'}; time used = 1.708956241607666s
epoch 80: {'train_loss': '2.35745'}; time used = 1.783280849456787s
epoch 85: {'train_loss': '2.35527'}; time used = 1.8100686073303223s
epoch 90: {'train_loss': '2.37600'}; time used = 1.6727268695831299s
epoch 95: {'train_loss': '2.36564'}; time used = 1.7593297958374023s
epoch 100: {'train_loss': '2.34596'}; time used = 1.721930742263794s
epoch 105: {'train_loss': '2.33653'}; time used = 1.8184304237365723s
epoch 110: {'train_loss': '2.33554'}; time used = 1.7128369808197021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.90046691894531.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.22146'}; time used = 2.4065656661987305s
epoch 10: {'train_loss': '1.17820'}; time used = 2.358867645263672s
epoch 15: {'train_loss': '1.12540'}; time used = 2.3202595710754395s
epoch 20: {'train_loss': '0.82753'}; time used = 2.3455734252929688s
epoch 25: {'train_loss': '0.87426'}; time used = 2.484471321105957s
epoch 30: {'train_loss': '0.34036'}; time used = 2.3535056114196777s
epoch 35: {'train_loss': '0.19175'}; time used = 2.4206087589263916s
epoch 40: {'train_loss': '0.11390'}; time used = 2.3192062377929688s
epoch 45: {'train_loss': '0.08630'}; time used = 2.5745813846588135s
epoch 50: {'train_loss': '0.02844'}; time used = 2.3975207805633545s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.461952209472656.
Training classifier using 80.00% nodes...
{'micro': 0.463768115942029, 'macro': 0.375030599755202, 'samples': 0.463768115942029, 'weighted': 0.3920955067142072, 'accuracy': 0.463768115942029}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99344'}; time used = 1.7035880088806152s
epoch 10: {'train_loss': '0.27171'}; time used = 1.6156394481658936s
epoch 15: {'train_loss': '0.09573'}; time used = 1.682809829711914s
epoch 20: {'train_loss': '0.23790'}; time used = 1.6148724555969238s
epoch 25: {'train_loss': '0.15686'}; time used = 1.6937434673309326s
epoch 30: {'train_loss': '0.09935'}; time used = 1.5950024127960205s
epoch 35: {'train_loss': '0.07928'}; time used = 1.568605661392212s
epoch 40: {'train_loss': '0.19133'}; time used = 1.5771386623382568s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.241713523864746.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86531'}; time used = 1.131859302520752s
epoch 10: {'train_loss': '2.81687'}; time used = 0.9448142051696777s
epoch 15: {'train_loss': '2.79006'}; time used = 1.0021789073944092s
epoch 20: {'train_loss': '2.77328'}; time used = 2.53761887550354s
epoch 25: {'train_loss': '2.77227'}; time used = 3.022472858428955s
epoch 30: {'train_loss': '2.77291'}; time used = 3.137385368347168s
epoch 35: {'train_loss': '2.77111'}; time used = 1.8253862857818604s
epoch 40: {'train_loss': '2.76897'}; time used = 1.013279914855957s
epoch 45: {'train_loss': '2.76673'}; time used = 1.0605418682098389s
epoch 50: {'train_loss': '2.76058'}; time used = 0.9223806858062744s
epoch 55: {'train_loss': '2.75010'}; time used = 0.9160969257354736s
epoch 60: {'train_loss': '2.73779'}; time used = 1.2371037006378174s
epoch 65: {'train_loss': '2.71067'}; time used = 0.9281024932861328s
epoch 70: {'train_loss': '2.64526'}; time used = 0.9374492168426514s
epoch 75: {'train_loss': '2.61161'}; time used = 0.9515683650970459s
epoch 80: {'train_loss': '2.53968'}; time used = 0.9347195625305176s
epoch 85: {'train_loss': '2.57008'}; time used = 0.9290516376495361s
epoch 90: {'train_loss': '2.53950'}; time used = 0.9115262031555176s
epoch 95: {'train_loss': '2.50882'}; time used = 0.9216818809509277s
epoch 100: {'train_loss': '2.47232'}; time used = 0.9841902256011963s
epoch 105: {'train_loss': '2.48036'}; time used = 1.0189857482910156s
epoch 110: {'train_loss': '2.39998'}; time used = 0.9737141132354736s
epoch 115: {'train_loss': '2.43106'}; time used = 1.0184431076049805s
epoch 120: {'train_loss': '2.45606'}; time used = 0.9359211921691895s
epoch 125: {'train_loss': '2.43056'}; time used = 1.1519501209259033s
epoch 130: {'train_loss': '2.44727'}; time used = 0.9634213447570801s
epoch 135: {'train_loss': '2.41142'}; time used = 0.9788789749145508s
epoch 140: {'train_loss': '2.39703'}; time used = 0.963853120803833s
epoch 145: {'train_loss': '2.36459'}; time used = 0.9768602848052979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.59117364883423.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78656'}; time used = 1.7487897872924805s
epoch 10: {'train_loss': '2.77481'}; time used = 1.7477600574493408s
epoch 15: {'train_loss': '2.77679'}; time used = 1.950479507446289s
epoch 20: {'train_loss': '2.77283'}; time used = 1.729301929473877s
epoch 25: {'train_loss': '2.76844'}; time used = 2.011042594909668s
epoch 30: {'train_loss': '2.76223'}; time used = 1.7073349952697754s
epoch 35: {'train_loss': '2.75985'}; time used = 1.7606549263000488s
epoch 40: {'train_loss': '2.75658'}; time used = 1.9509320259094238s
epoch 45: {'train_loss': '2.75558'}; time used = 1.9526903629302979s
epoch 50: {'train_loss': '2.75321'}; time used = 1.7708971500396729s
epoch 55: {'train_loss': '2.75750'}; time used = 1.7418696880340576s
epoch 60: {'train_loss': '2.75046'}; time used = 1.9430243968963623s
epoch 65: {'train_loss': '2.73482'}; time used = 2.204526662826538s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.913106441497803.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4189473684210526, 'samples': 0.5362318840579711, 'weighted': 0.4378642257818459, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78337'}; time used = 1.0008354187011719s
epoch 10: {'train_loss': '2.49296'}; time used = 0.9714829921722412s
epoch 15: {'train_loss': '2.08392'}; time used = 0.9391708374023438s
epoch 20: {'train_loss': '1.83465'}; time used = 0.9403040409088135s
epoch 25: {'train_loss': '1.83093'}; time used = 0.9939815998077393s
epoch 30: {'train_loss': '1.75923'}; time used = 0.9568767547607422s
epoch 35: {'train_loss': '1.64121'}; time used = 0.9530966281890869s
epoch 40: {'train_loss': '1.59391'}; time used = 1.1109387874603271s
epoch 45: {'train_loss': '1.66927'}; time used = 1.0890002250671387s
epoch 50: {'train_loss': '1.51924'}; time used = 1.069058895111084s
epoch 55: {'train_loss': '1.47540'}; time used = 1.134291648864746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.45164966583252.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92372'}; time used = 1.297306776046753s
epoch 10: {'train_loss': '2.88972'}; time used = 1.2526512145996094s
epoch 15: {'train_loss': '2.84413'}; time used = 1.1488139629364014s
epoch 20: {'train_loss': '2.81104'}; time used = 1.1061863899230957s
epoch 25: {'train_loss': '2.79528'}; time used = 2.5787689685821533s
epoch 30: {'train_loss': '2.79860'}; time used = 3.4820303916931152s
epoch 35: {'train_loss': '2.78958'}; time used = 2.3959906101226807s
epoch 40: {'train_loss': '2.79143'}; time used = 1.383014440536499s
epoch 45: {'train_loss': '2.79118'}; time used = 1.184917688369751s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.99856948852539.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.34811'}; time used = 1.7350711822509766s
epoch 10: {'train_loss': '0.36064'}; time used = 1.6553571224212646s
epoch 15: {'train_loss': '0.16037'}; time used = 1.5743839740753174s
epoch 20: {'train_loss': '0.10226'}; time used = 1.6830711364746094s
epoch 25: {'train_loss': '0.10592'}; time used = 1.9912478923797607s
epoch 30: {'train_loss': '0.03809'}; time used = 1.6298420429229736s
epoch 35: {'train_loss': '0.09125'}; time used = 1.5593113899230957s
epoch 40: {'train_loss': '0.07116'}; time used = 1.5747380256652832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.902515411376953.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.07507'}; time used = 1.3553292751312256s
epoch 10: {'train_loss': '2.70367'}; time used = 1.3674423694610596s
epoch 15: {'train_loss': '2.66740'}; time used = 1.3118305206298828s
epoch 20: {'train_loss': '2.61790'}; time used = 1.1626081466674805s
epoch 25: {'train_loss': '2.56119'}; time used = 1.2457082271575928s
epoch 30: {'train_loss': '2.42707'}; time used = 1.259908676147461s
epoch 35: {'train_loss': '2.36218'}; time used = 1.007988452911377s
epoch 40: {'train_loss': '2.32251'}; time used = 1.1131153106689453s
epoch 45: {'train_loss': '2.27099'}; time used = 0.992565393447876s
epoch 50: {'train_loss': '2.21910'}; time used = 0.9949674606323242s
epoch 55: {'train_loss': '2.18030'}; time used = 1.1851184368133545s
epoch 60: {'train_loss': '2.14738'}; time used = 1.0565354824066162s
epoch 65: {'train_loss': '2.10051'}; time used = 1.020900011062622s
epoch 70: {'train_loss': '2.11110'}; time used = 1.160191297531128s
epoch 75: {'train_loss': '2.08441'}; time used = 1.073685646057129s
epoch 80: {'train_loss': '2.08385'}; time used = 0.952202558517456s
epoch 85: {'train_loss': '2.11614'}; time used = 0.9996259212493896s
epoch 90: {'train_loss': '2.07030'}; time used = 1.3236000537872314s
epoch 95: {'train_loss': '1.99726'}; time used = 1.8388242721557617s
epoch 100: {'train_loss': '2.01075'}; time used = 2.0510873794555664s
epoch 105: {'train_loss': '2.11942'}; time used = 2.0467400550842285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.294564485549927.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5064935064935066, 'samples': 0.6052631578947368, 'weighted': 0.5413533834586466, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.93194'}; time used = 2.122264862060547s
epoch 10: {'train_loss': '2.81369'}; time used = 2.3578507900238037s
epoch 15: {'train_loss': '2.78278'}; time used = 1.8564667701721191s
epoch 20: {'train_loss': '2.77148'}; time used = 1.7091648578643799s
epoch 25: {'train_loss': '2.77563'}; time used = 1.8398089408874512s
epoch 30: {'train_loss': '2.77509'}; time used = 1.7158663272857666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.88004970550537.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77868'}; time used = 1.2590875625610352s
epoch 10: {'train_loss': '2.77418'}; time used = 1.1164131164550781s
epoch 15: {'train_loss': '2.77290'}; time used = 1.332531213760376s
epoch 20: {'train_loss': '2.77494'}; time used = 1.0845146179199219s
epoch 25: {'train_loss': '2.77437'}; time used = 1.2671897411346436s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.249301671981812.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.15306'}; time used = 1.8917675018310547s
epoch 10: {'train_loss': '0.50132'}; time used = 1.7598111629486084s
epoch 15: {'train_loss': '0.23165'}; time used = 1.7442197799682617s
epoch 20: {'train_loss': '0.31643'}; time used = 1.8140828609466553s
epoch 25: {'train_loss': '0.75468'}; time used = 1.8410289287567139s
epoch 30: {'train_loss': '0.29530'}; time used = 1.9726858139038086s
epoch 35: {'train_loss': '0.22444'}; time used = 1.9625627994537354s
epoch 40: {'train_loss': '0.34304'}; time used = 1.925295352935791s
epoch 45: {'train_loss': '0.34225'}; time used = 1.9755446910858154s
epoch 50: {'train_loss': '0.45305'}; time used = 1.812084674835205s
epoch 55: {'train_loss': '0.26074'}; time used = 2.144786834716797s
epoch 60: {'train_loss': '0.36962'}; time used = 1.7513740062713623s
epoch 65: {'train_loss': '0.51337'}; time used = 1.7129461765289307s
epoch 70: {'train_loss': '0.45280'}; time used = 1.7285645008087158s
epoch 75: {'train_loss': '0.45275'}; time used = 1.7153325080871582s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.66004753112793.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.15375'}; time used = 1.1086416244506836s
epoch 10: {'train_loss': '0.89878'}; time used = 1.076704502105713s
epoch 15: {'train_loss': '0.75239'}; time used = 1.0229403972625732s
epoch 20: {'train_loss': '0.61850'}; time used = 1.0165956020355225s
epoch 25: {'train_loss': '0.58617'}; time used = 1.023517370223999s
epoch 30: {'train_loss': '0.43099'}; time used = 1.8363077640533447s
epoch 35: {'train_loss': '0.41200'}; time used = 1.9142749309539795s
epoch 40: {'train_loss': '0.36621'}; time used = 1.899151086807251s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.965810775756836.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78808'}; time used = 2.158621311187744s
epoch 10: {'train_loss': '2.76267'}; time used = 1.789820909500122s
epoch 15: {'train_loss': '2.74237'}; time used = 2.1919257640838623s
epoch 20: {'train_loss': '2.70808'}; time used = 2.9234931468963623s
epoch 25: {'train_loss': '2.64571'}; time used = 3.4966166019439697s
epoch 30: {'train_loss': '2.60276'}; time used = 3.720463275909424s
epoch 35: {'train_loss': '2.54003'}; time used = 3.168836832046509s
epoch 40: {'train_loss': '2.44892'}; time used = 1.678274393081665s
epoch 45: {'train_loss': '2.57571'}; time used = 1.6739614009857178s
epoch 50: {'train_loss': '2.39375'}; time used = 1.5059974193572998s
epoch 55: {'train_loss': '2.35093'}; time used = 1.6350605487823486s
epoch 60: {'train_loss': '2.31241'}; time used = 1.5414457321166992s
epoch 65: {'train_loss': '2.22386'}; time used = 1.513423204421997s
epoch 70: {'train_loss': '2.15257'}; time used = 1.5015215873718262s
epoch 75: {'train_loss': '2.09349'}; time used = 1.5112686157226562s
epoch 80: {'train_loss': '2.03701'}; time used = 1.5961620807647705s
epoch 85: {'train_loss': '2.09166'}; time used = 1.535170078277588s
epoch 90: {'train_loss': '2.05201'}; time used = 1.6248464584350586s
epoch 95: {'train_loss': '1.95834'}; time used = 1.6655714511871338s
epoch 100: {'train_loss': '2.35791'}; time used = 1.731543779373169s
epoch 105: {'train_loss': '2.08310'}; time used = 2.40537428855896s
epoch 110: {'train_loss': '1.99281'}; time used = 2.490902900695801s
epoch 115: {'train_loss': '1.89285'}; time used = 2.7959413528442383s
epoch 120: {'train_loss': '1.85798'}; time used = 2.9901881217956543s
epoch 125: {'train_loss': '1.80478'}; time used = 3.2125489711761475s
epoch 130: {'train_loss': '1.78863'}; time used = 2.8730764389038086s
epoch 135: {'train_loss': '1.87161'}; time used = 1.7066550254821777s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.590193033218384.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29469'}; time used = 2.1556098461151123s
epoch 10: {'train_loss': '1.23119'}; time used = 2.1439943313598633s
epoch 15: {'train_loss': '1.18707'}; time used = 2.170614719390869s
epoch 20: {'train_loss': '1.30900'}; time used = 2.25821852684021s
epoch 25: {'train_loss': '1.25027'}; time used = 2.645451784133911s
epoch 30: {'train_loss': '1.19731'}; time used = 3.625385046005249s
epoch 35: {'train_loss': '1.32017'}; time used = 3.45151686668396s
epoch 40: {'train_loss': '1.19617'}; time used = 2.5822880268096924s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.630365133285522.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.4945615982241954, 'samples': 0.5217391304347826, 'weighted': 0.5030545770400039, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86017'}; time used = 1.906320333480835s
epoch 10: {'train_loss': '2.77852'}; time used = 1.5565977096557617s
epoch 15: {'train_loss': '2.73906'}; time used = 2.0573887825012207s
epoch 20: {'train_loss': '2.71816'}; time used = 2.613717794418335s
epoch 25: {'train_loss': '2.68979'}; time used = 1.6994585990905762s
epoch 30: {'train_loss': '2.66131'}; time used = 1.761885404586792s
epoch 35: {'train_loss': '2.63948'}; time used = 2.1325302124023438s
epoch 40: {'train_loss': '2.59561'}; time used = 2.142791271209717s
epoch 45: {'train_loss': '2.57901'}; time used = 1.9308717250823975s
epoch 50: {'train_loss': '2.54019'}; time used = 2.0341038703918457s
epoch 55: {'train_loss': '2.52949'}; time used = 3.0372557640075684s
epoch 60: {'train_loss': '2.55471'}; time used = 3.082596778869629s
epoch 65: {'train_loss': '2.51580'}; time used = 2.8784494400024414s
epoch 70: {'train_loss': '2.46931'}; time used = 2.2192068099975586s
epoch 75: {'train_loss': '2.43679'}; time used = 1.8403220176696777s
epoch 80: {'train_loss': '2.42289'}; time used = 1.5995056629180908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.4450786113739.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6515151515151516, 'samples': 0.6521739130434783, 'weighted': 0.6526130873956961, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36730'}; time used = 3.9979257583618164s
epoch 10: {'train_loss': '1.34330'}; time used = 3.84334659576416s
epoch 15: {'train_loss': '1.37551'}; time used = 2.24434232711792s
epoch 20: {'train_loss': '1.42177'}; time used = 2.3480584621429443s
epoch 25: {'train_loss': '1.39237'}; time used = 2.3996970653533936s
epoch 30: {'train_loss': '1.26325'}; time used = 2.9390430450439453s
epoch 35: {'train_loss': '1.21466'}; time used = 2.110435724258423s
epoch 40: {'train_loss': '1.07995'}; time used = 2.117838144302368s
epoch 45: {'train_loss': '0.92279'}; time used = 2.220708131790161s
epoch 50: {'train_loss': '0.72723'}; time used = 2.165623664855957s
epoch 55: {'train_loss': '0.51641'}; time used = 3.7676165103912354s
epoch 60: {'train_loss': '0.63865'}; time used = 2.210526466369629s
epoch 65: {'train_loss': '0.78134'}; time used = 2.1446516513824463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.25510358810425.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6423258958755915, 'samples': 0.6666666666666666, 'weighted': 0.6490872210953347, 'accuracy': 0.6666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36022'}; time used = 1.9659228324890137s
epoch 10: {'train_loss': '1.28608'}; time used = 1.9020342826843262s
epoch 15: {'train_loss': '1.28740'}; time used = 1.8722419738769531s
epoch 20: {'train_loss': '1.34145'}; time used = 1.7587344646453857s
epoch 25: {'train_loss': '1.30629'}; time used = 1.8666424751281738s
epoch 30: {'train_loss': '1.22176'}; time used = 1.79225754737854s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.578733205795288.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.44454'}; time used = 11.957771062850952s
epoch 10: {'train_loss': '2.85409'}; time used = 7.621353387832642s
epoch 15: {'train_loss': '2.85009'}; time used = 7.407077789306641s
epoch 20: {'train_loss': '2.85170'}; time used = 7.35417914390564s
epoch 25: {'train_loss': '2.82460'}; time used = 7.182589054107666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.15253210067749.
Training classifier using 80.00% nodes...
{'micro': 0.49, 'macro': 0.46680100649921413, 'samples': 0.49, 'weighted': 0.46103227042188477, 'accuracy': 0.49}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.69714'}; time used = 2.6579270362854004s
epoch 10: {'train_loss': '2.63683'}; time used = 3.379652976989746s
epoch 15: {'train_loss': '2.63180'}; time used = 3.222996234893799s
epoch 20: {'train_loss': '2.59617'}; time used = 1.8722546100616455s
epoch 25: {'train_loss': '2.57458'}; time used = 2.0211868286132812s
epoch 30: {'train_loss': '2.54241'}; time used = 1.7208216190338135s
epoch 35: {'train_loss': '2.51222'}; time used = 1.835008144378662s
epoch 40: {'train_loss': '2.47209'}; time used = 1.931339979171753s
epoch 45: {'train_loss': '2.46425'}; time used = 1.9012446403503418s
epoch 50: {'train_loss': '2.44956'}; time used = 1.7216134071350098s
epoch 55: {'train_loss': '2.41645'}; time used = 1.978241205215454s
epoch 60: {'train_loss': '2.40494'}; time used = 1.849954605102539s
epoch 65: {'train_loss': '2.39865'}; time used = 1.9998056888580322s
epoch 70: {'train_loss': '2.32276'}; time used = 1.7372238636016846s
epoch 75: {'train_loss': '2.31542'}; time used = 1.8022480010986328s
epoch 80: {'train_loss': '2.31043'}; time used = 1.9433667659759521s
epoch 85: {'train_loss': '2.29378'}; time used = 1.9451744556427002s
epoch 90: {'train_loss': '2.29170'}; time used = 1.7879793643951416s
epoch 95: {'train_loss': '2.40818'}; time used = 1.896639108657837s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.933931827545166.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98455'}; time used = 2.1055359840393066s
epoch 10: {'train_loss': '2.82624'}; time used = 2.0333995819091797s
epoch 15: {'train_loss': '2.78558'}; time used = 2.0584301948547363s
epoch 20: {'train_loss': '2.77511'}; time used = 2.1932859420776367s
epoch 25: {'train_loss': '2.78005'}; time used = 2.1433522701263428s
epoch 30: {'train_loss': '2.77668'}; time used = 2.0522518157958984s
epoch 35: {'train_loss': '2.77349'}; time used = 2.096975803375244s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.119863986968994.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.80067'}; time used = 1.0813305377960205s
epoch 10: {'train_loss': '0.90435'}; time used = 0.919867753982544s
epoch 15: {'train_loss': '0.35958'}; time used = 1.4223644733428955s
epoch 20: {'train_loss': '0.23567'}; time used = 1.7156479358673096s
epoch 25: {'train_loss': '0.21475'}; time used = 1.6376771926879883s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.290221929550171.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.95113'}; time used = 1.9928436279296875s
epoch 10: {'train_loss': '2.86275'}; time used = 1.8938140869140625s
epoch 15: {'train_loss': '2.78250'}; time used = 2.1772620677948s
epoch 20: {'train_loss': '2.78609'}; time used = 2.0065317153930664s
epoch 25: {'train_loss': '2.77406'}; time used = 2.163663625717163s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.77368688583374.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.47630'}; time used = 4.7075605392456055s
epoch 10: {'train_loss': '2.85854'}; time used = 5.291208982467651s
epoch 15: {'train_loss': '2.85065'}; time used = 4.903085708618164s
epoch 20: {'train_loss': '2.85271'}; time used = 4.1915013790130615s
epoch 25: {'train_loss': '2.82833'}; time used = 4.357617616653442s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.347516536712646.
Training classifier using 80.00% nodes...
{'micro': 0.7, 'macro': 0.6999699969997, 'samples': 0.7, 'weighted': 0.7000300030002999, 'accuracy': 0.7}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.38273'}; time used = 2.0002336502075195s
epoch 10: {'train_loss': '1.35135'}; time used = 2.035855770111084s
epoch 15: {'train_loss': '1.35060'}; time used = 1.9226598739624023s
epoch 20: {'train_loss': '1.37185'}; time used = 1.9110102653503418s
epoch 25: {'train_loss': '1.21204'}; time used = 2.0765373706817627s
epoch 30: {'train_loss': '0.94162'}; time used = 1.932988166809082s
epoch 35: {'train_loss': '1.01883'}; time used = 1.9533305168151855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.815369606018066.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78005'}; time used = 6.465271949768066s
epoch 10: {'train_loss': '2.78330'}; time used = 6.356086492538452s
epoch 15: {'train_loss': '2.77370'}; time used = 7.063831329345703s
epoch 20: {'train_loss': '2.77352'}; time used = 6.5270445346832275s
epoch 25: {'train_loss': '2.77577'}; time used = 6.381018400192261s
epoch 30: {'train_loss': '2.77443'}; time used = 6.38305401802063s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.151936769485474.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.45193159120188153, 'samples': 0.5066666666666667, 'weighted': 0.4431736434658251, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.32062'}; time used = 2.127833366394043s
epoch 10: {'train_loss': '1.24614'}; time used = 2.181102752685547s
epoch 15: {'train_loss': '1.23860'}; time used = 2.0748229026794434s
epoch 20: {'train_loss': '1.22136'}; time used = 2.045412302017212s
epoch 25: {'train_loss': '1.18261'}; time used = 2.126715898513794s
epoch 30: {'train_loss': '0.98794'}; time used = 2.2775444984436035s
epoch 35: {'train_loss': '0.91463'}; time used = 2.043518543243408s
epoch 40: {'train_loss': '0.87289'}; time used = 2.0244674682617188s
epoch 45: {'train_loss': '0.76341'}; time used = 2.0727760791778564s
epoch 50: {'train_loss': '0.74687'}; time used = 2.0730059146881104s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.282172918319702.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.07905'}; time used = 1.1371018886566162s
epoch 10: {'train_loss': '0.00240'}; time used = 0.9526784420013428s
epoch 15: {'train_loss': '0.00031'}; time used = 0.9936115741729736s
epoch 20: {'train_loss': '0.00000'}; time used = 0.9319953918457031s
epoch 25: {'train_loss': '0.00892'}; time used = 0.9344525337219238s
epoch 30: {'train_loss': '0.00073'}; time used = 0.9408595561981201s
epoch 35: {'train_loss': '0.00000'}; time used = 1.1394462585449219s
epoch 40: {'train_loss': '0.00002'}; time used = 1.0750346183776855s
epoch 45: {'train_loss': '0.00742'}; time used = 1.143556833267212s
epoch 50: {'train_loss': '0.00000'}; time used = 0.9415321350097656s
epoch 55: {'train_loss': '0.00000'}; time used = 0.8901865482330322s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.127509832382202.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.672156862745098, 'samples': 0.7105263157894737, 'weighted': 0.6898658410732714, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27002'}; time used = 3.0184385776519775s
epoch 10: {'train_loss': '2.95787'}; time used = 2.4533047676086426s
epoch 15: {'train_loss': '2.87804'}; time used = 1.3856356143951416s
epoch 20: {'train_loss': '2.80224'}; time used = 1.420257329940796s
epoch 25: {'train_loss': '2.81210'}; time used = 1.3534109592437744s
epoch 30: {'train_loss': '2.80054'}; time used = 1.4449570178985596s
epoch 35: {'train_loss': '2.79318'}; time used = 1.3312594890594482s
epoch 40: {'train_loss': '2.79020'}; time used = 1.3166382312774658s
epoch 45: {'train_loss': '2.79118'}; time used = 1.430741548538208s
epoch 50: {'train_loss': '2.78719'}; time used = 1.3487944602966309s
epoch 55: {'train_loss': '2.78174'}; time used = 1.3795881271362305s
epoch 60: {'train_loss': '2.78173'}; time used = 2.5661587715148926s
epoch 65: {'train_loss': '2.77783'}; time used = 2.6415271759033203s
epoch 70: {'train_loss': '2.77594'}; time used = 2.4124693870544434s
epoch 75: {'train_loss': '2.78583'}; time used = 2.499821186065674s
epoch 80: {'train_loss': '2.78014'}; time used = 2.020566701889038s
epoch 85: {'train_loss': '2.78066'}; time used = 1.4697275161743164s
epoch 90: {'train_loss': '2.78029'}; time used = 1.500131607055664s
epoch 95: {'train_loss': '2.77585'}; time used = 1.405773639678955s
epoch 100: {'train_loss': '2.77358'}; time used = 1.3414146900177002s
epoch 105: {'train_loss': '2.77254'}; time used = 1.3144068717956543s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.16576790809631.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.77226'}; time used = 1.0986855030059814s
epoch 10: {'train_loss': '2.53692'}; time used = 0.9183375835418701s
epoch 15: {'train_loss': '2.40254'}; time used = 1.0688011646270752s
epoch 20: {'train_loss': '2.21603'}; time used = 0.9827272891998291s
epoch 25: {'train_loss': '2.12540'}; time used = 0.9125502109527588s
epoch 30: {'train_loss': '2.03152'}; time used = 0.9993977546691895s
epoch 35: {'train_loss': '1.91862'}; time used = 0.9176433086395264s
epoch 40: {'train_loss': '1.86617'}; time used = 0.9415366649627686s
epoch 45: {'train_loss': '1.85619'}; time used = 0.9475481510162354s
epoch 50: {'train_loss': '1.84160'}; time used = 0.9311833381652832s
epoch 55: {'train_loss': '1.84676'}; time used = 0.9089450836181641s
epoch 60: {'train_loss': '1.84003'}; time used = 0.9915411472320557s
epoch 65: {'train_loss': '1.81483'}; time used = 0.9648644924163818s
epoch 70: {'train_loss': '1.82797'}; time used = 0.8997604846954346s
epoch 75: {'train_loss': '1.79430'}; time used = 0.9074440002441406s
epoch 80: {'train_loss': '1.80846'}; time used = 0.8895790576934814s
epoch 85: {'train_loss': '1.84867'}; time used = 0.8915390968322754s
epoch 90: {'train_loss': '1.82417'}; time used = 0.8775289058685303s
epoch 95: {'train_loss': '1.82047'}; time used = 1.0721747875213623s
epoch 100: {'train_loss': '1.83489'}; time used = 0.9042644500732422s
epoch 105: {'train_loss': '1.80361'}; time used = 1.0921192169189453s
epoch 110: {'train_loss': '1.80158'}; time used = 1.0494909286499023s
epoch 115: {'train_loss': '1.85271'}; time used = 0.9292173385620117s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.09128189086914.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.50982'}; time used = 1.3366193771362305s
epoch 10: {'train_loss': '0.24960'}; time used = 1.211364984512329s
epoch 15: {'train_loss': '0.24738'}; time used = 1.3361093997955322s
epoch 20: {'train_loss': '0.17206'}; time used = 1.304765224456787s
epoch 25: {'train_loss': '0.16510'}; time used = 1.2866172790527344s
epoch 30: {'train_loss': '0.13510'}; time used = 1.3353595733642578s
epoch 35: {'train_loss': '0.13298'}; time used = 1.330115556716919s
epoch 40: {'train_loss': '0.10331'}; time used = 1.3143374919891357s
epoch 45: {'train_loss': '0.17868'}; time used = 1.3517310619354248s
epoch 50: {'train_loss': '0.17697'}; time used = 1.385544776916504s
epoch 55: {'train_loss': '0.10591'}; time used = 1.3945882320404053s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.39669704437256.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82469'}; time used = 2.749096155166626s
epoch 10: {'train_loss': '2.76584'}; time used = 2.8612825870513916s
epoch 15: {'train_loss': '2.71519'}; time used = 2.864482879638672s
epoch 20: {'train_loss': '2.65145'}; time used = 2.287911891937256s
epoch 25: {'train_loss': '2.57978'}; time used = 1.7643346786499023s
epoch 30: {'train_loss': '2.52722'}; time used = 1.6740071773529053s
epoch 35: {'train_loss': '2.44771'}; time used = 1.6524324417114258s
epoch 40: {'train_loss': '2.33847'}; time used = 1.6667218208312988s
epoch 45: {'train_loss': '2.67846'}; time used = 1.6581437587738037s
epoch 50: {'train_loss': '2.33150'}; time used = 1.650730848312378s
epoch 55: {'train_loss': '2.34277'}; time used = 1.679090976715088s
epoch 60: {'train_loss': '2.25999'}; time used = 1.6365959644317627s
epoch 65: {'train_loss': '2.17811'}; time used = 1.6186673641204834s
epoch 70: {'train_loss': '2.12814'}; time used = 1.612706184387207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.878543615341187.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.65962'}; time used = 1.190561294555664s
epoch 10: {'train_loss': '0.47020'}; time used = 1.1337835788726807s
epoch 15: {'train_loss': '0.37761'}; time used = 0.9714787006378174s
epoch 20: {'train_loss': '0.25676'}; time used = 1.0865466594696045s
epoch 25: {'train_loss': '0.07554'}; time used = 1.4179527759552002s
epoch 30: {'train_loss': '0.03359'}; time used = 1.894899845123291s
epoch 35: {'train_loss': '0.05563'}; time used = 1.9191479682922363s
epoch 40: {'train_loss': '0.05469'}; time used = 1.9651620388031006s
epoch 45: {'train_loss': '0.04564'}; time used = 1.8935966491699219s
epoch 50: {'train_loss': '0.04301'}; time used = 1.6886608600616455s
epoch 55: {'train_loss': '0.03063'}; time used = 1.0747599601745605s
epoch 60: {'train_loss': '0.00728'}; time used = 1.058000087738037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.806846857070923.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.44 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39035'}; time used = 1.2236502170562744s
epoch 10: {'train_loss': '1.35799'}; time used = 1.0602803230285645s
epoch 15: {'train_loss': '1.28885'}; time used = 1.0352051258087158s
epoch 20: {'train_loss': '1.35105'}; time used = 1.5426418781280518s
epoch 25: {'train_loss': '1.22014'}; time used = 2.3046581745147705s
epoch 30: {'train_loss': '1.22029'}; time used = 3.7258529663085938s
epoch 35: {'train_loss': '1.26005'}; time used = 4.261948585510254s
epoch 40: {'train_loss': '1.19354'}; time used = 4.062755584716797s
epoch 45: {'train_loss': '1.05509'}; time used = 3.8385627269744873s
epoch 50: {'train_loss': '1.13936'}; time used = 4.2372167110443115s
epoch 55: {'train_loss': '1.13262'}; time used = 4.579679489135742s
epoch 60: {'train_loss': '1.26119'}; time used = 4.134885311126709s
epoch 65: {'train_loss': '1.12083'}; time used = 2.894033670425415s
epoch 70: {'train_loss': '1.25936'}; time used = 0.9749011993408203s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.3058021068573.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83886'}; time used = 1.7671427726745605s
epoch 10: {'train_loss': '2.72187'}; time used = 1.8159289360046387s
epoch 15: {'train_loss': '2.70216'}; time used = 1.8294477462768555s
epoch 20: {'train_loss': '2.68259'}; time used = 1.9647772312164307s
epoch 25: {'train_loss': '2.65924'}; time used = 1.9028003215789795s
epoch 30: {'train_loss': '2.64130'}; time used = 1.7478883266448975s
epoch 35: {'train_loss': '2.63267'}; time used = 1.7294652462005615s
epoch 40: {'train_loss': '2.61979'}; time used = 1.7357699871063232s
epoch 45: {'train_loss': '2.60730'}; time used = 1.6900873184204102s
epoch 50: {'train_loss': '2.58314'}; time used = 1.6991770267486572s
epoch 55: {'train_loss': '2.59144'}; time used = 1.8823492527008057s
epoch 60: {'train_loss': '2.59856'}; time used = 1.8219218254089355s
epoch 65: {'train_loss': '2.58477'}; time used = 1.7221145629882812s
epoch 70: {'train_loss': '2.57313'}; time used = 1.946882724761963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.892178535461426.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.96185'}; time used = 2.1256747245788574s
epoch 10: {'train_loss': '2.81142'}; time used = 2.0634677410125732s
epoch 15: {'train_loss': '2.79720'}; time used = 2.0063276290893555s
epoch 20: {'train_loss': '2.73455'}; time used = 1.8787496089935303s
epoch 25: {'train_loss': '2.61879'}; time used = 1.157799243927002s
epoch 30: {'train_loss': '2.43475'}; time used = 1.2802832126617432s
epoch 35: {'train_loss': '2.29530'}; time used = 1.1220757961273193s
epoch 40: {'train_loss': '2.19789'}; time used = 1.302164077758789s
epoch 45: {'train_loss': '2.20709'}; time used = 1.1394610404968262s
epoch 50: {'train_loss': '2.22096'}; time used = 1.437530755996704s
epoch 55: {'train_loss': '2.19927'}; time used = 1.2026612758636475s
epoch 60: {'train_loss': '2.16415'}; time used = 1.240114450454712s
epoch 65: {'train_loss': '2.12828'}; time used = 1.186098575592041s
epoch 70: {'train_loss': '2.15821'}; time used = 1.1769628524780273s
epoch 75: {'train_loss': '2.06762'}; time used = 1.1185903549194336s
epoch 80: {'train_loss': '2.08614'}; time used = 1.1987996101379395s
epoch 85: {'train_loss': '2.07676'}; time used = 1.3389561176300049s
epoch 90: {'train_loss': '2.14400'}; time used = 1.1696836948394775s
epoch 95: {'train_loss': '2.09467'}; time used = 1.2852363586425781s
epoch 100: {'train_loss': '2.05859'}; time used = 1.1474947929382324s
epoch 105: {'train_loss': '2.04557'}; time used = 1.4028115272521973s
epoch 110: {'train_loss': '2.03021'}; time used = 1.3183729648590088s
epoch 115: {'train_loss': '1.99752'}; time used = 1.3068983554840088s
epoch 120: {'train_loss': '1.98938'}; time used = 1.3061013221740723s
epoch 125: {'train_loss': '2.09628'}; time used = 1.1666407585144043s
epoch 130: {'train_loss': '1.99079'}; time used = 1.2693798542022705s
epoch 135: {'train_loss': '1.98323'}; time used = 1.1543078422546387s
epoch 140: {'train_loss': '1.96294'}; time used = 1.148188591003418s
epoch 145: {'train_loss': '1.98189'}; time used = 1.7060022354125977s
epoch 150: {'train_loss': '2.00279'}; time used = 2.043165683746338s
epoch 155: {'train_loss': '1.92655'}; time used = 2.0291168689727783s
epoch 160: {'train_loss': '2.08048'}; time used = 1.9562833309173584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.761131048202515.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01844'}; time used = 1.0027451515197754s
epoch 10: {'train_loss': '0.52292'}; time used = 0.877730131149292s
epoch 15: {'train_loss': '0.34858'}; time used = 0.8996338844299316s
epoch 20: {'train_loss': '0.29309'}; time used = 0.8435673713684082s
epoch 25: {'train_loss': '0.19221'}; time used = 0.892829179763794s
epoch 30: {'train_loss': '0.13123'}; time used = 0.8716566562652588s
epoch 35: {'train_loss': '0.07608'}; time used = 0.852142333984375s
epoch 40: {'train_loss': '0.05291'}; time used = 0.9762454032897949s
epoch 45: {'train_loss': '0.03781'}; time used = 1.0196506977081299s
epoch 50: {'train_loss': '0.02895'}; time used = 1.0288503170013428s
epoch 55: {'train_loss': '0.01644'}; time used = 1.022712230682373s
epoch 60: {'train_loss': '0.01774'}; time used = 1.1076648235321045s
epoch 65: {'train_loss': '0.01958'}; time used = 1.0404126644134521s
epoch 70: {'train_loss': '0.01209'}; time used = 1.054145097732544s
epoch 75: {'train_loss': '0.00924'}; time used = 1.0259594917297363s
epoch 80: {'train_loss': '0.01468'}; time used = 1.029646873474121s
epoch 85: {'train_loss': '0.02336'}; time used = 1.0457603931427002s
epoch 90: {'train_loss': '0.02308'}; time used = 1.0471956729888916s
epoch 95: {'train_loss': '0.01578'}; time used = 1.0533440113067627s
epoch 100: {'train_loss': '0.02084'}; time used = 1.0541961193084717s
epoch 105: {'train_loss': '0.01202'}; time used = 1.1405277252197266s
epoch 110: {'train_loss': '0.00983'}; time used = 1.1148920059204102s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.806235313415527.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39652'}; time used = 1.3230981826782227s
epoch 10: {'train_loss': '1.39832'}; time used = 1.175635576248169s
epoch 15: {'train_loss': '1.38573'}; time used = 1.177905797958374s
epoch 20: {'train_loss': '1.39059'}; time used = 1.1690254211425781s
epoch 25: {'train_loss': '1.38800'}; time used = 1.1579303741455078s
epoch 30: {'train_loss': '1.38517'}; time used = 1.1714894771575928s
epoch 35: {'train_loss': '1.39273'}; time used = 2.3948841094970703s
epoch 40: {'train_loss': '1.37175'}; time used = 3.7790846824645996s
epoch 45: {'train_loss': '1.34001'}; time used = 2.456345796585083s
epoch 50: {'train_loss': '1.39923'}; time used = 1.2033748626708984s
epoch 55: {'train_loss': '1.37088'}; time used = 1.1993041038513184s
epoch 60: {'train_loss': '1.34661'}; time used = 1.141860008239746s
epoch 65: {'train_loss': '1.25801'}; time used = 1.1829662322998047s
epoch 70: {'train_loss': '1.30839'}; time used = 1.1534409523010254s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.941984176635742.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.83734'}; time used = 1.1680397987365723s
epoch 10: {'train_loss': '0.42191'}; time used = 1.1316502094268799s
epoch 15: {'train_loss': '0.30129'}; time used = 1.0989739894866943s
epoch 20: {'train_loss': '0.25256'}; time used = 1.0046391487121582s
epoch 25: {'train_loss': '0.27721'}; time used = 0.8816711902618408s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.442738771438599.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77633'}; time used = 3.4390573501586914s
epoch 10: {'train_loss': '2.76536'}; time used = 3.5863943099975586s
epoch 15: {'train_loss': '2.76741'}; time used = 2.031541585922241s
epoch 20: {'train_loss': '2.74813'}; time used = 1.877910852432251s
epoch 25: {'train_loss': '2.73764'}; time used = 1.7664532661437988s
epoch 30: {'train_loss': '2.73598'}; time used = 1.7798843383789062s
epoch 35: {'train_loss': '2.74113'}; time used = 1.6270017623901367s
epoch 40: {'train_loss': '2.73229'}; time used = 1.7407197952270508s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.731303453445435.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01568'}; time used = 1.8191509246826172s
epoch 10: {'train_loss': '0.60216'}; time used = 1.959930181503296s
epoch 15: {'train_loss': '0.27461'}; time used = 1.0683317184448242s
epoch 20: {'train_loss': '0.14891'}; time used = 0.9944753646850586s
epoch 25: {'train_loss': '0.08477'}; time used = 0.9031054973602295s
epoch 30: {'train_loss': '0.04558'}; time used = 1.001758337020874s
epoch 35: {'train_loss': '0.03274'}; time used = 0.9140443801879883s
epoch 40: {'train_loss': '0.02288'}; time used = 0.8897445201873779s
epoch 45: {'train_loss': '0.01998'}; time used = 0.9066762924194336s
epoch 50: {'train_loss': '0.01007'}; time used = 1.2785930633544922s
epoch 55: {'train_loss': '0.00813'}; time used = 1.0430662631988525s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.502808809280396.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8246153846153846, 'samples': 0.8421052631578947, 'weighted': 0.8333603238866396, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83283'}; time used = 4.232923984527588s
epoch 10: {'train_loss': '2.80271'}; time used = 4.063649654388428s
epoch 15: {'train_loss': '2.78868'}; time used = 4.156891584396362s
epoch 20: {'train_loss': '2.78031'}; time used = 4.526824235916138s
epoch 25: {'train_loss': '2.77543'}; time used = 4.071580410003662s
epoch 30: {'train_loss': '2.77324'}; time used = 4.442746639251709s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.488929271698.
Training classifier using 80.00% nodes...
{'micro': 0.68, 'macro': 0.6784242789669379, 'samples': 0.68, 'weighted': 0.6779740729574917, 'accuracy': 0.68}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.12543'}; time used = 2.2007787227630615s
epoch 10: {'train_loss': '0.19978'}; time used = 1.965583086013794s
epoch 15: {'train_loss': '0.00599'}; time used = 1.9902458190917969s
epoch 20: {'train_loss': '0.04477'}; time used = 1.9446907043457031s
epoch 25: {'train_loss': '0.04610'}; time used = 1.7216317653656006s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.162383079528809.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.34750'}; time used = 1.693324327468872s
epoch 10: {'train_loss': '0.21238'}; time used = 0.9375371932983398s
epoch 15: {'train_loss': '0.14200'}; time used = 0.9164822101593018s
epoch 20: {'train_loss': '0.15263'}; time used = 0.9200479984283447s
epoch 25: {'train_loss': '0.17061'}; time used = 0.9317238330841064s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.238735914230347.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6492307692307693, 'samples': 0.6842105263157895, 'weighted': 0.6667206477732792, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36175'}; time used = 1.873337745666504s
epoch 10: {'train_loss': '1.28706'}; time used = 2.016310691833496s
epoch 15: {'train_loss': '1.17901'}; time used = 1.940352439880371s
epoch 20: {'train_loss': '1.21265'}; time used = 2.0603232383728027s
epoch 25: {'train_loss': '1.10668'}; time used = 2.331561326980591s
epoch 30: {'train_loss': '1.05247'}; time used = 2.749387264251709s
epoch 35: {'train_loss': '1.10929'}; time used = 3.627718210220337s
epoch 40: {'train_loss': '0.87443'}; time used = 3.535294771194458s
epoch 45: {'train_loss': '0.80625'}; time used = 2.5627973079681396s
epoch 50: {'train_loss': '0.68032'}; time used = 1.8350300788879395s
epoch 55: {'train_loss': '0.59843'}; time used = 1.7576298713684082s
epoch 60: {'train_loss': '0.70606'}; time used = 1.760413408279419s
epoch 65: {'train_loss': '0.74626'}; time used = 1.7093391418457031s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.69466543197632.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33653'}; time used = 2.634582757949829s
epoch 10: {'train_loss': '1.22648'}; time used = 2.7387375831604004s
epoch 15: {'train_loss': '1.21070'}; time used = 4.029310464859009s
epoch 20: {'train_loss': '1.20461'}; time used = 4.16710352897644s
epoch 25: {'train_loss': '1.15898'}; time used = 5.663376331329346s
epoch 30: {'train_loss': '1.09433'}; time used = 3.832127332687378s
epoch 35: {'train_loss': '0.99837'}; time used = 2.511990785598755s
epoch 40: {'train_loss': '0.91570'}; time used = 2.539886951446533s
epoch 45: {'train_loss': '1.00583'}; time used = 2.526332139968872s
epoch 50: {'train_loss': '0.68609'}; time used = 2.610628604888916s
epoch 55: {'train_loss': '0.60054'}; time used = 2.6029860973358154s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.137047290802.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.53045'}; time used = 1.528085708618164s
epoch 10: {'train_loss': '0.23896'}; time used = 1.213972568511963s
epoch 15: {'train_loss': '0.10122'}; time used = 1.114565372467041s
epoch 20: {'train_loss': '0.05313'}; time used = 1.2239885330200195s
epoch 25: {'train_loss': '0.13695'}; time used = 1.0970051288604736s
epoch 30: {'train_loss': '0.05066'}; time used = 1.2754542827606201s
epoch 35: {'train_loss': '0.05610'}; time used = 1.3069891929626465s
epoch 40: {'train_loss': '0.04805'}; time used = 1.1188290119171143s
epoch 45: {'train_loss': '0.06792'}; time used = 1.1007661819458008s
epoch 50: {'train_loss': '0.06685'}; time used = 1.9100897312164307s
epoch 55: {'train_loss': '0.04453'}; time used = 2.077582359313965s
epoch 60: {'train_loss': '0.02328'}; time used = 2.2449796199798584s
epoch 65: {'train_loss': '0.03020'}; time used = 2.0299854278564453s
epoch 70: {'train_loss': '0.02306'}; time used = 1.8936057090759277s
epoch 75: {'train_loss': '0.02219'}; time used = 1.1382718086242676s
epoch 80: {'train_loss': '0.00685'}; time used = 1.2721014022827148s
epoch 85: {'train_loss': '0.02787'}; time used = 1.2618706226348877s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.981821060180664.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31085'}; time used = 2.4731996059417725s
epoch 10: {'train_loss': '0.99990'}; time used = 2.520930767059326s
epoch 15: {'train_loss': '0.69996'}; time used = 2.56892728805542s
epoch 20: {'train_loss': '0.47053'}; time used = 2.468724489212036s
epoch 25: {'train_loss': '0.44749'}; time used = 2.6588053703308105s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.589117527008057.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.35259'}; time used = 1.7288289070129395s
epoch 10: {'train_loss': '1.29899'}; time used = 1.7290301322937012s
epoch 15: {'train_loss': '1.32151'}; time used = 1.6955015659332275s
epoch 20: {'train_loss': '1.40306'}; time used = 1.8803980350494385s
epoch 25: {'train_loss': '1.35590'}; time used = 1.8021197319030762s
epoch 30: {'train_loss': '1.29929'}; time used = 1.6909353733062744s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.68630337715149.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39286'}; time used = 1.3069276809692383s
epoch 10: {'train_loss': '1.41455'}; time used = 1.2178866863250732s
epoch 15: {'train_loss': '1.39239'}; time used = 1.2085084915161133s
epoch 20: {'train_loss': '1.37962'}; time used = 1.1851835250854492s
epoch 25: {'train_loss': '1.42587'}; time used = 1.8121235370635986s
epoch 30: {'train_loss': '1.37226'}; time used = 3.0287771224975586s
epoch 35: {'train_loss': '1.38055'}; time used = 1.5851812362670898s
epoch 40: {'train_loss': '1.36430'}; time used = 1.1739752292633057s
epoch 45: {'train_loss': '1.35853'}; time used = 1.2059268951416016s
epoch 50: {'train_loss': '1.41150'}; time used = 1.1644442081451416s
epoch 55: {'train_loss': '1.38413'}; time used = 2.1283535957336426s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.329495429992676.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.67229'}; time used = 2.4904239177703857s
epoch 10: {'train_loss': '2.56758'}; time used = 2.308246612548828s
epoch 15: {'train_loss': '2.52986'}; time used = 2.2169320583343506s
epoch 20: {'train_loss': '2.48161'}; time used = 1.9487831592559814s
epoch 25: {'train_loss': '2.43892'}; time used = 2.4874556064605713s
epoch 30: {'train_loss': '2.34886'}; time used = 2.304872989654541s
epoch 35: {'train_loss': '2.32516'}; time used = 2.187896966934204s
epoch 40: {'train_loss': '2.30330'}; time used = 2.196420192718506s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.559364318847656.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.92953'}; time used = 2.0927698612213135s
epoch 10: {'train_loss': '2.80842'}; time used = 2.0251054763793945s
epoch 15: {'train_loss': '2.76153'}; time used = 2.0089802742004395s
epoch 20: {'train_loss': '2.71295'}; time used = 2.004854917526245s
epoch 25: {'train_loss': '2.66646'}; time used = 2.1264901161193848s
epoch 30: {'train_loss': '2.62971'}; time used = 1.9906041622161865s
epoch 35: {'train_loss': '2.61171'}; time used = 1.9662652015686035s
epoch 40: {'train_loss': '2.58896'}; time used = 1.9887659549713135s
epoch 45: {'train_loss': '2.55581'}; time used = 1.9933686256408691s
epoch 50: {'train_loss': '2.52016'}; time used = 1.9105088710784912s
epoch 55: {'train_loss': '2.52282'}; time used = 1.9144237041473389s
epoch 60: {'train_loss': '2.51826'}; time used = 1.804267168045044s
epoch 65: {'train_loss': '2.49128'}; time used = 2.0216917991638184s
epoch 70: {'train_loss': '2.45635'}; time used = 1.7483444213867188s
epoch 75: {'train_loss': '2.43265'}; time used = 2.6403050422668457s
epoch 80: {'train_loss': '2.40407'}; time used = 3.1560657024383545s
epoch 85: {'train_loss': '2.41133'}; time used = 3.0437707901000977s
epoch 90: {'train_loss': '2.39321'}; time used = 1.967047929763794s
epoch 95: {'train_loss': '2.38779'}; time used = 1.8704938888549805s
epoch 100: {'train_loss': '2.36647'}; time used = 1.859339952468872s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.74741005897522.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.37864'}; time used = 2.4158902168273926s
epoch 10: {'train_loss': '0.25105'}; time used = 1.676088809967041s
epoch 15: {'train_loss': '0.22828'}; time used = 1.6589460372924805s
epoch 20: {'train_loss': '0.23493'}; time used = 1.6798090934753418s
epoch 25: {'train_loss': '0.29602'}; time used = 1.8929481506347656s
epoch 30: {'train_loss': '0.27284'}; time used = 1.7918121814727783s
epoch 35: {'train_loss': '0.20896'}; time used = 1.6559741497039795s
epoch 40: {'train_loss': '0.23396'}; time used = 1.660163164138794s
epoch 45: {'train_loss': '0.12679'}; time used = 1.635308027267456s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.089354515075684.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37640'}; time used = 1.9171183109283447s
epoch 10: {'train_loss': '1.32903'}; time used = 2.207819938659668s
epoch 15: {'train_loss': '1.35108'}; time used = 1.9728293418884277s
epoch 20: {'train_loss': '1.44247'}; time used = 1.8328235149383545s
epoch 25: {'train_loss': '1.39925'}; time used = 2.1604037284851074s
epoch 30: {'train_loss': '1.33820'}; time used = 1.8472888469696045s
epoch 35: {'train_loss': '1.23534'}; time used = 1.907069444656372s
epoch 40: {'train_loss': '1.15300'}; time used = 1.8410389423370361s
epoch 45: {'train_loss': '1.13991'}; time used = 1.8476762771606445s
epoch 50: {'train_loss': '0.93577'}; time used = 1.8907380104064941s
epoch 55: {'train_loss': '0.88715'}; time used = 1.9047057628631592s
epoch 60: {'train_loss': '0.80117'}; time used = 1.8569045066833496s
epoch 65: {'train_loss': '0.91708'}; time used = 1.9302761554718018s
epoch 70: {'train_loss': '0.87157'}; time used = 1.9642488956451416s
epoch 75: {'train_loss': '0.85141'}; time used = 2.007235050201416s
epoch 80: {'train_loss': '0.82873'}; time used = 1.9188716411590576s
epoch 85: {'train_loss': '0.65635'}; time used = 1.973658800125122s
epoch 90: {'train_loss': '0.85774'}; time used = 1.844489574432373s
epoch 95: {'train_loss': '0.80681'}; time used = 1.908691644668579s
epoch 100: {'train_loss': '0.66940'}; time used = 1.9870281219482422s
epoch 105: {'train_loss': '0.74056'}; time used = 1.8791184425354004s
epoch 110: {'train_loss': '0.59636'}; time used = 2.0182740688323975s
epoch 115: {'train_loss': '0.86210'}; time used = 1.9489517211914062s
epoch 120: {'train_loss': '0.84640'}; time used = 1.9481568336486816s
epoch 125: {'train_loss': '0.83312'}; time used = 2.051511526107788s
epoch 130: {'train_loss': '0.66255'}; time used = 2.2662625312805176s
epoch 135: {'train_loss': '0.68383'}; time used = 2.0728492736816406s
epoch 140: {'train_loss': '0.23746'}; time used = 3.308614492416382s
epoch 145: {'train_loss': '1.49204'}; time used = 2.387756824493408s
epoch 150: {'train_loss': '1.12657'}; time used = 3.5494987964630127s
epoch 155: {'train_loss': '0.67332'}; time used = 3.721240758895874s
epoch 160: {'train_loss': '0.26038'}; time used = 2.6335341930389404s
epoch 165: {'train_loss': '0.00935'}; time used = 2.7414629459381104s
epoch 170: {'train_loss': '0.08222'}; time used = 3.929070472717285s
epoch 175: {'train_loss': '0.01195'}; time used = 4.525003910064697s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 88.8769474029541.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.4453651905059814s
epoch 10: {'train_loss': '1.38629'}; time used = 7.263357877731323s
epoch 15: {'train_loss': '1.38629'}; time used = 4.85788893699646s
epoch 20: {'train_loss': '1.38629'}; time used = 4.275004625320435s
epoch 25: {'train_loss': '1.38629'}; time used = 4.998881816864014s
epoch 30: {'train_loss': '1.38629'}; time used = 4.292184352874756s
epoch 35: {'train_loss': '1.38629'}; time used = 4.353880167007446s
epoch 40: {'train_loss': '1.38629'}; time used = 4.345496892929077s
epoch 45: {'train_loss': '1.38629'}; time used = 4.597584247589111s
epoch 50: {'train_loss': '1.38629'}; time used = 4.601319313049316s
epoch 55: {'train_loss': '1.38629'}; time used = 4.3038153648376465s
epoch 60: {'train_loss': '1.38629'}; time used = 5.1712799072265625s
epoch 65: {'train_loss': '1.38629'}; time used = 4.339002370834351s
epoch 70: {'train_loss': '1.38629'}; time used = 4.341360569000244s
epoch 75: {'train_loss': '1.38629'}; time used = 5.277163982391357s
epoch 80: {'train_loss': '1.38629'}; time used = 4.381798505783081s
epoch 85: {'train_loss': '1.38629'}; time used = 4.309402227401733s
epoch 90: {'train_loss': '1.38629'}; time used = 4.266899108886719s
epoch 95: {'train_loss': '1.38629'}; time used = 4.8241753578186035s
epoch 100: {'train_loss': '1.38629'}; time used = 5.036258935928345s
epoch 105: {'train_loss': '1.38629'}; time used = 4.1623969078063965s
epoch 110: {'train_loss': '1.38629'}; time used = 4.284834623336792s
epoch 115: {'train_loss': '1.38629'}; time used = 4.388646602630615s
epoch 120: {'train_loss': '1.38629'}; time used = 4.302674770355225s
epoch 125: {'train_loss': '1.38629'}; time used = 4.614837884902954s
epoch 130: {'train_loss': '1.38629'}; time used = 4.522595643997192s
epoch 135: {'train_loss': '1.38629'}; time used = 4.312440395355225s
epoch 140: {'train_loss': '1.38629'}; time used = 4.351658582687378s
epoch 145: {'train_loss': '1.38629'}; time used = 4.225574970245361s
epoch 150: {'train_loss': '1.38629'}; time used = 4.1982574462890625s
epoch 155: {'train_loss': '1.38629'}; time used = 4.2177345752716064s
epoch 160: {'train_loss': '1.38629'}; time used = 4.229686737060547s
epoch 165: {'train_loss': '1.38629'}; time used = 4.305239915847778s
epoch 170: {'train_loss': '1.38629'}; time used = 4.588980674743652s
epoch 175: {'train_loss': '1.38629'}; time used = 4.928759336471558s
epoch 180: {'train_loss': '1.38629'}; time used = 7.2709808349609375s
epoch 185: {'train_loss': '1.38629'}; time used = 4.4891767501831055s
epoch 190: {'train_loss': '1.38629'}; time used = 4.350784063339233s
epoch 195: {'train_loss': '1.38629'}; time used = 5.25982141494751s
epoch 200: {'train_loss': '1.38629'}; time used = 6.829790830612183s
epoch 205: {'train_loss': '1.38629'}; time used = 4.559818506240845s
epoch 210: {'train_loss': '1.38629'}; time used = 4.427289247512817s
epoch 215: {'train_loss': '1.38629'}; time used = 5.391473293304443s
epoch 220: {'train_loss': '1.38629'}; time used = 6.982598543167114s
epoch 225: {'train_loss': '1.38629'}; time used = 4.715160369873047s
epoch 230: {'train_loss': '1.38629'}; time used = 5.014530658721924s
epoch 235: {'train_loss': '1.38629'}; time used = 4.980812072753906s
epoch 240: {'train_loss': '1.38629'}; time used = 5.193768739700317s
epoch 245: {'train_loss': '1.38629'}; time used = 6.5506980419158936s
epoch 250: {'train_loss': '1.38629'}; time used = 6.358319044113159s
epoch 255: {'train_loss': '1.38629'}; time used = 5.27621603012085s
epoch 260: {'train_loss': '1.38629'}; time used = 5.2348620891571045s
epoch 265: {'train_loss': '1.38629'}; time used = 5.838526487350464s
epoch 270: {'train_loss': '1.38629'}; time used = 4.2811219692230225s
epoch 275: {'train_loss': '1.38629'}; time used = 4.3019726276397705s
epoch 280: {'train_loss': '1.38629'}; time used = 4.266933917999268s
epoch 285: {'train_loss': '1.38629'}; time used = 4.33721137046814s
epoch 290: {'train_loss': '1.38629'}; time used = 5.460275650024414s
epoch 295: {'train_loss': '1.38629'}; time used = 6.873401165008545s
epoch 300: {'train_loss': '1.38629'}; time used = 6.048792362213135s
epoch 305: {'train_loss': '1.38629'}; time used = 4.963567018508911s
epoch 310: {'train_loss': '1.38629'}; time used = 4.385528802871704s
epoch 315: {'train_loss': '1.38629'}; time used = 4.303416967391968s
epoch 320: {'train_loss': '1.38629'}; time used = 4.35764217376709s
epoch 325: {'train_loss': '1.38629'}; time used = 4.370427131652832s
epoch 330: {'train_loss': '1.38629'}; time used = 4.170303106307983s
epoch 335: {'train_loss': '1.38629'}; time used = 4.289526700973511s
epoch 340: {'train_loss': '1.38629'}; time used = 4.410537004470825s
epoch 345: {'train_loss': '1.38629'}; time used = 4.348490953445435s
epoch 350: {'train_loss': '1.38629'}; time used = 4.310020923614502s
epoch 355: {'train_loss': '1.38629'}; time used = 4.101069211959839s
epoch 360: {'train_loss': '1.38629'}; time used = 4.1938536167144775s
epoch 365: {'train_loss': '1.38629'}; time used = 4.249023199081421s
epoch 370: {'train_loss': '1.38629'}; time used = 4.260391712188721s
epoch 375: {'train_loss': '1.38629'}; time used = 4.914499044418335s
epoch 380: {'train_loss': '1.38629'}; time used = 4.747785568237305s
epoch 385: {'train_loss': '1.38629'}; time used = 4.245388031005859s
epoch 390: {'train_loss': '1.38629'}; time used = 4.378255605697632s
epoch 395: {'train_loss': '1.38629'}; time used = 4.431872606277466s
epoch 400: {'train_loss': '1.38629'}; time used = 4.32146692276001s
epoch 405: {'train_loss': '1.38629'}; time used = 4.595261573791504s
epoch 410: {'train_loss': '1.38629'}; time used = 4.327578783035278s
epoch 415: {'train_loss': '1.38629'}; time used = 4.476754426956177s
epoch 420: {'train_loss': '1.38629'}; time used = 4.54685640335083s
epoch 425: {'train_loss': '1.38629'}; time used = 4.333014726638794s
epoch 430: {'train_loss': '1.38629'}; time used = 4.369806528091431s
epoch 435: {'train_loss': '1.38629'}; time used = 4.293146133422852s
epoch 440: {'train_loss': '1.38629'}; time used = 4.1268885135650635s
epoch 445: {'train_loss': '1.38629'}; time used = 4.208103179931641s
epoch 450: {'train_loss': '1.38629'}; time used = 4.222694635391235s
epoch 455: {'train_loss': '1.38629'}; time used = 4.353605031967163s
epoch 460: {'train_loss': '1.38629'}; time used = 4.4519407749176025s
epoch 465: {'train_loss': '1.38629'}; time used = 4.341537952423096s
epoch 470: {'train_loss': '1.38629'}; time used = 4.497708320617676s
epoch 475: {'train_loss': '1.38629'}; time used = 4.397779226303101s
epoch 480: {'train_loss': '1.38629'}; time used = 6.75084376335144s
epoch 485: {'train_loss': '1.38629'}; time used = 8.13071584701538s
epoch 490: {'train_loss': '1.38629'}; time used = 7.3032143115997314s
epoch 495: {'train_loss': '1.38629'}; time used = 5.940911769866943s
epoch 500: {'train_loss': '1.38629'}; time used = 4.383674383163452s
Finished training. Time used = 488.89345049858093.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81620'}; time used = 2.1486587524414062s
epoch 10: {'train_loss': '2.80341'}; time used = 2.272646427154541s
epoch 15: {'train_loss': '2.77725'}; time used = 2.365064859390259s
epoch 20: {'train_loss': '2.77898'}; time used = 2.3828558921813965s
epoch 25: {'train_loss': '2.75853'}; time used = 2.5261011123657227s
epoch 30: {'train_loss': '2.74163'}; time used = 2.135854721069336s
epoch 35: {'train_loss': '2.71938'}; time used = 2.294398069381714s
epoch 40: {'train_loss': '2.65049'}; time used = 2.434873580932617s
epoch 45: {'train_loss': '2.59544'}; time used = 2.3648412227630615s
epoch 50: {'train_loss': '2.55323'}; time used = 2.3839616775512695s
epoch 55: {'train_loss': '2.61930'}; time used = 2.4225997924804688s
epoch 60: {'train_loss': '2.55465'}; time used = 2.330561876296997s
epoch 65: {'train_loss': '2.52890'}; time used = 2.3261971473693848s
epoch 70: {'train_loss': '2.50617'}; time used = 2.3282811641693115s
epoch 75: {'train_loss': '2.46439'}; time used = 2.322619915008545s
epoch 80: {'train_loss': '2.44673'}; time used = 2.261153221130371s
epoch 85: {'train_loss': '2.43948'}; time used = 2.0155258178710938s
epoch 90: {'train_loss': '2.47430'}; time used = 2.0305304527282715s
epoch 95: {'train_loss': '2.43988'}; time used = 2.0921823978424072s
epoch 100: {'train_loss': '2.50495'}; time used = 2.0213189125061035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.99763512611389.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38966'}; time used = 1.3180861473083496s
epoch 10: {'train_loss': '1.35853'}; time used = 1.2053890228271484s
epoch 15: {'train_loss': '1.28733'}; time used = 1.1382036209106445s
epoch 20: {'train_loss': '1.29801'}; time used = 1.1565289497375488s
epoch 25: {'train_loss': '1.21134'}; time used = 1.161996841430664s
epoch 30: {'train_loss': '1.27975'}; time used = 1.1168105602264404s
epoch 35: {'train_loss': '1.31433'}; time used = 1.1286981105804443s
epoch 40: {'train_loss': '1.27554'}; time used = 1.1317319869995117s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.39377760887146.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.59666'}; time used = 1.2284209728240967s
epoch 10: {'train_loss': '0.13485'}; time used = 1.1013851165771484s
epoch 15: {'train_loss': '0.10586'}; time used = 1.2552902698516846s
epoch 20: {'train_loss': '0.06759'}; time used = 0.8863153457641602s
epoch 25: {'train_loss': '0.06649'}; time used = 0.8877592086791992s
epoch 30: {'train_loss': '0.06051'}; time used = 0.8547077178955078s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.039946556091309.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.07461'}; time used = 1.2207231521606445s
epoch 10: {'train_loss': '2.89431'}; time used = 1.2127087116241455s
epoch 15: {'train_loss': '2.84607'}; time used = 1.3336799144744873s
epoch 20: {'train_loss': '2.80204'}; time used = 1.1497406959533691s
epoch 25: {'train_loss': '2.73066'}; time used = 1.0904042720794678s
epoch 30: {'train_loss': '2.63721'}; time used = 1.1992871761322021s
epoch 35: {'train_loss': '2.48437'}; time used = 1.2399325370788574s
epoch 40: {'train_loss': '2.34637'}; time used = 1.181708574295044s
epoch 45: {'train_loss': '2.31050'}; time used = 1.0916748046875s
epoch 50: {'train_loss': '2.28388'}; time used = 1.0742406845092773s
epoch 55: {'train_loss': '2.20867'}; time used = 1.088301658630371s
epoch 60: {'train_loss': '2.17932'}; time used = 1.1520500183105469s
epoch 65: {'train_loss': '2.20191'}; time used = 1.0401194095611572s
epoch 70: {'train_loss': '2.26633'}; time used = 1.031792402267456s
epoch 75: {'train_loss': '2.17061'}; time used = 1.042891502380371s
epoch 80: {'train_loss': '2.15147'}; time used = 1.4236252307891846s
epoch 85: {'train_loss': '2.17039'}; time used = 1.2223997116088867s
epoch 90: {'train_loss': '2.14618'}; time used = 1.1918041706085205s
epoch 95: {'train_loss': '2.18022'}; time used = 1.234142780303955s
epoch 100: {'train_loss': '2.14684'}; time used = 1.0438647270202637s
epoch 105: {'train_loss': '2.13595'}; time used = 1.0845365524291992s
epoch 110: {'train_loss': '2.11877'}; time used = 1.1227126121520996s
epoch 115: {'train_loss': '2.11545'}; time used = 1.0446865558624268s
epoch 120: {'train_loss': '2.09442'}; time used = 1.1289150714874268s
epoch 125: {'train_loss': '2.10974'}; time used = 1.0711417198181152s
epoch 130: {'train_loss': '2.08721'}; time used = 1.0604138374328613s
epoch 135: {'train_loss': '2.09955'}; time used = 1.0856654644012451s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.60696315765381.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68889'}; time used = 2.3410167694091797s
epoch 10: {'train_loss': '2.63647'}; time used = 1.6641957759857178s
epoch 15: {'train_loss': '2.61866'}; time used = 2.0064857006073s
epoch 20: {'train_loss': '2.58329'}; time used = 1.9916136264801025s
epoch 25: {'train_loss': '2.56332'}; time used = 1.6283996105194092s
epoch 30: {'train_loss': '2.53356'}; time used = 1.5558054447174072s
epoch 35: {'train_loss': '2.50958'}; time used = 1.5695466995239258s
epoch 40: {'train_loss': '2.47382'}; time used = 1.5439982414245605s
epoch 45: {'train_loss': '2.44449'}; time used = 1.553234338760376s
epoch 50: {'train_loss': '2.41279'}; time used = 1.5378429889678955s
epoch 55: {'train_loss': '2.41730'}; time used = 1.6105608940124512s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.42317032814026.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75898'}; time used = 3.2101733684539795s
epoch 10: {'train_loss': '2.73986'}; time used = 1.8208684921264648s
epoch 15: {'train_loss': '2.71603'}; time used = 1.8076860904693604s
epoch 20: {'train_loss': '2.68694'}; time used = 2.271467685699463s
epoch 25: {'train_loss': '2.64136'}; time used = 2.0993995666503906s
epoch 30: {'train_loss': '2.59192'}; time used = 1.8258750438690186s
epoch 35: {'train_loss': '2.57027'}; time used = 1.8237056732177734s
epoch 40: {'train_loss': '2.51279'}; time used = 1.8323514461517334s
epoch 45: {'train_loss': '2.49821'}; time used = 1.8335189819335938s
epoch 50: {'train_loss': '2.46103'}; time used = 1.8380796909332275s
epoch 55: {'train_loss': '2.47525'}; time used = 1.8889234066009521s
epoch 60: {'train_loss': '2.47901'}; time used = 1.8219590187072754s
epoch 65: {'train_loss': '2.45849'}; time used = 1.8309049606323242s
epoch 70: {'train_loss': '2.42532'}; time used = 1.9079270362854004s
epoch 75: {'train_loss': '2.39300'}; time used = 2.306570529937744s
epoch 80: {'train_loss': '2.40193'}; time used = 2.872607946395874s
epoch 85: {'train_loss': '2.38387'}; time used = 1.8749773502349854s
epoch 90: {'train_loss': '2.41651'}; time used = 1.642577886581421s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.58892226219177.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.623109243697479, 'samples': 0.6231884057971014, 'weighted': 0.6235050541955912, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.96185'}; time used = 1.066030502319336s
epoch 10: {'train_loss': '2.64246'}; time used = 0.9820065498352051s
epoch 15: {'train_loss': '2.55063'}; time used = 1.1160848140716553s
epoch 20: {'train_loss': '2.49812'}; time used = 1.0505099296569824s
epoch 25: {'train_loss': '2.46398'}; time used = 1.7400760650634766s
epoch 30: {'train_loss': '2.36473'}; time used = 1.3520448207855225s
epoch 35: {'train_loss': '2.28171'}; time used = 1.0338480472564697s
epoch 40: {'train_loss': '2.18337'}; time used = 0.9488158226013184s
epoch 45: {'train_loss': '2.13867'}; time used = 1.0976543426513672s
epoch 50: {'train_loss': '2.15672'}; time used = 0.9840691089630127s
epoch 55: {'train_loss': '2.13096'}; time used = 1.021132230758667s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.22952151298523.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40860'}; time used = 1.1296706199645996s
epoch 10: {'train_loss': '1.37551'}; time used = 0.9956052303314209s
epoch 15: {'train_loss': '1.32501'}; time used = 1.1054091453552246s
epoch 20: {'train_loss': '1.31487'}; time used = 1.00270676612854s
epoch 25: {'train_loss': '1.25231'}; time used = 1.0077826976776123s
epoch 30: {'train_loss': '1.28009'}; time used = 1.106318712234497s
epoch 35: {'train_loss': '1.31137'}; time used = 1.0999679565429688s
epoch 40: {'train_loss': '1.28273'}; time used = 0.9750924110412598s
epoch 45: {'train_loss': '1.16837'}; time used = 1.0767569541931152s
epoch 50: {'train_loss': '1.20251'}; time used = 1.0688488483428955s
epoch 55: {'train_loss': '1.18520'}; time used = 0.9957530498504639s
epoch 60: {'train_loss': '1.23547'}; time used = 1.1670162677764893s
epoch 65: {'train_loss': '1.13305'}; time used = 1.1627655029296875s
epoch 70: {'train_loss': '1.26294'}; time used = 1.039025068283081s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.423731327056885.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89859'}; time used = 2.62589693069458s
epoch 10: {'train_loss': '2.81870'}; time used = 2.5267679691314697s
epoch 15: {'train_loss': '2.79683'}; time used = 2.81528639793396s
epoch 20: {'train_loss': '2.77904'}; time used = 2.7217180728912354s
epoch 25: {'train_loss': '2.77282'}; time used = 2.6436407566070557s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.641184091567993.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.5777233782129743, 'samples': 0.6376811594202898, 'weighted': 0.5892537207528425, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83391'}; time used = 7.951979398727417s
epoch 10: {'train_loss': '2.80330'}; time used = 6.52970290184021s
epoch 15: {'train_loss': '2.78925'}; time used = 6.331456661224365s
epoch 20: {'train_loss': '2.78004'}; time used = 6.696722984313965s
epoch 25: {'train_loss': '2.77483'}; time used = 6.294530630111694s
epoch 30: {'train_loss': '2.77284'}; time used = 6.2221081256866455s
epoch 35: {'train_loss': '2.77260'}; time used = 6.2468719482421875s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.47585129737854.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4416654605104453, 'samples': 0.5033333333333333, 'weighted': 0.43241549669513196, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92566'}; time used = 2.145880937576294s
epoch 10: {'train_loss': '2.81263'}; time used = 2.1185495853424072s
epoch 15: {'train_loss': '2.79482'}; time used = 2.1465883255004883s
epoch 20: {'train_loss': '2.78944'}; time used = 2.25038743019104s
epoch 25: {'train_loss': '2.78263'}; time used = 2.327904462814331s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.364033460617065.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5760869565217391, 'samples': 0.6231884057971014, 'weighted': 0.5863264020163832, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.96385'}; time used = 1.1796321868896484s
epoch 10: {'train_loss': '2.87198'}; time used = 1.0847275257110596s
epoch 15: {'train_loss': '2.87376'}; time used = 1.0898568630218506s
epoch 20: {'train_loss': '2.83214'}; time used = 1.0838608741760254s
epoch 25: {'train_loss': '2.80399'}; time used = 1.0875813961029053s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.571826934814453.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23109'}; time used = 1.1578717231750488s
epoch 10: {'train_loss': '2.89361'}; time used = 0.967233419418335s
epoch 15: {'train_loss': '2.77772'}; time used = 0.9820027351379395s
epoch 20: {'train_loss': '2.79009'}; time used = 1.0268235206604004s
epoch 25: {'train_loss': '2.78459'}; time used = 1.161433458328247s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.51748013496399.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.00429'}; time used = 2.0052084922790527s
epoch 10: {'train_loss': '0.70189'}; time used = 1.711226224899292s
epoch 15: {'train_loss': '0.57454'}; time used = 1.8608205318450928s
epoch 20: {'train_loss': '0.45827'}; time used = 1.6219828128814697s
epoch 25: {'train_loss': '0.43562'}; time used = 0.912905216217041s
epoch 30: {'train_loss': '0.32670'}; time used = 0.876563310623169s
epoch 35: {'train_loss': '0.32069'}; time used = 0.9772295951843262s
epoch 40: {'train_loss': '0.26065'}; time used = 0.9014120101928711s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.962043046951294.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39591'}; time used = 3.1134209632873535s
epoch 10: {'train_loss': '1.36817'}; time used = 2.2905964851379395s
epoch 15: {'train_loss': '1.26616'}; time used = 2.431382656097412s
epoch 20: {'train_loss': '1.26285'}; time used = 2.697042226791382s
epoch 25: {'train_loss': '1.06481'}; time used = 1.4486138820648193s
epoch 30: {'train_loss': '1.16276'}; time used = 1.0010077953338623s
epoch 35: {'train_loss': '1.15639'}; time used = 1.1764531135559082s
epoch 40: {'train_loss': '1.07687'}; time used = 1.1766810417175293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.332857847213745.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82469'}; time used = 1.9898083209991455s
epoch 10: {'train_loss': '2.76584'}; time used = 2.622865915298462s
epoch 15: {'train_loss': '2.71519'}; time used = 3.177926778793335s
epoch 20: {'train_loss': '2.65145'}; time used = 3.299513339996338s
epoch 25: {'train_loss': '2.57978'}; time used = 2.6099419593811035s
epoch 30: {'train_loss': '2.52722'}; time used = 1.877629280090332s
epoch 35: {'train_loss': '2.44771'}; time used = 1.844900369644165s
epoch 40: {'train_loss': '2.33847'}; time used = 2.0809073448181152s
epoch 45: {'train_loss': '2.67846'}; time used = 1.9273855686187744s
epoch 50: {'train_loss': '2.33150'}; time used = 2.0504417419433594s
epoch 55: {'train_loss': '2.34277'}; time used = 2.002168655395508s
epoch 60: {'train_loss': '2.25999'}; time used = 2.139915943145752s
epoch 65: {'train_loss': '2.17811'}; time used = 2.081364393234253s
epoch 70: {'train_loss': '2.12814'}; time used = 1.875349521636963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.14819097518921.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37745'}; time used = 1.185171365737915s
epoch 10: {'train_loss': '1.54904'}; time used = 1.0384533405303955s
epoch 15: {'train_loss': '1.38355'}; time used = 1.0770165920257568s
epoch 20: {'train_loss': '1.38899'}; time used = 1.146286964416504s
epoch 25: {'train_loss': '1.38783'}; time used = 2.426737070083618s
epoch 30: {'train_loss': '1.38416'}; time used = 2.6191840171813965s
epoch 35: {'train_loss': '1.39152'}; time used = 1.5516512393951416s
epoch 40: {'train_loss': '1.37133'}; time used = 1.2247774600982666s
epoch 45: {'train_loss': '1.33632'}; time used = 1.239497423171997s
epoch 50: {'train_loss': '1.40059'}; time used = 1.2532470226287842s
epoch 55: {'train_loss': '1.36883'}; time used = 1.2393410205841064s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.401350736618042.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.93261'}; time used = 1.4886929988861084s
epoch 10: {'train_loss': '0.63087'}; time used = 1.9771616458892822s
epoch 15: {'train_loss': '0.49064'}; time used = 1.6292836666107178s
epoch 20: {'train_loss': '0.38356'}; time used = 0.9083130359649658s
epoch 25: {'train_loss': '0.37600'}; time used = 0.9684164524078369s
epoch 30: {'train_loss': '0.27868'}; time used = 1.8368358612060547s
epoch 35: {'train_loss': '0.28207'}; time used = 2.001485824584961s
epoch 40: {'train_loss': '0.21365'}; time used = 0.9551758766174316s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.03351640701294.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.39684'}; time used = 1.493868350982666s
epoch 10: {'train_loss': '1.40259'}; time used = 1.2437074184417725s
epoch 15: {'train_loss': '1.38492'}; time used = 1.1678242683410645s
epoch 20: {'train_loss': '1.39332'}; time used = 1.154099702835083s
epoch 25: {'train_loss': '1.37584'}; time used = 1.5351076126098633s
epoch 30: {'train_loss': '1.33833'}; time used = 1.2024734020233154s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.114448070526123.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.98286'}; time used = 2.142237424850464s
epoch 10: {'train_loss': '2.82973'}; time used = 2.1491823196411133s
epoch 15: {'train_loss': '2.83497'}; time used = 2.1566343307495117s
epoch 20: {'train_loss': '2.81259'}; time used = 2.3437108993530273s
epoch 25: {'train_loss': '2.79629'}; time used = 2.3153247833251953s
epoch 30: {'train_loss': '2.78700'}; time used = 2.1175825595855713s
epoch 35: {'train_loss': '2.78126'}; time used = 2.1086902618408203s
epoch 40: {'train_loss': '2.77729'}; time used = 2.1935935020446777s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.62863278388977.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77177'}; time used = 1.173494577407837s
epoch 10: {'train_loss': '2.77366'}; time used = 0.9743044376373291s
epoch 15: {'train_loss': '2.77801'}; time used = 0.9715423583984375s
epoch 20: {'train_loss': '2.77524'}; time used = 1.00559401512146s
epoch 25: {'train_loss': '2.77225'}; time used = 1.115699291229248s
epoch 30: {'train_loss': '2.77254'}; time used = 1.172778844833374s
epoch 35: {'train_loss': '2.77252'}; time used = 1.2225580215454102s
epoch 40: {'train_loss': '2.77198'}; time used = 1.319190263748169s
epoch 45: {'train_loss': '2.77244'}; time used = 1.186964750289917s
epoch 50: {'train_loss': '2.77176'}; time used = 1.1259098052978516s
epoch 55: {'train_loss': '2.77115'}; time used = 1.1514062881469727s
epoch 60: {'train_loss': '2.77107'}; time used = 1.224536657333374s
epoch 65: {'train_loss': '2.77083'}; time used = 1.2273187637329102s
epoch 70: {'train_loss': '2.76816'}; time used = 1.1708629131317139s
epoch 75: {'train_loss': '2.76923'}; time used = 0.9940807819366455s
epoch 80: {'train_loss': '2.76793'}; time used = 1.0690364837646484s
epoch 85: {'train_loss': '2.76855'}; time used = 0.9716222286224365s
epoch 90: {'train_loss': '2.77850'}; time used = 0.9710681438446045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.242979049682617.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35025'}; time used = 1.2854619026184082s
epoch 10: {'train_loss': '1.40196'}; time used = 1.0629467964172363s
epoch 15: {'train_loss': '0.87848'}; time used = 1.078819990158081s
epoch 20: {'train_loss': '0.80770'}; time used = 1.132153034210205s
epoch 25: {'train_loss': '0.28304'}; time used = 1.1821708679199219s
epoch 30: {'train_loss': '0.15900'}; time used = 1.1140353679656982s
epoch 35: {'train_loss': '1.04074'}; time used = 1.2473430633544922s
epoch 40: {'train_loss': '0.02973'}; time used = 1.2723662853240967s
epoch 45: {'train_loss': '0.01209'}; time used = 1.0943455696105957s
epoch 50: {'train_loss': '0.00328'}; time used = 1.0697791576385498s
epoch 55: {'train_loss': '0.00054'}; time used = 1.0205068588256836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.421310663223267.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.32167'}; time used = 2.4854698181152344s
epoch 10: {'train_loss': '2.80770'}; time used = 2.3694233894348145s
epoch 15: {'train_loss': '2.77832'}; time used = 2.422475576400757s
epoch 20: {'train_loss': '2.79962'}; time used = 2.4908204078674316s
epoch 25: {'train_loss': '2.77012'}; time used = 2.55623459815979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.217835664749146.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.85519'}; time used = 1.2581672668457031s
epoch 10: {'train_loss': '2.87981'}; time used = 1.0131449699401855s
epoch 15: {'train_loss': '2.80441'}; time used = 1.0390660762786865s
epoch 20: {'train_loss': '2.77507'}; time used = 0.9963767528533936s
epoch 25: {'train_loss': '2.77676'}; time used = 1.1302447319030762s
epoch 30: {'train_loss': '2.77247'}; time used = 2.159700870513916s
epoch 35: {'train_loss': '2.77170'}; time used = 1.0614569187164307s
epoch 40: {'train_loss': '2.77304'}; time used = 1.0497534275054932s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.385396718978882.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34760'}; time used = 1.7796213626861572s
epoch 10: {'train_loss': '1.24590'}; time used = 1.6791951656341553s
epoch 15: {'train_loss': '1.18222'}; time used = 1.6999850273132324s
epoch 20: {'train_loss': '0.70796'}; time used = 1.6598637104034424s
epoch 25: {'train_loss': '0.82051'}; time used = 1.778850793838501s
epoch 30: {'train_loss': '0.79440'}; time used = 1.6665520668029785s
epoch 35: {'train_loss': '0.36407'}; time used = 1.6885464191436768s
epoch 40: {'train_loss': '0.71880'}; time used = 1.7861669063568115s
epoch 45: {'train_loss': '0.70885'}; time used = 1.737623691558838s
epoch 50: {'train_loss': '0.60804'}; time used = 1.756026029586792s
epoch 55: {'train_loss': '0.54965'}; time used = 1.6626403331756592s
epoch 60: {'train_loss': '0.48861'}; time used = 1.7971773147583008s
epoch 65: {'train_loss': '0.47238'}; time used = 1.8259425163269043s
epoch 70: {'train_loss': '0.44477'}; time used = 1.726938009262085s
epoch 75: {'train_loss': '0.45366'}; time used = 1.9357354640960693s
epoch 80: {'train_loss': '0.40533'}; time used = 3.457247257232666s
epoch 85: {'train_loss': '0.39276'}; time used = 3.2935404777526855s
epoch 90: {'train_loss': '0.41059'}; time used = 3.3803653717041016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.38320803642273.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38328'}; time used = 2.1751325130462646s
epoch 10: {'train_loss': '1.35535'}; time used = 2.1331915855407715s
epoch 15: {'train_loss': '1.38333'}; time used = 2.121279239654541s
epoch 20: {'train_loss': '1.44637'}; time used = 2.242480993270874s
epoch 25: {'train_loss': '1.41364'}; time used = 2.5685513019561768s
epoch 30: {'train_loss': '1.36690'}; time used = 2.415541887283325s
epoch 35: {'train_loss': '1.28694'}; time used = 2.2603261470794678s
epoch 40: {'train_loss': '1.12915'}; time used = 2.2605555057525635s
epoch 45: {'train_loss': '1.01269'}; time used = 2.3031539916992188s
epoch 50: {'train_loss': '0.70083'}; time used = 2.4689812660217285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.38653039932251.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37958'}; time used = 2.5778086185455322s
epoch 10: {'train_loss': '1.34871'}; time used = 2.436431407928467s
epoch 15: {'train_loss': '1.38300'}; time used = 2.572937250137329s
epoch 20: {'train_loss': '1.44533'}; time used = 2.5190792083740234s
epoch 25: {'train_loss': '1.42444'}; time used = 2.906353712081909s
epoch 30: {'train_loss': '1.38978'}; time used = 4.702174186706543s
epoch 35: {'train_loss': '1.38220'}; time used = 2.564486265182495s
epoch 40: {'train_loss': '1.35850'}; time used = 2.4082584381103516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.91411566734314.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.87859'}; time used = 2.4180448055267334s
epoch 10: {'train_loss': '2.79819'}; time used = 1.679142951965332s
epoch 15: {'train_loss': '2.77852'}; time used = 1.077765941619873s
epoch 20: {'train_loss': '2.77561'}; time used = 1.1045246124267578s
epoch 25: {'train_loss': '2.77607'}; time used = 1.0652596950531006s
epoch 30: {'train_loss': '2.77418'}; time used = 1.0517232418060303s
epoch 35: {'train_loss': '2.77461'}; time used = 1.2141835689544678s
epoch 40: {'train_loss': '2.77269'}; time used = 1.0260279178619385s
epoch 45: {'train_loss': '2.77396'}; time used = 1.016129970550537s
epoch 50: {'train_loss': '2.77149'}; time used = 1.1657013893127441s
epoch 55: {'train_loss': '2.77146'}; time used = 1.0839033126831055s
epoch 60: {'train_loss': '2.77196'}; time used = 1.0464868545532227s
epoch 65: {'train_loss': '2.77162'}; time used = 1.0087502002716064s
epoch 70: {'train_loss': '2.77048'}; time used = 1.6415870189666748s
epoch 75: {'train_loss': '2.76979'}; time used = 2.2799758911132812s
epoch 80: {'train_loss': '2.76722'}; time used = 2.392512321472168s
epoch 85: {'train_loss': '2.76739'}; time used = 2.598125696182251s
epoch 90: {'train_loss': '2.76472'}; time used = 1.8316047191619873s
epoch 95: {'train_loss': '2.76213'}; time used = 1.148482084274292s
epoch 100: {'train_loss': '2.75491'}; time used = 1.0443122386932373s
epoch 105: {'train_loss': '2.74685'}; time used = 1.073866605758667s
epoch 110: {'train_loss': '2.72501'}; time used = 1.0691578388214111s
epoch 115: {'train_loss': '2.69539'}; time used = 1.1005475521087646s
epoch 120: {'train_loss': '2.68064'}; time used = 1.011054277420044s
epoch 125: {'train_loss': '2.64043'}; time used = 1.0165834426879883s
epoch 130: {'train_loss': '2.63965'}; time used = 1.0326550006866455s
epoch 135: {'train_loss': '2.61164'}; time used = 1.0233361721038818s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.9576632976532.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.25962'}; time used = 1.2674686908721924s
epoch 10: {'train_loss': '2.84992'}; time used = 1.1413824558258057s
epoch 15: {'train_loss': '2.71637'}; time used = 1.177889108657837s
epoch 20: {'train_loss': '2.64156'}; time used = 1.156531810760498s
epoch 25: {'train_loss': '2.52580'}; time used = 1.2968759536743164s
epoch 30: {'train_loss': '2.43514'}; time used = 1.3629004955291748s
epoch 35: {'train_loss': '2.37888'}; time used = 1.1607294082641602s
epoch 40: {'train_loss': '2.36922'}; time used = 1.2649562358856201s
epoch 45: {'train_loss': '2.34255'}; time used = 1.243025302886963s
epoch 50: {'train_loss': '2.32549'}; time used = 1.1633548736572266s
epoch 55: {'train_loss': '2.32195'}; time used = 1.1841957569122314s
epoch 60: {'train_loss': '2.29183'}; time used = 1.2972519397735596s
epoch 65: {'train_loss': '2.26723'}; time used = 1.1852633953094482s
epoch 70: {'train_loss': '2.28343'}; time used = 1.1457571983337402s
epoch 75: {'train_loss': '2.25606'}; time used = 1.097282886505127s
epoch 80: {'train_loss': '2.22820'}; time used = 1.1510918140411377s
epoch 85: {'train_loss': '2.29465'}; time used = 0.9728870391845703s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.863722324371338.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.23948'}; time used = 1.2708148956298828s
epoch 10: {'train_loss': '0.04622'}; time used = 1.7041261196136475s
epoch 15: {'train_loss': '0.00213'}; time used = 1.8893547058105469s
epoch 20: {'train_loss': '0.00012'}; time used = 1.8286232948303223s
epoch 25: {'train_loss': '0.00743'}; time used = 1.950010061264038s
epoch 30: {'train_loss': '0.00019'}; time used = 1.7075412273406982s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.977300643920898.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7564102564102564, 'samples': 0.7894736842105263, 'weighted': 0.7705802968960862, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87621'}; time used = 2.423938512802124s
epoch 10: {'train_loss': '2.79899'}; time used = 2.6157336235046387s
epoch 15: {'train_loss': '2.78607'}; time used = 2.5494751930236816s
epoch 20: {'train_loss': '2.77566'}; time used = 3.535977602005005s
epoch 25: {'train_loss': '2.76650'}; time used = 3.901616334915161s
epoch 30: {'train_loss': '2.74845'}; time used = 2.880486011505127s
epoch 35: {'train_loss': '2.72483'}; time used = 2.459240674972534s
epoch 40: {'train_loss': '2.71172'}; time used = 2.472437858581543s
epoch 45: {'train_loss': '2.66839'}; time used = 2.7168118953704834s
epoch 50: {'train_loss': '2.61994'}; time used = 2.4354310035705566s
epoch 55: {'train_loss': '2.60133'}; time used = 2.4741921424865723s
epoch 60: {'train_loss': '2.60124'}; time used = 2.595270872116089s
epoch 65: {'train_loss': '2.52989'}; time used = 2.4730684757232666s
epoch 70: {'train_loss': '2.46892'}; time used = 2.437467575073242s
epoch 75: {'train_loss': '2.44717'}; time used = 2.4154651165008545s
epoch 80: {'train_loss': '2.42671'}; time used = 2.4879534244537354s
epoch 85: {'train_loss': '2.39805'}; time used = 2.38403058052063s
epoch 90: {'train_loss': '2.45728'}; time used = 2.3462953567504883s
epoch 95: {'train_loss': '2.37849'}; time used = 2.3556110858917236s
epoch 100: {'train_loss': '2.34045'}; time used = 2.3463778495788574s
epoch 105: {'train_loss': '2.36833'}; time used = 2.497307538986206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.439104080200195.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.11455'}; time used = 1.7925348281860352s
epoch 10: {'train_loss': '1.00920'}; time used = 1.8492240905761719s
epoch 15: {'train_loss': '0.86030'}; time used = 1.831366777420044s
epoch 20: {'train_loss': '0.57960'}; time used = 1.8473641872406006s
epoch 25: {'train_loss': '0.27600'}; time used = 1.8819663524627686s
epoch 30: {'train_loss': '0.13117'}; time used = 1.7775964736938477s
epoch 35: {'train_loss': '0.08214'}; time used = 1.7043037414550781s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.912050485610962.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.596679915828852, 'samples': 0.6376811594202898, 'weighted': 0.6059983802814516, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74569'}; time used = 1.420163869857788s
epoch 10: {'train_loss': '2.64887'}; time used = 1.0122764110565186s
epoch 15: {'train_loss': '2.46980'}; time used = 1.0698919296264648s
epoch 20: {'train_loss': '2.38941'}; time used = 1.0910933017730713s
epoch 25: {'train_loss': '2.29601'}; time used = 1.074470043182373s
epoch 30: {'train_loss': '2.15432'}; time used = 1.0653877258300781s
epoch 35: {'train_loss': '1.85865'}; time used = 1.0473246574401855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.38783597946167.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35478'}; time used = 1.7492578029632568s
epoch 10: {'train_loss': '1.05232'}; time used = 1.9403419494628906s
epoch 15: {'train_loss': '0.66455'}; time used = 1.9082129001617432s
epoch 20: {'train_loss': '0.78327'}; time used = 1.9155700206756592s
epoch 25: {'train_loss': '0.68389'}; time used = 1.8128983974456787s
epoch 30: {'train_loss': '0.32587'}; time used = 1.64839768409729s
epoch 35: {'train_loss': '0.91210'}; time used = 1.6743688583374023s
epoch 40: {'train_loss': '0.74201'}; time used = 1.9213733673095703s
epoch 45: {'train_loss': '0.35702'}; time used = 1.738274097442627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.592118501663208.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.64279'}; time used = 1.3152751922607422s
epoch 10: {'train_loss': '2.44709'}; time used = 1.3800702095031738s
epoch 15: {'train_loss': '2.39500'}; time used = 1.2907018661499023s
epoch 20: {'train_loss': '2.34729'}; time used = 0.948615312576294s
epoch 25: {'train_loss': '2.25441'}; time used = 0.9323697090148926s
epoch 30: {'train_loss': '2.04039'}; time used = 0.9465517997741699s
epoch 35: {'train_loss': '2.47443'}; time used = 1.005387783050537s
epoch 40: {'train_loss': '1.97988'}; time used = 0.9428515434265137s
epoch 45: {'train_loss': '1.80982'}; time used = 0.9620006084442139s
epoch 50: {'train_loss': '1.92144'}; time used = 0.9489617347717285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.543052434921265.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87214'}; time used = 1.8725059032440186s
epoch 10: {'train_loss': '2.78964'}; time used = 2.840909242630005s
epoch 15: {'train_loss': '2.77614'}; time used = 3.596336841583252s
epoch 20: {'train_loss': '2.77008'}; time used = 2.118525505065918s
epoch 25: {'train_loss': '2.77151'}; time used = 4.06264066696167s
epoch 30: {'train_loss': '2.77135'}; time used = 1.8085196018218994s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.95948839187622.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34292'}; time used = 1.936549425125122s
epoch 10: {'train_loss': '1.16755'}; time used = 1.880073070526123s
epoch 15: {'train_loss': '1.02185'}; time used = 2.069106340408325s
epoch 20: {'train_loss': '1.04992'}; time used = 1.8881065845489502s
epoch 25: {'train_loss': '1.05075'}; time used = 3.3725056648254395s
epoch 30: {'train_loss': '0.80235'}; time used = 3.509880304336548s
epoch 35: {'train_loss': '0.66571'}; time used = 3.6732404232025146s
epoch 40: {'train_loss': '0.59233'}; time used = 1.8814024925231934s
epoch 45: {'train_loss': '0.57872'}; time used = 2.074664354324341s
epoch 50: {'train_loss': '0.64244'}; time used = 2.0458970069885254s
epoch 55: {'train_loss': '0.39506'}; time used = 1.9223806858062744s
epoch 60: {'train_loss': '0.54391'}; time used = 2.0902044773101807s
epoch 65: {'train_loss': '0.92754'}; time used = 1.7693126201629639s
epoch 70: {'train_loss': '1.27387'}; time used = 1.7469289302825928s
epoch 75: {'train_loss': '0.62003'}; time used = 1.7892212867736816s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.85104417800903.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38567'}; time used = 3.306272029876709s
epoch 10: {'train_loss': '1.30387'}; time used = 3.571732759475708s
epoch 15: {'train_loss': '1.15835'}; time used = 3.308854341506958s
epoch 20: {'train_loss': '1.08424'}; time used = 2.819300413131714s
epoch 25: {'train_loss': '0.86584'}; time used = 1.9762208461761475s
epoch 30: {'train_loss': '0.88549'}; time used = 1.939812183380127s
epoch 35: {'train_loss': '0.80821'}; time used = 1.8536996841430664s
epoch 40: {'train_loss': '0.62811'}; time used = 1.823394775390625s
epoch 45: {'train_loss': '0.40704'}; time used = 1.7373836040496826s
epoch 50: {'train_loss': '0.46753'}; time used = 1.8013842105865479s
epoch 55: {'train_loss': '0.26749'}; time used = 1.7410082817077637s
epoch 60: {'train_loss': '0.66976'}; time used = 1.7736248970031738s
epoch 65: {'train_loss': '0.72217'}; time used = 1.79085111618042s
epoch 70: {'train_loss': '0.71891'}; time used = 2.1769890785217285s
epoch 75: {'train_loss': '0.72827'}; time used = 2.322097063064575s
epoch 80: {'train_loss': '0.62855'}; time used = 1.964303731918335s
epoch 85: {'train_loss': '0.12979'}; time used = 2.0745315551757812s
epoch 90: {'train_loss': '0.03772'}; time used = 1.9927361011505127s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.475133180618286.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30682'}; time used = 2.2656753063201904s
epoch 10: {'train_loss': '1.08113'}; time used = 3.635166645050049s
epoch 15: {'train_loss': '0.87740'}; time used = 3.7793211936950684s
epoch 20: {'train_loss': '0.73961'}; time used = 3.846346616744995s
epoch 25: {'train_loss': '0.65123'}; time used = 2.3801109790802s
epoch 30: {'train_loss': '0.57956'}; time used = 1.950070858001709s
epoch 35: {'train_loss': '0.51387'}; time used = 1.961653709411621s
epoch 40: {'train_loss': '0.39097'}; time used = 2.0203468799591064s
epoch 45: {'train_loss': '0.33409'}; time used = 2.0245349407196045s
epoch 50: {'train_loss': '0.19269'}; time used = 1.9309310913085938s
epoch 55: {'train_loss': '0.09857'}; time used = 2.0015745162963867s
epoch 60: {'train_loss': '0.24791'}; time used = 1.9607269763946533s
epoch 65: {'train_loss': '0.35160'}; time used = 2.0266964435577393s
epoch 70: {'train_loss': '0.45376'}; time used = 1.8972318172454834s
epoch 75: {'train_loss': '0.37101'}; time used = 2.0087287425994873s
epoch 80: {'train_loss': '0.21732'}; time used = 1.9179847240447998s
epoch 85: {'train_loss': '0.13814'}; time used = 2.1094391345977783s
epoch 90: {'train_loss': '0.13598'}; time used = 1.9198052883148193s
epoch 95: {'train_loss': '0.05901'}; time used = 2.039182186126709s
epoch 100: {'train_loss': '0.13023'}; time used = 2.044694185256958s
epoch 105: {'train_loss': '0.18498'}; time used = 1.986058235168457s
epoch 110: {'train_loss': '0.08091'}; time used = 2.050713539123535s
epoch 115: {'train_loss': '0.08114'}; time used = 1.9296674728393555s
epoch 120: {'train_loss': '0.09259'}; time used = 2.1524264812469482s
epoch 125: {'train_loss': '0.04830'}; time used = 1.9465367794036865s
epoch 130: {'train_loss': '0.01565'}; time used = 1.9926047325134277s
epoch 135: {'train_loss': '0.01453'}; time used = 1.9778060913085938s
epoch 140: {'train_loss': '0.00047'}; time used = 1.958406686782837s
epoch 145: {'train_loss': '0.19099'}; time used = 1.9603362083435059s
epoch 150: {'train_loss': '0.06949'}; time used = 2.291020631790161s
epoch 155: {'train_loss': '0.05273'}; time used = 2.733231782913208s
epoch 160: {'train_loss': '0.04100'}; time used = 1.9496910572052002s
epoch 165: {'train_loss': '0.00927'}; time used = 2.1617109775543213s
epoch 170: {'train_loss': '0.06888'}; time used = 1.9093573093414307s
epoch 175: {'train_loss': '0.00161'}; time used = 2.0889358520507812s
epoch 180: {'train_loss': '0.00860'}; time used = 2.0145211219787598s
epoch 185: {'train_loss': '0.00912'}; time used = 2.1165976524353027s
epoch 190: {'train_loss': '0.00005'}; time used = 1.9077422618865967s
epoch 195: {'train_loss': '0.00768'}; time used = 1.969700813293457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 90.07214617729187.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5922727272727273, 'samples': 0.6231884057971014, 'weighted': 0.6004084321475626, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.01 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83283'}; time used = 4.813399076461792s
epoch 10: {'train_loss': '2.80271'}; time used = 4.946370363235474s
epoch 15: {'train_loss': '2.78868'}; time used = 4.7865941524505615s
epoch 20: {'train_loss': '2.78031'}; time used = 4.339507341384888s
epoch 25: {'train_loss': '2.77543'}; time used = 4.396315574645996s
epoch 30: {'train_loss': '2.77324'}; time used = 4.228176593780518s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.19129133224487.
Training classifier using 80.00% nodes...
{'micro': 0.68, 'macro': 0.6784242789669379, 'samples': 0.68, 'weighted': 0.6779740729574917, 'accuracy': 0.68}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03901'}; time used = 1.8572719097137451s
epoch 10: {'train_loss': '3.01995'}; time used = 1.7160675525665283s
epoch 15: {'train_loss': '2.88130'}; time used = 1.7544879913330078s
epoch 20: {'train_loss': '2.82047'}; time used = 1.7876107692718506s
epoch 25: {'train_loss': '2.78299'}; time used = 2.026869773864746s
epoch 30: {'train_loss': '2.75858'}; time used = 1.7731173038482666s
epoch 35: {'train_loss': '2.73782'}; time used = 1.6467251777648926s
epoch 40: {'train_loss': '2.71889'}; time used = 1.837512493133545s
epoch 45: {'train_loss': '2.68921'}; time used = 1.875450849533081s
epoch 50: {'train_loss': '2.63912'}; time used = 1.7029423713684082s
epoch 55: {'train_loss': '2.59734'}; time used = 2.1693665981292725s
epoch 60: {'train_loss': '2.54509'}; time used = 2.138026714324951s
epoch 65: {'train_loss': '2.42566'}; time used = 1.662238359451294s
epoch 70: {'train_loss': '2.41094'}; time used = 1.7538928985595703s
epoch 75: {'train_loss': '2.44290'}; time used = 1.6613798141479492s
epoch 80: {'train_loss': '2.35453'}; time used = 1.7604928016662598s
epoch 85: {'train_loss': '2.31165'}; time used = 1.691617488861084s
epoch 90: {'train_loss': '2.22314'}; time used = 1.6707515716552734s
epoch 95: {'train_loss': '2.50401'}; time used = 1.665717363357544s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.64057946205139.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84200'}; time used = 1.2572803497314453s
epoch 10: {'train_loss': '2.72678'}; time used = 1.0450243949890137s
epoch 15: {'train_loss': '2.63985'}; time used = 1.0194666385650635s
epoch 20: {'train_loss': '2.58773'}; time used = 1.0803606510162354s
epoch 25: {'train_loss': '2.52720'}; time used = 1.0427007675170898s
epoch 30: {'train_loss': '2.46643'}; time used = 1.004887342453003s
epoch 35: {'train_loss': '2.39927'}; time used = 1.0224859714508057s
epoch 40: {'train_loss': '2.34415'}; time used = 1.0713739395141602s
epoch 45: {'train_loss': '2.29766'}; time used = 1.1360180377960205s
epoch 50: {'train_loss': '2.29668'}; time used = 1.148461103439331s
epoch 55: {'train_loss': '2.25177'}; time used = 1.1269609928131104s
epoch 60: {'train_loss': '2.21748'}; time used = 1.0528957843780518s
epoch 65: {'train_loss': '2.20459'}; time used = 0.9560000896453857s
epoch 70: {'train_loss': '2.18190'}; time used = 0.9701097011566162s
epoch 75: {'train_loss': '2.18901'}; time used = 0.9812207221984863s
epoch 80: {'train_loss': '2.35633'}; time used = 1.0785274505615234s
epoch 85: {'train_loss': '2.30778'}; time used = 0.9495611190795898s
epoch 90: {'train_loss': '2.16609'}; time used = 0.9272820949554443s
epoch 95: {'train_loss': '2.15040'}; time used = 0.9485588073730469s
epoch 100: {'train_loss': '2.13696'}; time used = 0.9962155818939209s
epoch 105: {'train_loss': '2.11793'}; time used = 1.1540842056274414s
epoch 110: {'train_loss': '2.07488'}; time used = 1.035740852355957s
epoch 115: {'train_loss': '2.04551'}; time used = 1.2479493618011475s
epoch 120: {'train_loss': '2.03244'}; time used = 1.0612642765045166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.82659149169922.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74081'}; time used = 1.037492275238037s
epoch 10: {'train_loss': '2.68036'}; time used = 0.9459612369537354s
epoch 15: {'train_loss': '2.57154'}; time used = 0.88667893409729s
epoch 20: {'train_loss': '2.41289'}; time used = 0.9175968170166016s
epoch 25: {'train_loss': '2.20120'}; time used = 0.9245197772979736s
epoch 30: {'train_loss': '2.28263'}; time used = 0.9162869453430176s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.568745613098145.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83388'}; time used = 4.459822177886963s
epoch 10: {'train_loss': '2.80319'}; time used = 5.808101415634155s
epoch 15: {'train_loss': '2.78918'}; time used = 5.1340484619140625s
epoch 20: {'train_loss': '2.78005'}; time used = 4.870456695556641s
epoch 25: {'train_loss': '2.77487'}; time used = 7.590284585952759s
epoch 30: {'train_loss': '2.77287'}; time used = 5.546891212463379s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.60868740081787.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87616'}; time used = 1.9444987773895264s
epoch 10: {'train_loss': '2.82119'}; time used = 2.1580066680908203s
epoch 15: {'train_loss': '2.78759'}; time used = 2.1156253814697266s
epoch 20: {'train_loss': '2.77264'}; time used = 2.060675621032715s
epoch 25: {'train_loss': '2.76999'}; time used = 1.9978716373443604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.46494722366333.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.14873'}; time used = 1.1487815380096436s
epoch 10: {'train_loss': '2.73244'}; time used = 0.8600225448608398s
epoch 15: {'train_loss': '2.59489'}; time used = 0.9595396518707275s
epoch 20: {'train_loss': '2.47031'}; time used = 1.001051425933838s
epoch 25: {'train_loss': '2.38043'}; time used = 0.9067871570587158s
epoch 30: {'train_loss': '2.29840'}; time used = 0.8861663341522217s
epoch 35: {'train_loss': '2.24611'}; time used = 0.8369274139404297s
epoch 40: {'train_loss': '2.18306'}; time used = 1.1101858615875244s
epoch 45: {'train_loss': '2.08072'}; time used = 1.043726921081543s
epoch 50: {'train_loss': '1.94963'}; time used = 0.8860516548156738s
epoch 55: {'train_loss': '1.82332'}; time used = 1.025696039199829s
epoch 60: {'train_loss': '1.68566'}; time used = 1.621093511581421s
epoch 65: {'train_loss': '1.62341'}; time used = 1.5816776752471924s
epoch 70: {'train_loss': '1.86601'}; time used = 1.6614432334899902s
epoch 75: {'train_loss': '1.68572'}; time used = 1.8026020526885986s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.114593029022217.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.20126'}; time used = 1.2336082458496094s
epoch 10: {'train_loss': '1.60662'}; time used = 1.225189447402954s
epoch 15: {'train_loss': '1.37859'}; time used = 1.1372976303100586s
epoch 20: {'train_loss': '1.43272'}; time used = 1.298964262008667s
epoch 25: {'train_loss': '1.30062'}; time used = 1.1127841472625732s
epoch 30: {'train_loss': '1.15699'}; time used = 1.1050608158111572s
epoch 35: {'train_loss': '0.74924'}; time used = 1.370011568069458s
epoch 40: {'train_loss': '0.25564'}; time used = 1.1839494705200195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.14397931098938.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '3.06875'}; time used = 2.03962779045105s
epoch 10: {'train_loss': '3.00728'}; time used = 2.066791296005249s
epoch 15: {'train_loss': '2.97457'}; time used = 2.6080470085144043s
epoch 20: {'train_loss': '2.92052'}; time used = 2.1406171321868896s
epoch 25: {'train_loss': '2.84145'}; time used = 2.184701681137085s
epoch 30: {'train_loss': '2.75794'}; time used = 2.1937966346740723s
epoch 35: {'train_loss': '2.70549'}; time used = 2.1169707775115967s
epoch 40: {'train_loss': '2.64965'}; time used = 1.8577256202697754s
epoch 45: {'train_loss': '2.61858'}; time used = 1.7321031093597412s
epoch 50: {'train_loss': '2.58445'}; time used = 1.8576030731201172s
epoch 55: {'train_loss': '2.57245'}; time used = 2.1366591453552246s
epoch 60: {'train_loss': '2.56182'}; time used = 1.8839621543884277s
epoch 65: {'train_loss': '2.53811'}; time used = 1.7062833309173584s
epoch 70: {'train_loss': '2.52627'}; time used = 1.7749028205871582s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.173641204833984.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.71374'}; time used = 1.3100545406341553s
epoch 10: {'train_loss': '0.46392'}; time used = 0.9717404842376709s
epoch 15: {'train_loss': '0.34292'}; time used = 1.006150484085083s
epoch 20: {'train_loss': '0.20059'}; time used = 1.0015907287597656s
epoch 25: {'train_loss': '0.17785'}; time used = 1.0048191547393799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.508275747299194.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92432'}; time used = 2.336571216583252s
epoch 10: {'train_loss': '2.80128'}; time used = 1.8298320770263672s
epoch 15: {'train_loss': '2.76344'}; time used = 1.7201159000396729s
epoch 20: {'train_loss': '2.74079'}; time used = 1.6924479007720947s
epoch 25: {'train_loss': '2.71790'}; time used = 1.760800838470459s
epoch 30: {'train_loss': '2.69485'}; time used = 1.711226224899292s
epoch 35: {'train_loss': '2.67166'}; time used = 1.6996486186981201s
epoch 40: {'train_loss': '2.62160'}; time used = 1.6840481758117676s
epoch 45: {'train_loss': '2.59228'}; time used = 1.9626240730285645s
epoch 50: {'train_loss': '2.53776'}; time used = 1.8535563945770264s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.53441071510315.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39657'}; time used = 1.1234712600708008s
epoch 10: {'train_loss': '1.37657'}; time used = 0.9754238128662109s
epoch 15: {'train_loss': '1.25997'}; time used = 0.9844644069671631s
epoch 20: {'train_loss': '1.22466'}; time used = 0.9956040382385254s
epoch 25: {'train_loss': '1.07887'}; time used = 1.017512559890747s
epoch 30: {'train_loss': '1.04458'}; time used = 0.972914457321167s
epoch 35: {'train_loss': '0.90110'}; time used = 0.9820005893707275s
epoch 40: {'train_loss': '0.89669'}; time used = 0.9738407135009766s
epoch 45: {'train_loss': '0.71853'}; time used = 1.0083768367767334s
epoch 50: {'train_loss': '1.01798'}; time used = 0.9821386337280273s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.790092468261719.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76219'}; time used = 1.7503883838653564s
epoch 10: {'train_loss': '2.72199'}; time used = 1.782911777496338s
epoch 15: {'train_loss': '2.69066'}; time used = 1.9613430500030518s
epoch 20: {'train_loss': '2.65363'}; time used = 1.7519445419311523s
epoch 25: {'train_loss': '2.57817'}; time used = 1.8125s
epoch 30: {'train_loss': '2.51656'}; time used = 1.5961298942565918s
epoch 35: {'train_loss': '2.45336'}; time used = 1.7509689331054688s
epoch 40: {'train_loss': '2.37328'}; time used = 1.8012244701385498s
epoch 45: {'train_loss': '2.58237'}; time used = 2.344661235809326s
epoch 50: {'train_loss': '2.32471'}; time used = 2.900000810623169s
epoch 55: {'train_loss': '2.33079'}; time used = 3.0233445167541504s
epoch 60: {'train_loss': '2.29777'}; time used = 2.8919646739959717s
epoch 65: {'train_loss': '2.19912'}; time used = 1.7402899265289307s
epoch 70: {'train_loss': '2.13059'}; time used = 1.6703426837921143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.936296463012695.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.65584'}; time used = 1.3078994750976562s
epoch 10: {'train_loss': '2.56983'}; time used = 1.3459532260894775s
epoch 15: {'train_loss': '2.31591'}; time used = 1.0384314060211182s
epoch 20: {'train_loss': '2.08621'}; time used = 1.0240528583526611s
epoch 25: {'train_loss': '2.04179'}; time used = 1.022350549697876s
epoch 30: {'train_loss': '1.99757'}; time used = 1.0043013095855713s
epoch 35: {'train_loss': '1.89535'}; time used = 1.0010406970977783s
epoch 40: {'train_loss': '1.89025'}; time used = 1.0511360168457031s
epoch 45: {'train_loss': '1.86755'}; time used = 1.135828971862793s
epoch 50: {'train_loss': '1.84082'}; time used = 1.1581013202667236s
epoch 55: {'train_loss': '1.82583'}; time used = 1.1846816539764404s
epoch 60: {'train_loss': '1.81014'}; time used = 1.1801567077636719s
epoch 65: {'train_loss': '1.77152'}; time used = 1.0147550106048584s
epoch 70: {'train_loss': '1.78873'}; time used = 1.182427167892456s
epoch 75: {'train_loss': '1.73814'}; time used = 1.105689287185669s
epoch 80: {'train_loss': '1.74102'}; time used = 1.1560404300689697s
epoch 85: {'train_loss': '1.77275'}; time used = 1.1060707569122314s
epoch 90: {'train_loss': '1.74817'}; time used = 1.9166715145111084s
epoch 95: {'train_loss': '1.73086'}; time used = 2.5076637268066406s
epoch 100: {'train_loss': '1.74624'}; time used = 1.1605522632598877s
epoch 105: {'train_loss': '1.71962'}; time used = 0.9741291999816895s
epoch 110: {'train_loss': '1.71728'}; time used = 1.0406558513641357s
epoch 115: {'train_loss': '1.70428'}; time used = 1.1194324493408203s
epoch 120: {'train_loss': '1.68236'}; time used = 0.8919270038604736s
epoch 125: {'train_loss': '1.69988'}; time used = 0.8960170745849609s
epoch 130: {'train_loss': '1.67923'}; time used = 0.8948290348052979s
epoch 135: {'train_loss': '1.74558'}; time used = 0.8910257816314697s
epoch 140: {'train_loss': '1.79614'}; time used = 1.014129638671875s
epoch 145: {'train_loss': '1.75874'}; time used = 0.9004995822906494s
epoch 150: {'train_loss': '1.71929'}; time used = 0.8937227725982666s
epoch 155: {'train_loss': '1.69258'}; time used = 0.8943963050842285s
epoch 160: {'train_loss': '1.68511'}; time used = 1.2611525058746338s
epoch 165: {'train_loss': '1.72556'}; time used = 1.8085269927978516s
epoch 170: {'train_loss': '1.67165'}; time used = 1.7659368515014648s
epoch 175: {'train_loss': '1.65502'}; time used = 1.7252004146575928s
epoch 180: {'train_loss': '1.67367'}; time used = 1.876906156539917s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.5021185874939.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.856386999244142, 'samples': 0.868421052631579, 'weighted': 0.8629510283645622, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94857'}; time used = 2.3825128078460693s
epoch 10: {'train_loss': '2.75751'}; time used = 2.413820505142212s
epoch 15: {'train_loss': '2.76499'}; time used = 2.318089485168457s
epoch 20: {'train_loss': '2.74160'}; time used = 2.408128023147583s
epoch 25: {'train_loss': '2.71817'}; time used = 2.465287208557129s
epoch 30: {'train_loss': '2.69382'}; time used = 2.3375332355499268s
epoch 35: {'train_loss': '2.65999'}; time used = 2.341769218444824s
epoch 40: {'train_loss': '2.62197'}; time used = 2.3203020095825195s
epoch 45: {'train_loss': '2.56366'}; time used = 2.416073799133301s
epoch 50: {'train_loss': '2.54232'}; time used = 2.3673782348632812s
epoch 55: {'train_loss': '2.51508'}; time used = 2.4125590324401855s
epoch 60: {'train_loss': '2.50235'}; time used = 2.3708343505859375s
epoch 65: {'train_loss': '2.45804'}; time used = 2.3381221294403076s
epoch 70: {'train_loss': '2.45146'}; time used = 2.3978614807128906s
epoch 75: {'train_loss': '2.44067'}; time used = 2.297933578491211s
epoch 80: {'train_loss': '2.42200'}; time used = 2.8292980194091797s
epoch 85: {'train_loss': '2.42986'}; time used = 3.469146728515625s
epoch 90: {'train_loss': '2.44280'}; time used = 3.3369693756103516s
epoch 95: {'train_loss': '2.38141'}; time used = 2.7572386264801025s
epoch 100: {'train_loss': '2.35995'}; time used = 2.342583417892456s
epoch 105: {'train_loss': '2.38253'}; time used = 2.5788869857788086s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 58.380189180374146.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5208333333333334, 'samples': 0.5652173913043478, 'weighted': 0.5314009661835749, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38714'}; time used = 1.2479596138000488s
epoch 10: {'train_loss': '1.34747'}; time used = 0.9956917762756348s
epoch 15: {'train_loss': '1.18094'}; time used = 1.0104825496673584s
epoch 20: {'train_loss': '1.03783'}; time used = 1.012134313583374s
epoch 25: {'train_loss': '0.62421'}; time used = 1.003465175628662s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.319333791732788.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.85049'}; time used = 2.6929609775543213s
epoch 10: {'train_loss': '2.77985'}; time used = 2.2798123359680176s
epoch 15: {'train_loss': '2.78093'}; time used = 1.2258539199829102s
epoch 20: {'train_loss': '2.77920'}; time used = 0.9949188232421875s
epoch 25: {'train_loss': '2.77305'}; time used = 1.1159958839416504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.734269857406616.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39952'}; time used = 1.147005319595337s
epoch 10: {'train_loss': '1.39259'}; time used = 1.0275866985321045s
epoch 15: {'train_loss': '1.38087'}; time used = 0.9821469783782959s
epoch 20: {'train_loss': '1.37582'}; time used = 1.8230011463165283s
epoch 25: {'train_loss': '1.30733'}; time used = 2.4177114963531494s
epoch 30: {'train_loss': '1.24891'}; time used = 2.2533068656921387s
epoch 35: {'train_loss': '1.28940'}; time used = 2.32853364944458s
epoch 40: {'train_loss': '1.18739'}; time used = 2.3757596015930176s
epoch 45: {'train_loss': '1.04133'}; time used = 1.06203293800354s
epoch 50: {'train_loss': '1.14541'}; time used = 1.2897095680236816s
epoch 55: {'train_loss': '1.09383'}; time used = 2.681910276412964s
epoch 60: {'train_loss': '1.14950'}; time used = 2.231846809387207s
epoch 65: {'train_loss': '0.98843'}; time used = 1.0324382781982422s
epoch 70: {'train_loss': '1.25174'}; time used = 1.0224802494049072s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.5552978515625.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11988'}; time used = 1.214515209197998s
epoch 10: {'train_loss': '2.81467'}; time used = 1.0894696712493896s
epoch 15: {'train_loss': '2.81679'}; time used = 1.1034939289093018s
epoch 20: {'train_loss': '2.80065'}; time used = 1.1115121841430664s
epoch 25: {'train_loss': '2.78697'}; time used = 1.0783488750457764s
epoch 30: {'train_loss': '2.78021'}; time used = 1.1452291011810303s
epoch 35: {'train_loss': '2.77682'}; time used = 1.0830070972442627s
epoch 40: {'train_loss': '2.77531'}; time used = 1.2793843746185303s
epoch 45: {'train_loss': '2.77483'}; time used = 1.0973517894744873s
epoch 50: {'train_loss': '2.77420'}; time used = 1.1528146266937256s
epoch 55: {'train_loss': '2.77363'}; time used = 1.0617804527282715s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.308334827423096.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.32167'}; time used = 2.405971050262451s
epoch 10: {'train_loss': '2.80770'}; time used = 2.368464469909668s
epoch 15: {'train_loss': '2.77832'}; time used = 2.5144548416137695s
epoch 20: {'train_loss': '2.79962'}; time used = 2.4026639461517334s
epoch 25: {'train_loss': '2.77012'}; time used = 2.410465955734253s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.156533241271973.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.25433'}; time used = 1.893064260482788s
epoch 10: {'train_loss': '1.17586'}; time used = 1.8023107051849365s
epoch 15: {'train_loss': '1.12973'}; time used = 2.070831775665283s
epoch 20: {'train_loss': '0.95037'}; time used = 1.7771742343902588s
epoch 25: {'train_loss': '0.84994'}; time used = 2.037597179412842s
epoch 30: {'train_loss': '0.54971'}; time used = 1.6886239051818848s
epoch 35: {'train_loss': '0.39776'}; time used = 1.7574536800384521s
epoch 40: {'train_loss': '0.22240'}; time used = 1.7210040092468262s
epoch 45: {'train_loss': '0.22269'}; time used = 1.9958271980285645s
epoch 50: {'train_loss': '0.15049'}; time used = 1.8659090995788574s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.349056243896484.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.40665742024965323, 'samples': 0.5507246376811594, 'weighted': 0.42784377575428645, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85613'}; time used = 1.3092420101165771s
epoch 10: {'train_loss': '2.78714'}; time used = 0.9909169673919678s
epoch 15: {'train_loss': '2.77368'}; time used = 1.0070583820343018s
epoch 20: {'train_loss': '2.78401'}; time used = 0.9991109371185303s
epoch 25: {'train_loss': '2.77668'}; time used = 0.9924426078796387s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.243034362792969.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87616'}; time used = 1.7750906944274902s
epoch 10: {'train_loss': '2.82119'}; time used = 1.6535682678222656s
epoch 15: {'train_loss': '2.78759'}; time used = 1.66782808303833s
epoch 20: {'train_loss': '2.77264'}; time used = 1.7091920375823975s
epoch 25: {'train_loss': '2.76999'}; time used = 1.7546422481536865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.125260829925537.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38966'}; time used = 1.2604951858520508s
epoch 10: {'train_loss': '1.35853'}; time used = 1.1168503761291504s
epoch 15: {'train_loss': '1.28733'}; time used = 1.1344146728515625s
epoch 20: {'train_loss': '1.29801'}; time used = 1.1082589626312256s
epoch 25: {'train_loss': '1.21134'}; time used = 1.1288738250732422s
epoch 30: {'train_loss': '1.27975'}; time used = 1.112168788909912s
epoch 35: {'train_loss': '1.31433'}; time used = 1.1229321956634521s
epoch 40: {'train_loss': '1.27554'}; time used = 1.105926275253296s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.138938426971436.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.01432'}; time used = 1.1556131839752197s
epoch 10: {'train_loss': '0.74265'}; time used = 1.0268511772155762s
epoch 15: {'train_loss': '0.58850'}; time used = 1.035123348236084s
epoch 20: {'train_loss': '0.41183'}; time used = 1.0324594974517822s
epoch 25: {'train_loss': '0.30101'}; time used = 1.0265867710113525s
epoch 30: {'train_loss': '0.26712'}; time used = 1.0370843410491943s
epoch 35: {'train_loss': '0.20666'}; time used = 1.02327299118042s
epoch 40: {'train_loss': '0.13428'}; time used = 1.0206198692321777s
epoch 45: {'train_loss': '0.10493'}; time used = 1.0477590560913086s
epoch 50: {'train_loss': '0.09780'}; time used = 1.0453474521636963s
epoch 55: {'train_loss': '0.08614'}; time used = 1.0749778747558594s
epoch 60: {'train_loss': '0.07452'}; time used = 1.0156445503234863s
epoch 65: {'train_loss': '0.06973'}; time used = 0.8886229991912842s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.146169662475586.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85620'}; time used = 5.011238098144531s
epoch 10: {'train_loss': '2.78187'}; time used = 4.82946252822876s
epoch 15: {'train_loss': '2.77542'}; time used = 5.260071277618408s
epoch 20: {'train_loss': '2.78389'}; time used = 4.95038366317749s
epoch 25: {'train_loss': '2.77568'}; time used = 4.361208200454712s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.895068883895874.
Training classifier using 80.00% nodes...
{'micro': 0.66, 'macro': 0.6594551282051282, 'samples': 0.66, 'weighted': 0.6597275641025641, 'accuracy': 0.66}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.76817'}; time used = 1.0687403678894043s
epoch 10: {'train_loss': '2.40174'}; time used = 1.010016918182373s
epoch 15: {'train_loss': '2.27525'}; time used = 1.0054442882537842s
epoch 20: {'train_loss': '2.15543'}; time used = 1.013246774673462s
epoch 25: {'train_loss': '2.10852'}; time used = 1.0062932968139648s
epoch 30: {'train_loss': '2.05726'}; time used = 1.0490398406982422s
epoch 35: {'train_loss': '2.00031'}; time used = 1.1231958866119385s
epoch 40: {'train_loss': '1.96373'}; time used = 0.9741027355194092s
epoch 45: {'train_loss': '1.96110'}; time used = 1.0065207481384277s
epoch 50: {'train_loss': '1.91435'}; time used = 0.9753377437591553s
epoch 55: {'train_loss': '1.88538'}; time used = 0.996187686920166s
epoch 60: {'train_loss': '1.86024'}; time used = 1.0366179943084717s
epoch 65: {'train_loss': '1.80914'}; time used = 0.9973287582397461s
epoch 70: {'train_loss': '1.81951'}; time used = 0.9911751747131348s
epoch 75: {'train_loss': '1.77572'}; time used = 1.039421558380127s
epoch 80: {'train_loss': '1.78021'}; time used = 1.139894723892212s
epoch 85: {'train_loss': '1.81324'}; time used = 1.0314772129058838s
epoch 90: {'train_loss': '1.78622'}; time used = 1.008368730545044s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.54992413520813.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.22998'}; time used = 1.2211987972259521s
epoch 10: {'train_loss': '2.87490'}; time used = 1.1400251388549805s
epoch 15: {'train_loss': '2.84091'}; time used = 1.0960218906402588s
epoch 20: {'train_loss': '2.81845'}; time used = 1.0628454685211182s
epoch 25: {'train_loss': '2.79574'}; time used = 1.068892002105713s
epoch 30: {'train_loss': '2.78591'}; time used = 1.235842227935791s
epoch 35: {'train_loss': '2.79264'}; time used = 1.1212835311889648s
epoch 40: {'train_loss': '2.78476'}; time used = 1.0192604064941406s
epoch 45: {'train_loss': '2.78399'}; time used = 1.025719404220581s
epoch 50: {'train_loss': '2.77870'}; time used = 1.1114296913146973s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.817638635635376.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.125371932983398s
epoch 10: {'train_loss': '1.38629'}; time used = 4.807145118713379s
epoch 15: {'train_loss': '1.38629'}; time used = 5.077653169631958s
epoch 20: {'train_loss': '1.38629'}; time used = 7.577065944671631s
epoch 25: {'train_loss': '1.38629'}; time used = 5.323282957077026s
epoch 30: {'train_loss': '1.38629'}; time used = 5.123774528503418s
epoch 35: {'train_loss': '1.38629'}; time used = 4.355594873428345s
epoch 40: {'train_loss': '1.38629'}; time used = 4.588799238204956s
epoch 45: {'train_loss': '1.38629'}; time used = 4.329617977142334s
epoch 50: {'train_loss': '1.38629'}; time used = 4.221924543380737s
epoch 55: {'train_loss': '1.38629'}; time used = 4.108505725860596s
epoch 60: {'train_loss': '1.38629'}; time used = 4.223585605621338s
epoch 65: {'train_loss': '1.38629'}; time used = 4.198772192001343s
epoch 70: {'train_loss': '1.38629'}; time used = 4.231969356536865s
epoch 75: {'train_loss': '1.38629'}; time used = 4.125922203063965s
epoch 80: {'train_loss': '1.38629'}; time used = 4.170453071594238s
epoch 85: {'train_loss': '1.38629'}; time used = 4.235753774642944s
epoch 90: {'train_loss': '1.38629'}; time used = 4.173855304718018s
epoch 95: {'train_loss': '1.38629'}; time used = 4.193055629730225s
epoch 100: {'train_loss': '1.38629'}; time used = 4.242577075958252s
epoch 105: {'train_loss': '1.38629'}; time used = 4.371872663497925s
epoch 110: {'train_loss': '1.38629'}; time used = 4.336659908294678s
epoch 115: {'train_loss': '1.38629'}; time used = 4.311372518539429s
epoch 120: {'train_loss': '1.38629'}; time used = 4.384396076202393s
epoch 125: {'train_loss': '1.38629'}; time used = 4.183048486709595s
epoch 130: {'train_loss': '1.38629'}; time used = 4.251780033111572s
epoch 135: {'train_loss': '1.38629'}; time used = 4.239375591278076s
epoch 140: {'train_loss': '1.38629'}; time used = 4.263475179672241s
epoch 145: {'train_loss': '1.38629'}; time used = 4.355058670043945s
epoch 150: {'train_loss': '1.38629'}; time used = 4.475552320480347s
epoch 155: {'train_loss': '1.38629'}; time used = 4.40783166885376s
epoch 160: {'train_loss': '1.38629'}; time used = 4.542369842529297s
epoch 165: {'train_loss': '1.38629'}; time used = 4.355980396270752s
epoch 170: {'train_loss': '1.38629'}; time used = 4.342070817947388s
epoch 175: {'train_loss': '1.38629'}; time used = 4.4076247215271s
epoch 180: {'train_loss': '1.38629'}; time used = 4.271503210067749s
epoch 185: {'train_loss': '1.38629'}; time used = 4.212238073348999s
epoch 190: {'train_loss': '1.38629'}; time used = 4.256494522094727s
epoch 195: {'train_loss': '1.38629'}; time used = 4.160642147064209s
epoch 200: {'train_loss': '1.38629'}; time used = 4.327020883560181s
epoch 205: {'train_loss': '1.38629'}; time used = 4.239282131195068s
epoch 210: {'train_loss': '1.38629'}; time used = 4.304478406906128s
epoch 215: {'train_loss': '1.38629'}; time used = 4.192647695541382s
epoch 220: {'train_loss': '1.38629'}; time used = 4.3677308559417725s
epoch 225: {'train_loss': '1.38629'}; time used = 4.332754135131836s
epoch 230: {'train_loss': '1.38629'}; time used = 4.296659708023071s
epoch 235: {'train_loss': '1.38629'}; time used = 4.257355451583862s
epoch 240: {'train_loss': '1.38629'}; time used = 4.4086737632751465s
epoch 245: {'train_loss': '1.38629'}; time used = 4.445669889450073s
epoch 250: {'train_loss': '1.38629'}; time used = 4.259119987487793s
epoch 255: {'train_loss': '1.38629'}; time used = 4.2845001220703125s
epoch 260: {'train_loss': '1.38629'}; time used = 4.301455736160278s
epoch 265: {'train_loss': '1.38629'}; time used = 4.414822101593018s
epoch 270: {'train_loss': '1.38629'}; time used = 4.293516397476196s
epoch 275: {'train_loss': '1.38629'}; time used = 4.272059679031372s
epoch 280: {'train_loss': '1.38629'}; time used = 4.239516973495483s
epoch 285: {'train_loss': '1.38629'}; time used = 4.402067422866821s
epoch 290: {'train_loss': '1.38629'}; time used = 4.222776174545288s
epoch 295: {'train_loss': '1.38629'}; time used = 4.184134244918823s
epoch 300: {'train_loss': '1.38629'}; time used = 4.186556816101074s
epoch 305: {'train_loss': '1.38629'}; time used = 4.222779035568237s
epoch 310: {'train_loss': '1.38629'}; time used = 4.30937933921814s
epoch 315: {'train_loss': '1.38629'}; time used = 4.611675024032593s
epoch 320: {'train_loss': '1.38629'}; time used = 4.371935606002808s
epoch 325: {'train_loss': '1.38629'}; time used = 4.261137008666992s
epoch 330: {'train_loss': '1.38629'}; time used = 4.2320826053619385s
epoch 335: {'train_loss': '1.38629'}; time used = 6.502161979675293s
epoch 340: {'train_loss': '1.38629'}; time used = 6.382779121398926s
epoch 345: {'train_loss': '1.38629'}; time used = 4.536976099014282s
epoch 350: {'train_loss': '1.38629'}; time used = 4.329118490219116s
epoch 355: {'train_loss': '1.38629'}; time used = 4.303637504577637s
epoch 360: {'train_loss': '1.38629'}; time used = 4.398977994918823s
epoch 365: {'train_loss': '1.38629'}; time used = 4.369125843048096s
epoch 370: {'train_loss': '1.38629'}; time used = 6.154348134994507s
epoch 375: {'train_loss': '1.38629'}; time used = 6.651691675186157s
epoch 380: {'train_loss': '1.38629'}; time used = 4.350208282470703s
epoch 385: {'train_loss': '1.38629'}; time used = 4.291244268417358s
epoch 390: {'train_loss': '1.38629'}; time used = 4.507396936416626s
epoch 395: {'train_loss': '1.38629'}; time used = 4.211405992507935s
epoch 400: {'train_loss': '1.38629'}; time used = 4.195226669311523s
epoch 405: {'train_loss': '1.38629'}; time used = 4.2276458740234375s
epoch 410: {'train_loss': '1.38629'}; time used = 4.2387535572052s
epoch 415: {'train_loss': '1.38629'}; time used = 4.243438959121704s
epoch 420: {'train_loss': '1.38629'}; time used = 4.20363712310791s
epoch 425: {'train_loss': '1.38629'}; time used = 4.11068320274353s
epoch 430: {'train_loss': '1.38629'}; time used = 4.1930320262908936s
epoch 435: {'train_loss': '1.38629'}; time used = 4.221819877624512s
epoch 440: {'train_loss': '1.38629'}; time used = 4.19180703163147s
epoch 445: {'train_loss': '1.38629'}; time used = 4.302610635757446s
epoch 450: {'train_loss': '1.38629'}; time used = 4.292919635772705s
epoch 455: {'train_loss': '1.38629'}; time used = 4.191711664199829s
epoch 460: {'train_loss': '1.38629'}; time used = 4.16903018951416s
epoch 465: {'train_loss': '1.38629'}; time used = 4.200846195220947s
epoch 470: {'train_loss': '1.38629'}; time used = 4.209035873413086s
epoch 475: {'train_loss': '1.38629'}; time used = 4.20588231086731s
epoch 480: {'train_loss': '1.38629'}; time used = 4.2261645793914795s
epoch 485: {'train_loss': '1.38629'}; time used = 4.21192741394043s
epoch 490: {'train_loss': '1.38629'}; time used = 4.137951135635376s
epoch 495: {'train_loss': '1.38629'}; time used = 4.200730085372925s
epoch 500: {'train_loss': '1.38629'}; time used = 5.507330417633057s
Finished training. Time used = 453.8255248069763.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84101'}; time used = 1.2311899662017822s
epoch 10: {'train_loss': '2.71585'}; time used = 1.0624573230743408s
epoch 15: {'train_loss': '2.62508'}; time used = 1.0453598499298096s
epoch 20: {'train_loss': '2.56273'}; time used = 1.0669047832489014s
epoch 25: {'train_loss': '2.49246'}; time used = 1.0449800491333008s
epoch 30: {'train_loss': '2.43201'}; time used = 1.0406546592712402s
epoch 35: {'train_loss': '2.39683'}; time used = 1.031376600265503s
epoch 40: {'train_loss': '2.35278'}; time used = 1.0261685848236084s
epoch 45: {'train_loss': '2.30498'}; time used = 1.099705696105957s
epoch 50: {'train_loss': '2.26612'}; time used = 1.1556837558746338s
epoch 55: {'train_loss': '2.28221'}; time used = 1.0599191188812256s
epoch 60: {'train_loss': '2.23946'}; time used = 1.1265766620635986s
epoch 65: {'train_loss': '2.18459'}; time used = 1.0272941589355469s
epoch 70: {'train_loss': '2.18865'}; time used = 1.0384454727172852s
epoch 75: {'train_loss': '2.15002'}; time used = 1.1158473491668701s
epoch 80: {'train_loss': '2.22176'}; time used = 1.0090031623840332s
epoch 85: {'train_loss': '2.19295'}; time used = 1.0102155208587646s
epoch 90: {'train_loss': '2.17943'}; time used = 1.023271083831787s
epoch 95: {'train_loss': '2.11234'}; time used = 1.0384290218353271s
epoch 100: {'train_loss': '2.12202'}; time used = 1.0456647872924805s
epoch 105: {'train_loss': '2.10061'}; time used = 1.1112375259399414s
epoch 110: {'train_loss': '2.07397'}; time used = 1.039592981338501s
epoch 115: {'train_loss': '2.03950'}; time used = 1.0803325176239014s
epoch 120: {'train_loss': '2.05294'}; time used = 1.0752182006835938s
epoch 125: {'train_loss': '2.07949'}; time used = 1.0113804340362549s
epoch 130: {'train_loss': '2.02342'}; time used = 0.9713451862335205s
epoch 135: {'train_loss': '2.05273'}; time used = 1.032092809677124s
epoch 140: {'train_loss': '2.03445'}; time used = 1.011394739151001s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.56659007072449.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84264'}; time used = 1.721681833267212s
epoch 10: {'train_loss': '2.77450'}; time used = 1.4312894344329834s
epoch 15: {'train_loss': '2.78142'}; time used = 1.3688101768493652s
epoch 20: {'train_loss': '2.78407'}; time used = 1.4632062911987305s
epoch 25: {'train_loss': '2.77319'}; time used = 1.4281506538391113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.338221788406372.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.81097'}; time used = 2.103621006011963s
epoch 10: {'train_loss': '2.70174'}; time used = 1.8315250873565674s
epoch 15: {'train_loss': '2.61865'}; time used = 1.862884521484375s
epoch 20: {'train_loss': '2.53021'}; time used = 1.822563648223877s
epoch 25: {'train_loss': '2.41663'}; time used = 1.7758445739746094s
epoch 30: {'train_loss': '2.28663'}; time used = 1.7165491580963135s
epoch 35: {'train_loss': '2.14908'}; time used = 1.2435054779052734s
epoch 40: {'train_loss': '2.05308'}; time used = 1.0404531955718994s
epoch 45: {'train_loss': '2.07825'}; time used = 1.030930995941162s
epoch 50: {'train_loss': '1.92941'}; time used = 0.9670586585998535s
epoch 55: {'train_loss': '1.85995'}; time used = 0.9752943515777588s
epoch 60: {'train_loss': '1.83577'}; time used = 0.9821305274963379s
epoch 65: {'train_loss': '1.80003'}; time used = 0.9328651428222656s
epoch 70: {'train_loss': '1.81352'}; time used = 0.9136428833007812s
epoch 75: {'train_loss': '1.78316'}; time used = 0.9427986145019531s
epoch 80: {'train_loss': '1.78766'}; time used = 0.922929048538208s
epoch 85: {'train_loss': '1.83035'}; time used = 1.1044151782989502s
epoch 90: {'train_loss': '1.81531'}; time used = 0.9528460502624512s
epoch 95: {'train_loss': '1.80666'}; time used = 0.9470381736755371s
epoch 100: {'train_loss': '1.82455'}; time used = 1.0893528461456299s
epoch 105: {'train_loss': '1.79672'}; time used = 1.127206563949585s
epoch 110: {'train_loss': '1.79161'}; time used = 0.9218385219573975s
epoch 115: {'train_loss': '1.78099'}; time used = 0.9435088634490967s
epoch 120: {'train_loss': '1.77390'}; time used = 0.9186904430389404s
epoch 125: {'train_loss': '1.78760'}; time used = 0.9214260578155518s
epoch 130: {'train_loss': '1.76338'}; time used = 0.9188783168792725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.29905390739441.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35711'}; time used = 1.2282748222351074s
epoch 10: {'train_loss': '1.24259'}; time used = 1.017805814743042s
epoch 15: {'train_loss': '0.91691'}; time used = 1.6345443725585938s
epoch 20: {'train_loss': '0.48174'}; time used = 3.072768211364746s
epoch 25: {'train_loss': '0.11753'}; time used = 3.480982542037964s
epoch 30: {'train_loss': '0.09409'}; time used = 2.7423508167266846s
epoch 35: {'train_loss': '0.05107'}; time used = 2.476715326309204s
epoch 40: {'train_loss': '0.12925'}; time used = 2.3747828006744385s
epoch 45: {'train_loss': '0.00897'}; time used = 1.9317762851715088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.695106029510498.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.62014'}; time used = 1.1305460929870605s
epoch 10: {'train_loss': '2.44861'}; time used = 1.1312434673309326s
epoch 15: {'train_loss': '2.33860'}; time used = 1.0561182498931885s
epoch 20: {'train_loss': '2.28007'}; time used = 1.0401148796081543s
epoch 25: {'train_loss': '2.19167'}; time used = 0.9993414878845215s
epoch 30: {'train_loss': '2.12509'}; time used = 1.6446352005004883s
epoch 35: {'train_loss': '2.11969'}; time used = 1.6334075927734375s
epoch 40: {'train_loss': '2.12698'}; time used = 1.765465259552002s
epoch 45: {'train_loss': '2.11748'}; time used = 1.6604132652282715s
epoch 50: {'train_loss': '2.13107'}; time used = 1.7074718475341797s
epoch 55: {'train_loss': '2.11267'}; time used = 1.1509947776794434s
epoch 60: {'train_loss': '2.09535'}; time used = 0.9860334396362305s
epoch 65: {'train_loss': '2.09993'}; time used = 0.9195976257324219s
epoch 70: {'train_loss': '2.10461'}; time used = 0.9537637233734131s
epoch 75: {'train_loss': '2.07404'}; time used = 0.9076375961303711s
epoch 80: {'train_loss': '2.08792'}; time used = 0.9559326171875s
epoch 85: {'train_loss': '2.09473'}; time used = 0.9230968952178955s
epoch 90: {'train_loss': '2.05428'}; time used = 0.9336483478546143s
epoch 95: {'train_loss': '2.08513'}; time used = 0.8881034851074219s
epoch 100: {'train_loss': '2.10835'}; time used = 0.9803769588470459s
epoch 105: {'train_loss': '2.08079'}; time used = 1.071018934249878s
epoch 110: {'train_loss': '2.04892'}; time used = 0.9281067848205566s
epoch 115: {'train_loss': '2.06836'}; time used = 0.9214777946472168s
epoch 120: {'train_loss': '2.05550'}; time used = 1.0062596797943115s
epoch 125: {'train_loss': '2.08525'}; time used = 0.9603235721588135s
epoch 130: {'train_loss': '2.06897'}; time used = 0.8636980056762695s
epoch 135: {'train_loss': '2.04491'}; time used = 0.8717555999755859s
epoch 140: {'train_loss': '2.06365'}; time used = 0.9427378177642822s
epoch 145: {'train_loss': '2.05916'}; time used = 0.902036190032959s
epoch 150: {'train_loss': '2.04483'}; time used = 1.023108959197998s
epoch 155: {'train_loss': '2.07557'}; time used = 0.9041244983673096s
epoch 160: {'train_loss': '2.05832'}; time used = 0.8779628276824951s
epoch 165: {'train_loss': '2.07999'}; time used = 0.8894531726837158s
epoch 170: {'train_loss': '2.09667'}; time used = 0.8788490295410156s
epoch 175: {'train_loss': '2.03995'}; time used = 0.8670473098754883s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.93016505241394.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80477'}; time used = 1.6790993213653564s
epoch 10: {'train_loss': '2.89514'}; time used = 1.7552566528320312s
epoch 15: {'train_loss': '2.80707'}; time used = 2.011535882949829s
epoch 20: {'train_loss': '2.77534'}; time used = 1.7045960426330566s
epoch 25: {'train_loss': '2.76846'}; time used = 1.7776463031768799s
epoch 30: {'train_loss': '2.76808'}; time used = 1.6684939861297607s
epoch 35: {'train_loss': '2.76868'}; time used = 1.6943624019622803s
epoch 40: {'train_loss': '2.76865'}; time used = 1.7280831336975098s
epoch 45: {'train_loss': '2.76169'}; time used = 1.8269340991973877s
epoch 50: {'train_loss': '2.75648'}; time used = 1.766589641571045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.83933687210083.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5503468572629808, 'samples': 0.5507246376811594, 'weighted': 0.5512913083084272, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51544'}; time used = 1.766186237335205s
epoch 10: {'train_loss': '0.25865'}; time used = 1.503382921218872s
epoch 15: {'train_loss': '0.20821'}; time used = 1.469346046447754s
epoch 20: {'train_loss': '0.12773'}; time used = 1.5044775009155273s
epoch 25: {'train_loss': '0.01726'}; time used = 1.449314832687378s
epoch 30: {'train_loss': '0.00008'}; time used = 1.4221646785736084s
epoch 35: {'train_loss': '0.09175'}; time used = 1.4537489414215088s
epoch 40: {'train_loss': '0.09613'}; time used = 1.3848958015441895s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.54883337020874.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76076'}; time used = 1.508582592010498s
epoch 10: {'train_loss': '2.75252'}; time used = 1.3363656997680664s
epoch 15: {'train_loss': '2.72866'}; time used = 1.3262412548065186s
epoch 20: {'train_loss': '2.65938'}; time used = 1.3443026542663574s
epoch 25: {'train_loss': '2.51346'}; time used = 1.4391388893127441s
epoch 30: {'train_loss': '2.33053'}; time used = 1.3421757221221924s
epoch 35: {'train_loss': '2.23452'}; time used = 1.3298969268798828s
epoch 40: {'train_loss': '2.23968'}; time used = 1.292170763015747s
epoch 45: {'train_loss': '2.17371'}; time used = 1.2474498748779297s
epoch 50: {'train_loss': '2.11558'}; time used = 1.2525310516357422s
epoch 55: {'train_loss': '1.97081'}; time used = 1.2245798110961914s
epoch 60: {'train_loss': '2.04928'}; time used = 1.3249359130859375s
epoch 65: {'train_loss': '2.04532'}; time used = 1.260737657546997s
epoch 70: {'train_loss': '1.97604'}; time used = 1.2846753597259521s
epoch 75: {'train_loss': '1.85252'}; time used = 1.2563540935516357s
epoch 80: {'train_loss': '1.88105'}; time used = 1.278315782546997s
epoch 85: {'train_loss': '1.83880'}; time used = 1.231269121170044s
epoch 90: {'train_loss': '1.80983'}; time used = 1.2581145763397217s
epoch 95: {'train_loss': '1.83553'}; time used = 1.2647967338562012s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.57755160331726.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84898'}; time used = 1.1226396560668945s
epoch 10: {'train_loss': '0.22916'}; time used = 0.9574108123779297s
epoch 15: {'train_loss': '0.19918'}; time used = 0.9719786643981934s
epoch 20: {'train_loss': '0.14971'}; time used = 1.0514099597930908s
epoch 25: {'train_loss': '0.16390'}; time used = 0.9769606590270996s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.804876327514648.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.19730'}; time used = 1.7835299968719482s
epoch 10: {'train_loss': '1.13556'}; time used = 1.5511655807495117s
epoch 15: {'train_loss': '1.11674'}; time used = 1.6648187637329102s
epoch 20: {'train_loss': '1.05524'}; time used = 1.8903346061706543s
epoch 25: {'train_loss': '0.70409'}; time used = 2.085514545440674s
epoch 30: {'train_loss': '0.45165'}; time used = 2.0321762561798096s
epoch 35: {'train_loss': '0.29033'}; time used = 1.9097084999084473s
epoch 40: {'train_loss': '0.34413'}; time used = 1.8844449520111084s
epoch 45: {'train_loss': '0.29507'}; time used = 1.8094723224639893s
epoch 50: {'train_loss': '0.30151'}; time used = 1.7377471923828125s
epoch 55: {'train_loss': '0.12387'}; time used = 1.9293849468231201s
epoch 60: {'train_loss': '0.22135'}; time used = 1.8448452949523926s
epoch 65: {'train_loss': '0.02403'}; time used = 1.6913461685180664s
epoch 70: {'train_loss': '0.10373'}; time used = 1.4898931980133057s
epoch 75: {'train_loss': '0.00619'}; time used = 2.432013750076294s
epoch 80: {'train_loss': '0.00471'}; time used = 3.0383386611938477s
epoch 85: {'train_loss': '0.00376'}; time used = 3.0682168006896973s
epoch 90: {'train_loss': '0.09377'}; time used = 2.272921085357666s
epoch 95: {'train_loss': '0.17386'}; time used = 1.8259844779968262s
epoch 100: {'train_loss': '0.11884'}; time used = 1.5189743041992188s
epoch 105: {'train_loss': '0.09480'}; time used = 1.729598045349121s
epoch 110: {'train_loss': '0.18491'}; time used = 1.488774061203003s
epoch 115: {'train_loss': '0.17996'}; time used = 1.5118534564971924s
epoch 120: {'train_loss': '0.07794'}; time used = 1.628028392791748s
epoch 125: {'train_loss': '0.16712'}; time used = 1.5545897483825684s
epoch 130: {'train_loss': '0.25631'}; time used = 2.4937407970428467s
epoch 135: {'train_loss': '0.01265'}; time used = 2.701892137527466s
epoch 140: {'train_loss': '0.00976'}; time used = 2.806216239929199s
epoch 145: {'train_loss': '0.17748'}; time used = 2.1441991329193115s
epoch 150: {'train_loss': '0.00634'}; time used = 1.9509727954864502s
epoch 155: {'train_loss': '0.09151'}; time used = 1.6019501686096191s
epoch 160: {'train_loss': '0.08937'}; time used = 1.7581617832183838s
epoch 165: {'train_loss': '0.09336'}; time used = 1.564666986465454s
epoch 170: {'train_loss': '0.17064'}; time used = 1.565244436264038s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 69.44379997253418.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '3.06875'}; time used = 2.0129446983337402s
epoch 10: {'train_loss': '3.00728'}; time used = 1.8718526363372803s
epoch 15: {'train_loss': '2.97457'}; time used = 1.8277561664581299s
epoch 20: {'train_loss': '2.92052'}; time used = 1.825878620147705s
epoch 25: {'train_loss': '2.84145'}; time used = 1.7722742557525635s
epoch 30: {'train_loss': '2.75794'}; time used = 1.74770188331604s
epoch 35: {'train_loss': '2.70549'}; time used = 1.685378074645996s
epoch 40: {'train_loss': '2.64965'}; time used = 1.6878077983856201s
epoch 45: {'train_loss': '2.61858'}; time used = 1.6631245613098145s
epoch 50: {'train_loss': '2.58445'}; time used = 1.660959243774414s
epoch 55: {'train_loss': '2.57245'}; time used = 1.7039744853973389s
epoch 60: {'train_loss': '2.56182'}; time used = 1.642735242843628s
epoch 65: {'train_loss': '2.53811'}; time used = 1.65864896774292s
epoch 70: {'train_loss': '2.52627'}; time used = 1.6523182392120361s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.273348331451416.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13827'}; time used = 1.557474136352539s
epoch 10: {'train_loss': '0.87982'}; time used = 1.6439144611358643s
epoch 15: {'train_loss': '0.34379'}; time used = 1.5284149646759033s
epoch 20: {'train_loss': '0.43435'}; time used = 1.6523759365081787s
epoch 25: {'train_loss': '0.43407'}; time used = 1.5636274814605713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.467231512069702.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.87170'}; time used = 2.7698686122894287s
epoch 10: {'train_loss': '2.50567'}; time used = 2.161128044128418s
epoch 15: {'train_loss': '2.51463'}; time used = 2.2538390159606934s
epoch 20: {'train_loss': '2.47565'}; time used = 1.7541227340698242s
epoch 25: {'train_loss': '2.43399'}; time used = 1.7281744480133057s
epoch 30: {'train_loss': '2.36053'}; time used = 0.8966648578643799s
epoch 35: {'train_loss': '2.30483'}; time used = 0.8874378204345703s
epoch 40: {'train_loss': '2.25163'}; time used = 0.9685776233673096s
epoch 45: {'train_loss': '2.20466'}; time used = 1.1298940181732178s
epoch 50: {'train_loss': '2.17895'}; time used = 0.9984979629516602s
epoch 55: {'train_loss': '2.14776'}; time used = 0.8902344703674316s
epoch 60: {'train_loss': '2.11888'}; time used = 1.0905635356903076s
epoch 65: {'train_loss': '2.12471'}; time used = 0.9609527587890625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.73286747932434.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.13268'}; time used = 1.17423677444458s
epoch 10: {'train_loss': '2.79335'}; time used = 0.985527515411377s
epoch 15: {'train_loss': '2.78170'}; time used = 0.9870226383209229s
epoch 20: {'train_loss': '2.79644'}; time used = 1.0072166919708252s
epoch 25: {'train_loss': '2.77689'}; time used = 0.9880843162536621s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.547110795974731.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.67229'}; time used = 1.2261981964111328s
epoch 10: {'train_loss': '2.56758'}; time used = 0.9819135665893555s
epoch 15: {'train_loss': '2.52986'}; time used = 0.9700126647949219s
epoch 20: {'train_loss': '2.48161'}; time used = 0.9688739776611328s
epoch 25: {'train_loss': '2.43892'}; time used = 0.9756240844726562s
epoch 30: {'train_loss': '2.34886'}; time used = 0.9647276401519775s
epoch 35: {'train_loss': '2.32516'}; time used = 0.9451184272766113s
epoch 40: {'train_loss': '2.30330'}; time used = 0.9517500400543213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.339983224868774.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.19634'}; time used = 1.7549700736999512s
epoch 10: {'train_loss': '1.13981'}; time used = 1.8342492580413818s
epoch 15: {'train_loss': '0.82085'}; time used = 1.6894023418426514s
epoch 20: {'train_loss': '0.65300'}; time used = 1.944434404373169s
epoch 25: {'train_loss': '0.58963'}; time used = 1.853571891784668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.835736989974976.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.626642465591431s
epoch 10: {'train_loss': '1.38629'}; time used = 6.908627510070801s
epoch 15: {'train_loss': '1.38629'}; time used = 9.352945804595947s
epoch 20: {'train_loss': '1.38629'}; time used = 7.1501240730285645s
epoch 25: {'train_loss': '1.38629'}; time used = 6.378976345062256s
epoch 30: {'train_loss': '1.38629'}; time used = 6.355218887329102s
epoch 35: {'train_loss': '1.38629'}; time used = 6.16878604888916s
epoch 40: {'train_loss': '1.38629'}; time used = 6.836069107055664s
epoch 45: {'train_loss': '1.38629'}; time used = 7.195772886276245s
epoch 50: {'train_loss': '1.38629'}; time used = 7.479591369628906s
epoch 55: {'train_loss': '1.38629'}; time used = 6.259440183639526s
epoch 60: {'train_loss': '1.38629'}; time used = 6.206502437591553s
epoch 65: {'train_loss': '1.38629'}; time used = 6.632936239242554s
epoch 70: {'train_loss': '1.38629'}; time used = 6.1954474449157715s
epoch 75: {'train_loss': '1.38629'}; time used = 7.661128759384155s
epoch 80: {'train_loss': '1.38629'}; time used = 7.769395112991333s
epoch 85: {'train_loss': '1.38629'}; time used = 6.219783306121826s
epoch 90: {'train_loss': '1.38629'}; time used = 6.289560079574585s
epoch 95: {'train_loss': '1.38629'}; time used = 6.232949733734131s
epoch 100: {'train_loss': '1.38629'}; time used = 6.232746124267578s
epoch 105: {'train_loss': '1.38629'}; time used = 6.230041027069092s
epoch 110: {'train_loss': '1.38629'}; time used = 8.06715726852417s
epoch 115: {'train_loss': '1.38629'}; time used = 8.73235297203064s
epoch 120: {'train_loss': '1.38629'}; time used = 10.60904335975647s
epoch 125: {'train_loss': '1.38629'}; time used = 8.566677331924438s
epoch 130: {'train_loss': '1.38629'}; time used = 6.203605890274048s
epoch 135: {'train_loss': '1.38629'}; time used = 8.333726167678833s
epoch 140: {'train_loss': '1.38629'}; time used = 7.554722309112549s
epoch 145: {'train_loss': '1.38629'}; time used = 7.0687174797058105s
epoch 150: {'train_loss': '1.38629'}; time used = 9.579771518707275s
epoch 155: {'train_loss': '1.38629'}; time used = 7.186061859130859s
epoch 160: {'train_loss': '1.38629'}; time used = 7.5282042026519775s
epoch 165: {'train_loss': '1.38629'}; time used = 9.827265739440918s
epoch 170: {'train_loss': '1.38629'}; time used = 8.972489833831787s
epoch 175: {'train_loss': '1.38629'}; time used = 6.200721740722656s
epoch 180: {'train_loss': '1.38629'}; time used = 6.034404277801514s
epoch 185: {'train_loss': '1.38629'}; time used = 7.397794723510742s
epoch 190: {'train_loss': '1.38629'}; time used = 6.304640769958496s
epoch 195: {'train_loss': '1.38629'}; time used = 6.516559362411499s
epoch 200: {'train_loss': '1.38629'}; time used = 6.48732590675354s
epoch 205: {'train_loss': '1.38629'}; time used = 6.2889404296875s
epoch 210: {'train_loss': '1.38629'}; time used = 6.081536293029785s
epoch 215: {'train_loss': '1.38629'}; time used = 6.0338263511657715s
epoch 220: {'train_loss': '1.38629'}; time used = 7.378284454345703s
epoch 225: {'train_loss': '1.38629'}; time used = 6.400561094284058s
epoch 230: {'train_loss': '1.38629'}; time used = 10.255220890045166s
epoch 235: {'train_loss': '1.38629'}; time used = 6.415404796600342s
epoch 240: {'train_loss': '1.38629'}; time used = 6.386123418807983s
epoch 245: {'train_loss': '1.38629'}; time used = 6.348347425460815s
epoch 250: {'train_loss': '1.38629'}; time used = 6.298283815383911s
epoch 255: {'train_loss': '1.38629'}; time used = 6.351409435272217s
epoch 260: {'train_loss': '1.38629'}; time used = 6.002659320831299s
epoch 265: {'train_loss': '1.38629'}; time used = 6.125267028808594s
epoch 270: {'train_loss': '1.38629'}; time used = 6.206230640411377s
epoch 275: {'train_loss': '1.38629'}; time used = 6.163964509963989s
epoch 280: {'train_loss': '1.38629'}; time used = 6.250544309616089s
epoch 285: {'train_loss': '1.38629'}; time used = 6.408825159072876s
epoch 290: {'train_loss': '1.38629'}; time used = 11.540339946746826s
epoch 295: {'train_loss': '1.38629'}; time used = 7.2948973178863525s
epoch 300: {'train_loss': '1.38629'}; time used = 6.226071357727051s
epoch 305: {'train_loss': '1.38629'}; time used = 6.15507960319519s
epoch 310: {'train_loss': '1.38629'}; time used = 7.81835150718689s
epoch 315: {'train_loss': '1.38629'}; time used = 7.014119625091553s
epoch 320: {'train_loss': '1.38629'}; time used = 6.78404974937439s
epoch 325: {'train_loss': '1.38629'}; time used = 7.956683397293091s
epoch 330: {'train_loss': '1.38629'}; time used = 6.852997541427612s
epoch 335: {'train_loss': '1.38629'}; time used = 6.237952709197998s
epoch 340: {'train_loss': '1.38629'}; time used = 6.227431774139404s
epoch 345: {'train_loss': '1.38629'}; time used = 6.374926805496216s
epoch 350: {'train_loss': '1.38629'}; time used = 6.468035459518433s
epoch 355: {'train_loss': '1.38629'}; time used = 6.329356670379639s
epoch 360: {'train_loss': '1.38629'}; time used = 6.329493045806885s
epoch 365: {'train_loss': '1.38629'}; time used = 7.006169557571411s
epoch 370: {'train_loss': '1.38629'}; time used = 6.15508246421814s
epoch 375: {'train_loss': '1.38629'}; time used = 6.109597682952881s
epoch 380: {'train_loss': '1.38629'}; time used = 6.332821846008301s
epoch 385: {'train_loss': '1.38629'}; time used = 6.286602973937988s
epoch 390: {'train_loss': '1.38629'}; time used = 9.922879934310913s
epoch 395: {'train_loss': '1.38629'}; time used = 6.332881212234497s
epoch 400: {'train_loss': '1.38629'}; time used = 6.294095516204834s
epoch 405: {'train_loss': '1.38629'}; time used = 6.293764114379883s
epoch 410: {'train_loss': '1.38629'}; time used = 6.265738010406494s
epoch 415: {'train_loss': '1.38629'}; time used = 6.435634613037109s
epoch 420: {'train_loss': '1.38629'}; time used = 9.860174894332886s
epoch 425: {'train_loss': '1.38629'}; time used = 6.435093641281128s
epoch 430: {'train_loss': '1.38629'}; time used = 7.582515239715576s
epoch 435: {'train_loss': '1.38629'}; time used = 11.472371816635132s
epoch 440: {'train_loss': '1.38629'}; time used = 11.206369161605835s
epoch 445: {'train_loss': '1.38629'}; time used = 7.496603965759277s
epoch 450: {'train_loss': '1.38629'}; time used = 6.852294683456421s
epoch 455: {'train_loss': '1.38629'}; time used = 6.160562515258789s
epoch 460: {'train_loss': '1.38629'}; time used = 6.348408222198486s
epoch 465: {'train_loss': '1.38629'}; time used = 6.142954349517822s
epoch 470: {'train_loss': '1.38629'}; time used = 6.134066343307495s
epoch 475: {'train_loss': '1.38629'}; time used = 6.339487075805664s
epoch 480: {'train_loss': '1.38629'}; time used = 6.19825553894043s
epoch 485: {'train_loss': '1.38629'}; time used = 6.35813045501709s
epoch 490: {'train_loss': '1.38629'}; time used = 8.846826076507568s
epoch 495: {'train_loss': '1.38629'}; time used = 8.625598907470703s
epoch 500: {'train_loss': '1.38629'}; time used = 7.5767199993133545s
Finished training. Time used = 718.9254803657532.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.83538293838501s
epoch 10: {'train_loss': '1.38629'}; time used = 6.71062159538269s
epoch 15: {'train_loss': '1.38629'}; time used = 6.820484161376953s
epoch 20: {'train_loss': '1.38629'}; time used = 7.137970685958862s
epoch 25: {'train_loss': '1.38629'}; time used = 7.092307806015015s
epoch 30: {'train_loss': '1.38629'}; time used = 7.190946817398071s
epoch 35: {'train_loss': '1.38629'}; time used = 6.968882322311401s
epoch 40: {'train_loss': '1.38629'}; time used = 7.066543102264404s
epoch 45: {'train_loss': '1.38629'}; time used = 7.080068826675415s
epoch 50: {'train_loss': '1.38629'}; time used = 7.3669798374176025s
epoch 55: {'train_loss': '1.38629'}; time used = 10.981133460998535s
epoch 60: {'train_loss': '1.38629'}; time used = 7.1606550216674805s
epoch 65: {'train_loss': '1.38629'}; time used = 7.067835807800293s
epoch 70: {'train_loss': '1.38629'}; time used = 7.011377334594727s
epoch 75: {'train_loss': '1.38629'}; time used = 6.569143295288086s
epoch 80: {'train_loss': '1.38629'}; time used = 6.98738694190979s
epoch 85: {'train_loss': '1.38629'}; time used = 7.108416795730591s
epoch 90: {'train_loss': '1.38629'}; time used = 7.070119857788086s
epoch 95: {'train_loss': '1.38629'}; time used = 6.3376336097717285s
epoch 100: {'train_loss': '1.38629'}; time used = 6.257343769073486s
epoch 105: {'train_loss': '1.38629'}; time used = 6.894958734512329s
epoch 110: {'train_loss': '1.38629'}; time used = 6.4689621925354s
epoch 115: {'train_loss': '1.38629'}; time used = 7.052906274795532s
epoch 120: {'train_loss': '1.38629'}; time used = 6.260242938995361s
epoch 125: {'train_loss': '1.38629'}; time used = 6.560573577880859s
epoch 130: {'train_loss': '1.38629'}; time used = 6.361492395401001s
epoch 135: {'train_loss': '1.38629'}; time used = 6.439935684204102s
epoch 140: {'train_loss': '1.38629'}; time used = 6.238899230957031s
epoch 145: {'train_loss': '1.38629'}; time used = 6.387461423873901s
epoch 150: {'train_loss': '1.38629'}; time used = 6.250795364379883s
epoch 155: {'train_loss': '1.38629'}; time used = 6.274364709854126s
epoch 160: {'train_loss': '1.38629'}; time used = 6.387792110443115s
epoch 165: {'train_loss': '1.38629'}; time used = 6.163011312484741s
epoch 170: {'train_loss': '1.38629'}; time used = 6.2105324268341064s
epoch 175: {'train_loss': '1.38629'}; time used = 7.411373615264893s
epoch 180: {'train_loss': '1.38629'}; time used = 6.310269832611084s
epoch 185: {'train_loss': '1.38629'}; time used = 6.384325265884399s
epoch 190: {'train_loss': '1.38629'}; time used = 6.331607103347778s
epoch 195: {'train_loss': '1.38629'}; time used = 9.508427858352661s
epoch 200: {'train_loss': '1.38629'}; time used = 6.446541786193848s
epoch 205: {'train_loss': '1.38629'}; time used = 6.3791913986206055s
epoch 210: {'train_loss': '1.38629'}; time used = 6.253777265548706s
epoch 215: {'train_loss': '1.38629'}; time used = 6.410052061080933s
epoch 220: {'train_loss': '1.38629'}; time used = 6.324192047119141s
epoch 225: {'train_loss': '1.38629'}; time used = 6.385697603225708s
epoch 230: {'train_loss': '1.38629'}; time used = 6.182553768157959s
epoch 235: {'train_loss': '1.38629'}; time used = 6.38286566734314s
epoch 240: {'train_loss': '1.38629'}; time used = 6.138612985610962s
epoch 245: {'train_loss': '1.38629'}; time used = 6.194118499755859s
epoch 250: {'train_loss': '1.38629'}; time used = 6.30582594871521s
epoch 255: {'train_loss': '1.38629'}; time used = 6.780088901519775s
epoch 260: {'train_loss': '1.38629'}; time used = 6.297302007675171s
epoch 265: {'train_loss': '1.38629'}; time used = 6.2066779136657715s
epoch 270: {'train_loss': '1.38629'}; time used = 6.200772047042847s
epoch 275: {'train_loss': '1.38629'}; time used = 6.4728803634643555s
epoch 280: {'train_loss': '1.38629'}; time used = 6.757786273956299s
epoch 285: {'train_loss': '1.38629'}; time used = 6.347191572189331s
epoch 290: {'train_loss': '1.38629'}; time used = 6.285802841186523s
epoch 295: {'train_loss': '1.38629'}; time used = 6.41858696937561s
epoch 300: {'train_loss': '1.38629'}; time used = 6.235062837600708s
epoch 305: {'train_loss': '1.38629'}; time used = 7.442674398422241s
epoch 310: {'train_loss': '1.38629'}; time used = 7.417480230331421s
epoch 315: {'train_loss': '1.38629'}; time used = 6.2305145263671875s
epoch 320: {'train_loss': '1.38629'}; time used = 6.442707777023315s
epoch 325: {'train_loss': '1.38629'}; time used = 6.234211206436157s
epoch 330: {'train_loss': '1.38629'}; time used = 6.242293119430542s
epoch 335: {'train_loss': '1.38629'}; time used = 7.326295614242554s
epoch 340: {'train_loss': '1.38629'}; time used = 6.482032537460327s
epoch 345: {'train_loss': '1.38629'}; time used = 6.457381010055542s
epoch 350: {'train_loss': '1.38629'}; time used = 6.24007511138916s
epoch 355: {'train_loss': '1.38629'}; time used = 6.125226020812988s
epoch 360: {'train_loss': '1.38629'}; time used = 6.22352147102356s
epoch 365: {'train_loss': '1.38629'}; time used = 6.207145690917969s
epoch 370: {'train_loss': '1.38629'}; time used = 6.243421792984009s
epoch 375: {'train_loss': '1.38629'}; time used = 6.188277006149292s
epoch 380: {'train_loss': '1.38629'}; time used = 6.310216426849365s
epoch 385: {'train_loss': '1.38629'}; time used = 6.16046667098999s
epoch 390: {'train_loss': '1.38629'}; time used = 6.254563808441162s
epoch 395: {'train_loss': '1.38629'}; time used = 6.415110349655151s
epoch 400: {'train_loss': '1.38629'}; time used = 6.273683547973633s
epoch 405: {'train_loss': '1.38629'}; time used = 9.978879690170288s
epoch 410: {'train_loss': '1.38629'}; time used = 6.470734357833862s
epoch 415: {'train_loss': '1.38629'}; time used = 6.240674018859863s
epoch 420: {'train_loss': '1.38629'}; time used = 6.518355131149292s
epoch 425: {'train_loss': '1.38629'}; time used = 6.295490026473999s
epoch 430: {'train_loss': '1.38629'}; time used = 6.300530433654785s
epoch 435: {'train_loss': '1.38629'}; time used = 6.537880897521973s
epoch 440: {'train_loss': '1.38629'}; time used = 6.519430160522461s
epoch 445: {'train_loss': '1.38629'}; time used = 6.178685665130615s
epoch 450: {'train_loss': '1.38629'}; time used = 6.23185396194458s
epoch 455: {'train_loss': '1.38629'}; time used = 6.147731781005859s
epoch 460: {'train_loss': '1.38629'}; time used = 6.4350526332855225s
epoch 465: {'train_loss': '1.38629'}; time used = 6.2576916217803955s
epoch 470: {'train_loss': '1.38629'}; time used = 6.359745979309082s
epoch 475: {'train_loss': '1.38629'}; time used = 6.303693532943726s
epoch 480: {'train_loss': '1.38629'}; time used = 9.915295362472534s
epoch 485: {'train_loss': '1.38629'}; time used = 6.768637180328369s
epoch 490: {'train_loss': '1.38629'}; time used = 6.746247053146362s
epoch 495: {'train_loss': '1.38629'}; time used = 7.193706035614014s
epoch 500: {'train_loss': '1.38629'}; time used = 6.2672553062438965s
Finished training. Time used = 676.5569934844971.
Training classifier using 80.00% nodes...
{'micro': 0.4533333333333333, 'macro': 0.36773416489300265, 'samples': 0.4533333333333333, 'weighted': 0.35670213994621264, 'accuracy': 0.4533333333333333}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05572'}; time used = 7.375956773757935s
epoch 10: {'train_loss': '2.78048'}; time used = 7.597273826599121s
epoch 15: {'train_loss': '2.80789'}; time used = 6.990432024002075s
epoch 20: {'train_loss': '2.79575'}; time used = 6.31916356086731s
epoch 25: {'train_loss': '2.77356'}; time used = 6.214648008346558s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.33002233505249.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.45922930832247993, 'samples': 0.46, 'weighted': 0.45716671478709126, 'accuracy': 0.46}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.15962'}; time used = 1.7549710273742676s
epoch 10: {'train_loss': '2.88797'}; time used = 1.733597755432129s
epoch 15: {'train_loss': '2.79712'}; time used = 1.881310224533081s
epoch 20: {'train_loss': '2.77436'}; time used = 1.8272545337677002s
epoch 25: {'train_loss': '2.78510'}; time used = 1.7043612003326416s
epoch 30: {'train_loss': '2.77329'}; time used = 1.600283145904541s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.631929397583008.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5063131313131313, 'samples': 0.5072463768115942, 'weighted': 0.5078685404772362, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92348'}; time used = 1.7168545722961426s
epoch 10: {'train_loss': '2.80450'}; time used = 1.9505615234375s
epoch 15: {'train_loss': '2.79079'}; time used = 1.7325217723846436s
epoch 20: {'train_loss': '2.78506'}; time used = 2.0371975898742676s
epoch 25: {'train_loss': '2.77614'}; time used = 1.7821934223175049s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.787554264068604.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36773'}; time used = 4.716604232788086s
epoch 10: {'train_loss': '1.39112'}; time used = 4.520352840423584s
epoch 15: {'train_loss': '1.37926'}; time used = 4.607579469680786s
epoch 20: {'train_loss': '1.33100'}; time used = 4.677446126937866s
epoch 25: {'train_loss': '1.19198'}; time used = 4.633081912994385s
epoch 30: {'train_loss': '1.12837'}; time used = 4.4827001094818115s
epoch 35: {'train_loss': '0.87719'}; time used = 4.63178277015686s
epoch 40: {'train_loss': '1.17020'}; time used = 4.508774042129517s
epoch 45: {'train_loss': '0.60790'}; time used = 5.314746618270874s
epoch 50: {'train_loss': '0.69062'}; time used = 5.667162656784058s
epoch 55: {'train_loss': '0.61240'}; time used = 4.778664588928223s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 77.96089744567871.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6949923748093703, 'samples': 0.695, 'weighted': 0.6949618740468512, 'accuracy': 0.695}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85735'}; time used = 1.8919100761413574s
epoch 10: {'train_loss': '2.78024'}; time used = 1.7006621360778809s
epoch 15: {'train_loss': '2.73976'}; time used = 1.7110998630523682s
epoch 20: {'train_loss': '2.70787'}; time used = 1.7577424049377441s
epoch 25: {'train_loss': '2.66140'}; time used = 1.8175690174102783s
epoch 30: {'train_loss': '2.62259'}; time used = 1.6983962059020996s
epoch 35: {'train_loss': '2.59077'}; time used = 2.4902865886688232s
epoch 40: {'train_loss': '2.53273'}; time used = 1.6973633766174316s
epoch 45: {'train_loss': '2.49057'}; time used = 1.6739976406097412s
epoch 50: {'train_loss': '2.42517'}; time used = 1.6744041442871094s
epoch 55: {'train_loss': '2.40917'}; time used = 1.7639124393463135s
epoch 60: {'train_loss': '2.38035'}; time used = 1.7157447338104248s
epoch 65: {'train_loss': '2.35643'}; time used = 1.7160754203796387s
epoch 70: {'train_loss': '2.37342'}; time used = 1.7143306732177734s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.20866370201111.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.68 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.64 GiB already allocated; 1.25 GiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72283'}; time used = 1.4054062366485596s
epoch 10: {'train_loss': '2.49086'}; time used = 1.0805375576019287s
epoch 15: {'train_loss': '2.37971'}; time used = 1.0474796295166016s
epoch 20: {'train_loss': '2.30904'}; time used = 1.041590929031372s
epoch 25: {'train_loss': '2.21251'}; time used = 1.0272817611694336s
epoch 30: {'train_loss': '2.02655'}; time used = 1.0225112438201904s
epoch 35: {'train_loss': '1.85864'}; time used = 1.0230755805969238s
epoch 40: {'train_loss': '1.71022'}; time used = 1.0289173126220703s
epoch 45: {'train_loss': '1.65102'}; time used = 1.0149719715118408s
epoch 50: {'train_loss': '1.64865'}; time used = 1.0244224071502686s
epoch 55: {'train_loss': '1.55438'}; time used = 1.0250146389007568s
epoch 60: {'train_loss': '1.81576'}; time used = 1.0843136310577393s
epoch 65: {'train_loss': '1.66898'}; time used = 1.1875860691070557s
epoch 70: {'train_loss': '1.62389'}; time used = 1.3267028331756592s
epoch 75: {'train_loss': '1.43614'}; time used = 1.2787628173828125s
epoch 80: {'train_loss': '1.54824'}; time used = 1.243513584136963s
epoch 85: {'train_loss': '1.53936'}; time used = 1.3475091457366943s
epoch 90: {'train_loss': '1.49469'}; time used = 1.0876026153564453s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.52293062210083.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.89908'}; time used = 1.2178401947021484s
epoch 10: {'train_loss': '2.79037'}; time used = 1.0845844745635986s
epoch 15: {'train_loss': '2.77259'}; time used = 1.086451768875122s
epoch 20: {'train_loss': '2.77928'}; time used = 1.1083571910858154s
epoch 25: {'train_loss': '2.77721'}; time used = 1.1022961139678955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.308103084564209.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83995'}; time used = 1.5258760452270508s
epoch 10: {'train_loss': '2.75679'}; time used = 1.397597312927246s
epoch 15: {'train_loss': '2.69149'}; time used = 1.3430428504943848s
epoch 20: {'train_loss': '2.60305'}; time used = 1.3493657112121582s
epoch 25: {'train_loss': '2.55109'}; time used = 1.3688514232635498s
epoch 30: {'train_loss': '2.49825'}; time used = 1.4537341594696045s
epoch 35: {'train_loss': '2.37654'}; time used = 1.3906726837158203s
epoch 40: {'train_loss': '2.34938'}; time used = 1.2980575561523438s
epoch 45: {'train_loss': '2.34665'}; time used = 1.2981247901916504s
epoch 50: {'train_loss': '2.38573'}; time used = 1.3946216106414795s
epoch 55: {'train_loss': '2.32191'}; time used = 1.5808660984039307s
epoch 60: {'train_loss': '2.23095'}; time used = 1.6157124042510986s
epoch 65: {'train_loss': '2.17068'}; time used = 1.4049010276794434s
epoch 70: {'train_loss': '2.12950'}; time used = 1.3840985298156738s
epoch 75: {'train_loss': '2.05942'}; time used = 1.4296658039093018s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.050137519836426.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5529411764705883, 'samples': 0.6052631578947368, 'weighted': 0.5770897832817338, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.04837'}; time used = 2.0160791873931885s
epoch 10: {'train_loss': '2.80355'}; time used = 1.0897417068481445s
epoch 15: {'train_loss': '2.69720'}; time used = 1.0060396194458008s
epoch 20: {'train_loss': '2.55187'}; time used = 1.0161962509155273s
epoch 25: {'train_loss': '2.33078'}; time used = 1.0216448307037354s
epoch 30: {'train_loss': '2.10267'}; time used = 0.9723861217498779s
epoch 35: {'train_loss': '2.01162'}; time used = 1.5874366760253906s
epoch 40: {'train_loss': '2.04148'}; time used = 1.3887834548950195s
epoch 45: {'train_loss': '1.94914'}; time used = 1.0353858470916748s
epoch 50: {'train_loss': '1.93851'}; time used = 1.0236730575561523s
epoch 55: {'train_loss': '1.90353'}; time used = 1.014218807220459s
epoch 60: {'train_loss': '1.81903'}; time used = 1.0550224781036377s
epoch 65: {'train_loss': '1.83349'}; time used = 1.0087780952453613s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.973142385482788.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39783'}; time used = 1.3976292610168457s
epoch 10: {'train_loss': '1.40760'}; time used = 1.4588737487792969s
epoch 15: {'train_loss': '1.38540'}; time used = 1.4466392993927002s
epoch 20: {'train_loss': '1.39193'}; time used = 1.3358099460601807s
epoch 25: {'train_loss': '1.38641'}; time used = 1.5952966213226318s
epoch 30: {'train_loss': '1.38516'}; time used = 1.475217342376709s
epoch 35: {'train_loss': '1.39226'}; time used = 1.3669729232788086s
epoch 40: {'train_loss': '1.37251'}; time used = 1.4140217304229736s
epoch 45: {'train_loss': '1.34748'}; time used = 1.38124418258667s
epoch 50: {'train_loss': '1.40637'}; time used = 1.2380585670471191s
epoch 55: {'train_loss': '1.37694'}; time used = 1.3610754013061523s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.562158584594727.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.18819'}; time used = 2.0647499561309814s
epoch 10: {'train_loss': '0.53207'}; time used = 1.847712755203247s
epoch 15: {'train_loss': '0.44285'}; time used = 2.2238388061523438s
epoch 20: {'train_loss': '0.36828'}; time used = 2.397226095199585s
epoch 25: {'train_loss': '0.30778'}; time used = 1.9383978843688965s
epoch 30: {'train_loss': '0.26827'}; time used = 2.8382275104522705s
epoch 35: {'train_loss': '0.26937'}; time used = 2.0058116912841797s
epoch 40: {'train_loss': '0.28663'}; time used = 1.9750258922576904s
epoch 45: {'train_loss': '0.28766'}; time used = 2.022855758666992s
epoch 50: {'train_loss': '0.28693'}; time used = 1.9758987426757812s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.394098043441772.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36008'}; time used = 1.3172361850738525s
epoch 10: {'train_loss': '1.39274'}; time used = 1.1201894283294678s
epoch 15: {'train_loss': '1.38434'}; time used = 1.7211494445800781s
epoch 20: {'train_loss': '1.38662'}; time used = 2.0920486450195312s
epoch 25: {'train_loss': '1.38239'}; time used = 1.1379237174987793s
epoch 30: {'train_loss': '1.37403'}; time used = 1.2556405067443848s
epoch 35: {'train_loss': '1.37820'}; time used = 1.351858377456665s
epoch 40: {'train_loss': '1.32280'}; time used = 3.0429787635803223s
epoch 45: {'train_loss': '1.20744'}; time used = 2.9500389099121094s
epoch 50: {'train_loss': '1.26263'}; time used = 1.3067238330841064s
epoch 55: {'train_loss': '1.21836'}; time used = 1.1491003036499023s
epoch 60: {'train_loss': '1.33641'}; time used = 1.1700081825256348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.06439471244812.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7301136363636364, 'samples': 0.7368421052631579, 'weighted': 0.7368421052631579, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77101'}; time used = 1.219167947769165s
epoch 10: {'train_loss': '2.69579'}; time used = 0.9728562831878662s
epoch 15: {'train_loss': '2.54917'}; time used = 0.9880673885345459s
epoch 20: {'train_loss': '2.37545'}; time used = 0.9475312232971191s
epoch 25: {'train_loss': '2.17012'}; time used = 1.0020270347595215s
epoch 30: {'train_loss': '2.10935'}; time used = 1.1875953674316406s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.92568588256836.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86158'}; time used = 3.2802016735076904s
epoch 10: {'train_loss': '2.77819'}; time used = 2.0943727493286133s
epoch 15: {'train_loss': '2.77561'}; time used = 2.019704580307007s
epoch 20: {'train_loss': '2.78196'}; time used = 2.1446006298065186s
epoch 25: {'train_loss': '2.77369'}; time used = 2.5764498710632324s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.63367247581482.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37547'}; time used = 1.7560265064239502s
epoch 10: {'train_loss': '1.30036'}; time used = 1.743227481842041s
epoch 15: {'train_loss': '1.26664'}; time used = 1.7036278247833252s
epoch 20: {'train_loss': '1.34806'}; time used = 1.7465839385986328s
epoch 25: {'train_loss': '1.21496'}; time used = 1.9825308322906494s
epoch 30: {'train_loss': '1.07154'}; time used = 2.0726025104522705s
epoch 35: {'train_loss': '1.24740'}; time used = 2.30928111076355s
epoch 40: {'train_loss': '1.15138'}; time used = 2.0215301513671875s
epoch 45: {'train_loss': '1.24312'}; time used = 1.921846628189087s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.14794898033142.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5988372093023256, 'samples': 0.6231884057971014, 'weighted': 0.6059993259184361, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79690'}; time used = 2.631070375442505s
epoch 10: {'train_loss': '2.83151'}; time used = 2.6086173057556152s
epoch 15: {'train_loss': '2.77503'}; time used = 2.6238415241241455s
epoch 20: {'train_loss': '2.76498'}; time used = 2.7004096508026123s
epoch 25: {'train_loss': '2.76308'}; time used = 2.5519745349884033s
epoch 30: {'train_loss': '2.74998'}; time used = 2.477998733520508s
epoch 35: {'train_loss': '2.72765'}; time used = 2.537632942199707s
epoch 40: {'train_loss': '2.72222'}; time used = 2.5032427310943604s
epoch 45: {'train_loss': '2.69295'}; time used = 2.466219902038574s
epoch 50: {'train_loss': '2.66702'}; time used = 2.4694504737854004s
epoch 55: {'train_loss': '2.61676'}; time used = 2.6625568866729736s
epoch 60: {'train_loss': '2.63145'}; time used = 2.7118585109710693s
epoch 65: {'train_loss': '2.52958'}; time used = 2.8726909160614014s
epoch 70: {'train_loss': '2.50541'}; time used = 2.8006184101104736s
epoch 75: {'train_loss': '2.46283'}; time used = 2.509767770767212s
epoch 80: {'train_loss': '2.45522'}; time used = 3.638834238052368s
epoch 85: {'train_loss': '2.41101'}; time used = 3.5144412517547607s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.943944692611694.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37090'}; time used = 1.1178278923034668s
epoch 10: {'train_loss': '1.29348'}; time used = 1.011786699295044s
epoch 15: {'train_loss': '1.21037'}; time used = 1.3064520359039307s
epoch 20: {'train_loss': '1.20340'}; time used = 1.1138770580291748s
epoch 25: {'train_loss': '1.06763'}; time used = 0.9499866962432861s
epoch 30: {'train_loss': '1.00070'}; time used = 1.4087646007537842s
epoch 35: {'train_loss': '0.91901'}; time used = 1.1034471988677979s
epoch 40: {'train_loss': '0.87317'}; time used = 1.1863455772399902s
epoch 45: {'train_loss': '0.67570'}; time used = 1.1241793632507324s
epoch 50: {'train_loss': '0.81708'}; time used = 1.210784673690796s
epoch 55: {'train_loss': '0.72732'}; time used = 1.1528253555297852s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.234872579574585.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77633'}; time used = 2.1843249797821045s
epoch 10: {'train_loss': '2.76536'}; time used = 2.371325969696045s
epoch 15: {'train_loss': '2.76741'}; time used = 2.0439648628234863s
epoch 20: {'train_loss': '2.74813'}; time used = 2.1205930709838867s
epoch 25: {'train_loss': '2.73764'}; time used = 2.230367660522461s
epoch 30: {'train_loss': '2.73598'}; time used = 1.9655728340148926s
epoch 35: {'train_loss': '2.74113'}; time used = 1.9754538536071777s
epoch 40: {'train_loss': '2.73229'}; time used = 2.0329296588897705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.906237840652466.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05075'}; time used = 1.385920524597168s
epoch 10: {'train_loss': '0.83889'}; time used = 1.3637895584106445s
epoch 15: {'train_loss': '0.73815'}; time used = 1.4122166633605957s
epoch 20: {'train_loss': '0.52236'}; time used = 1.2727234363555908s
epoch 25: {'train_loss': '0.46012'}; time used = 1.2963435649871826s
epoch 30: {'train_loss': '0.34677'}; time used = 1.1422417163848877s
epoch 35: {'train_loss': '0.31750'}; time used = 0.9680736064910889s
epoch 40: {'train_loss': '0.26674'}; time used = 0.9759871959686279s
epoch 45: {'train_loss': '0.21076'}; time used = 1.1009395122528076s
epoch 50: {'train_loss': '0.22840'}; time used = 1.034492015838623s
epoch 55: {'train_loss': '0.14717'}; time used = 0.974024772644043s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.18750762939453.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85855'}; time used = 1.3648593425750732s
epoch 10: {'train_loss': '2.77647'}; time used = 1.0674545764923096s
epoch 15: {'train_loss': '2.80594'}; time used = 1.4100022315979004s
epoch 20: {'train_loss': '2.77712'}; time used = 1.2256605625152588s
epoch 25: {'train_loss': '2.77814'}; time used = 1.2114002704620361s
epoch 30: {'train_loss': '2.77434'}; time used = 1.037637710571289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.204434633255005.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.13303'}; time used = 1.8740785121917725s
epoch 10: {'train_loss': '1.06821'}; time used = 1.9037408828735352s
epoch 15: {'train_loss': '1.01867'}; time used = 1.784867763519287s
epoch 20: {'train_loss': '0.97529'}; time used = 1.9378283023834229s
epoch 25: {'train_loss': '0.95227'}; time used = 1.8624894618988037s
epoch 30: {'train_loss': '0.86013'}; time used = 1.9039437770843506s
epoch 35: {'train_loss': '0.83059'}; time used = 1.7554402351379395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.92074155807495.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.486815415821501, 'samples': 0.5217391304347826, 'weighted': 0.4965164476585237, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.86596'}; time used = 2.584988832473755s
epoch 10: {'train_loss': '2.79962'}; time used = 1.492372751235962s
epoch 15: {'train_loss': '2.78496'}; time used = 1.110703945159912s
epoch 20: {'train_loss': '2.77648'}; time used = 1.8484914302825928s
epoch 25: {'train_loss': '2.77011'}; time used = 2.432295799255371s
epoch 30: {'train_loss': '2.76814'}; time used = 2.4165565967559814s
epoch 35: {'train_loss': '2.76477'}; time used = 2.464627504348755s
epoch 40: {'train_loss': '2.76111'}; time used = 2.391740083694458s
epoch 45: {'train_loss': '2.75770'}; time used = 2.4950757026672363s
epoch 50: {'train_loss': '2.75419'}; time used = 1.0919530391693115s
epoch 55: {'train_loss': '2.75062'}; time used = 0.9719388484954834s
epoch 60: {'train_loss': '2.75200'}; time used = 1.198268175125122s
epoch 65: {'train_loss': '2.74706'}; time used = 2.1471059322357178s
epoch 70: {'train_loss': '2.73383'}; time used = 2.265930414199829s
epoch 75: {'train_loss': '2.73469'}; time used = 2.390180826187134s
epoch 80: {'train_loss': '2.70941'}; time used = 2.3020997047424316s
epoch 85: {'train_loss': '2.71774'}; time used = 2.28010892868042s
epoch 90: {'train_loss': '2.70296'}; time used = 1.7016146183013916s
epoch 95: {'train_loss': '2.69291'}; time used = 1.0350582599639893s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.259071588516235.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30715'}; time used = 2.2106435298919678s
epoch 10: {'train_loss': '1.22915'}; time used = 2.124610424041748s
epoch 15: {'train_loss': '1.19738'}; time used = 2.3125102519989014s
epoch 20: {'train_loss': '1.32404'}; time used = 2.27819561958313s
epoch 25: {'train_loss': '1.28353'}; time used = 2.409637689590454s
epoch 30: {'train_loss': '1.23218'}; time used = 2.3802285194396973s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.82766604423523.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6778438030560272, 'samples': 0.6811594202898551, 'weighted': 0.68021210108019, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.98286'}; time used = 2.4799466133117676s
epoch 10: {'train_loss': '2.82973'}; time used = 2.468101739883423s
epoch 15: {'train_loss': '2.83497'}; time used = 2.5943732261657715s
epoch 20: {'train_loss': '2.81259'}; time used = 2.6347789764404297s
epoch 25: {'train_loss': '2.79629'}; time used = 2.689422369003296s
epoch 30: {'train_loss': '2.78700'}; time used = 2.483215808868408s
epoch 35: {'train_loss': '2.78126'}; time used = 2.422928810119629s
epoch 40: {'train_loss': '2.77729'}; time used = 2.4426827430725098s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.102221965789795.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90277'}; time used = 2.6073808670043945s
epoch 10: {'train_loss': '2.79521'}; time used = 3.6498334407806396s
epoch 15: {'train_loss': '2.77093'}; time used = 3.4482364654541016s
epoch 20: {'train_loss': '2.75614'}; time used = 3.707287311553955s
epoch 25: {'train_loss': '2.75043'}; time used = 2.117528200149536s
epoch 30: {'train_loss': '2.74652'}; time used = 1.903263807296753s
epoch 35: {'train_loss': '2.74089'}; time used = 2.1146461963653564s
epoch 40: {'train_loss': '2.73098'}; time used = 1.9276599884033203s
epoch 45: {'train_loss': '2.72202'}; time used = 2.0456132888793945s
epoch 50: {'train_loss': '2.71510'}; time used = 1.916968822479248s
epoch 55: {'train_loss': '2.71506'}; time used = 2.6562626361846924s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.243977546691895.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5473015873015873, 'samples': 0.5507246376811594, 'weighted': 0.550154129284564, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.06703'}; time used = 2.1736204624176025s
epoch 10: {'train_loss': '2.95598'}; time used = 2.119664192199707s
epoch 15: {'train_loss': '2.86457'}; time used = 1.8669853210449219s
epoch 20: {'train_loss': '2.82729'}; time used = 1.8186218738555908s
epoch 25: {'train_loss': '2.80190'}; time used = 2.1755218505859375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.396166801452637.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.46215740507920544, 'samples': 0.5507246376811594, 'weighted': 0.4779729823295543, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76089'}; time used = 1.555560827255249s
epoch 10: {'train_loss': '2.75429'}; time used = 1.3622651100158691s
epoch 15: {'train_loss': '2.73332'}; time used = 1.3347127437591553s
epoch 20: {'train_loss': '2.66584'}; time used = 1.3824522495269775s
epoch 25: {'train_loss': '2.51826'}; time used = 1.4011497497558594s
epoch 30: {'train_loss': '2.31545'}; time used = 1.7920622825622559s
epoch 35: {'train_loss': '2.19687'}; time used = 2.2949602603912354s
epoch 40: {'train_loss': '2.09701'}; time used = 1.4856348037719727s
epoch 45: {'train_loss': '2.16540'}; time used = 1.410430908203125s
epoch 50: {'train_loss': '2.18655'}; time used = 1.3661518096923828s
epoch 55: {'train_loss': '2.10641'}; time used = 1.413351058959961s
epoch 60: {'train_loss': '2.03695'}; time used = 1.453359603881836s
epoch 65: {'train_loss': '1.96784'}; time used = 1.3232228755950928s
epoch 70: {'train_loss': '1.93964'}; time used = 1.3683586120605469s
epoch 75: {'train_loss': '1.82049'}; time used = 1.415177822113037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.076252937316895.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.29775'}; time used = 2.080871343612671s
epoch 10: {'train_loss': '1.22153'}; time used = 2.306248664855957s
epoch 15: {'train_loss': '1.16093'}; time used = 2.312833309173584s
epoch 20: {'train_loss': '1.04539'}; time used = 2.190204620361328s
epoch 25: {'train_loss': '0.91993'}; time used = 3.2638888359069824s
epoch 30: {'train_loss': '0.80606'}; time used = 3.2189860343933105s
epoch 35: {'train_loss': '0.69842'}; time used = 3.2188329696655273s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.822466373443604.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.26537'}; time used = 2.3134608268737793s
epoch 10: {'train_loss': '1.16720'}; time used = 2.212202310562134s
epoch 15: {'train_loss': '1.01277'}; time used = 1.7847464084625244s
epoch 20: {'train_loss': '0.97289'}; time used = 2.2073636054992676s
epoch 25: {'train_loss': '0.91148'}; time used = 2.100907802581787s
epoch 30: {'train_loss': '0.84685'}; time used = 1.8748447895050049s
epoch 35: {'train_loss': '0.83079'}; time used = 1.7352275848388672s
epoch 40: {'train_loss': '0.75845'}; time used = 2.0284030437469482s
epoch 45: {'train_loss': '0.56758'}; time used = 2.1730997562408447s
epoch 50: {'train_loss': '0.43026'}; time used = 3.0953471660614014s
epoch 55: {'train_loss': '0.21724'}; time used = 3.1840124130249023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.012158155441284.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.20592'}; time used = 1.1997220516204834s
epoch 10: {'train_loss': '0.54686'}; time used = 1.059394121170044s
epoch 15: {'train_loss': '0.19122'}; time used = 1.0888428688049316s
epoch 20: {'train_loss': '0.07863'}; time used = 1.1940884590148926s
epoch 25: {'train_loss': '0.03969'}; time used = 1.161776065826416s
epoch 30: {'train_loss': '0.03526'}; time used = 1.1207401752471924s
epoch 35: {'train_loss': '0.02553'}; time used = 1.1105968952178955s
epoch 40: {'train_loss': '0.01936'}; time used = 1.1736218929290771s
epoch 45: {'train_loss': '0.01135'}; time used = 1.0370664596557617s
epoch 50: {'train_loss': '0.00437'}; time used = 1.0434515476226807s
epoch 55: {'train_loss': '0.00237'}; time used = 1.2902700901031494s
epoch 60: {'train_loss': '0.00236'}; time used = 1.0808274745941162s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.291832208633423.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.43159'}; time used = 1.4153659343719482s
epoch 10: {'train_loss': '0.23979'}; time used = 1.3904128074645996s
epoch 15: {'train_loss': '0.15571'}; time used = 1.449906349182129s
epoch 20: {'train_loss': '0.01661'}; time used = 1.2928388118743896s
epoch 25: {'train_loss': '0.03961'}; time used = 1.2208049297332764s
epoch 30: {'train_loss': '0.33113'}; time used = 1.1594302654266357s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.878521919250488.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37637'}; time used = 4.1004767417907715s
epoch 10: {'train_loss': '1.31464'}; time used = 2.578786611557007s
epoch 15: {'train_loss': '1.28636'}; time used = 1.9241199493408203s
epoch 20: {'train_loss': '1.26554'}; time used = 1.7718825340270996s
epoch 25: {'train_loss': '1.12979'}; time used = 1.9818775653839111s
epoch 30: {'train_loss': '1.05109'}; time used = 1.8422760963439941s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.499441146850586.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.17175'}; time used = 1.3265349864959717s
epoch 10: {'train_loss': '1.05340'}; time used = 1.239854335784912s
epoch 15: {'train_loss': '0.94216'}; time used = 1.4435737133026123s
epoch 20: {'train_loss': '0.77612'}; time used = 1.2547953128814697s
epoch 25: {'train_loss': '0.58626'}; time used = 1.184605360031128s
epoch 30: {'train_loss': '0.38781'}; time used = 1.1866278648376465s
epoch 35: {'train_loss': '0.32676'}; time used = 1.1899158954620361s
epoch 40: {'train_loss': '0.23214'}; time used = 1.26170015335083s
epoch 45: {'train_loss': '0.18889'}; time used = 1.2510230541229248s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.802783012390137.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10808'}; time used = 1.9482734203338623s
epoch 10: {'train_loss': '1.11438'}; time used = 1.8602383136749268s
epoch 15: {'train_loss': '0.67282'}; time used = 1.9198853969573975s
epoch 20: {'train_loss': '0.01325'}; time used = 1.9374258518218994s
epoch 25: {'train_loss': '0.00023'}; time used = 2.005885601043701s
epoch 30: {'train_loss': '0.00000'}; time used = 1.9143033027648926s
epoch 35: {'train_loss': '0.00000'}; time used = 2.0013203620910645s
epoch 40: {'train_loss': '0.00000'}; time used = 2.015259265899658s
epoch 45: {'train_loss': '0.00344'}; time used = 1.925647258758545s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.64345121383667.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5920608108108107, 'samples': 0.5942028985507246, 'weighted': 0.5942028985507246, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.13981'}; time used = 1.874394178390503s
epoch 10: {'train_loss': '0.06406'}; time used = 1.8221817016601562s
epoch 15: {'train_loss': '0.09634'}; time used = 1.7385303974151611s
epoch 20: {'train_loss': '0.00476'}; time used = 1.8525288105010986s
epoch 25: {'train_loss': '0.02896'}; time used = 2.101511001586914s
epoch 30: {'train_loss': '0.00760'}; time used = 1.928072452545166s
epoch 35: {'train_loss': '0.05533'}; time used = 1.8796262741088867s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.54082703590393.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83814'}; time used = 2.3916842937469482s
epoch 10: {'train_loss': '2.77371'}; time used = 1.5629851818084717s
epoch 15: {'train_loss': '2.78430'}; time used = 1.5261824131011963s
epoch 20: {'train_loss': '2.78418'}; time used = 1.5024704933166504s
epoch 25: {'train_loss': '2.77287'}; time used = 1.5884299278259277s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.06983232498169.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84823'}; time used = 6.877563953399658s
epoch 10: {'train_loss': '2.77736'}; time used = 7.138515472412109s
epoch 15: {'train_loss': '2.78156'}; time used = 7.104758262634277s
epoch 20: {'train_loss': '2.77758'}; time used = 7.186420917510986s
epoch 25: {'train_loss': '2.77369'}; time used = 7.596120834350586s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.0515570640564.
Training classifier using 80.00% nodes...
{'micro': 0.5, 'macro': 0.43165824164932104, 'samples': 0.5, 'weighted': 0.42178541747676446, 'accuracy': 0.5}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38225'}; time used = 2.192422866821289s
epoch 10: {'train_loss': '1.35245'}; time used = 2.236769199371338s
epoch 15: {'train_loss': '1.37976'}; time used = 2.1478078365325928s
epoch 20: {'train_loss': '1.43833'}; time used = 2.2899370193481445s
epoch 25: {'train_loss': '1.40452'}; time used = 2.4286015033721924s
epoch 30: {'train_loss': '1.34453'}; time used = 2.331592321395874s
epoch 35: {'train_loss': '1.31188'}; time used = 2.390547037124634s
epoch 40: {'train_loss': '1.26139'}; time used = 2.0847392082214355s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.608683824539185.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.74446'}; time used = 1.1552386283874512s
epoch 10: {'train_loss': '2.67673'}; time used = 1.1280426979064941s
epoch 15: {'train_loss': '2.49117'}; time used = 1.1294338703155518s
epoch 20: {'train_loss': '2.33324'}; time used = 1.0141990184783936s
epoch 25: {'train_loss': '2.09321'}; time used = 1.007411003112793s
epoch 30: {'train_loss': '2.22740'}; time used = 1.0047879219055176s
epoch 35: {'train_loss': '2.19447'}; time used = 1.0276381969451904s
epoch 40: {'train_loss': '2.16904'}; time used = 1.0219862461090088s
epoch 45: {'train_loss': '2.00443'}; time used = 0.9935312271118164s
epoch 50: {'train_loss': '1.97564'}; time used = 1.0362415313720703s
epoch 55: {'train_loss': '1.93233'}; time used = 1.1188209056854248s
epoch 60: {'train_loss': '1.84586'}; time used = 1.053562879562378s
epoch 65: {'train_loss': '1.95473'}; time used = 0.9605402946472168s
epoch 70: {'train_loss': '1.83040'}; time used = 1.056419849395752s
epoch 75: {'train_loss': '1.82769'}; time used = 1.0894007682800293s
epoch 80: {'train_loss': '1.85007'}; time used = 1.0922794342041016s
epoch 85: {'train_loss': '1.83983'}; time used = 1.0809004306793213s
epoch 90: {'train_loss': '1.78926'}; time used = 1.09665846824646s
epoch 95: {'train_loss': '1.83012'}; time used = 0.9625258445739746s
epoch 100: {'train_loss': '1.81305'}; time used = 0.9569990634918213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.91282343864441.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.98022'}; time used = 1.228713035583496s
epoch 10: {'train_loss': '2.74124'}; time used = 1.0367074012756348s
epoch 15: {'train_loss': '2.65612'}; time used = 1.1478025913238525s
epoch 20: {'train_loss': '2.61414'}; time used = 1.115903377532959s
epoch 25: {'train_loss': '2.55627'}; time used = 1.1194157600402832s
epoch 30: {'train_loss': '2.43234'}; time used = 1.0973310470581055s
epoch 35: {'train_loss': '2.34765'}; time used = 1.0006651878356934s
epoch 40: {'train_loss': '2.30555'}; time used = 0.9851765632629395s
epoch 45: {'train_loss': '2.24173'}; time used = 1.0125737190246582s
epoch 50: {'train_loss': '2.18326'}; time used = 1.0985658168792725s
epoch 55: {'train_loss': '2.13975'}; time used = 1.0801365375518799s
epoch 60: {'train_loss': '2.09065'}; time used = 1.0493626594543457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.359657526016235.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72283'}; time used = 1.1613287925720215s
epoch 10: {'train_loss': '2.49086'}; time used = 0.9580898284912109s
epoch 15: {'train_loss': '2.37971'}; time used = 0.9308667182922363s
epoch 20: {'train_loss': '2.30904'}; time used = 0.9412617683410645s
epoch 25: {'train_loss': '2.21251'}; time used = 0.9787194728851318s
epoch 30: {'train_loss': '2.02655'}; time used = 1.047579288482666s
epoch 35: {'train_loss': '1.85864'}; time used = 1.1590547561645508s
epoch 40: {'train_loss': '1.71022'}; time used = 1.1060173511505127s
epoch 45: {'train_loss': '1.65102'}; time used = 0.9832198619842529s
epoch 50: {'train_loss': '1.64865'}; time used = 0.9608554840087891s
epoch 55: {'train_loss': '1.55438'}; time used = 1.0155029296875s
epoch 60: {'train_loss': '1.81576'}; time used = 1.0511143207550049s
epoch 65: {'train_loss': '1.66898'}; time used = 0.9505789279937744s
epoch 70: {'train_loss': '1.62389'}; time used = 1.1492745876312256s
epoch 75: {'train_loss': '1.43614'}; time used = 1.2055833339691162s
epoch 80: {'train_loss': '1.54824'}; time used = 1.2198717594146729s
epoch 85: {'train_loss': '1.53936'}; time used = 1.1118907928466797s
epoch 90: {'train_loss': '1.49469'}; time used = 1.0529513359069824s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.18224024772644.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35365'}; time used = 1.8734147548675537s
epoch 10: {'train_loss': '1.23887'}; time used = 2.180558681488037s
epoch 15: {'train_loss': '1.18815'}; time used = 1.8961598873138428s
epoch 20: {'train_loss': '1.30286'}; time used = 1.9932680130004883s
epoch 25: {'train_loss': '1.22251'}; time used = 2.1461946964263916s
epoch 30: {'train_loss': '1.11797'}; time used = 2.1564927101135254s
epoch 35: {'train_loss': '1.23958'}; time used = 1.805483102798462s
epoch 40: {'train_loss': '1.15184'}; time used = 2.0119457244873047s
epoch 45: {'train_loss': '1.23323'}; time used = 1.7819290161132812s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.429973125457764.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5361344537815126, 'samples': 0.5362318840579711, 'weighted': 0.5366216051638046, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.31793'}; time used = 8.359897136688232s
epoch 10: {'train_loss': '1.29275'}; time used = 9.21221923828125s
epoch 15: {'train_loss': '1.18101'}; time used = 8.605541944503784s
epoch 20: {'train_loss': '0.95610'}; time used = 11.25596570968628s
epoch 25: {'train_loss': '0.78763'}; time used = 7.712517261505127s
epoch 30: {'train_loss': '0.70174'}; time used = 7.582128047943115s
epoch 35: {'train_loss': '0.45836'}; time used = 7.623344898223877s
epoch 40: {'train_loss': '0.50374'}; time used = 7.248941421508789s
epoch 45: {'train_loss': '0.47167'}; time used = 8.098474025726318s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 96.69197392463684.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.4772828503916032, 'samples': 0.5166666666666667, 'weighted': 0.4701285439843326, 'accuracy': 0.5166666666666667}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99186'}; time used = 1.3757045269012451s
epoch 10: {'train_loss': '0.59542'}; time used = 1.226916790008545s
epoch 15: {'train_loss': '0.36097'}; time used = 1.090374231338501s
epoch 20: {'train_loss': '0.19137'}; time used = 1.197906494140625s
epoch 25: {'train_loss': '0.12181'}; time used = 0.9579582214355469s
epoch 30: {'train_loss': '0.06730'}; time used = 0.9265170097351074s
epoch 35: {'train_loss': '0.05954'}; time used = 1.1572444438934326s
epoch 40: {'train_loss': '0.03863'}; time used = 1.1857237815856934s
epoch 45: {'train_loss': '0.04773'}; time used = 1.1078815460205078s
epoch 50: {'train_loss': '0.03547'}; time used = 1.1144764423370361s
epoch 55: {'train_loss': '0.01915'}; time used = 1.0429325103759766s
epoch 60: {'train_loss': '0.01529'}; time used = 0.9879136085510254s
epoch 65: {'train_loss': '0.02144'}; time used = 0.9576029777526855s
epoch 70: {'train_loss': '0.01594'}; time used = 1.1735179424285889s
epoch 75: {'train_loss': '0.01024'}; time used = 1.0396387577056885s
epoch 80: {'train_loss': '0.01558'}; time used = 1.00382661819458s
epoch 85: {'train_loss': '0.01721'}; time used = 1.063493251800537s
epoch 90: {'train_loss': '0.02047'}; time used = 1.198317289352417s
epoch 95: {'train_loss': '0.02506'}; time used = 1.0630934238433838s
epoch 100: {'train_loss': '0.02972'}; time used = 1.1237397193908691s
epoch 105: {'train_loss': '0.03857'}; time used = 1.226503849029541s
epoch 110: {'train_loss': '0.04154'}; time used = 1.0825700759887695s
epoch 115: {'train_loss': '0.03890'}; time used = 0.9947164058685303s
epoch 120: {'train_loss': '0.03917'}; time used = 0.9032070636749268s
epoch 125: {'train_loss': '0.02300'}; time used = 0.9156105518341064s
epoch 130: {'train_loss': '0.02378'}; time used = 1.0988860130310059s
epoch 135: {'train_loss': '0.02922'}; time used = 1.0685861110687256s
epoch 140: {'train_loss': '0.03347'}; time used = 1.074631690979004s
epoch 145: {'train_loss': '0.01571'}; time used = 0.9799010753631592s
epoch 150: {'train_loss': '0.01757'}; time used = 1.2086639404296875s
epoch 155: {'train_loss': '0.02291'}; time used = 1.2060377597808838s
epoch 160: {'train_loss': '0.01530'}; time used = 1.0936195850372314s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.6364951133728.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33878'}; time used = 1.15576171875s
epoch 10: {'train_loss': '1.60689'}; time used = 1.1959517002105713s
epoch 15: {'train_loss': '1.39092'}; time used = 1.0859177112579346s
epoch 20: {'train_loss': '1.58400'}; time used = 1.099947452545166s
epoch 25: {'train_loss': '1.18642'}; time used = 1.214200496673584s
epoch 30: {'train_loss': '1.43162'}; time used = 1.1099364757537842s
epoch 35: {'train_loss': '1.43147'}; time used = 1.1659131050109863s
epoch 40: {'train_loss': '1.19853'}; time used = 1.1150710582733154s
epoch 45: {'train_loss': '1.11629'}; time used = 1.0296776294708252s
epoch 50: {'train_loss': '1.06424'}; time used = 1.1540119647979736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.824482202529907.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 542.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37511'}; time used = 2.0055534839630127s
epoch 10: {'train_loss': '1.41316'}; time used = 3.248321533203125s
epoch 15: {'train_loss': '1.37138'}; time used = 1.84183931350708s
epoch 20: {'train_loss': '1.38808'}; time used = 1.0811328887939453s
epoch 25: {'train_loss': '1.35555'}; time used = 1.0976684093475342s
epoch 30: {'train_loss': '1.34333'}; time used = 1.1240925788879395s
epoch 35: {'train_loss': '1.33826'}; time used = 1.1116001605987549s
epoch 40: {'train_loss': '1.34416'}; time used = 1.2904982566833496s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.889082431793213.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.6027874564459931, 'samples': 0.6052631578947368, 'weighted': 0.6077388593434807, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16527'}; time used = 3.3399975299835205s
epoch 10: {'train_loss': '1.07387'}; time used = 3.0054214000701904s
epoch 15: {'train_loss': '0.98585'}; time used = 2.6753315925598145s
epoch 20: {'train_loss': '0.82553'}; time used = 2.267503499984741s
epoch 25: {'train_loss': '0.51941'}; time used = 2.0957696437835693s
epoch 30: {'train_loss': '0.38032'}; time used = 1.9626879692077637s
epoch 35: {'train_loss': '0.20452'}; time used = 1.8562562465667725s
epoch 40: {'train_loss': '0.13387'}; time used = 1.7707607746124268s
epoch 45: {'train_loss': '0.06172'}; time used = 1.619422435760498s
epoch 50: {'train_loss': '0.04303'}; time used = 1.589463710784912s
epoch 55: {'train_loss': '0.10180'}; time used = 1.7370824813842773s
epoch 60: {'train_loss': '0.03570'}; time used = 1.6561720371246338s
epoch 65: {'train_loss': '0.02645'}; time used = 1.6442444324493408s
epoch 70: {'train_loss': '0.02050'}; time used = 1.6783299446105957s
epoch 75: {'train_loss': '0.02327'}; time used = 1.7853589057922363s
epoch 80: {'train_loss': '0.01495'}; time used = 2.0207903385162354s
epoch 85: {'train_loss': '0.01882'}; time used = 1.9819626808166504s
epoch 90: {'train_loss': '0.01518'}; time used = 1.8790860176086426s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.34806418418884.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.94446'}; time used = 2.6327126026153564s
epoch 10: {'train_loss': '2.80539'}; time used = 1.2881369590759277s
epoch 15: {'train_loss': '2.77625'}; time used = 1.2481729984283447s
epoch 20: {'train_loss': '2.77622'}; time used = 1.4205188751220703s
epoch 25: {'train_loss': '2.77887'}; time used = 1.2030575275421143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.57891058921814.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.19620'}; time used = 1.178797960281372s
epoch 10: {'train_loss': '0.96944'}; time used = 1.0636603832244873s
epoch 15: {'train_loss': '0.64883'}; time used = 1.105865478515625s
epoch 20: {'train_loss': '0.43326'}; time used = 1.1062157154083252s
epoch 25: {'train_loss': '0.34680'}; time used = 1.1221208572387695s
epoch 30: {'train_loss': '0.23684'}; time used = 1.0582566261291504s
epoch 35: {'train_loss': '0.20630'}; time used = 1.0271201133728027s
epoch 40: {'train_loss': '0.29192'}; time used = 1.0040900707244873s
epoch 45: {'train_loss': '0.23534'}; time used = 1.072704792022705s
epoch 50: {'train_loss': '0.22364'}; time used = 1.4921154975891113s
epoch 55: {'train_loss': '0.13651'}; time used = 1.2993252277374268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.357874631881714.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77868'}; time used = 1.2365152835845947s
epoch 10: {'train_loss': '2.77378'}; time used = 1.1048378944396973s
epoch 15: {'train_loss': '2.78424'}; time used = 1.173360824584961s
epoch 20: {'train_loss': '2.78060'}; time used = 1.112898349761963s
epoch 25: {'train_loss': '2.77204'}; time used = 1.1435308456420898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.461002111434937.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83810'}; time used = 1.2750718593597412s
epoch 10: {'train_loss': '2.78783'}; time used = 1.1943461894989014s
epoch 15: {'train_loss': '2.77264'}; time used = 1.238767147064209s
epoch 20: {'train_loss': '2.77648'}; time used = 1.169891357421875s
epoch 25: {'train_loss': '2.77518'}; time used = 1.0840399265289307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.34113883972168.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.83734'}; time used = 2.046835422515869s
epoch 10: {'train_loss': '0.42191'}; time used = 1.710857629776001s
epoch 15: {'train_loss': '0.30129'}; time used = 1.2250661849975586s
epoch 20: {'train_loss': '0.25256'}; time used = 1.0340890884399414s
epoch 25: {'train_loss': '0.27721'}; time used = 1.0440235137939453s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.50234580039978.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 110.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76007'}; time used = 2.1026408672332764s
epoch 10: {'train_loss': '2.74084'}; time used = 2.0534956455230713s
epoch 15: {'train_loss': '2.71797'}; time used = 2.0695865154266357s
epoch 20: {'train_loss': '2.69350'}; time used = 2.225346326828003s
epoch 25: {'train_loss': '2.65128'}; time used = 2.1477017402648926s
epoch 30: {'train_loss': '2.60969'}; time used = 2.1695239543914795s
epoch 35: {'train_loss': '2.58552'}; time used = 2.16144061088562s
epoch 40: {'train_loss': '2.55296'}; time used = 2.224893569946289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.84195613861084.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 498.44 MiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.80923'}; time used = 1.275169849395752s
epoch 10: {'train_loss': '2.77750'}; time used = 1.2420597076416016s
epoch 15: {'train_loss': '2.77381'}; time used = 1.2201313972473145s
epoch 20: {'train_loss': '2.77881'}; time used = 1.3106915950775146s
epoch 25: {'train_loss': '2.77685'}; time used = 1.2417175769805908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.382420063018799.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 498.44 MiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39066'}; time used = 1.9579265117645264s
epoch 10: {'train_loss': '1.30751'}; time used = 1.9117400646209717s
epoch 15: {'train_loss': '1.18148'}; time used = 2.477081060409546s
epoch 20: {'train_loss': '1.21256'}; time used = 2.1452908515930176s
epoch 25: {'train_loss': '1.09643'}; time used = 1.9224717617034912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.509145975112915.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36926'}; time used = 2.4745583534240723s
epoch 10: {'train_loss': '1.34528'}; time used = 2.4976770877838135s
epoch 15: {'train_loss': '1.37787'}; time used = 2.4691739082336426s
epoch 20: {'train_loss': '1.44802'}; time used = 2.565525531768799s
epoch 25: {'train_loss': '1.42927'}; time used = 2.8352341651916504s
epoch 30: {'train_loss': '1.39554'}; time used = 4.416313648223877s
epoch 35: {'train_loss': '1.37334'}; time used = 4.3166375160217285s
epoch 40: {'train_loss': '1.35644'}; time used = 4.46523118019104s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.71580934524536.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91092'}; time used = 2.9282500743865967s
epoch 10: {'train_loss': '2.78920'}; time used = 3.7940945625305176s
epoch 15: {'train_loss': '2.79855'}; time used = 3.9612815380096436s
epoch 20: {'train_loss': '2.78797'}; time used = 3.1203713417053223s
epoch 25: {'train_loss': '2.76779'}; time used = 1.9958415031433105s
epoch 30: {'train_loss': '2.75781'}; time used = 2.06850266456604s
epoch 35: {'train_loss': '2.75293'}; time used = 2.0493903160095215s
epoch 40: {'train_loss': '2.73960'}; time used = 4.125955104827881s
epoch 45: {'train_loss': '2.73014'}; time used = 2.9810657501220703s
epoch 50: {'train_loss': '2.71982'}; time used = 2.049088954925537s
epoch 55: {'train_loss': '2.71713'}; time used = 2.3077704906463623s
epoch 60: {'train_loss': '2.70718'}; time used = 1.9721615314483643s
epoch 65: {'train_loss': '2.70377'}; time used = 2.025345802307129s
epoch 70: {'train_loss': '2.71035'}; time used = 2.1062324047088623s
epoch 75: {'train_loss': '2.69026'}; time used = 2.195044755935669s
epoch 80: {'train_loss': '2.70051'}; time used = 2.194056987762451s
epoch 85: {'train_loss': '2.70666'}; time used = 2.121906280517578s
epoch 90: {'train_loss': '2.69025'}; time used = 2.123094320297241s
epoch 95: {'train_loss': '2.68679'}; time used = 2.0478298664093018s
epoch 100: {'train_loss': '2.69574'}; time used = 2.1985647678375244s
epoch 105: {'train_loss': '2.68922'}; time used = 2.0662713050842285s
epoch 110: {'train_loss': '2.68627'}; time used = 2.256290912628174s
epoch 115: {'train_loss': '2.66943'}; time used = 2.0756759643554688s
epoch 120: {'train_loss': '2.67662'}; time used = 2.0710017681121826s
epoch 125: {'train_loss': '2.67122'}; time used = 2.1694867610931396s
epoch 130: {'train_loss': '2.66772'}; time used = 2.133155584335327s
epoch 135: {'train_loss': '2.67503'}; time used = 2.005451202392578s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 74.09518122673035.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.04187'}; time used = 1.3091299533843994s
epoch 10: {'train_loss': '2.79966'}; time used = 1.1314191818237305s
epoch 15: {'train_loss': '2.78163'}; time used = 1.1191294193267822s
epoch 20: {'train_loss': '2.79801'}; time used = 1.0804591178894043s
epoch 25: {'train_loss': '2.77417'}; time used = 1.2122077941894531s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.108755826950073.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33531'}; time used = 2.3118128776550293s
epoch 10: {'train_loss': '1.54096'}; time used = 2.432331085205078s
epoch 15: {'train_loss': '1.23222'}; time used = 2.530587911605835s
epoch 20: {'train_loss': '0.70040'}; time used = 1.7413923740386963s
epoch 25: {'train_loss': '0.11377'}; time used = 1.308476209640503s
epoch 30: {'train_loss': '0.13817'}; time used = 1.2170665264129639s
epoch 35: {'train_loss': '0.05087'}; time used = 1.18308687210083s
epoch 40: {'train_loss': '0.13809'}; time used = 1.200721025466919s
epoch 45: {'train_loss': '0.77325'}; time used = 1.0845820903778076s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.531419038772583.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68044'}; time used = 2.262171745300293s
epoch 10: {'train_loss': '2.44386'}; time used = 2.1059482097625732s
epoch 15: {'train_loss': '2.17279'}; time used = 1.2696754932403564s
epoch 20: {'train_loss': '1.82904'}; time used = 1.2851605415344238s
epoch 25: {'train_loss': '1.77277'}; time used = 1.2708196640014648s
epoch 30: {'train_loss': '1.70548'}; time used = 1.0420629978179932s
epoch 35: {'train_loss': '1.83349'}; time used = 1.1148512363433838s
epoch 40: {'train_loss': '1.78623'}; time used = 1.1235902309417725s
epoch 45: {'train_loss': '1.65484'}; time used = 1.0909132957458496s
epoch 50: {'train_loss': '1.57445'}; time used = 1.169780969619751s
epoch 55: {'train_loss': '1.56636'}; time used = 1.0726747512817383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.730576038360596.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 452.44 MiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.55 GiB already allocated; 498.44 MiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38567'}; time used = 2.1719563007354736s
epoch 10: {'train_loss': '1.30387'}; time used = 1.9211211204528809s
epoch 15: {'train_loss': '1.15835'}; time used = 1.7496130466461182s
epoch 20: {'train_loss': '1.08424'}; time used = 1.9066357612609863s
epoch 25: {'train_loss': '0.86584'}; time used = 2.2982397079467773s
epoch 30: {'train_loss': '0.88549'}; time used = 2.3961713314056396s
epoch 35: {'train_loss': '0.80821'}; time used = 2.1317265033721924s
epoch 40: {'train_loss': '0.62811'}; time used = 1.98097562789917s
epoch 45: {'train_loss': '0.40704'}; time used = 1.917576551437378s
epoch 50: {'train_loss': '0.46753'}; time used = 2.4002315998077393s
epoch 55: {'train_loss': '0.26749'}; time used = 2.2542924880981445s
epoch 60: {'train_loss': '0.66976'}; time used = 2.2019705772399902s
epoch 65: {'train_loss': '0.72217'}; time used = 1.888230323791504s
epoch 70: {'train_loss': '0.71891'}; time used = 2.094494581222534s
epoch 75: {'train_loss': '0.72827'}; time used = 1.9414613246917725s
epoch 80: {'train_loss': '0.62855'}; time used = 3.4187097549438477s
epoch 85: {'train_loss': '0.12979'}; time used = 4.1832990646362305s
epoch 90: {'train_loss': '0.03772'}; time used = 3.991297721862793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.86355686187744.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.42208'}; time used = 2.234361410140991s
epoch 10: {'train_loss': '2.91760'}; time used = 2.094414472579956s
epoch 15: {'train_loss': '2.88454'}; time used = 2.2023611068725586s
epoch 20: {'train_loss': '2.84181'}; time used = 2.419513463973999s
epoch 25: {'train_loss': '2.79332'}; time used = 2.349663734436035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.24862289428711.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5871794871794872, 'samples': 0.5942028985507246, 'weighted': 0.5910813823857303, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40003'}; time used = 1.418375015258789s
epoch 10: {'train_loss': '1.39432'}; time used = 1.2020127773284912s
epoch 15: {'train_loss': '1.38000'}; time used = 1.268517255783081s
epoch 20: {'train_loss': '1.38306'}; time used = 1.1951675415039062s
epoch 25: {'train_loss': '1.35159'}; time used = 1.4168763160705566s
epoch 30: {'train_loss': '1.37045'}; time used = 1.2775654792785645s
epoch 35: {'train_loss': '1.36827'}; time used = 1.4123239517211914s
epoch 40: {'train_loss': '1.30055'}; time used = 1.4031615257263184s
epoch 45: {'train_loss': '1.10331'}; time used = 1.622816801071167s
epoch 50: {'train_loss': '1.09097'}; time used = 1.4897377490997314s
epoch 55: {'train_loss': '1.16112'}; time used = 1.282989501953125s
epoch 60: {'train_loss': '0.99404'}; time used = 1.253990650177002s
epoch 65: {'train_loss': '0.93709'}; time used = 1.2555413246154785s
epoch 70: {'train_loss': '0.95802'}; time used = 1.2170989513397217s
epoch 75: {'train_loss': '0.85989'}; time used = 1.3020308017730713s
epoch 80: {'train_loss': '0.76493'}; time used = 1.3820769786834717s
epoch 85: {'train_loss': '0.73636'}; time used = 1.352400541305542s
epoch 90: {'train_loss': '0.80518'}; time used = 1.5815300941467285s
epoch 95: {'train_loss': '0.90581'}; time used = 1.2766177654266357s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.11053967475891.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.672156862745098, 'samples': 0.7105263157894737, 'weighted': 0.6898658410732714, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76026'}; time used = 1.9419469833374023s
epoch 10: {'train_loss': '2.73737'}; time used = 1.7688746452331543s
epoch 15: {'train_loss': '2.71300'}; time used = 1.8529136180877686s
epoch 20: {'train_loss': '2.68323'}; time used = 2.6444413661956787s
epoch 25: {'train_loss': '2.64526'}; time used = 1.8719689846038818s
epoch 30: {'train_loss': '2.62313'}; time used = 1.8329379558563232s
epoch 35: {'train_loss': '2.60392'}; time used = 1.7394065856933594s
epoch 40: {'train_loss': '2.57843'}; time used = 1.801954746246338s
epoch 45: {'train_loss': '2.54590'}; time used = 2.091524839401245s
epoch 50: {'train_loss': '2.50439'}; time used = 1.8615753650665283s
epoch 55: {'train_loss': '2.47686'}; time used = 1.9952564239501953s
epoch 60: {'train_loss': '2.45246'}; time used = 2.4554426670074463s
epoch 65: {'train_loss': '2.42796'}; time used = 3.3938705921173096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.17395544052124.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77240'}; time used = 2.076712131500244s
epoch 10: {'train_loss': '2.77057'}; time used = 2.8114616870880127s
epoch 15: {'train_loss': '2.77089'}; time used = 2.3777108192443848s
epoch 20: {'train_loss': '2.76823'}; time used = 2.1991829872131348s
epoch 25: {'train_loss': '2.76317'}; time used = 2.6806390285491943s
epoch 30: {'train_loss': '2.75861'}; time used = 2.16860032081604s
epoch 35: {'train_loss': '2.75562'}; time used = 2.047452688217163s
epoch 40: {'train_loss': '2.75505'}; time used = 2.533540964126587s
epoch 45: {'train_loss': '2.75138'}; time used = 4.095906972885132s
epoch 50: {'train_loss': '2.75082'}; time used = 2.597665309906006s
epoch 55: {'train_loss': '2.75291'}; time used = 2.144594192504883s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.88969302177429.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 466.44 MiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.00911'}; time used = 2.1334826946258545s
epoch 10: {'train_loss': '0.76039'}; time used = 2.0102908611297607s
epoch 15: {'train_loss': '0.00380'}; time used = 1.7362420558929443s
epoch 20: {'train_loss': '0.19395'}; time used = 1.6082382202148438s
epoch 25: {'train_loss': '0.06993'}; time used = 1.695070505142212s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.693131923675537.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85279'}; time used = 1.7842841148376465s
epoch 10: {'train_loss': '2.78885'}; time used = 1.8437585830688477s
epoch 15: {'train_loss': '2.75420'}; time used = 1.8195793628692627s
epoch 20: {'train_loss': '2.71192'}; time used = 2.177949905395508s
epoch 25: {'train_loss': '2.66510'}; time used = 2.0669264793395996s
epoch 30: {'train_loss': '2.62191'}; time used = 2.1658129692077637s
epoch 35: {'train_loss': '2.59785'}; time used = 2.0240983963012695s
epoch 40: {'train_loss': '2.54053'}; time used = 2.1221375465393066s
epoch 45: {'train_loss': '2.50836'}; time used = 1.7219264507293701s
epoch 50: {'train_loss': '2.45465'}; time used = 1.7193536758422852s
epoch 55: {'train_loss': '2.43399'}; time used = 1.7990484237670898s
epoch 60: {'train_loss': '2.42883'}; time used = 2.8347342014312744s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.284473180770874.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5644143090951601, 'samples': 0.6086956521739131, 'weighted': 0.5744782507039676, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83038'}; time used = 2.0613245964050293s
epoch 10: {'train_loss': '2.37220'}; time used = 1.8059444427490234s
epoch 15: {'train_loss': '1.88824'}; time used = 1.2969446182250977s
epoch 20: {'train_loss': '1.46903'}; time used = 1.073091745376587s
epoch 25: {'train_loss': '1.42786'}; time used = 1.2036328315734863s
epoch 30: {'train_loss': '1.24535'}; time used = 1.2861731052398682s
epoch 35: {'train_loss': '1.11143'}; time used = 1.047278642654419s
epoch 40: {'train_loss': '1.70767'}; time used = 0.9833424091339111s
epoch 45: {'train_loss': '1.31006'}; time used = 1.127901554107666s
epoch 50: {'train_loss': '1.07032'}; time used = 1.861685037612915s
epoch 55: {'train_loss': '1.12290'}; time used = 1.0532691478729248s
epoch 60: {'train_loss': '1.02579'}; time used = 1.2485904693603516s
epoch 65: {'train_loss': '1.02033'}; time used = 1.1446828842163086s
epoch 70: {'train_loss': '0.95783'}; time used = 1.0699877738952637s
epoch 75: {'train_loss': '0.86507'}; time used = 1.5234625339508057s
epoch 80: {'train_loss': '0.95591'}; time used = 1.8954854011535645s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.555281400680542.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.22742'}; time used = 1.5442461967468262s
epoch 10: {'train_loss': '2.81674'}; time used = 1.3818514347076416s
epoch 15: {'train_loss': '2.72405'}; time used = 1.449472188949585s
epoch 20: {'train_loss': '2.72919'}; time used = 1.3278765678405762s
epoch 25: {'train_loss': '2.66783'}; time used = 1.3827176094055176s
epoch 30: {'train_loss': '2.56848'}; time used = 1.307844877243042s
epoch 35: {'train_loss': '2.45545'}; time used = 1.4870262145996094s
epoch 40: {'train_loss': '2.34170'}; time used = 1.2964553833007812s
epoch 45: {'train_loss': '2.23209'}; time used = 1.4585363864898682s
epoch 50: {'train_loss': '2.19594'}; time used = 1.4614019393920898s
epoch 55: {'train_loss': '2.17207'}; time used = 1.531212329864502s
epoch 60: {'train_loss': '2.13683'}; time used = 1.5754125118255615s
epoch 65: {'train_loss': '2.15524'}; time used = 1.518768072128296s
epoch 70: {'train_loss': '2.11140'}; time used = 1.595829725265503s
epoch 75: {'train_loss': '2.02465'}; time used = 1.3545174598693848s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.61500859260559.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.5128205128205128, 'samples': 0.5789473684210527, 'weighted': 0.5411605937921727, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.19615'}; time used = 1.2798452377319336s
epoch 10: {'train_loss': '2.76744'}; time used = 1.2558720111846924s
epoch 15: {'train_loss': '2.76323'}; time used = 1.2541477680206299s
epoch 20: {'train_loss': '2.75841'}; time used = 1.1074120998382568s
epoch 25: {'train_loss': '2.73891'}; time used = 1.1409721374511719s
epoch 30: {'train_loss': '2.62287'}; time used = 1.022057056427002s
epoch 35: {'train_loss': '1.80920'}; time used = 1.2043704986572266s
epoch 40: {'train_loss': '2.24691'}; time used = 1.32403564453125s
epoch 45: {'train_loss': '1.63511'}; time used = 1.1715233325958252s
epoch 50: {'train_loss': '1.51049'}; time used = 1.2540783882141113s
epoch 55: {'train_loss': '1.28943'}; time used = 1.2690696716308594s
epoch 60: {'train_loss': '1.20618'}; time used = 1.4471702575683594s
epoch 65: {'train_loss': '1.17787'}; time used = 1.3464617729187012s
epoch 70: {'train_loss': '1.10702'}; time used = 1.256556749343872s
epoch 75: {'train_loss': '1.01387'}; time used = 1.078434944152832s
epoch 80: {'train_loss': '1.11480'}; time used = 1.4825127124786377s
epoch 85: {'train_loss': '1.11500'}; time used = 1.1222007274627686s
epoch 90: {'train_loss': '1.00396'}; time used = 1.1512846946716309s
epoch 95: {'train_loss': '0.99832'}; time used = 1.033639669418335s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.03538990020752.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83391'}; time used = 8.50907301902771s
epoch 10: {'train_loss': '2.80330'}; time used = 7.916085958480835s
epoch 15: {'train_loss': '2.78925'}; time used = 7.1722252368927s
epoch 20: {'train_loss': '2.78004'}; time used = 6.591799020767212s
epoch 25: {'train_loss': '2.77483'}; time used = 6.845111131668091s
epoch 30: {'train_loss': '2.77284'}; time used = 6.804664134979248s
epoch 35: {'train_loss': '2.77260'}; time used = 8.122752904891968s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 64.26786303520203.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4416654605104453, 'samples': 0.5033333333333333, 'weighted': 0.43241549669513196, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.20611'}; time used = 1.3138062953948975s
epoch 10: {'train_loss': '0.20873'}; time used = 1.0480000972747803s
epoch 15: {'train_loss': '0.10664'}; time used = 1.528430700302124s
epoch 20: {'train_loss': '0.12548'}; time used = 1.5969676971435547s
epoch 25: {'train_loss': '0.14398'}; time used = 1.2208139896392822s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.5993812084198.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 46.44 MiB free; 27.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82259'}; time used = 1.246274471282959s
epoch 10: {'train_loss': '2.66416'}; time used = 1.2956318855285645s
epoch 15: {'train_loss': '2.04933'}; time used = 1.2871427536010742s
epoch 20: {'train_loss': '1.69356'}; time used = 1.27073335647583s
epoch 25: {'train_loss': '1.63660'}; time used = 1.0878078937530518s
epoch 30: {'train_loss': '1.71458'}; time used = 1.0976285934448242s
epoch 35: {'train_loss': '1.37390'}; time used = 1.0845987796783447s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.599852800369263.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87799'}; time used = 2.427726984024048s
epoch 10: {'train_loss': '2.78631'}; time used = 3.1125757694244385s
epoch 15: {'train_loss': '2.77445'}; time used = 2.43928861618042s
epoch 20: {'train_loss': '2.76923'}; time used = 1.9280338287353516s
epoch 25: {'train_loss': '2.76917'}; time used = 2.239586353302002s
epoch 30: {'train_loss': '2.76731'}; time used = 1.9447317123413086s
epoch 35: {'train_loss': '2.76589'}; time used = 2.029690980911255s
epoch 40: {'train_loss': '2.76338'}; time used = 1.9463703632354736s
epoch 45: {'train_loss': '2.76500'}; time used = 1.9034805297851562s
epoch 50: {'train_loss': '2.75931'}; time used = 1.9753735065460205s
epoch 55: {'train_loss': '2.76135'}; time used = 2.1966099739074707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.577372550964355.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5208333333333333, 'samples': 0.5942028985507246, 'weighted': 0.5344202898550725, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37011'}; time used = 1.224508285522461s
epoch 10: {'train_loss': '1.41125'}; time used = 1.3160088062286377s
epoch 15: {'train_loss': '1.27159'}; time used = 1.1219894886016846s
epoch 20: {'train_loss': '1.32843'}; time used = 1.2367641925811768s
epoch 25: {'train_loss': '0.52043'}; time used = 1.1684596538543701s
epoch 30: {'train_loss': '1.38012'}; time used = 1.1797301769256592s
epoch 35: {'train_loss': '1.38336'}; time used = 1.348680019378662s
epoch 40: {'train_loss': '1.34718'}; time used = 1.2106537818908691s
epoch 45: {'train_loss': '1.18019'}; time used = 1.2902319431304932s
epoch 50: {'train_loss': '1.06096'}; time used = 1.3754525184631348s
epoch 55: {'train_loss': '1.20574'}; time used = 1.3909738063812256s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.195932626724243.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6266061980347695, 'samples': 0.6578947368421053, 'weighted': 0.6436726737478617, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38177'}; time used = 2.2277228832244873s
epoch 10: {'train_loss': '1.33433'}; time used = 2.6715927124023438s
epoch 15: {'train_loss': '1.37166'}; time used = 4.01481294631958s
epoch 20: {'train_loss': '1.45535'}; time used = 4.85109806060791s
epoch 25: {'train_loss': '1.42983'}; time used = 4.851878643035889s
epoch 30: {'train_loss': '1.38858'}; time used = 3.675419569015503s
epoch 35: {'train_loss': '1.36941'}; time used = 2.557922601699829s
epoch 40: {'train_loss': '0.64515'}; time used = 2.378072500228882s
epoch 45: {'train_loss': '0.00000'}; time used = 2.3395516872406006s
epoch 50: {'train_loss': '0.00000'}; time used = 2.35408878326416s
epoch 55: {'train_loss': '0.00000'}; time used = 2.2731711864471436s
epoch 60: {'train_loss': '0.00000'}; time used = 2.199918746948242s
epoch 65: {'train_loss': '0.70135'}; time used = 3.372565507888794s
epoch 70: {'train_loss': '0.00000'}; time used = 4.275338649749756s
epoch 75: {'train_loss': '0.00000'}; time used = 4.195065975189209s
epoch 80: {'train_loss': '0.00000'}; time used = 2.6879703998565674s
epoch 85: {'train_loss': '0.00000'}; time used = 2.2804765701293945s
epoch 90: {'train_loss': '0.00000'}; time used = 2.214491367340088s
epoch 95: {'train_loss': '0.00000'}; time used = 3.3213493824005127s
epoch 100: {'train_loss': '0.00000'}; time used = 2.306892156600952s
epoch 105: {'train_loss': '0.00000'}; time used = 2.3192062377929688s
epoch 110: {'train_loss': '0.00000'}; time used = 2.60878586769104s
epoch 115: {'train_loss': '0.00000'}; time used = 4.1294286251068115s
epoch 120: {'train_loss': '0.00000'}; time used = 4.002630710601807s
epoch 125: {'train_loss': '0.00000'}; time used = 3.9333066940307617s
epoch 130: {'train_loss': '0.00000'}; time used = 2.673407793045044s
epoch 135: {'train_loss': '0.00000'}; time used = 2.2773308753967285s
epoch 140: {'train_loss': '0.72022'}; time used = 2.173435926437378s
epoch 145: {'train_loss': '0.00000'}; time used = 2.1854939460754395s
epoch 150: {'train_loss': '0.00000'}; time used = 2.3640623092651367s
epoch 155: {'train_loss': '0.00000'}; time used = 2.5804712772369385s
epoch 160: {'train_loss': '0.00000'}; time used = 2.5054571628570557s
epoch 165: {'train_loss': '0.00000'}; time used = 2.322018623352051s
epoch 170: {'train_loss': '0.00000'}; time used = 2.2966148853302s
epoch 175: {'train_loss': '0.66542'}; time used = 2.260005235671997s
epoch 180: {'train_loss': '0.00000'}; time used = 2.3041961193084717s
epoch 185: {'train_loss': '0.00000'}; time used = 2.4631617069244385s
epoch 190: {'train_loss': '0.00000'}; time used = 2.486266851425171s
epoch 195: {'train_loss': '0.00000'}; time used = 2.179689645767212s
epoch 200: {'train_loss': '0.00000'}; time used = 2.525737762451172s
epoch 205: {'train_loss': '0.00000'}; time used = 2.505605459213257s
epoch 210: {'train_loss': '0.70070'}; time used = 2.3574743270874023s
epoch 215: {'train_loss': '0.00000'}; time used = 2.459754467010498s
epoch 220: {'train_loss': '0.00000'}; time used = 2.28713059425354s
epoch 225: {'train_loss': '0.70330'}; time used = 2.4411637783050537s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 131.0045075416565.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 412.44 MiB free; 44.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 4.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.09375'}; time used = 1.557584524154663s
epoch 10: {'train_loss': '0.43240'}; time used = 1.0564558506011963s
epoch 15: {'train_loss': '0.34771'}; time used = 1.1530020236968994s
epoch 20: {'train_loss': '0.31146'}; time used = 1.3233706951141357s
epoch 25: {'train_loss': '0.35721'}; time used = 1.2824733257293701s
epoch 30: {'train_loss': '0.28641'}; time used = 1.137319564819336s
epoch 35: {'train_loss': '0.31732'}; time used = 1.0571975708007812s
epoch 40: {'train_loss': '0.28453'}; time used = 1.01914381980896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.29677677154541.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 150.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85162'}; time used = 8.798349618911743s
epoch 10: {'train_loss': '2.77659'}; time used = 7.375454902648926s
epoch 15: {'train_loss': '2.77430'}; time used = 11.971299886703491s
epoch 20: {'train_loss': '2.78035'}; time used = 8.54861307144165s
epoch 25: {'train_loss': '2.76678'}; time used = 7.672162294387817s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 85.71438598632812.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.464967516241879, 'samples': 0.5033333333333333, 'weighted': 0.4575402298850575, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34908'}; time used = 1.270942211151123s
epoch 10: {'train_loss': '1.39204'}; time used = 1.1363489627838135s
epoch 15: {'train_loss': '1.38579'}; time used = 1.1722347736358643s
epoch 20: {'train_loss': '1.38921'}; time used = 1.1625244617462158s
epoch 25: {'train_loss': '1.38917'}; time used = 1.168609619140625s
epoch 30: {'train_loss': '1.38570'}; time used = 1.0531527996063232s
epoch 35: {'train_loss': '1.39394'}; time used = 2.1841108798980713s
epoch 40: {'train_loss': '1.37467'}; time used = 2.787548780441284s
epoch 45: {'train_loss': '1.34336'}; time used = 1.2311763763427734s
epoch 50: {'train_loss': '1.40997'}; time used = 1.3193440437316895s
epoch 55: {'train_loss': '1.38000'}; time used = 1.383592128753662s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.692942142486572.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82341'}; time used = 1.9118461608886719s
epoch 10: {'train_loss': '2.77701'}; time used = 2.2714664936065674s
epoch 15: {'train_loss': '2.77431'}; time used = 2.2881112098693848s
epoch 20: {'train_loss': '2.77952'}; time used = 2.518251419067383s
epoch 25: {'train_loss': '2.77634'}; time used = 2.5522892475128174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.607641220092773.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 208.44 MiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 228.44 MiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.64250'}; time used = 1.335261344909668s
epoch 10: {'train_loss': '2.53954'}; time used = 1.1619057655334473s
epoch 15: {'train_loss': '2.41155'}; time used = 1.0467557907104492s
epoch 20: {'train_loss': '2.33511'}; time used = 1.188417911529541s
epoch 25: {'train_loss': '2.26618'}; time used = 1.4256012439727783s
epoch 30: {'train_loss': '2.19837'}; time used = 1.9935503005981445s
epoch 35: {'train_loss': '2.07141'}; time used = 1.9155704975128174s
epoch 40: {'train_loss': '1.91234'}; time used = 1.2187778949737549s
epoch 45: {'train_loss': '2.19064'}; time used = 1.1054422855377197s
epoch 50: {'train_loss': '2.24673'}; time used = 1.1887092590332031s
epoch 55: {'train_loss': '2.09891'}; time used = 1.1674737930297852s
epoch 60: {'train_loss': '2.07191'}; time used = 1.4088773727416992s
epoch 65: {'train_loss': '1.88851'}; time used = 1.0644915103912354s
epoch 70: {'train_loss': '1.81986'}; time used = 1.1305220127105713s
epoch 75: {'train_loss': '1.66300'}; time used = 0.9931347370147705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.857598781585693.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 300.44 MiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77418'}; time used = 1.929455041885376s
epoch 10: {'train_loss': '2.74192'}; time used = 2.1440088748931885s
epoch 15: {'train_loss': '2.65173'}; time used = 1.9953279495239258s
epoch 20: {'train_loss': '2.64058'}; time used = 1.7030506134033203s
epoch 25: {'train_loss': '2.61906'}; time used = 1.994535207748413s
epoch 30: {'train_loss': '2.58713'}; time used = 1.8973639011383057s
epoch 35: {'train_loss': '2.55200'}; time used = 1.839003086090088s
epoch 40: {'train_loss': '2.51125'}; time used = 1.890160322189331s
epoch 45: {'train_loss': '2.46760'}; time used = 1.9660708904266357s
epoch 50: {'train_loss': '2.46883'}; time used = 1.7208237648010254s
epoch 55: {'train_loss': '2.43303'}; time used = 1.8703362941741943s
epoch 60: {'train_loss': '2.43991'}; time used = 1.7868244647979736s
epoch 65: {'train_loss': '2.38014'}; time used = 1.810638427734375s
epoch 70: {'train_loss': '2.33362'}; time used = 1.7679224014282227s
epoch 75: {'train_loss': '2.27836'}; time used = 1.7590539455413818s
epoch 80: {'train_loss': '2.28132'}; time used = 1.8480472564697266s
epoch 85: {'train_loss': '2.25386'}; time used = 1.7378902435302734s
epoch 90: {'train_loss': '2.23843'}; time used = 1.867091178894043s
epoch 95: {'train_loss': '2.39117'}; time used = 1.803886890411377s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.90279746055603.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4668181818181818, 'samples': 0.5072463768115942, 'weighted': 0.4774571805006588, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89588'}; time used = 7.134881258010864s
epoch 10: {'train_loss': '2.85663'}; time used = 7.030069828033447s
epoch 15: {'train_loss': '2.84477'}; time used = 7.120511770248413s
epoch 20: {'train_loss': '2.81468'}; time used = 5.439739942550659s
epoch 25: {'train_loss': '2.79247'}; time used = 2.9427499771118164s
epoch 30: {'train_loss': '2.78964'}; time used = 2.8221466541290283s
epoch 35: {'train_loss': '2.79277'}; time used = 2.9295217990875244s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.311192750930786.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.35371'}; time used = 1.2750415802001953s
epoch 10: {'train_loss': '0.24694'}; time used = 1.0890965461730957s
epoch 15: {'train_loss': '0.24278'}; time used = 1.1224830150604248s
epoch 20: {'train_loss': '0.24256'}; time used = 1.0533735752105713s
epoch 25: {'train_loss': '0.29010'}; time used = 1.325758695602417s
epoch 30: {'train_loss': '0.24238'}; time used = 2.4031543731689453s
epoch 35: {'train_loss': '0.27743'}; time used = 2.1615397930145264s
epoch 40: {'train_loss': '0.21970'}; time used = 1.0845582485198975s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.9732346534729.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 466.44 MiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13827'}; time used = 3.7711808681488037s
epoch 10: {'train_loss': '0.87982'}; time used = 2.8106980323791504s
epoch 15: {'train_loss': '0.34379'}; time used = 1.614377498626709s
epoch 20: {'train_loss': '0.43435'}; time used = 1.8731017112731934s
epoch 25: {'train_loss': '0.43407'}; time used = 1.6991853713989258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.02130961418152.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.95113'}; time used = 4.087782859802246s
epoch 10: {'train_loss': '2.86275'}; time used = 2.6363863945007324s
epoch 15: {'train_loss': '2.78250'}; time used = 2.1436164379119873s
epoch 20: {'train_loss': '2.78609'}; time used = 2.1353824138641357s
epoch 25: {'train_loss': '2.77406'}; time used = 2.3518478870391846s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.30020570755005.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 380.44 MiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36078'}; time used = 1.5094013214111328s
epoch 10: {'train_loss': '1.27797'}; time used = 1.4246070384979248s
epoch 15: {'train_loss': '1.16872'}; time used = 1.4844036102294922s
epoch 20: {'train_loss': '1.37162'}; time used = 1.550147294998169s
epoch 25: {'train_loss': '1.38780'}; time used = 1.5525214672088623s
epoch 30: {'train_loss': '1.37454'}; time used = 1.4783992767333984s
epoch 35: {'train_loss': '1.36606'}; time used = 1.5228478908538818s
epoch 40: {'train_loss': '1.29304'}; time used = 1.484144926071167s
epoch 45: {'train_loss': '1.13781'}; time used = 1.6212811470031738s
epoch 50: {'train_loss': '1.03393'}; time used = 1.3863916397094727s
epoch 55: {'train_loss': '1.03499'}; time used = 1.514927864074707s
epoch 60: {'train_loss': '0.98586'}; time used = 1.4760947227478027s
epoch 65: {'train_loss': '0.67361'}; time used = 1.4978086948394775s
epoch 70: {'train_loss': '0.79861'}; time used = 1.3763046264648438s
epoch 75: {'train_loss': '0.68790'}; time used = 1.387493371963501s
epoch 80: {'train_loss': '0.66695'}; time used = 1.4754669666290283s
epoch 85: {'train_loss': '0.51780'}; time used = 1.3509774208068848s
epoch 90: {'train_loss': '0.71856'}; time used = 1.45025634765625s
epoch 95: {'train_loss': '0.83693'}; time used = 1.494321346282959s
epoch 100: {'train_loss': '0.72668'}; time used = 1.3619143962860107s
epoch 105: {'train_loss': '0.52317'}; time used = 1.4891293048858643s
epoch 110: {'train_loss': '0.63886'}; time used = 1.4997773170471191s
epoch 115: {'train_loss': '0.69756'}; time used = 1.467813491821289s
epoch 120: {'train_loss': '0.77765'}; time used = 1.535168170928955s
epoch 125: {'train_loss': '0.51522'}; time used = 1.5115880966186523s
epoch 130: {'train_loss': '0.52005'}; time used = 1.478013515472412s
epoch 135: {'train_loss': '0.35611'}; time used = 1.3916172981262207s
epoch 140: {'train_loss': '0.58653'}; time used = 1.8692591190338135s
epoch 145: {'train_loss': '0.67999'}; time used = 1.3611352443695068s
epoch 150: {'train_loss': '0.53785'}; time used = 1.7018887996673584s
epoch 155: {'train_loss': '0.44447'}; time used = 1.7075674533843994s
epoch 160: {'train_loss': '0.49799'}; time used = 1.7568492889404297s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.625253438949585.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78311'}; time used = 2.2317628860473633s
epoch 10: {'train_loss': '2.76510'}; time used = 2.216132164001465s
epoch 15: {'train_loss': '2.75637'}; time used = 1.9073631763458252s
epoch 20: {'train_loss': '2.73715'}; time used = 1.8128929138183594s
epoch 25: {'train_loss': '2.69785'}; time used = 1.9449114799499512s
epoch 30: {'train_loss': '2.66609'}; time used = 1.7803370952606201s
epoch 35: {'train_loss': '2.62386'}; time used = 1.6905436515808105s
epoch 40: {'train_loss': '2.54524'}; time used = 1.8749549388885498s
epoch 45: {'train_loss': '2.50179'}; time used = 1.814565896987915s
epoch 50: {'train_loss': '2.42941'}; time used = 3.0230295658111572s
epoch 55: {'train_loss': '2.45753'}; time used = 3.310453414916992s
epoch 60: {'train_loss': '2.42356'}; time used = 3.137234926223755s
epoch 65: {'train_loss': '2.35887'}; time used = 2.346782684326172s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.943110704422.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.21292'}; time used = 1.1845507621765137s
epoch 10: {'train_loss': '0.10264'}; time used = 1.008204698562622s
epoch 15: {'train_loss': '0.08044'}; time used = 1.0557637214660645s
epoch 20: {'train_loss': '0.11614'}; time used = 1.0614545345306396s
epoch 25: {'train_loss': '0.14393'}; time used = 1.0569987297058105s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.121429443359375.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 64.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.33823'}; time used = 1.483309268951416s
epoch 10: {'train_loss': '1.40287'}; time used = 1.3815958499908447s
epoch 15: {'train_loss': '1.38673'}; time used = 1.5101094245910645s
epoch 20: {'train_loss': '1.38810'}; time used = 1.4467246532440186s
epoch 25: {'train_loss': '1.38096'}; time used = 1.3448853492736816s
epoch 30: {'train_loss': '1.36856'}; time used = 1.449974775314331s
epoch 35: {'train_loss': '1.36580'}; time used = 1.4371988773345947s
epoch 40: {'train_loss': '1.33330'}; time used = 1.3712313175201416s
epoch 45: {'train_loss': '1.28328'}; time used = 1.421760082244873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.954665422439575.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 332.44 MiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14275'}; time used = 2.3873794078826904s
epoch 10: {'train_loss': '1.00327'}; time used = 2.377941370010376s
epoch 15: {'train_loss': '0.14830'}; time used = 2.3769383430480957s
epoch 20: {'train_loss': '0.00097'}; time used = 2.497040033340454s
epoch 25: {'train_loss': '0.00095'}; time used = 2.4060168266296387s
epoch 30: {'train_loss': '0.02732'}; time used = 2.3994362354278564s
epoch 35: {'train_loss': '0.10219'}; time used = 2.3378803730010986s
epoch 40: {'train_loss': '0.16416'}; time used = 2.467940330505371s
epoch 45: {'train_loss': '0.00607'}; time used = 2.3531904220581055s
epoch 50: {'train_loss': '0.00612'}; time used = 2.3812265396118164s
epoch 55: {'train_loss': '0.00208'}; time used = 2.6475307941436768s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.934580087661743.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.21956'}; time used = 2.0320372581481934s
epoch 10: {'train_loss': '0.84522'}; time used = 2.055340051651001s
epoch 15: {'train_loss': '0.14057'}; time used = 2.0230352878570557s
epoch 20: {'train_loss': '0.10538'}; time used = 2.0288217067718506s
epoch 25: {'train_loss': '0.00160'}; time used = 2.033447265625s
epoch 30: {'train_loss': '0.00054'}; time used = 2.081301212310791s
epoch 35: {'train_loss': '0.36247'}; time used = 2.0454301834106445s
epoch 40: {'train_loss': '0.19174'}; time used = 2.2433009147644043s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.911463022232056.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.67779'}; time used = 1.3016870021820068s
epoch 10: {'train_loss': '2.59274'}; time used = 1.0729615688323975s
epoch 15: {'train_loss': '2.23043'}; time used = 1.1443912982940674s
epoch 20: {'train_loss': '2.12070'}; time used = 1.1162705421447754s
epoch 25: {'train_loss': '2.07077'}; time used = 1.1373789310455322s
epoch 30: {'train_loss': '2.00685'}; time used = 1.1199476718902588s
epoch 35: {'train_loss': '1.94451'}; time used = 1.2266228199005127s
epoch 40: {'train_loss': '1.91954'}; time used = 1.1888279914855957s
epoch 45: {'train_loss': '1.95941'}; time used = 1.3582849502563477s
epoch 50: {'train_loss': '1.92698'}; time used = 1.1237993240356445s
epoch 55: {'train_loss': '1.92411'}; time used = 1.2628495693206787s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.124104976654053.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 380.44 MiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37489'}; time used = 2.003170967102051s
epoch 10: {'train_loss': '1.03608'}; time used = 2.0876710414886475s
epoch 15: {'train_loss': '0.49307'}; time used = 2.1717145442962646s
epoch 20: {'train_loss': '0.36471'}; time used = 2.0627403259277344s
epoch 25: {'train_loss': '0.12140'}; time used = 2.6623263359069824s
epoch 30: {'train_loss': '0.10259'}; time used = 2.0131208896636963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.625789403915405.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5132275132275133, 'samples': 0.5362318840579711, 'weighted': 0.5208956368376658, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.21007'}; time used = 1.176621675491333s
epoch 10: {'train_loss': '2.77959'}; time used = 1.0193583965301514s
epoch 15: {'train_loss': '2.77894'}; time used = 1.058410406112671s
epoch 20: {'train_loss': '2.75280'}; time used = 1.0693151950836182s
epoch 25: {'train_loss': '2.70729'}; time used = 1.0116889476776123s
epoch 30: {'train_loss': '2.61528'}; time used = 0.9960782527923584s
epoch 35: {'train_loss': '2.37223'}; time used = 1.189335584640503s
epoch 40: {'train_loss': '2.11430'}; time used = 1.272670030593872s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.692383766174316.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.09269'}; time used = 1.2982196807861328s
epoch 10: {'train_loss': '0.80218'}; time used = 1.2773666381835938s
epoch 15: {'train_loss': '0.53760'}; time used = 1.2449283599853516s
epoch 20: {'train_loss': '0.39125'}; time used = 1.3367335796356201s
epoch 25: {'train_loss': '0.35448'}; time used = 1.3345422744750977s
epoch 30: {'train_loss': '0.16255'}; time used = 1.4068796634674072s
epoch 35: {'train_loss': '0.07849'}; time used = 1.2613356113433838s
epoch 40: {'train_loss': '0.06761'}; time used = 1.3194735050201416s
epoch 45: {'train_loss': '0.05063'}; time used = 1.4509027004241943s
epoch 50: {'train_loss': '0.04486'}; time used = 1.270890474319458s
epoch 55: {'train_loss': '0.02220'}; time used = 1.2258226871490479s
epoch 60: {'train_loss': '0.15570'}; time used = 1.559237003326416s
epoch 65: {'train_loss': '0.03724'}; time used = 1.3736426830291748s
epoch 70: {'train_loss': '0.04648'}; time used = 1.2967524528503418s
epoch 75: {'train_loss': '0.02930'}; time used = 1.3305888175964355s
epoch 80: {'train_loss': '0.11887'}; time used = 1.2508962154388428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.155747413635254.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37414'}; time used = 2.094078540802002s
epoch 10: {'train_loss': '1.27046'}; time used = 2.12896728515625s
epoch 15: {'train_loss': '1.04917'}; time used = 2.3568215370178223s
epoch 20: {'train_loss': '0.84263'}; time used = 2.0995118618011475s
epoch 25: {'train_loss': '0.64813'}; time used = 2.2369234561920166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.12812638282776.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76762'}; time used = 2.06602144241333s
epoch 10: {'train_loss': '2.76077'}; time used = 1.7926769256591797s
epoch 15: {'train_loss': '2.74671'}; time used = 1.893472671508789s
epoch 20: {'train_loss': '2.72378'}; time used = 1.846118450164795s
epoch 25: {'train_loss': '2.68488'}; time used = 2.1225171089172363s
epoch 30: {'train_loss': '2.63936'}; time used = 2.1486048698425293s
epoch 35: {'train_loss': '2.59493'}; time used = 1.9750702381134033s
epoch 40: {'train_loss': '2.53742'}; time used = 1.6767022609710693s
epoch 45: {'train_loss': '2.46866'}; time used = 2.0800271034240723s
epoch 50: {'train_loss': '2.39649'}; time used = 1.9239718914031982s
epoch 55: {'train_loss': '2.36520'}; time used = 1.9812867641448975s
epoch 60: {'train_loss': '2.31517'}; time used = 1.8221862316131592s
epoch 65: {'train_loss': '2.38791'}; time used = 1.7726848125457764s
epoch 70: {'train_loss': '2.32048'}; time used = 2.1451427936553955s
epoch 75: {'train_loss': '2.19692'}; time used = 1.959472894668579s
epoch 80: {'train_loss': '2.55152'}; time used = 1.872041940689087s
epoch 85: {'train_loss': '2.27419'}; time used = 1.729889154434204s
epoch 90: {'train_loss': '2.24716'}; time used = 1.8422527313232422s
epoch 95: {'train_loss': '2.12929'}; time used = 1.6985912322998047s
epoch 100: {'train_loss': '2.03966'}; time used = 1.734224796295166s
epoch 105: {'train_loss': '2.02121'}; time used = 2.0091066360473633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.882534980773926.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 150.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92432'}; time used = 2.291090965270996s
epoch 10: {'train_loss': '2.80128'}; time used = 2.019200325012207s
epoch 15: {'train_loss': '2.76344'}; time used = 2.001781463623047s
epoch 20: {'train_loss': '2.74079'}; time used = 2.0269863605499268s
epoch 25: {'train_loss': '2.71790'}; time used = 1.9603581428527832s
epoch 30: {'train_loss': '2.69485'}; time used = 1.7751495838165283s
epoch 35: {'train_loss': '2.67166'}; time used = 1.9984943866729736s
epoch 40: {'train_loss': '2.62160'}; time used = 1.665459156036377s
epoch 45: {'train_loss': '2.59228'}; time used = 1.9801414012908936s
epoch 50: {'train_loss': '2.53776'}; time used = 1.7704002857208252s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.383949279785156.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.77135'}; time used = 1.1946358680725098s
epoch 10: {'train_loss': '2.56205'}; time used = 1.0830378532409668s
epoch 15: {'train_loss': '2.41932'}; time used = 1.0218937397003174s
epoch 20: {'train_loss': '2.21000'}; time used = 1.045295000076294s
epoch 25: {'train_loss': '2.12225'}; time used = 1.1689534187316895s
epoch 30: {'train_loss': '2.02714'}; time used = 1.0733258724212646s
epoch 35: {'train_loss': '1.90864'}; time used = 1.1362724304199219s
epoch 40: {'train_loss': '1.87545'}; time used = 1.0924482345581055s
epoch 45: {'train_loss': '1.85802'}; time used = 1.265343427658081s
epoch 50: {'train_loss': '1.83595'}; time used = 1.0926744937896729s
epoch 55: {'train_loss': '1.82431'}; time used = 1.1877570152282715s
epoch 60: {'train_loss': '1.82372'}; time used = 1.3809113502502441s
epoch 65: {'train_loss': '1.79221'}; time used = 1.3222143650054932s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.620914220809937.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.62 GiB already allocated; 446.44 MiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 142.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 110.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37308'}; time used = 2.643876791000366s
epoch 10: {'train_loss': '1.31931'}; time used = 2.361278772354126s
epoch 15: {'train_loss': '1.16626'}; time used = 2.293515205383301s
epoch 20: {'train_loss': '1.04141'}; time used = 3.040203332901001s
epoch 25: {'train_loss': '0.75849'}; time used = 4.911270618438721s
epoch 30: {'train_loss': '0.74747'}; time used = 4.628140926361084s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.79864478111267.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.21506'}; time used = 2.0901660919189453s
epoch 10: {'train_loss': '0.84309'}; time used = 1.8334572315216064s
epoch 15: {'train_loss': '0.43707'}; time used = 2.018122434616089s
epoch 20: {'train_loss': '0.20803'}; time used = 2.0440402030944824s
epoch 25: {'train_loss': '0.13390'}; time used = 2.0334856510162354s
epoch 30: {'train_loss': '0.32957'}; time used = 1.8627989292144775s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.039273738861084.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.94665'}; time used = 3.4646339416503906s
epoch 10: {'train_loss': '2.82925'}; time used = 1.935546636581421s
epoch 15: {'train_loss': '2.79916'}; time used = 2.2136247158050537s
epoch 20: {'train_loss': '2.77263'}; time used = 2.780517578125s
epoch 25: {'train_loss': '2.75581'}; time used = 3.884549617767334s
epoch 30: {'train_loss': '2.74422'}; time used = 3.6397674083709717s
epoch 35: {'train_loss': '2.72838'}; time used = 3.529313564300537s
epoch 40: {'train_loss': '2.70558'}; time used = 1.9248874187469482s
epoch 45: {'train_loss': '2.68108'}; time used = 1.875246524810791s
epoch 50: {'train_loss': '2.65452'}; time used = 1.9702138900756836s
epoch 55: {'train_loss': '2.63715'}; time used = 1.8551445007324219s
epoch 60: {'train_loss': '2.59949'}; time used = 1.788893461227417s
epoch 65: {'train_loss': '2.56642'}; time used = 1.8911542892456055s
epoch 70: {'train_loss': '2.55732'}; time used = 1.7957508563995361s
epoch 75: {'train_loss': '2.49074'}; time used = 1.8540120124816895s
epoch 80: {'train_loss': '2.48163'}; time used = 1.8454856872558594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.443822145462036.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77665'}; time used = 1.8309392929077148s
epoch 10: {'train_loss': '2.65845'}; time used = 1.8689141273498535s
epoch 15: {'train_loss': '2.63574'}; time used = 2.000077486038208s
epoch 20: {'train_loss': '2.61070'}; time used = 2.0308306217193604s
epoch 25: {'train_loss': '2.58411'}; time used = 2.125231981277466s
epoch 30: {'train_loss': '2.55819'}; time used = 1.9669008255004883s
epoch 35: {'train_loss': '2.52184'}; time used = 2.025534152984619s
epoch 40: {'train_loss': '2.48288'}; time used = 2.105853319168091s
epoch 45: {'train_loss': '2.43084'}; time used = 2.6356825828552246s
epoch 50: {'train_loss': '2.35485'}; time used = 3.0002636909484863s
epoch 55: {'train_loss': '2.37964'}; time used = 3.3615989685058594s
epoch 60: {'train_loss': '2.38017'}; time used = 3.297609806060791s
epoch 65: {'train_loss': '2.33831'}; time used = 2.105585813522339s
epoch 70: {'train_loss': '2.41740'}; time used = 1.8307554721832275s
epoch 75: {'train_loss': '2.35856'}; time used = 1.9548256397247314s
epoch 80: {'train_loss': '2.32150'}; time used = 1.7278485298156738s
epoch 85: {'train_loss': '2.31364'}; time used = 1.710852861404419s
epoch 90: {'train_loss': '2.29655'}; time used = 1.7049362659454346s
epoch 95: {'train_loss': '2.27080'}; time used = 1.7045276165008545s
epoch 100: {'train_loss': '2.22257'}; time used = 1.7786853313446045s
epoch 105: {'train_loss': '2.22799'}; time used = 1.9404373168945312s
epoch 110: {'train_loss': '2.20109'}; time used = 1.7613813877105713s
epoch 115: {'train_loss': '2.17716'}; time used = 1.9618122577667236s
epoch 120: {'train_loss': '2.21622'}; time used = 1.9502179622650146s
epoch 125: {'train_loss': '2.18086'}; time used = 2.0998566150665283s
epoch 130: {'train_loss': '2.18492'}; time used = 2.0815584659576416s
epoch 135: {'train_loss': '2.15146'}; time used = 1.9282152652740479s
epoch 140: {'train_loss': '2.25511'}; time used = 1.9021177291870117s
epoch 145: {'train_loss': '2.31671'}; time used = 2.1367857456207275s
epoch 150: {'train_loss': '2.24668'}; time used = 2.00968599319458s
epoch 155: {'train_loss': '2.18660'}; time used = 4.0088701248168945s
epoch 160: {'train_loss': '2.21598'}; time used = 2.9038944244384766s
epoch 165: {'train_loss': '2.16819'}; time used = 1.9007620811462402s
epoch 170: {'train_loss': '2.13650'}; time used = 1.9598698616027832s
epoch 175: {'train_loss': '2.11364'}; time used = 1.7920703887939453s
epoch 180: {'train_loss': '2.11406'}; time used = 1.7814698219299316s
epoch 185: {'train_loss': '2.12147'}; time used = 1.790653944015503s
epoch 190: {'train_loss': '2.07026'}; time used = 1.939225196838379s
epoch 195: {'train_loss': '2.13221'}; time used = 2.0235345363616943s
epoch 200: {'train_loss': '2.07450'}; time used = 1.8442041873931885s
epoch 205: {'train_loss': '2.06888'}; time used = 1.7543036937713623s
epoch 210: {'train_loss': '2.03414'}; time used = 2.0759761333465576s
epoch 215: {'train_loss': '2.04934'}; time used = 1.9176814556121826s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 94.8367931842804.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5282051282051283, 'samples': 0.5362318840579711, 'weighted': 0.5326644370122631, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '0.41234'}; time used = 2.1901333332061768s
epoch 10: {'train_loss': '0.28914'}; time used = 2.109217882156372s
epoch 15: {'train_loss': '0.19308'}; time used = 2.706016778945923s
epoch 20: {'train_loss': '0.31267'}; time used = 2.101379632949829s
epoch 25: {'train_loss': '0.70885'}; time used = 2.169506788253784s
epoch 30: {'train_loss': '0.28229'}; time used = 1.933837890625s
epoch 35: {'train_loss': '0.47985'}; time used = 1.8120722770690918s
epoch 40: {'train_loss': '0.34453'}; time used = 1.945054531097412s
epoch 45: {'train_loss': '0.33202'}; time used = 1.9344170093536377s
epoch 50: {'train_loss': '0.41289'}; time used = 1.9988560676574707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.613369703292847.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5899830220713073, 'samples': 0.5942028985507246, 'weighted': 0.5929972195566053, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.67437'}; time used = 1.4694633483886719s
epoch 10: {'train_loss': '2.47799'}; time used = 1.0043830871582031s
epoch 15: {'train_loss': '2.35911'}; time used = 1.2375235557556152s
epoch 20: {'train_loss': '2.31056'}; time used = 1.140320062637329s
epoch 25: {'train_loss': '2.24488'}; time used = 1.690824031829834s
epoch 30: {'train_loss': '2.09311'}; time used = 1.9296276569366455s
epoch 35: {'train_loss': '1.87898'}; time used = 1.9381895065307617s
epoch 40: {'train_loss': '2.57545'}; time used = 1.9521234035491943s
epoch 45: {'train_loss': '2.27934'}; time used = 2.126744270324707s
epoch 50: {'train_loss': '2.11264'}; time used = 1.5337417125701904s
epoch 55: {'train_loss': '2.05404'}; time used = 1.0236401557922363s
epoch 60: {'train_loss': '1.94955'}; time used = 1.2479586601257324s
epoch 65: {'train_loss': '1.84182'}; time used = 1.2551531791687012s
epoch 70: {'train_loss': '1.72341'}; time used = 1.0352697372436523s
epoch 75: {'train_loss': '1.64475'}; time used = 1.1684324741363525s
epoch 80: {'train_loss': '1.64656'}; time used = 1.0581109523773193s
epoch 85: {'train_loss': '1.63708'}; time used = 1.2381172180175781s
epoch 90: {'train_loss': '1.56191'}; time used = 1.1553444862365723s
epoch 95: {'train_loss': '2.20728'}; time used = 1.2470438480377197s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.47765326499939.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 130.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76895'}; time used = 1.7763538360595703s
epoch 10: {'train_loss': '2.74339'}; time used = 1.8121931552886963s
epoch 15: {'train_loss': '2.72106'}; time used = 1.7593002319335938s
epoch 20: {'train_loss': '2.69925'}; time used = 1.719733476638794s
epoch 25: {'train_loss': '2.67149'}; time used = 1.71974778175354s
epoch 30: {'train_loss': '2.65129'}; time used = 1.7040619850158691s
epoch 35: {'train_loss': '2.64308'}; time used = 1.8921360969543457s
epoch 40: {'train_loss': '2.62733'}; time used = 3.1298532485961914s
epoch 45: {'train_loss': '2.60506'}; time used = 1.7807843685150146s
epoch 50: {'train_loss': '2.57822'}; time used = 1.874082088470459s
epoch 55: {'train_loss': '2.57227'}; time used = 2.1494812965393066s
epoch 60: {'train_loss': '2.55666'}; time used = 2.1488242149353027s
epoch 65: {'train_loss': '2.52314'}; time used = 1.7165486812591553s
epoch 70: {'train_loss': '2.48454'}; time used = 1.7517805099487305s
epoch 75: {'train_loss': '2.46328'}; time used = 1.9356155395507812s
epoch 80: {'train_loss': '2.42216'}; time used = 1.7586090564727783s
epoch 85: {'train_loss': '2.42562'}; time used = 1.856743574142456s
epoch 90: {'train_loss': '2.41790'}; time used = 2.449199676513672s
epoch 95: {'train_loss': '2.40551'}; time used = 3.353846311569214s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.365647315979004.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.64 GiB already allocated; 412.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 184.44 MiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.55 GiB already allocated; 498.44 MiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87784'}; time used = 1.866492509841919s
epoch 10: {'train_loss': '2.97629'}; time used = 1.6998376846313477s
epoch 15: {'train_loss': '2.88337'}; time used = 1.6760013103485107s
epoch 20: {'train_loss': '2.81858'}; time used = 2.0104053020477295s
epoch 25: {'train_loss': '2.77828'}; time used = 1.9666879177093506s
epoch 30: {'train_loss': '2.74813'}; time used = 1.6962096691131592s
epoch 35: {'train_loss': '2.72770'}; time used = 2.082031011581421s
epoch 40: {'train_loss': '2.69683'}; time used = 1.758380651473999s
epoch 45: {'train_loss': '2.65034'}; time used = 2.2260308265686035s
epoch 50: {'train_loss': '2.58124'}; time used = 2.9632413387298584s
epoch 55: {'train_loss': '2.56778'}; time used = 3.3447301387786865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.080458879470825.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 142.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.90986'}; time used = 5.014158487319946s
epoch 10: {'train_loss': '2.80482'}; time used = 5.036181211471558s
epoch 15: {'train_loss': '2.78170'}; time used = 4.225180387496948s
epoch 20: {'train_loss': '2.76375'}; time used = 3.513775587081909s
epoch 25: {'train_loss': '2.75225'}; time used = 3.101118564605713s
epoch 30: {'train_loss': '2.74195'}; time used = 1.7582740783691406s
epoch 35: {'train_loss': '2.73283'}; time used = 1.9725253582000732s
epoch 40: {'train_loss': '2.72230'}; time used = 1.811328411102295s
epoch 45: {'train_loss': '2.69942'}; time used = 2.137336492538452s
epoch 50: {'train_loss': '2.68553'}; time used = 1.9148805141448975s
epoch 55: {'train_loss': '2.67534'}; time used = 1.8639411926269531s
epoch 60: {'train_loss': '2.63098'}; time used = 1.7324938774108887s
epoch 65: {'train_loss': '2.60142'}; time used = 1.8486328125s
epoch 70: {'train_loss': '2.59101'}; time used = 1.9073445796966553s
epoch 75: {'train_loss': '2.53364'}; time used = 2.374927520751953s
epoch 80: {'train_loss': '2.53203'}; time used = 1.9747898578643799s
epoch 85: {'train_loss': '2.54426'}; time used = 1.768723487854004s
epoch 90: {'train_loss': '2.49084'}; time used = 1.9159116744995117s
epoch 95: {'train_loss': '2.49938'}; time used = 2.092851400375366s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 64.28109335899353.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.15306'}; time used = 3.9786570072174072s
epoch 10: {'train_loss': '0.50132'}; time used = 3.8586153984069824s
epoch 15: {'train_loss': '0.23165'}; time used = 3.6682775020599365s
epoch 20: {'train_loss': '0.31643'}; time used = 3.42602276802063s
epoch 25: {'train_loss': '0.75468'}; time used = 2.42913818359375s
epoch 30: {'train_loss': '0.29530'}; time used = 1.8336710929870605s
epoch 35: {'train_loss': '0.22444'}; time used = 1.759458303451538s
epoch 40: {'train_loss': '0.34304'}; time used = 1.734117031097412s
epoch 45: {'train_loss': '0.34225'}; time used = 1.7574522495269775s
epoch 50: {'train_loss': '0.45305'}; time used = 1.7800793647766113s
epoch 55: {'train_loss': '0.26074'}; time used = 1.8515591621398926s
epoch 60: {'train_loss': '0.36962'}; time used = 1.7835164070129395s
epoch 65: {'train_loss': '0.51337'}; time used = 1.8000881671905518s
epoch 70: {'train_loss': '0.45280'}; time used = 1.8339858055114746s
epoch 75: {'train_loss': '0.45275'}; time used = 1.8296360969543457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.51108717918396.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.28257'}; time used = 2.060603141784668s
epoch 10: {'train_loss': '1.17331'}; time used = 1.9418470859527588s
epoch 15: {'train_loss': '1.10404'}; time used = 2.124396562576294s
epoch 20: {'train_loss': '1.11482'}; time used = 3.099118709564209s
epoch 25: {'train_loss': '1.07740'}; time used = 3.941204309463501s
epoch 30: {'train_loss': '0.94495'}; time used = 4.763852834701538s
epoch 35: {'train_loss': '0.87408'}; time used = 4.734524726867676s
epoch 40: {'train_loss': '0.86272'}; time used = 4.56473970413208s
epoch 45: {'train_loss': '0.82050'}; time used = 3.793205738067627s
epoch 50: {'train_loss': '0.65527'}; time used = 3.673034191131592s
epoch 55: {'train_loss': '0.57603'}; time used = 2.1827781200408936s
epoch 60: {'train_loss': '0.36132'}; time used = 2.7320516109466553s
epoch 65: {'train_loss': '1.01588'}; time used = 2.526432514190674s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.38135623931885.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89520'}; time used = 2.4377167224884033s
epoch 10: {'train_loss': '2.81756'}; time used = 1.8323006629943848s
epoch 15: {'train_loss': '2.79545'}; time used = 1.723315954208374s
epoch 20: {'train_loss': '2.78138'}; time used = 1.8457963466644287s
epoch 25: {'train_loss': '2.77065'}; time used = 1.832711935043335s
epoch 30: {'train_loss': '2.76608'}; time used = 1.8099489212036133s
epoch 35: {'train_loss': '2.76518'}; time used = 1.761765718460083s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.794442653656006.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5434782608695652, 'samples': 0.5942028985507246, 'weighted': 0.5545053560176434, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 64.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81414'}; time used = 1.31679105758667s
epoch 10: {'train_loss': '2.21158'}; time used = 1.2723124027252197s
epoch 15: {'train_loss': '1.59489'}; time used = 1.0816059112548828s
epoch 20: {'train_loss': '1.57543'}; time used = 1.4510648250579834s
epoch 25: {'train_loss': '1.39826'}; time used = 1.937952995300293s
epoch 30: {'train_loss': '1.30952'}; time used = 1.850719928741455s
epoch 35: {'train_loss': '1.14161'}; time used = 1.9293735027313232s
epoch 40: {'train_loss': '1.43790'}; time used = 1.9622342586517334s
epoch 45: {'train_loss': '1.23236'}; time used = 2.2255899906158447s
epoch 50: {'train_loss': '1.18277'}; time used = 2.0254409313201904s
epoch 55: {'train_loss': '1.13396'}; time used = 1.4094674587249756s
epoch 60: {'train_loss': '1.07543'}; time used = 1.1444354057312012s
epoch 65: {'train_loss': '1.02938'}; time used = 1.137364149093628s
epoch 70: {'train_loss': '0.96544'}; time used = 1.0299427509307861s
epoch 75: {'train_loss': '0.89287'}; time used = 1.1111395359039307s
epoch 80: {'train_loss': '0.99287'}; time used = 1.1673109531402588s
epoch 85: {'train_loss': '0.98341'}; time used = 1.2715814113616943s
epoch 90: {'train_loss': '0.92832'}; time used = 1.1245718002319336s
epoch 95: {'train_loss': '0.95426'}; time used = 1.3156659603118896s
epoch 100: {'train_loss': '1.08315'}; time used = 1.2253153324127197s
epoch 105: {'train_loss': '0.90874'}; time used = 1.216191291809082s
epoch 110: {'train_loss': '0.91904'}; time used = 1.0937163829803467s
epoch 115: {'train_loss': '0.89831'}; time used = 1.1415317058563232s
epoch 120: {'train_loss': '0.85685'}; time used = 1.2016286849975586s
epoch 125: {'train_loss': '0.89340'}; time used = 1.2368378639221191s
epoch 130: {'train_loss': '0.80405'}; time used = 1.1611125469207764s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.72687768936157.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.20778'}; time used = 1.8521265983581543s
epoch 10: {'train_loss': '1.02254'}; time used = 1.938356876373291s
epoch 15: {'train_loss': '0.47395'}; time used = 1.854435920715332s
epoch 20: {'train_loss': '0.27501'}; time used = 1.7122995853424072s
epoch 25: {'train_loss': '0.13586'}; time used = 2.4043538570404053s
epoch 30: {'train_loss': '0.09666'}; time used = 1.946486234664917s
epoch 35: {'train_loss': '0.11933'}; time used = 2.382366895675659s
epoch 40: {'train_loss': '0.13395'}; time used = 3.538670778274536s
epoch 45: {'train_loss': '0.14752'}; time used = 3.1504974365234375s
epoch 50: {'train_loss': '0.18302'}; time used = 3.0297179222106934s
epoch 55: {'train_loss': '0.14242'}; time used = 2.460315227508545s
epoch 60: {'train_loss': '0.12573'}; time used = 1.8791587352752686s
epoch 65: {'train_loss': '0.09060'}; time used = 1.9758334159851074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.029101610183716.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 300.44 MiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76026'}; time used = 1.6824121475219727s
epoch 10: {'train_loss': '2.73737'}; time used = 1.635890007019043s
epoch 15: {'train_loss': '2.71300'}; time used = 1.6373865604400635s
epoch 20: {'train_loss': '2.68323'}; time used = 1.658937931060791s
epoch 25: {'train_loss': '2.64526'}; time used = 1.8652827739715576s
epoch 30: {'train_loss': '2.62313'}; time used = 1.6288297176361084s
epoch 35: {'train_loss': '2.60392'}; time used = 1.7609024047851562s
epoch 40: {'train_loss': '2.57843'}; time used = 1.753725290298462s
epoch 45: {'train_loss': '2.54590'}; time used = 1.901977300643921s
epoch 50: {'train_loss': '2.50439'}; time used = 1.9798603057861328s
epoch 55: {'train_loss': '2.47686'}; time used = 1.999009370803833s
epoch 60: {'train_loss': '2.45246'}; time used = 2.2918355464935303s
epoch 65: {'train_loss': '2.42796'}; time used = 2.2654130458831787s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.80286979675293.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37598'}; time used = 2.276242971420288s
epoch 10: {'train_loss': '1.33216'}; time used = 2.490079879760742s
epoch 15: {'train_loss': '1.33438'}; time used = 2.314650535583496s
epoch 20: {'train_loss': '1.39671'}; time used = 2.1330599784851074s
epoch 25: {'train_loss': '1.34840'}; time used = 2.06485915184021s
epoch 30: {'train_loss': '1.29639'}; time used = 2.265666961669922s
epoch 35: {'train_loss': '1.28202'}; time used = 4.675047397613525s
epoch 40: {'train_loss': '1.26790'}; time used = 2.150710344314575s
epoch 45: {'train_loss': '1.28630'}; time used = 1.913722276687622s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.15385866165161.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84376'}; time used = 1.2724716663360596s
epoch 10: {'train_loss': '2.78779'}; time used = 1.3339359760284424s
epoch 15: {'train_loss': '2.77516'}; time used = 1.191617727279663s
epoch 20: {'train_loss': '2.77292'}; time used = 1.2139198780059814s
epoch 25: {'train_loss': '2.77483'}; time used = 1.1121368408203125s
epoch 30: {'train_loss': '2.77426'}; time used = 1.1234173774719238s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.559192895889282.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 208.44 MiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.15931'}; time used = 1.1466915607452393s
epoch 10: {'train_loss': '0.96798'}; time used = 1.1178712844848633s
epoch 15: {'train_loss': '0.82937'}; time used = 1.1753206253051758s
epoch 20: {'train_loss': '0.69579'}; time used = 1.1280977725982666s
epoch 25: {'train_loss': '0.47111'}; time used = 1.1309494972229004s
epoch 30: {'train_loss': '0.23558'}; time used = 1.0169401168823242s
epoch 35: {'train_loss': '0.27392'}; time used = 0.9551184177398682s
epoch 40: {'train_loss': '0.13537'}; time used = 1.1324889659881592s
epoch 45: {'train_loss': '0.12871'}; time used = 0.9723334312438965s
epoch 50: {'train_loss': '0.10649'}; time used = 1.049283742904663s
epoch 55: {'train_loss': '0.08365'}; time used = 1.439756155014038s
epoch 60: {'train_loss': '0.07078'}; time used = 1.9960412979125977s
epoch 65: {'train_loss': '0.06462'}; time used = 1.8168487548828125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.99289345741272.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83281'}; time used = 6.919446229934692s
epoch 10: {'train_loss': '2.80258'}; time used = 7.255418062210083s
epoch 15: {'train_loss': '2.78871'}; time used = 6.281605958938599s
epoch 20: {'train_loss': '2.78033'}; time used = 6.673513889312744s
epoch 25: {'train_loss': '2.77541'}; time used = 6.299149990081787s
epoch 30: {'train_loss': '2.77317'}; time used = 8.511250734329224s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.90355896949768.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.45356186651367375, 'samples': 0.46, 'weighted': 0.45224072480397787, 'accuracy': 0.46}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99009'}; time used = 1.1976208686828613s
epoch 10: {'train_loss': '0.59553'}; time used = 1.029068946838379s
epoch 15: {'train_loss': '0.37015'}; time used = 0.9917640686035156s
epoch 20: {'train_loss': '0.19337'}; time used = 0.9968972206115723s
epoch 25: {'train_loss': '0.13914'}; time used = 1.347473382949829s
epoch 30: {'train_loss': '0.09042'}; time used = 1.1728050708770752s
epoch 35: {'train_loss': '0.05315'}; time used = 1.2924175262451172s
epoch 40: {'train_loss': '0.04419'}; time used = 1.1518826484680176s
epoch 45: {'train_loss': '0.03884'}; time used = 1.032623291015625s
epoch 50: {'train_loss': '0.02852'}; time used = 1.132519006729126s
epoch 55: {'train_loss': '0.01955'}; time used = 1.0735046863555908s
epoch 60: {'train_loss': '0.01201'}; time used = 1.2607226371765137s
epoch 65: {'train_loss': '0.02292'}; time used = 1.1657702922821045s
epoch 70: {'train_loss': '0.01524'}; time used = 1.1541781425476074s
epoch 75: {'train_loss': '0.01443'}; time used = 1.1959750652313232s
epoch 80: {'train_loss': '1.05939'}; time used = 1.056753158569336s
epoch 85: {'train_loss': '0.33650'}; time used = 1.0977869033813477s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.389804124832153.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.57514'}; time used = 1.2216408252716064s
epoch 10: {'train_loss': '2.44900'}; time used = 1.0056138038635254s
epoch 15: {'train_loss': '2.36224'}; time used = 1.0600128173828125s
epoch 20: {'train_loss': '2.31988'}; time used = 1.1154537200927734s
epoch 25: {'train_loss': '2.29444'}; time used = 0.9988203048706055s
epoch 30: {'train_loss': '2.23280'}; time used = 1.056248426437378s
epoch 35: {'train_loss': '2.18912'}; time used = 1.00337815284729s
epoch 40: {'train_loss': '2.16590'}; time used = 1.01041841506958s
epoch 45: {'train_loss': '2.14761'}; time used = 1.1560194492340088s
epoch 50: {'train_loss': '2.15996'}; time used = 2.0011990070343018s
epoch 55: {'train_loss': '2.14017'}; time used = 1.9397528171539307s
epoch 60: {'train_loss': '2.12690'}; time used = 1.972421646118164s
epoch 65: {'train_loss': '2.13425'}; time used = 1.5525307655334473s
epoch 70: {'train_loss': '2.14304'}; time used = 1.814307451248169s
epoch 75: {'train_loss': '2.11465'}; time used = 1.739964485168457s
epoch 80: {'train_loss': '2.13138'}; time used = 1.3937296867370605s
epoch 85: {'train_loss': '2.13801'}; time used = 1.036271095275879s
epoch 90: {'train_loss': '2.10190'}; time used = 0.9193878173828125s
epoch 95: {'train_loss': '2.13478'}; time used = 1.022108554840088s
epoch 100: {'train_loss': '2.14681'}; time used = 2.4894285202026367s
epoch 105: {'train_loss': '2.12217'}; time used = 2.631239891052246s
epoch 110: {'train_loss': '2.09964'}; time used = 1.1661787033081055s
epoch 115: {'train_loss': '2.10430'}; time used = 0.9276399612426758s
epoch 120: {'train_loss': '2.08936'}; time used = 0.9665648937225342s
epoch 125: {'train_loss': '2.11637'}; time used = 1.233860969543457s
epoch 130: {'train_loss': '2.09648'}; time used = 1.1059279441833496s
epoch 135: {'train_loss': '2.08166'}; time used = 1.1184003353118896s
epoch 140: {'train_loss': '2.09833'}; time used = 1.2609901428222656s
epoch 145: {'train_loss': '2.10329'}; time used = 1.0520496368408203s
epoch 150: {'train_loss': '2.09270'}; time used = 1.0068869590759277s
epoch 155: {'train_loss': '2.11340'}; time used = 0.8857457637786865s
epoch 160: {'train_loss': '2.10643'}; time used = 1.2425165176391602s
epoch 165: {'train_loss': '2.11721'}; time used = 1.23073148727417s
epoch 170: {'train_loss': '2.12451'}; time used = 1.200986623764038s
epoch 175: {'train_loss': '2.07698'}; time used = 1.0320038795471191s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.16326141357422.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 248.44 MiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39517'}; time used = 4.435328006744385s
epoch 10: {'train_loss': '1.38261'}; time used = 1.6121437549591064s
epoch 15: {'train_loss': '1.34414'}; time used = 1.126176118850708s
epoch 20: {'train_loss': '1.34436'}; time used = 1.2105164527893066s
epoch 25: {'train_loss': '1.31979'}; time used = 1.1266059875488281s
epoch 30: {'train_loss': '1.30152'}; time used = 1.1615099906921387s
epoch 35: {'train_loss': '1.27288'}; time used = 1.2586510181427002s
epoch 40: {'train_loss': '1.22149'}; time used = 1.2159152030944824s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.97522807121277.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68044'}; time used = 1.1878235340118408s
epoch 10: {'train_loss': '2.44386'}; time used = 1.010993480682373s
epoch 15: {'train_loss': '2.17279'}; time used = 0.9691166877746582s
epoch 20: {'train_loss': '1.82904'}; time used = 1.0153038501739502s
epoch 25: {'train_loss': '1.77277'}; time used = 1.0315275192260742s
epoch 30: {'train_loss': '1.70548'}; time used = 1.0089857578277588s
epoch 35: {'train_loss': '1.83349'}; time used = 1.0449185371398926s
epoch 40: {'train_loss': '1.78623'}; time used = 1.2496118545532227s
epoch 45: {'train_loss': '1.65484'}; time used = 1.074599266052246s
epoch 50: {'train_loss': '1.57445'}; time used = 1.1217474937438965s
epoch 55: {'train_loss': '1.56636'}; time used = 1.2292847633361816s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.082865953445435.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94857'}; time used = 2.6231677532196045s
epoch 10: {'train_loss': '2.75751'}; time used = 2.4464404582977295s
epoch 15: {'train_loss': '2.76499'}; time used = 2.690227746963501s
epoch 20: {'train_loss': '2.74160'}; time used = 2.4005470275878906s
epoch 25: {'train_loss': '2.71817'}; time used = 2.5928914546966553s
epoch 30: {'train_loss': '2.69382'}; time used = 2.4769814014434814s
epoch 35: {'train_loss': '2.65999'}; time used = 2.7026126384735107s
epoch 40: {'train_loss': '2.62197'}; time used = 2.7387497425079346s
epoch 45: {'train_loss': '2.56366'}; time used = 2.618345260620117s
epoch 50: {'train_loss': '2.54232'}; time used = 2.6288058757781982s
epoch 55: {'train_loss': '2.51508'}; time used = 2.892585039138794s
epoch 60: {'train_loss': '2.50235'}; time used = 2.590702533721924s
epoch 65: {'train_loss': '2.45804'}; time used = 2.4708235263824463s
epoch 70: {'train_loss': '2.45146'}; time used = 2.718878746032715s
epoch 75: {'train_loss': '2.44067'}; time used = 2.781311511993408s
epoch 80: {'train_loss': '2.42200'}; time used = 2.566897392272949s
epoch 85: {'train_loss': '2.42986'}; time used = 2.568953275680542s
epoch 90: {'train_loss': '2.44280'}; time used = 2.594818592071533s
epoch 95: {'train_loss': '2.38141'}; time used = 2.593322277069092s
epoch 100: {'train_loss': '2.35995'}; time used = 2.6284918785095215s
epoch 105: {'train_loss': '2.38253'}; time used = 2.5971179008483887s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.12600564956665.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5208333333333334, 'samples': 0.5652173913043478, 'weighted': 0.5314009661835749, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77240'}; time used = 1.4408252239227295s
epoch 10: {'train_loss': '2.78425'}; time used = 1.5040969848632812s
epoch 15: {'train_loss': '2.78095'}; time used = 1.1816785335540771s
epoch 20: {'train_loss': '2.77229'}; time used = 1.3768391609191895s
epoch 25: {'train_loss': '2.77531'}; time used = 1.1841285228729248s
epoch 30: {'train_loss': '2.77211'}; time used = 1.239555835723877s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.698052167892456.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 4.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 420.44 MiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.64 GiB already allocated; 412.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90433'}; time used = 1.9471435546875s
epoch 10: {'train_loss': '2.79846'}; time used = 1.989133596420288s
epoch 15: {'train_loss': '2.77469'}; time used = 2.007714033126831s
epoch 20: {'train_loss': '2.77335'}; time used = 1.9136040210723877s
epoch 25: {'train_loss': '2.77581'}; time used = 1.9819223880767822s
epoch 30: {'train_loss': '2.76899'}; time used = 1.8983917236328125s
epoch 35: {'train_loss': '2.76965'}; time used = 1.9355478286743164s
epoch 40: {'train_loss': '2.76865'}; time used = 1.9197442531585693s
epoch 45: {'train_loss': '2.76599'}; time used = 1.9458527565002441s
epoch 50: {'train_loss': '2.76372'}; time used = 2.0105843544006348s
epoch 55: {'train_loss': '2.76315'}; time used = 1.9430453777313232s
epoch 60: {'train_loss': '2.75979'}; time used = 1.902754783630371s
epoch 65: {'train_loss': '2.75801'}; time used = 1.917881727218628s
epoch 70: {'train_loss': '2.75632'}; time used = 1.9427669048309326s
epoch 75: {'train_loss': '2.75212'}; time used = 1.977954626083374s
epoch 80: {'train_loss': '2.75316'}; time used = 1.9986522197723389s
epoch 85: {'train_loss': '2.75242'}; time used = 2.1320085525512695s
epoch 90: {'train_loss': '2.74626'}; time used = 2.0363504886627197s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.236408710479736.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.77757'}; time used = 7.713672637939453s
epoch 10: {'train_loss': '2.77894'}; time used = 7.37293553352356s
epoch 15: {'train_loss': '2.76824'}; time used = 7.322136163711548s
epoch 20: {'train_loss': '2.76615'}; time used = 7.38064432144165s
epoch 25: {'train_loss': '2.76326'}; time used = 7.640332937240601s
epoch 30: {'train_loss': '2.75321'}; time used = 7.456307649612427s
epoch 35: {'train_loss': '2.73465'}; time used = 9.439438104629517s
epoch 40: {'train_loss': '2.72272'}; time used = 9.612953424453735s
epoch 45: {'train_loss': '2.71849'}; time used = 7.560953617095947s
epoch 50: {'train_loss': '2.71915'}; time used = 7.204895973205566s
epoch 55: {'train_loss': '2.71688'}; time used = 7.7693023681640625s
epoch 60: {'train_loss': '2.71935'}; time used = 7.563914775848389s
epoch 65: {'train_loss': '2.71480'}; time used = 7.084054470062256s
epoch 70: {'train_loss': '2.71750'}; time used = 7.575029373168945s
epoch 75: {'train_loss': '2.71411'}; time used = 7.728604078292847s
epoch 80: {'train_loss': '2.71843'}; time used = 8.95623230934143s
epoch 85: {'train_loss': '2.71436'}; time used = 7.711858034133911s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 153.64162945747375.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4213642213642214, 'samples': 0.5033333333333333, 'weighted': 0.4103449163449163, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.48759'}; time used = 2.1321864128112793s
epoch 10: {'train_loss': '3.00275'}; time used = 1.908379316329956s
epoch 15: {'train_loss': '2.88663'}; time used = 1.9998338222503662s
epoch 20: {'train_loss': '2.85358'}; time used = 2.1034319400787354s
epoch 25: {'train_loss': '2.82021'}; time used = 2.1277387142181396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.527403593063354.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4891114982578397, 'samples': 0.5072463768115942, 'weighted': 0.49608645154774533, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 426.44 MiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.25145'}; time used = 1.4109206199645996s
epoch 10: {'train_loss': '2.84066'}; time used = 1.2469813823699951s
epoch 15: {'train_loss': '2.71351'}; time used = 1.1498167514801025s
epoch 20: {'train_loss': '2.63489'}; time used = 1.0166733264923096s
epoch 25: {'train_loss': '2.51993'}; time used = 1.0136351585388184s
epoch 30: {'train_loss': '2.43396'}; time used = 1.0201969146728516s
epoch 35: {'train_loss': '2.37934'}; time used = 1.1584136486053467s
epoch 40: {'train_loss': '2.36758'}; time used = 1.2002861499786377s
epoch 45: {'train_loss': '2.32925'}; time used = 1.1585030555725098s
epoch 50: {'train_loss': '2.30832'}; time used = 1.1987900733947754s
epoch 55: {'train_loss': '2.30555'}; time used = 1.0028939247131348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.599937915802002.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5438596491228069, 'samples': 0.6578947368421053, 'weighted': 0.579870729455217, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98843'}; time used = 1.9751489162445068s
epoch 10: {'train_loss': '2.78480'}; time used = 1.9908411502838135s
epoch 15: {'train_loss': '2.74778'}; time used = 2.06760835647583s
epoch 20: {'train_loss': '2.72421'}; time used = 2.0326390266418457s
epoch 25: {'train_loss': '2.70666'}; time used = 1.9986655712127686s
epoch 30: {'train_loss': '2.69054'}; time used = 1.7958917617797852s
epoch 35: {'train_loss': '2.67187'}; time used = 2.1560754776000977s
epoch 40: {'train_loss': '2.63527'}; time used = 2.3583145141601562s
epoch 45: {'train_loss': '2.61920'}; time used = 2.3215925693511963s
epoch 50: {'train_loss': '2.58483'}; time used = 2.004387378692627s
epoch 55: {'train_loss': '2.57867'}; time used = 1.939042568206787s
epoch 60: {'train_loss': '2.55649'}; time used = 1.8896305561065674s
epoch 65: {'train_loss': '2.52846'}; time used = 2.0524227619171143s
epoch 70: {'train_loss': '2.50742'}; time used = 1.963521957397461s
epoch 75: {'train_loss': '2.46801'}; time used = 1.9544713497161865s
epoch 80: {'train_loss': '2.47590'}; time used = 1.9521231651306152s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.7127947807312.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.40665742024965323, 'samples': 0.5507246376811594, 'weighted': 0.42784377575428645, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84638'}; time used = 8.331152439117432s
epoch 10: {'train_loss': '2.77651'}; time used = 7.39552116394043s
epoch 15: {'train_loss': '2.77959'}; time used = 6.5630505084991455s
epoch 20: {'train_loss': '2.77642'}; time used = 6.534470319747925s
epoch 25: {'train_loss': '2.77055'}; time used = 6.4939866065979s
epoch 30: {'train_loss': '2.76952'}; time used = 6.454977989196777s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 69.19981694221497.
Training classifier using 80.00% nodes...
{'micro': 0.4666666666666667, 'macro': 0.4603738103428506, 'samples': 0.4666666666666667, 'weighted': 0.4589155372090357, 'accuracy': 0.4666666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 352.44 MiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85623'}; time used = 4.040072679519653s
epoch 10: {'train_loss': '2.86702'}; time used = 2.1829020977020264s
epoch 15: {'train_loss': '2.82571'}; time used = 2.1265413761138916s
epoch 20: {'train_loss': '2.78447'}; time used = 3.551705837249756s
epoch 25: {'train_loss': '2.76228'}; time used = 3.982759475708008s
epoch 30: {'train_loss': '2.75147'}; time used = 3.6519999504089355s
epoch 35: {'train_loss': '2.74889'}; time used = 2.1436750888824463s
epoch 40: {'train_loss': '2.74311'}; time used = 2.2995107173919678s
epoch 45: {'train_loss': '2.73481'}; time used = 2.062128782272339s
epoch 50: {'train_loss': '2.72286'}; time used = 2.1873273849487305s
epoch 55: {'train_loss': '2.72105'}; time used = 2.1527974605560303s
epoch 60: {'train_loss': '2.70118'}; time used = 2.1880970001220703s
epoch 65: {'train_loss': '2.69484'}; time used = 2.111560821533203s
epoch 70: {'train_loss': '2.69802'}; time used = 1.9998576641082764s
epoch 75: {'train_loss': '2.67032'}; time used = 2.3021225929260254s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.87344288825989.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5410856039476507, 'samples': 0.5507246376811594, 'weighted': 0.545905120814405, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.36392'}; time used = 4.968865871429443s
epoch 10: {'train_loss': '1.38621'}; time used = 4.714680194854736s
epoch 15: {'train_loss': '1.34830'}; time used = 4.815201282501221s
epoch 20: {'train_loss': '1.34302'}; time used = 5.033370494842529s
epoch 25: {'train_loss': '1.28354'}; time used = 6.942672252655029s
epoch 30: {'train_loss': '1.24445'}; time used = 7.746727466583252s
epoch 35: {'train_loss': '1.19675'}; time used = 4.916752338409424s
epoch 40: {'train_loss': '1.37614'}; time used = 4.625364780426025s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.418418407440186.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049336100622641, 'samples': 0.705, 'weighted': 0.7050221299792454, 'accuracy': 0.705}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.83 GiB already allocated; 228.44 MiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77436'}; time used = 2.111915349960327s
epoch 10: {'train_loss': '2.77105'}; time used = 2.0595862865448s
epoch 15: {'train_loss': '2.77088'}; time used = 2.1000583171844482s
epoch 20: {'train_loss': '2.76932'}; time used = 1.9985020160675049s
epoch 25: {'train_loss': '2.76390'}; time used = 2.028752326965332s
epoch 30: {'train_loss': '2.74626'}; time used = 2.0698959827423096s
epoch 35: {'train_loss': '2.71388'}; time used = 3.2032063007354736s
epoch 40: {'train_loss': '2.65962'}; time used = 2.2316315174102783s
epoch 45: {'train_loss': '2.68056'}; time used = 2.147864818572998s
epoch 50: {'train_loss': '2.69232'}; time used = 2.249556303024292s
epoch 55: {'train_loss': '2.64661'}; time used = 2.121032953262329s
epoch 60: {'train_loss': '2.60161'}; time used = 2.129622459411621s
epoch 65: {'train_loss': '2.59083'}; time used = 2.005967617034912s
epoch 70: {'train_loss': '2.57994'}; time used = 2.00846266746521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.875622510910034.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85461'}; time used = 1.04240083694458s
epoch 10: {'train_loss': '2.78953'}; time used = 0.9654276371002197s
epoch 15: {'train_loss': '2.77369'}; time used = 0.9723176956176758s
epoch 20: {'train_loss': '2.78500'}; time used = 0.9686980247497559s
epoch 25: {'train_loss': '2.77735'}; time used = 1.0583915710449219s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.492919206619263.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.73 GiB already allocated; 320.44 MiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39736'}; time used = 2.624743938446045s
epoch 10: {'train_loss': '1.35337'}; time used = 2.6444945335388184s
epoch 15: {'train_loss': '1.38843'}; time used = 2.7914271354675293s
epoch 20: {'train_loss': '1.44606'}; time used = 2.7342469692230225s
epoch 25: {'train_loss': '1.43057'}; time used = 2.6361474990844727s
epoch 30: {'train_loss': '1.39909'}; time used = 2.7120046615600586s
epoch 35: {'train_loss': '1.38159'}; time used = 4.333209753036499s
epoch 40: {'train_loss': '1.35790'}; time used = 2.5845561027526855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.507624626159668.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5174825174825175, 'samples': 0.6086956521739131, 'weighted': 0.53268470659775, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.22998'}; time used = 1.2201361656188965s
epoch 10: {'train_loss': '2.87490'}; time used = 1.161264181137085s
epoch 15: {'train_loss': '2.84091'}; time used = 1.117879867553711s
epoch 20: {'train_loss': '2.81845'}; time used = 1.0581495761871338s
epoch 25: {'train_loss': '2.79574'}; time used = 1.1071135997772217s
epoch 30: {'train_loss': '2.78591'}; time used = 1.0485351085662842s
epoch 35: {'train_loss': '2.79264'}; time used = 1.075495958328247s
epoch 40: {'train_loss': '2.78476'}; time used = 1.0584816932678223s
epoch 45: {'train_loss': '2.78399'}; time used = 1.0326814651489258s
epoch 50: {'train_loss': '2.77870'}; time used = 1.0509347915649414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.962007761001587.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89148'}; time used = 1.8416473865509033s
epoch 10: {'train_loss': '2.81382'}; time used = 1.988297462463379s
epoch 15: {'train_loss': '2.79422'}; time used = 1.8206722736358643s
epoch 20: {'train_loss': '2.78646'}; time used = 2.1561005115509033s
epoch 25: {'train_loss': '2.77782'}; time used = 1.8885629177093506s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.28444528579712.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77865'}; time used = 3.4114749431610107s
epoch 10: {'train_loss': '2.77478'}; time used = 2.11476469039917s
epoch 15: {'train_loss': '2.77321'}; time used = 2.0167691707611084s
epoch 20: {'train_loss': '2.77370'}; time used = 2.290755033493042s
epoch 25: {'train_loss': '2.77363'}; time used = 2.844672203063965s
epoch 30: {'train_loss': '2.77267'}; time used = 2.0628538131713867s
epoch 35: {'train_loss': '2.77253'}; time used = 2.0304646492004395s
epoch 40: {'train_loss': '2.77283'}; time used = 2.072390556335449s
epoch 45: {'train_loss': '2.77242'}; time used = 2.0892221927642822s
epoch 50: {'train_loss': '2.77284'}; time used = 2.1099255084991455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.496670722961426.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4189473684210526, 'samples': 0.5362318840579711, 'weighted': 0.4378642257818459, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94880'}; time used = 1.811082363128662s
epoch 10: {'train_loss': '2.82326'}; time used = 1.1706490516662598s
epoch 15: {'train_loss': '2.80027'}; time used = 1.1258752346038818s
epoch 20: {'train_loss': '2.72728'}; time used = 1.2001292705535889s
epoch 25: {'train_loss': '2.59371'}; time used = 1.1886413097381592s
epoch 30: {'train_loss': '2.40703'}; time used = 1.3203740119934082s
epoch 35: {'train_loss': '2.29153'}; time used = 1.142153024673462s
epoch 40: {'train_loss': '2.22885'}; time used = 1.1062703132629395s
epoch 45: {'train_loss': '2.21067'}; time used = 1.090102195739746s
epoch 50: {'train_loss': '2.18935'}; time used = 1.0842182636260986s
epoch 55: {'train_loss': '2.11961'}; time used = 1.0988249778747559s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.708160161972046.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85623'}; time used = 2.248699903488159s
epoch 10: {'train_loss': '2.86702'}; time used = 2.06331729888916s
epoch 15: {'train_loss': '2.82571'}; time used = 2.6024389266967773s
epoch 20: {'train_loss': '2.78447'}; time used = 2.262507915496826s
epoch 25: {'train_loss': '2.76228'}; time used = 2.299368381500244s
epoch 30: {'train_loss': '2.75147'}; time used = 2.2188706398010254s
epoch 35: {'train_loss': '2.74889'}; time used = 2.0813040733337402s
epoch 40: {'train_loss': '2.74311'}; time used = 2.1413707733154297s
epoch 45: {'train_loss': '2.73481'}; time used = 2.0708560943603516s
epoch 50: {'train_loss': '2.72286'}; time used = 2.2843401432037354s
epoch 55: {'train_loss': '2.72105'}; time used = 2.1889758110046387s
epoch 60: {'train_loss': '2.70118'}; time used = 2.2544021606445312s
epoch 65: {'train_loss': '2.69484'}; time used = 2.0884480476379395s
epoch 70: {'train_loss': '2.69802'}; time used = 2.059270143508911s
epoch 75: {'train_loss': '2.67032'}; time used = 2.162652015686035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.54745626449585.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5410856039476507, 'samples': 0.5507246376811594, 'weighted': 0.545905120814405, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83995'}; time used = 1.589665412902832s
epoch 10: {'train_loss': '2.75679'}; time used = 1.4946956634521484s
epoch 15: {'train_loss': '2.69149'}; time used = 1.315415382385254s
epoch 20: {'train_loss': '2.60305'}; time used = 1.2863259315490723s
epoch 25: {'train_loss': '2.55109'}; time used = 1.5348200798034668s
epoch 30: {'train_loss': '2.49825'}; time used = 1.8200626373291016s
epoch 35: {'train_loss': '2.37654'}; time used = 1.3125755786895752s
epoch 40: {'train_loss': '2.34938'}; time used = 1.298154592514038s
epoch 45: {'train_loss': '2.34665'}; time used = 1.312412977218628s
epoch 50: {'train_loss': '2.38573'}; time used = 1.2890369892120361s
epoch 55: {'train_loss': '2.32191'}; time used = 1.293142318725586s
epoch 60: {'train_loss': '2.23095'}; time used = 1.4006602764129639s
epoch 65: {'train_loss': '2.17068'}; time used = 1.2962415218353271s
epoch 70: {'train_loss': '2.12950'}; time used = 1.3036105632781982s
epoch 75: {'train_loss': '2.05942'}; time used = 1.429222822189331s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.546637535095215.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5529411764705883, 'samples': 0.6052631578947368, 'weighted': 0.5770897832817338, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.32305'}; time used = 5.61594820022583s
epoch 10: {'train_loss': '1.34799'}; time used = 6.485977649688721s
epoch 15: {'train_loss': '1.33491'}; time used = 6.0346949100494385s
epoch 20: {'train_loss': '1.33815'}; time used = 5.260669708251953s
epoch 25: {'train_loss': '1.31748'}; time used = 5.5762858390808105s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 70.03586149215698.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.72997299729973, 'samples': 0.73, 'weighted': 0.72991899189919, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39503'}; time used = 1.2797484397888184s
epoch 10: {'train_loss': '1.40859'}; time used = 1.2133543491363525s
epoch 15: {'train_loss': '1.37390'}; time used = 2.294018030166626s
epoch 20: {'train_loss': '1.37298'}; time used = 2.172602653503418s
epoch 25: {'train_loss': '1.31044'}; time used = 2.142103433609009s
epoch 30: {'train_loss': '1.26766'}; time used = 2.0969078540802s
epoch 35: {'train_loss': '1.35387'}; time used = 1.722635269165039s
epoch 40: {'train_loss': '1.31193'}; time used = 1.0415732860565186s
epoch 45: {'train_loss': '1.14860'}; time used = 1.016597032546997s
epoch 50: {'train_loss': '1.23558'}; time used = 1.049717664718628s
epoch 55: {'train_loss': '1.22039'}; time used = 1.0218119621276855s
epoch 60: {'train_loss': '1.25786'}; time used = 1.0284829139709473s
epoch 65: {'train_loss': '1.02455'}; time used = 1.0597765445709229s
epoch 70: {'train_loss': '1.24392'}; time used = 0.9634411334991455s
epoch 75: {'train_loss': '1.32010'}; time used = 0.9544327259063721s
epoch 80: {'train_loss': '1.12827'}; time used = 1.0408275127410889s
epoch 85: {'train_loss': '1.22543'}; time used = 1.3406782150268555s
epoch 90: {'train_loss': '1.06919'}; time used = 2.6502685546875s
epoch 95: {'train_loss': '1.17619'}; time used = 4.051230430603027s
epoch 100: {'train_loss': '1.14890'}; time used = 3.55328631401062s
epoch 105: {'train_loss': '1.08823'}; time used = 2.1793212890625s
epoch 110: {'train_loss': '1.20788'}; time used = 2.3627333641052246s
epoch 115: {'train_loss': '1.37560'}; time used = 2.7436349391937256s
epoch 120: {'train_loss': '1.29055'}; time used = 3.1441051959991455s
epoch 125: {'train_loss': '1.01007'}; time used = 2.5814218521118164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.58854293823242.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83767'}; time used = 2.111670970916748s
epoch 10: {'train_loss': '2.77224'}; time used = 2.1111338138580322s
epoch 15: {'train_loss': '2.79451'}; time used = 1.9580028057098389s
epoch 20: {'train_loss': '2.78205'}; time used = 1.8669030666351318s
epoch 25: {'train_loss': '2.77104'}; time used = 1.9728302955627441s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.800515174865723.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.600300364728599, 'samples': 0.6086956521739131, 'weighted': 0.6044980084512561, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.74446'}; time used = 1.2208657264709473s
epoch 10: {'train_loss': '2.67673'}; time used = 1.056718349456787s
epoch 15: {'train_loss': '2.49117'}; time used = 1.047290325164795s
epoch 20: {'train_loss': '2.33324'}; time used = 1.0696923732757568s
epoch 25: {'train_loss': '2.09321'}; time used = 0.9710419178009033s
epoch 30: {'train_loss': '2.22740'}; time used = 0.9788386821746826s
epoch 35: {'train_loss': '2.19447'}; time used = 1.1018130779266357s
epoch 40: {'train_loss': '2.16904'}; time used = 0.9794063568115234s
epoch 45: {'train_loss': '2.00443'}; time used = 0.9923200607299805s
epoch 50: {'train_loss': '1.97564'}; time used = 0.9852113723754883s
epoch 55: {'train_loss': '1.93233'}; time used = 0.9863853454589844s
epoch 60: {'train_loss': '1.84586'}; time used = 1.0579345226287842s
epoch 65: {'train_loss': '1.95473'}; time used = 1.0260932445526123s
epoch 70: {'train_loss': '1.83040'}; time used = 0.9996981620788574s
epoch 75: {'train_loss': '1.82769'}; time used = 0.9798576831817627s
epoch 80: {'train_loss': '1.85007'}; time used = 0.9683184623718262s
epoch 85: {'train_loss': '1.83983'}; time used = 0.9670524597167969s
epoch 90: {'train_loss': '1.78926'}; time used = 0.9553794860839844s
epoch 95: {'train_loss': '1.83012'}; time used = 0.959791898727417s
epoch 100: {'train_loss': '1.81305'}; time used = 0.96832275390625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.25160264968872.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.110793590545654s
epoch 10: {'train_loss': '1.38629'}; time used = 4.957111835479736s
epoch 15: {'train_loss': '1.38629'}; time used = 5.262795925140381s
epoch 20: {'train_loss': '1.38629'}; time used = 4.472244501113892s
epoch 25: {'train_loss': '1.38629'}; time used = 5.264981508255005s
epoch 30: {'train_loss': '1.38629'}; time used = 7.123754501342773s
epoch 35: {'train_loss': '1.38629'}; time used = 4.840468168258667s
epoch 40: {'train_loss': '1.38629'}; time used = 4.387009859085083s
epoch 45: {'train_loss': '1.38629'}; time used = 5.334892988204956s
epoch 50: {'train_loss': '1.38629'}; time used = 9.953900337219238s
epoch 55: {'train_loss': '1.38629'}; time used = 9.420952081680298s
epoch 60: {'train_loss': '1.38629'}; time used = 9.50934624671936s
epoch 65: {'train_loss': '1.38629'}; time used = 7.0436177253723145s
epoch 70: {'train_loss': '1.38629'}; time used = 4.360978841781616s
epoch 75: {'train_loss': '1.38629'}; time used = 4.21313214302063s
epoch 80: {'train_loss': '1.38629'}; time used = 4.170555114746094s
epoch 85: {'train_loss': '1.38629'}; time used = 4.151698350906372s
epoch 90: {'train_loss': '1.38629'}; time used = 4.126182317733765s
epoch 95: {'train_loss': '1.38629'}; time used = 4.140982389450073s
epoch 100: {'train_loss': '1.38629'}; time used = 4.131036996841431s
epoch 105: {'train_loss': '1.38629'}; time used = 4.0219926834106445s
epoch 110: {'train_loss': '1.38629'}; time used = 4.282912492752075s
epoch 115: {'train_loss': '1.38629'}; time used = 4.260494709014893s
epoch 120: {'train_loss': '1.38629'}; time used = 4.686660289764404s
epoch 125: {'train_loss': '1.38629'}; time used = 6.311068773269653s
epoch 130: {'train_loss': '1.38629'}; time used = 8.53775930404663s
epoch 135: {'train_loss': '1.38629'}; time used = 4.181824207305908s
epoch 140: {'train_loss': '1.38629'}; time used = 4.142319679260254s
epoch 145: {'train_loss': '1.38629'}; time used = 4.335800886154175s
epoch 150: {'train_loss': '1.38629'}; time used = 4.239358186721802s
epoch 155: {'train_loss': '1.38629'}; time used = 4.040677547454834s
epoch 160: {'train_loss': '1.38629'}; time used = 5.634043455123901s
epoch 165: {'train_loss': '1.38629'}; time used = 6.136049270629883s
epoch 170: {'train_loss': '1.38629'}; time used = 4.1773362159729s
epoch 175: {'train_loss': '1.38629'}; time used = 5.009828805923462s
epoch 180: {'train_loss': '1.38629'}; time used = 4.963941335678101s
epoch 185: {'train_loss': '1.38629'}; time used = 4.102340936660767s
epoch 190: {'train_loss': '1.38629'}; time used = 4.12434196472168s
epoch 195: {'train_loss': '1.38629'}; time used = 3.9889392852783203s
epoch 200: {'train_loss': '1.38629'}; time used = 4.079533100128174s
epoch 205: {'train_loss': '1.38629'}; time used = 4.26685357093811s
epoch 210: {'train_loss': '1.38629'}; time used = 4.048171281814575s
epoch 215: {'train_loss': '1.38629'}; time used = 5.188896179199219s
epoch 220: {'train_loss': '1.38629'}; time used = 5.189164638519287s
epoch 225: {'train_loss': '1.38629'}; time used = 5.034027099609375s
epoch 230: {'train_loss': '1.38629'}; time used = 4.8611297607421875s
epoch 235: {'train_loss': '1.38629'}; time used = 4.963746547698975s
epoch 240: {'train_loss': '1.38629'}; time used = 4.788758754730225s
epoch 245: {'train_loss': '1.38629'}; time used = 4.118784189224243s
epoch 250: {'train_loss': '1.38629'}; time used = 4.0031163692474365s
epoch 255: {'train_loss': '1.38629'}; time used = 3.9974193572998047s
epoch 260: {'train_loss': '1.38629'}; time used = 4.052394151687622s
epoch 265: {'train_loss': '1.38629'}; time used = 4.20441460609436s
epoch 270: {'train_loss': '1.38629'}; time used = 4.160232305526733s
epoch 275: {'train_loss': '1.38629'}; time used = 4.099985122680664s
epoch 280: {'train_loss': '1.38629'}; time used = 3.9494528770446777s
epoch 285: {'train_loss': '1.38629'}; time used = 5.829861879348755s
epoch 290: {'train_loss': '1.38629'}; time used = 4.08042049407959s
epoch 295: {'train_loss': '1.38629'}; time used = 3.989189863204956s
epoch 300: {'train_loss': '1.38629'}; time used = 6.560041189193726s
epoch 305: {'train_loss': '1.38629'}; time used = 5.911759376525879s
epoch 310: {'train_loss': '1.38629'}; time used = 4.30600380897522s
epoch 315: {'train_loss': '1.38629'}; time used = 6.024043083190918s
epoch 320: {'train_loss': '1.38629'}; time used = 5.960633277893066s
epoch 325: {'train_loss': '1.38629'}; time used = 4.293520927429199s
epoch 330: {'train_loss': '1.38629'}; time used = 4.158853769302368s
epoch 335: {'train_loss': '1.38629'}; time used = 4.191279172897339s
epoch 340: {'train_loss': '1.38629'}; time used = 4.2434401512146s
epoch 345: {'train_loss': '1.38629'}; time used = 4.760775327682495s
epoch 350: {'train_loss': '1.38629'}; time used = 4.089325904846191s
epoch 355: {'train_loss': '1.38629'}; time used = 4.1533753871917725s
epoch 360: {'train_loss': '1.38629'}; time used = 4.135724306106567s
epoch 365: {'train_loss': '1.38629'}; time used = 4.255131483078003s
epoch 370: {'train_loss': '1.38629'}; time used = 4.093993902206421s
epoch 375: {'train_loss': '1.38629'}; time used = 4.232086658477783s
epoch 380: {'train_loss': '1.38629'}; time used = 4.134222745895386s
epoch 385: {'train_loss': '1.38629'}; time used = 4.452484846115112s
epoch 390: {'train_loss': '1.38629'}; time used = 4.287373065948486s
epoch 395: {'train_loss': '1.38629'}; time used = 4.180422306060791s
epoch 400: {'train_loss': '1.38629'}; time used = 4.185474872589111s
epoch 405: {'train_loss': '1.38629'}; time used = 4.206286907196045s
epoch 410: {'train_loss': '1.38629'}; time used = 4.249268054962158s
epoch 415: {'train_loss': '1.38629'}; time used = 4.162167549133301s
epoch 420: {'train_loss': '1.38629'}; time used = 4.122040271759033s
epoch 425: {'train_loss': '1.38629'}; time used = 4.284794092178345s
epoch 430: {'train_loss': '1.38629'}; time used = 4.417966842651367s
epoch 435: {'train_loss': '1.38629'}; time used = 4.217144727706909s
epoch 440: {'train_loss': '1.38629'}; time used = 4.219736576080322s
epoch 445: {'train_loss': '1.38629'}; time used = 5.567535400390625s
epoch 450: {'train_loss': '1.38629'}; time used = 4.1718809604644775s
epoch 455: {'train_loss': '1.38629'}; time used = 4.4739089012146s
epoch 460: {'train_loss': '1.38629'}; time used = 7.3249595165252686s
epoch 465: {'train_loss': '1.38629'}; time used = 4.803298473358154s
epoch 470: {'train_loss': '1.38629'}; time used = 4.617723226547241s
epoch 475: {'train_loss': '1.38629'}; time used = 4.286275148391724s
epoch 480: {'train_loss': '1.38629'}; time used = 4.367684841156006s
epoch 485: {'train_loss': '1.38629'}; time used = 4.144111156463623s
epoch 490: {'train_loss': '1.38629'}; time used = 4.058363199234009s
epoch 495: {'train_loss': '1.38629'}; time used = 4.188421964645386s
epoch 500: {'train_loss': '1.38629'}; time used = 4.2311718463897705s
Finished training. Time used = 486.73213267326355.
Training classifier using 80.00% nodes...
{'micro': 0.67, 'macro': 0.6659580929243851, 'samples': 0.67, 'weighted': 0.6652232007288187, 'accuracy': 0.67}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.55 GiB already allocated; 498.44 MiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.41718'}; time used = 1.1510906219482422s
epoch 10: {'train_loss': '2.82430'}; time used = 0.9980549812316895s
epoch 15: {'train_loss': '2.80480'}; time used = 0.9897453784942627s
epoch 20: {'train_loss': '2.80628'}; time used = 1.068800687789917s
epoch 25: {'train_loss': '2.80301'}; time used = 1.0461852550506592s
epoch 30: {'train_loss': '2.79471'}; time used = 1.0360848903656006s
epoch 35: {'train_loss': '2.78374'}; time used = 1.0415887832641602s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.586979389190674.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 228.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.23948'}; time used = 1.3540892601013184s
epoch 10: {'train_loss': '0.04622'}; time used = 1.2064552307128906s
epoch 15: {'train_loss': '0.00213'}; time used = 1.119048833847046s
epoch 20: {'train_loss': '0.00012'}; time used = 1.0922541618347168s
epoch 25: {'train_loss': '0.00743'}; time used = 1.029508113861084s
epoch 30: {'train_loss': '0.00019'}; time used = 1.1083216667175293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.14621090888977.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7564102564102564, 'samples': 0.7894736842105263, 'weighted': 0.7705802968960862, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 110.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31085'}; time used = 2.646610975265503s
epoch 10: {'train_loss': '0.99990'}; time used = 2.5102133750915527s
epoch 15: {'train_loss': '0.69996'}; time used = 2.67229962348938s
epoch 20: {'train_loss': '0.47053'}; time used = 4.134191274642944s
epoch 25: {'train_loss': '0.44749'}; time used = 4.432361364364624s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.005234956741333.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78896'}; time used = 1.8938636779785156s
epoch 10: {'train_loss': '2.80994'}; time used = 2.805509567260742s
epoch 15: {'train_loss': '2.78940'}; time used = 1.1589932441711426s
epoch 20: {'train_loss': '2.77469'}; time used = 1.098423719406128s
epoch 25: {'train_loss': '2.77286'}; time used = 1.3310108184814453s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.463729619979858.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.95 GiB already allocated; 110.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.06939'}; time used = 1.9070467948913574s
epoch 10: {'train_loss': '0.81483'}; time used = 1.7581775188446045s
epoch 15: {'train_loss': '0.83622'}; time used = 1.8312644958496094s
epoch 20: {'train_loss': '0.88522'}; time used = 1.9233548641204834s
epoch 25: {'train_loss': '1.34384'}; time used = 1.7749807834625244s
epoch 30: {'train_loss': '1.09114'}; time used = 1.6549315452575684s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.309473514556885.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.92 GiB already allocated; 150.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 452.44 MiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83524'}; time used = 2.2470388412475586s
epoch 10: {'train_loss': '2.78227'}; time used = 1.9956951141357422s
epoch 15: {'train_loss': '2.77518'}; time used = 2.050351142883301s
epoch 20: {'train_loss': '2.77085'}; time used = 2.214242696762085s
epoch 25: {'train_loss': '2.76241'}; time used = 2.1434011459350586s
epoch 30: {'train_loss': '2.75404'}; time used = 2.0202503204345703s
epoch 35: {'train_loss': '2.72837'}; time used = 2.0215415954589844s
epoch 40: {'train_loss': '2.67444'}; time used = 2.134199619293213s
epoch 45: {'train_loss': '2.61074'}; time used = 2.035922050476074s
epoch 50: {'train_loss': '2.54520'}; time used = 2.0615382194519043s
epoch 55: {'train_loss': '2.53606'}; time used = 2.157132387161255s
epoch 60: {'train_loss': '2.52760'}; time used = 2.170290946960449s
epoch 65: {'train_loss': '2.49434'}; time used = 2.0204854011535645s
epoch 70: {'train_loss': '2.47069'}; time used = 2.0416994094848633s
epoch 75: {'train_loss': '2.42366'}; time used = 2.0190422534942627s
epoch 80: {'train_loss': '2.42395'}; time used = 2.0680816173553467s
epoch 85: {'train_loss': '2.42064'}; time used = 2.0906307697296143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.720762968063354.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6057142857142858, 'samples': 0.6086956521739131, 'weighted': 0.6081987577639751, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 150.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.95757'}; time used = 2.1572344303131104s
epoch 10: {'train_loss': '0.86366'}; time used = 1.8098790645599365s
epoch 15: {'train_loss': '0.30816'}; time used = 1.8355796337127686s
epoch 20: {'train_loss': '0.05425'}; time used = 3.423022747039795s
epoch 25: {'train_loss': '0.00209'}; time used = 4.5490593910217285s
epoch 30: {'train_loss': '0.00212'}; time used = 2.5582942962646484s
epoch 35: {'train_loss': '0.00003'}; time used = 2.029740810394287s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.488295793533325.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 142.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 412.44 MiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 142.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.62762'}; time used = 1.3540153503417969s
epoch 10: {'train_loss': '0.69476'}; time used = 1.0626873970031738s
epoch 15: {'train_loss': '0.48198'}; time used = 0.997999906539917s
epoch 20: {'train_loss': '0.35423'}; time used = 1.028198003768921s
epoch 25: {'train_loss': '0.29696'}; time used = 1.0205249786376953s
epoch 30: {'train_loss': '0.17945'}; time used = 1.092437505722046s
epoch 35: {'train_loss': '0.06090'}; time used = 1.2183074951171875s
epoch 40: {'train_loss': '0.14367'}; time used = 1.176598072052002s
epoch 45: {'train_loss': '0.12563'}; time used = 1.1559765338897705s
epoch 50: {'train_loss': '0.14268'}; time used = 1.1391208171844482s
epoch 55: {'train_loss': '0.20790'}; time used = 1.1475563049316406s
epoch 60: {'train_loss': '0.12044'}; time used = 1.2866034507751465s
epoch 65: {'train_loss': '0.10281'}; time used = 1.1574838161468506s
epoch 70: {'train_loss': '0.12464'}; time used = 1.155121088027954s
epoch 75: {'train_loss': '0.11743'}; time used = 1.2351737022399902s
epoch 80: {'train_loss': '0.18700'}; time used = 1.192384958267212s
epoch 85: {'train_loss': '0.19934'}; time used = 1.1357090473175049s
epoch 90: {'train_loss': '0.02922'}; time used = 1.0674314498901367s
epoch 95: {'train_loss': '0.02426'}; time used = 0.9725790023803711s
epoch 100: {'train_loss': '0.22078'}; time used = 0.9402172565460205s
epoch 105: {'train_loss': '0.15510'}; time used = 1.0664293766021729s
epoch 110: {'train_loss': '0.15592'}; time used = 0.9317915439605713s
epoch 115: {'train_loss': '0.12253'}; time used = 0.9187130928039551s
epoch 120: {'train_loss': '0.08450'}; time used = 0.9065728187561035s
epoch 125: {'train_loss': '0.07659'}; time used = 1.7880756855010986s
epoch 130: {'train_loss': '0.07586'}; time used = 1.8949079513549805s
epoch 135: {'train_loss': '0.04628'}; time used = 1.820582389831543s
epoch 140: {'train_loss': '0.11686'}; time used = 1.7618639469146729s
epoch 145: {'train_loss': '0.11002'}; time used = 2.015181064605713s
epoch 150: {'train_loss': '0.07479'}; time used = 1.8285179138183594s
epoch 155: {'train_loss': '0.08599'}; time used = 1.0381598472595215s
epoch 160: {'train_loss': '0.05629'}; time used = 1.157346248626709s
epoch 165: {'train_loss': '0.10085'}; time used = 1.04618239402771s
epoch 170: {'train_loss': '0.08676'}; time used = 1.040085792541504s
epoch 175: {'train_loss': '0.07425'}; time used = 1.0364539623260498s
epoch 180: {'train_loss': '0.01197'}; time used = 1.8825733661651611s
epoch 185: {'train_loss': '0.04662'}; time used = 1.984173059463501s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.74639892578125.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34731'}; time used = 5.528361797332764s
epoch 10: {'train_loss': '1.29989'}; time used = 4.992833137512207s
epoch 15: {'train_loss': '1.19635'}; time used = 4.892277479171753s
epoch 20: {'train_loss': '1.13176'}; time used = 4.818044185638428s
epoch 25: {'train_loss': '1.02228'}; time used = 5.222461938858032s
epoch 30: {'train_loss': '0.63209'}; time used = 4.967090606689453s
epoch 35: {'train_loss': '0.60894'}; time used = 4.890151739120483s
epoch 40: {'train_loss': '0.52547'}; time used = 4.873931884765625s
epoch 45: {'train_loss': '0.43099'}; time used = 4.89193868637085s
epoch 50: {'train_loss': '0.94969'}; time used = 5.231464147567749s
epoch 55: {'train_loss': '0.52241'}; time used = 5.334824562072754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 76.12960910797119.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99344'}; time used = 1.8491711616516113s
epoch 10: {'train_loss': '0.27171'}; time used = 1.6751370429992676s
epoch 15: {'train_loss': '0.09573'}; time used = 1.8723623752593994s
epoch 20: {'train_loss': '0.23790'}; time used = 1.7073051929473877s
epoch 25: {'train_loss': '0.15686'}; time used = 1.8419485092163086s
epoch 30: {'train_loss': '0.09935'}; time used = 1.668283224105835s
epoch 35: {'train_loss': '0.07928'}; time used = 1.6914632320404053s
epoch 40: {'train_loss': '0.19133'}; time used = 1.6453840732574463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.411165237426758.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.62 GiB already allocated; 446.44 MiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.47860'}; time used = 1.601410150527954s
epoch 10: {'train_loss': '0.18238'}; time used = 1.397740125656128s
epoch 15: {'train_loss': '0.13222'}; time used = 1.4487628936767578s
epoch 20: {'train_loss': '0.22015'}; time used = 1.4023406505584717s
epoch 25: {'train_loss': '0.15167'}; time used = 1.3995270729064941s
epoch 30: {'train_loss': '0.13900'}; time used = 1.3846197128295898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.747923851013184.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_convc.py", line 51, in forward
    pre_sup = torch.mm(x, getattr(self, 'weights'))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 8.44 MiB free; 6.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39426'}; time used = 1.1818578243255615s
epoch 10: {'train_loss': '1.38112'}; time used = 1.011040210723877s
epoch 15: {'train_loss': '1.29377'}; time used = 0.9805586338043213s
epoch 20: {'train_loss': '1.29119'}; time used = 0.9639527797698975s
epoch 25: {'train_loss': '1.05462'}; time used = 0.9690918922424316s
epoch 30: {'train_loss': '1.20096'}; time used = 1.202660083770752s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.672917366027832.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4933333333333334, 'samples': 0.5526315789473685, 'weighted': 0.520701754385965, 'accuracy': 0.5526315789473685}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.8552939891815186s
epoch 10: {'train_loss': '1.38629'}; time used = 6.415229320526123s
epoch 15: {'train_loss': '1.38629'}; time used = 8.00884747505188s
epoch 20: {'train_loss': '1.38629'}; time used = 5.927746295928955s
epoch 25: {'train_loss': '1.38629'}; time used = 4.4685282707214355s
epoch 30: {'train_loss': '1.38629'}; time used = 4.204691648483276s
epoch 35: {'train_loss': '1.38629'}; time used = 6.591628789901733s
epoch 40: {'train_loss': '1.38629'}; time used = 5.7226481437683105s
epoch 45: {'train_loss': '1.38629'}; time used = 4.367691278457642s
epoch 50: {'train_loss': '1.38629'}; time used = 4.46506142616272s
epoch 55: {'train_loss': '1.38629'}; time used = 4.202466011047363s
epoch 60: {'train_loss': '1.38629'}; time used = 4.304314613342285s
epoch 65: {'train_loss': '1.38629'}; time used = 4.096817493438721s
epoch 70: {'train_loss': '1.38629'}; time used = 4.108289957046509s
epoch 75: {'train_loss': '1.38629'}; time used = 4.030638694763184s
epoch 80: {'train_loss': '1.38629'}; time used = 4.255418539047241s
epoch 85: {'train_loss': '1.38629'}; time used = 4.3666791915893555s
epoch 90: {'train_loss': '1.38629'}; time used = 4.195596218109131s
epoch 95: {'train_loss': '1.38629'}; time used = 4.1295530796051025s
epoch 100: {'train_loss': '1.38629'}; time used = 4.160564184188843s
epoch 105: {'train_loss': '1.38629'}; time used = 3.9812679290771484s
epoch 110: {'train_loss': '1.38629'}; time used = 4.231014013290405s
epoch 115: {'train_loss': '1.38629'}; time used = 4.2299065589904785s
epoch 120: {'train_loss': '1.38629'}; time used = 4.069377183914185s
epoch 125: {'train_loss': '1.38629'}; time used = 4.103728294372559s
epoch 130: {'train_loss': '1.38629'}; time used = 4.123658895492554s
epoch 135: {'train_loss': '1.38629'}; time used = 4.101876974105835s
epoch 140: {'train_loss': '1.38629'}; time used = 4.264189720153809s
epoch 145: {'train_loss': '1.38629'}; time used = 4.0977160930633545s
epoch 150: {'train_loss': '1.38629'}; time used = 4.147618770599365s
epoch 155: {'train_loss': '1.38629'}; time used = 4.167896032333374s
epoch 160: {'train_loss': '1.38629'}; time used = 4.224492788314819s
epoch 165: {'train_loss': '1.38629'}; time used = 4.372080564498901s
epoch 170: {'train_loss': '1.38629'}; time used = 4.202114582061768s
epoch 175: {'train_loss': '1.38629'}; time used = 6.123847961425781s
epoch 180: {'train_loss': '1.38629'}; time used = 4.797111988067627s
epoch 185: {'train_loss': '1.38629'}; time used = 4.657779216766357s
epoch 190: {'train_loss': '1.38629'}; time used = 4.1538355350494385s
epoch 195: {'train_loss': '1.38629'}; time used = 4.020533800125122s
epoch 200: {'train_loss': '1.38629'}; time used = 4.125735521316528s
epoch 205: {'train_loss': '1.38629'}; time used = 4.3022308349609375s
epoch 210: {'train_loss': '1.38629'}; time used = 4.600500583648682s
epoch 215: {'train_loss': '1.38629'}; time used = 4.10772967338562s
epoch 220: {'train_loss': '1.38629'}; time used = 5.789529800415039s
epoch 225: {'train_loss': '1.38629'}; time used = 6.7290260791778564s
epoch 230: {'train_loss': '1.38629'}; time used = 4.413276195526123s
epoch 235: {'train_loss': '1.38629'}; time used = 4.329980850219727s
epoch 240: {'train_loss': '1.38629'}; time used = 4.141540050506592s
epoch 245: {'train_loss': '1.38629'}; time used = 4.15583348274231s
epoch 250: {'train_loss': '1.38629'}; time used = 4.178892612457275s
epoch 255: {'train_loss': '1.38629'}; time used = 4.320481061935425s
epoch 260: {'train_loss': '1.38629'}; time used = 5.978147029876709s
epoch 265: {'train_loss': '1.38629'}; time used = 6.080926418304443s
epoch 270: {'train_loss': '1.38629'}; time used = 4.2625486850738525s
epoch 275: {'train_loss': '1.38629'}; time used = 4.633078098297119s
epoch 280: {'train_loss': '1.38629'}; time used = 5.3692615032196045s
epoch 285: {'train_loss': '1.38629'}; time used = 4.218570947647095s
epoch 290: {'train_loss': '1.38629'}; time used = 4.151607513427734s
epoch 295: {'train_loss': '1.38629'}; time used = 4.52340841293335s
epoch 300: {'train_loss': '1.38629'}; time used = 4.345837831497192s
epoch 305: {'train_loss': '1.38629'}; time used = 3.963405132293701s
epoch 310: {'train_loss': '1.38629'}; time used = 4.031835079193115s
epoch 315: {'train_loss': '1.38629'}; time used = 4.05338716506958s
epoch 320: {'train_loss': '1.38629'}; time used = 4.214050531387329s
epoch 325: {'train_loss': '1.38629'}; time used = 4.182969808578491s
epoch 330: {'train_loss': '1.38629'}; time used = 4.115824460983276s
epoch 335: {'train_loss': '1.38629'}; time used = 6.355297088623047s
epoch 340: {'train_loss': '1.38629'}; time used = 5.68673300743103s
epoch 345: {'train_loss': '1.38629'}; time used = 4.149903297424316s
epoch 350: {'train_loss': '1.38629'}; time used = 4.159282445907593s
epoch 355: {'train_loss': '1.38629'}; time used = 4.070071220397949s
epoch 360: {'train_loss': '1.38629'}; time used = 4.169564962387085s
epoch 365: {'train_loss': '1.38629'}; time used = 4.248912811279297s
epoch 370: {'train_loss': '1.38629'}; time used = 4.306438446044922s
epoch 375: {'train_loss': '1.38629'}; time used = 4.2134294509887695s
epoch 380: {'train_loss': '1.38629'}; time used = 4.2649571895599365s
epoch 385: {'train_loss': '1.38629'}; time used = 4.301990985870361s
epoch 390: {'train_loss': '1.38629'}; time used = 4.184799909591675s
epoch 395: {'train_loss': '1.38629'}; time used = 4.167357444763184s
epoch 400: {'train_loss': '1.38629'}; time used = 4.265312433242798s
epoch 405: {'train_loss': '1.38629'}; time used = 4.185625791549683s
epoch 410: {'train_loss': '1.38629'}; time used = 4.252139329910278s
epoch 415: {'train_loss': '1.38629'}; time used = 4.329020977020264s
epoch 420: {'train_loss': '1.38629'}; time used = 4.21601676940918s
epoch 425: {'train_loss': '1.38629'}; time used = 4.101433277130127s
epoch 430: {'train_loss': '1.38629'}; time used = 4.084688425064087s
epoch 435: {'train_loss': '1.38629'}; time used = 4.396062135696411s
epoch 440: {'train_loss': '1.38629'}; time used = 4.171562671661377s
epoch 445: {'train_loss': '1.38629'}; time used = 4.173057794570923s
epoch 450: {'train_loss': '1.38629'}; time used = 4.206472635269165s
epoch 455: {'train_loss': '1.38629'}; time used = 4.192637205123901s
epoch 460: {'train_loss': '1.38629'}; time used = 4.165623188018799s
epoch 465: {'train_loss': '1.38629'}; time used = 4.284754753112793s
epoch 470: {'train_loss': '1.38629'}; time used = 4.6598310470581055s
epoch 475: {'train_loss': '1.38629'}; time used = 4.204469680786133s
epoch 480: {'train_loss': '1.38629'}; time used = 4.52238130569458s
epoch 485: {'train_loss': '1.38629'}; time used = 4.22575831413269s
epoch 490: {'train_loss': '1.38629'}; time used = 4.29292106628418s
epoch 495: {'train_loss': '1.38629'}; time used = 4.24046516418457s
epoch 500: {'train_loss': '1.38629'}; time used = 4.289964199066162s
Finished training. Time used = 457.29903388023376.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 4.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78059'}; time used = 1.2983806133270264s
epoch 10: {'train_loss': '2.77964'}; time used = 1.0173022747039795s
epoch 15: {'train_loss': '2.77958'}; time used = 1.0266304016113281s
epoch 20: {'train_loss': '2.77487'}; time used = 1.0324039459228516s
epoch 25: {'train_loss': '2.77245'}; time used = 1.086988925933838s
epoch 30: {'train_loss': '2.77301'}; time used = 1.03867506980896s
epoch 35: {'train_loss': '2.77362'}; time used = 1.048248291015625s
epoch 40: {'train_loss': '2.77244'}; time used = 1.0420386791229248s
epoch 45: {'train_loss': '2.77292'}; time used = 1.0473544597625732s
epoch 50: {'train_loss': '2.77126'}; time used = 1.0250275135040283s
epoch 55: {'train_loss': '2.77147'}; time used = 1.0130393505096436s
epoch 60: {'train_loss': '2.77144'}; time used = 0.9961504936218262s
epoch 65: {'train_loss': '2.77021'}; time used = 1.1535835266113281s
epoch 70: {'train_loss': '2.76924'}; time used = 0.9756684303283691s
epoch 75: {'train_loss': '2.76904'}; time used = 1.01393723487854s
epoch 80: {'train_loss': '2.76791'}; time used = 1.1029644012451172s
epoch 85: {'train_loss': '2.76681'}; time used = 1.1817269325256348s
epoch 90: {'train_loss': '2.76518'}; time used = 1.2395548820495605s
epoch 95: {'train_loss': '2.76535'}; time used = 1.170785665512085s
epoch 100: {'train_loss': '2.76466'}; time used = 1.1685404777526855s
epoch 105: {'train_loss': '2.76308'}; time used = 1.165517807006836s
epoch 110: {'train_loss': '2.76391'}; time used = 1.1546411514282227s
epoch 115: {'train_loss': '2.76122'}; time used = 1.2259008884429932s
epoch 120: {'train_loss': '2.76258'}; time used = 1.0048627853393555s
epoch 125: {'train_loss': '2.76317'}; time used = 0.9236793518066406s
epoch 130: {'train_loss': '2.76128'}; time used = 0.965106725692749s
epoch 135: {'train_loss': '2.76196'}; time used = 0.9728653430938721s
epoch 140: {'train_loss': '2.76357'}; time used = 1.0381579399108887s
epoch 145: {'train_loss': '2.75953'}; time used = 0.9435765743255615s
epoch 150: {'train_loss': '2.76283'}; time used = 0.938148021697998s
epoch 155: {'train_loss': '2.75903'}; time used = 0.978813886642456s
epoch 160: {'train_loss': '2.75971'}; time used = 0.9374954700469971s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.68224000930786.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 188.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77051'}; time used = 1.2848775386810303s
epoch 10: {'train_loss': '2.79333'}; time used = 1.0329821109771729s
epoch 15: {'train_loss': '2.71861'}; time used = 1.7144644260406494s
epoch 20: {'train_loss': '2.42166'}; time used = 2.1443264484405518s
epoch 25: {'train_loss': '1.85531'}; time used = 1.5037944316864014s
epoch 30: {'train_loss': '1.92331'}; time used = 1.0215377807617188s
epoch 35: {'train_loss': '1.70951'}; time used = 1.0333735942840576s
epoch 40: {'train_loss': '1.64813'}; time used = 1.1559967994689941s
epoch 45: {'train_loss': '1.57795'}; time used = 1.2964212894439697s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.795531749725342.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.30653'}; time used = 1.8792483806610107s
epoch 10: {'train_loss': '1.23310'}; time used = 1.8436822891235352s
epoch 15: {'train_loss': '1.21731'}; time used = 2.009164333343506s
epoch 20: {'train_loss': '1.31929'}; time used = 2.020723819732666s
epoch 25: {'train_loss': '1.28410'}; time used = 1.9339947700500488s
epoch 30: {'train_loss': '1.20863'}; time used = 1.9636931419372559s
epoch 35: {'train_loss': '1.23904'}; time used = 1.808274507522583s
epoch 40: {'train_loss': '1.19874'}; time used = 1.816246509552002s
epoch 45: {'train_loss': '1.27081'}; time used = 1.9971017837524414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.18081021308899.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12015'}; time used = 2.4038267135620117s
epoch 10: {'train_loss': '0.17893'}; time used = 1.9590277671813965s
epoch 15: {'train_loss': '0.00016'}; time used = 1.9557089805603027s
epoch 20: {'train_loss': '0.00001'}; time used = 1.9581878185272217s
epoch 25: {'train_loss': '0.00000'}; time used = 2.0531179904937744s
epoch 30: {'train_loss': '0.00000'}; time used = 1.959669828414917s
epoch 35: {'train_loss': '0.00278'}; time used = 1.9652371406555176s
epoch 40: {'train_loss': '0.00000'}; time used = 1.9684290885925293s
epoch 45: {'train_loss': '0.00000'}; time used = 1.9927926063537598s
epoch 50: {'train_loss': '0.00000'}; time used = 1.985273838043213s
epoch 55: {'train_loss': '0.00013'}; time used = 2.047520637512207s
epoch 60: {'train_loss': '0.00000'}; time used = 2.050852060317993s
epoch 65: {'train_loss': '0.00000'}; time used = 2.0470149517059326s
epoch 70: {'train_loss': '0.00000'}; time used = 1.9896583557128906s
epoch 75: {'train_loss': '0.00000'}; time used = 2.0779366493225098s
epoch 80: {'train_loss': '0.00000'}; time used = 2.060260057449341s
epoch 85: {'train_loss': '0.00000'}; time used = 2.1198480129241943s
epoch 90: {'train_loss': '0.00000'}; time used = 2.02382755279541s
epoch 95: {'train_loss': '0.00000'}; time used = 1.9765045642852783s
epoch 100: {'train_loss': '0.00000'}; time used = 2.1260297298431396s
epoch 105: {'train_loss': '0.00000'}; time used = 2.083435535430908s
epoch 110: {'train_loss': '0.00000'}; time used = 2.0301053524017334s
epoch 115: {'train_loss': '0.00000'}; time used = 2.1384119987487793s
epoch 120: {'train_loss': '0.00000'}; time used = 2.036985397338867s
epoch 125: {'train_loss': '0.00000'}; time used = 2.048521041870117s
epoch 130: {'train_loss': '0.00000'}; time used = 2.1595492362976074s
epoch 135: {'train_loss': '0.00000'}; time used = 2.226541042327881s
epoch 140: {'train_loss': '0.00000'}; time used = 2.0036935806274414s
epoch 145: {'train_loss': '0.00000'}; time used = 2.093785524368286s
epoch 150: {'train_loss': '0.00000'}; time used = 4.19551157951355s
epoch 155: {'train_loss': '0.00000'}; time used = 3.6557297706604004s
epoch 160: {'train_loss': '0.00000'}; time used = 3.3277697563171387s
epoch 165: {'train_loss': '0.00000'}; time used = 3.294353485107422s
epoch 170: {'train_loss': '0.00000'}; time used = 2.551530361175537s
epoch 175: {'train_loss': '0.00000'}; time used = 2.427967071533203s
epoch 180: {'train_loss': '0.00000'}; time used = 3.516617774963379s
epoch 185: {'train_loss': '0.00000'}; time used = 3.7533304691314697s
epoch 190: {'train_loss': '0.00000'}; time used = 3.4027626514434814s
epoch 195: {'train_loss': '0.00000'}; time used = 2.255284070968628s
epoch 200: {'train_loss': '0.00000'}; time used = 2.063913345336914s
epoch 205: {'train_loss': '0.00000'}; time used = 2.1979434490203857s
epoch 210: {'train_loss': '0.00000'}; time used = 2.581570625305176s
epoch 215: {'train_loss': '0.00000'}; time used = 2.0558371543884277s
epoch 220: {'train_loss': '0.00000'}; time used = 1.9636256694793701s
epoch 225: {'train_loss': '0.00000'}; time used = 2.2151975631713867s
epoch 230: {'train_loss': '0.00000'}; time used = 3.2203524112701416s
epoch 235: {'train_loss': '0.00000'}; time used = 3.1373751163482666s
epoch 240: {'train_loss': '0.00000'}; time used = 2.979919195175171s
epoch 245: {'train_loss': '0.00000'}; time used = 1.9288246631622314s
epoch 250: {'train_loss': '0.00000'}; time used = 1.9929265975952148s
epoch 255: {'train_loss': '0.00000'}; time used = 1.9648122787475586s
epoch 260: {'train_loss': '0.00000'}; time used = 1.950908899307251s
epoch 265: {'train_loss': '0.00000'}; time used = 1.9815244674682617s
epoch 270: {'train_loss': '0.00000'}; time used = 2.0045371055603027s
epoch 275: {'train_loss': '0.00000'}; time used = 1.9986114501953125s
epoch 280: {'train_loss': '0.00000'}; time used = 2.0092051029205322s
epoch 285: {'train_loss': '0.00000'}; time used = 2.009251832962036s
epoch 290: {'train_loss': '0.00000'}; time used = 1.9789133071899414s
epoch 295: {'train_loss': '0.00000'}; time used = 1.9869630336761475s
epoch 300: {'train_loss': '0.00000'}; time used = 1.9583461284637451s
epoch 305: {'train_loss': '0.00000'}; time used = 3.438457727432251s
epoch 310: {'train_loss': '0.00000'}; time used = 2.304809808731079s
epoch 315: {'train_loss': '0.00000'}; time used = 3.2434847354888916s
epoch 320: {'train_loss': '0.00000'}; time used = 2.2728402614593506s
epoch 325: {'train_loss': '0.00000'}; time used = 2.010723114013672s
epoch 330: {'train_loss': '0.00000'}; time used = 1.958878993988037s
epoch 335: {'train_loss': '0.00000'}; time used = 1.9881064891815186s
epoch 340: {'train_loss': '0.00000'}; time used = 2.287553071975708s
epoch 345: {'train_loss': '0.00000'}; time used = 3.293238878250122s
epoch 350: {'train_loss': '0.00000'}; time used = 3.414511203765869s
epoch 355: {'train_loss': '0.00005'}; time used = 3.3372762203216553s
epoch 360: {'train_loss': '0.00000'}; time used = 2.0672388076782227s
epoch 365: {'train_loss': '0.00000'}; time used = 2.0768308639526367s
epoch 370: {'train_loss': '0.00000'}; time used = 1.9984290599822998s
epoch 375: {'train_loss': '0.00000'}; time used = 2.088839292526245s
epoch 380: {'train_loss': '0.00000'}; time used = 2.0279276371002197s
epoch 385: {'train_loss': '0.00000'}; time used = 2.0986523628234863s
epoch 390: {'train_loss': '0.00000'}; time used = 2.089198350906372s
epoch 395: {'train_loss': '0.00000'}; time used = 1.9253668785095215s
epoch 400: {'train_loss': '0.00000'}; time used = 2.050737142562866s
epoch 405: {'train_loss': '0.00000'}; time used = 2.106224536895752s
epoch 410: {'train_loss': '0.00000'}; time used = 1.9400100708007812s
epoch 415: {'train_loss': '0.00000'}; time used = 2.1403048038482666s
epoch 420: {'train_loss': '0.00000'}; time used = 2.0568408966064453s
epoch 425: {'train_loss': '0.00000'}; time used = 1.9679017066955566s
epoch 430: {'train_loss': '0.00000'}; time used = 2.0360007286071777s
epoch 435: {'train_loss': '0.00000'}; time used = 1.9834554195404053s
epoch 440: {'train_loss': '0.00000'}; time used = 1.9717297554016113s
epoch 445: {'train_loss': '0.00000'}; time used = 1.9192097187042236s
epoch 450: {'train_loss': '0.00000'}; time used = 1.9446656703948975s
epoch 455: {'train_loss': '0.00001'}; time used = 1.9266839027404785s
epoch 460: {'train_loss': '0.00018'}; time used = 2.0851893424987793s
epoch 465: {'train_loss': '0.00000'}; time used = 2.804933786392212s
epoch 470: {'train_loss': '0.00006'}; time used = 2.7989683151245117s
epoch 475: {'train_loss': '0.99074'}; time used = 2.1787426471710205s
epoch 480: {'train_loss': '0.25285'}; time used = 1.9922161102294922s
epoch 485: {'train_loss': '0.00035'}; time used = 2.0851316452026367s
epoch 490: {'train_loss': '0.00002'}; time used = 1.9430272579193115s
epoch 495: {'train_loss': '0.00000'}; time used = 3.1776692867279053s
epoch 500: {'train_loss': '0.00003'}; time used = 3.248569965362549s
Finished training. Time used = 233.42692685127258.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.16001'}; time used = 1.014491081237793s
epoch 10: {'train_loss': '0.98014'}; time used = 0.9844048023223877s
epoch 15: {'train_loss': '0.89485'}; time used = 0.9362201690673828s
epoch 20: {'train_loss': '0.61166'}; time used = 1.0396788120269775s
epoch 25: {'train_loss': '0.43632'}; time used = 0.9915595054626465s
epoch 30: {'train_loss': '0.31035'}; time used = 1.6760973930358887s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.045749425888062.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.35380'}; time used = 0.9862203598022461s
epoch 10: {'train_loss': '0.24596'}; time used = 0.9952442646026611s
epoch 15: {'train_loss': '0.24066'}; time used = 1.0522773265838623s
epoch 20: {'train_loss': '0.23398'}; time used = 1.0485544204711914s
epoch 25: {'train_loss': '0.27155'}; time used = 1.0276861190795898s
epoch 30: {'train_loss': '0.19694'}; time used = 1.0208687782287598s
epoch 35: {'train_loss': '0.20978'}; time used = 1.0473759174346924s
epoch 40: {'train_loss': '0.19240'}; time used = 1.0318913459777832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.450080633163452.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.97617'}; time used = 3.2706568241119385s
epoch 10: {'train_loss': '2.81092'}; time used = 1.7389163970947266s
epoch 15: {'train_loss': '2.81442'}; time used = 1.7142479419708252s
epoch 20: {'train_loss': '2.79567'}; time used = 1.832338809967041s
epoch 25: {'train_loss': '2.77935'}; time used = 2.387216329574585s
epoch 30: {'train_loss': '2.76147'}; time used = 1.6649701595306396s
epoch 35: {'train_loss': '2.72718'}; time used = 1.6663174629211426s
epoch 40: {'train_loss': '2.66107'}; time used = 1.6615545749664307s
epoch 45: {'train_loss': '2.59866'}; time used = 1.6028456687927246s
epoch 50: {'train_loss': '2.54052'}; time used = 1.6166751384735107s
epoch 55: {'train_loss': '2.49920'}; time used = 1.670546293258667s
epoch 60: {'train_loss': '2.44508'}; time used = 1.7968769073486328s
epoch 65: {'train_loss': '2.30585'}; time used = 1.6720728874206543s
epoch 70: {'train_loss': '2.28413'}; time used = 1.6216869354248047s
epoch 75: {'train_loss': '2.16943'}; time used = 1.6271324157714844s
epoch 80: {'train_loss': '2.11720'}; time used = 1.7162339687347412s
epoch 85: {'train_loss': '2.07543'}; time used = 3.496922492980957s
epoch 90: {'train_loss': '2.04735'}; time used = 2.2766125202178955s
epoch 95: {'train_loss': '2.02675'}; time used = 1.6119294166564941s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.67841982841492.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5527777777777778, 'samples': 0.5942028985507246, 'weighted': 0.5626409017713365, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 498.44 MiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 352.44 MiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.88521'}; time used = 1.943526029586792s
epoch 10: {'train_loss': '2.83284'}; time used = 1.7575807571411133s
epoch 15: {'train_loss': '2.77521'}; time used = 1.906569242477417s
epoch 20: {'train_loss': '2.78328'}; time used = 1.7870941162109375s
epoch 25: {'train_loss': '2.77080'}; time used = 2.0662593841552734s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.555315017700195.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27720'}; time used = 2.155057907104492s
epoch 10: {'train_loss': '2.89442'}; time used = 1.8090734481811523s
epoch 15: {'train_loss': '2.83683'}; time used = 1.7895331382751465s
epoch 20: {'train_loss': '2.78746'}; time used = 1.7368218898773193s
epoch 25: {'train_loss': '2.77191'}; time used = 1.7936043739318848s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.393996000289917.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.81 GiB already allocated; 248.44 MiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38683'}; time used = 1.477921962738037s
epoch 10: {'train_loss': '1.43138'}; time used = 1.4883496761322021s
epoch 15: {'train_loss': '1.39949'}; time used = 1.4170777797698975s
epoch 20: {'train_loss': '1.35106'}; time used = 1.4222276210784912s
epoch 25: {'train_loss': '1.38615'}; time used = 2.4823391437530518s
epoch 30: {'train_loss': '1.36777'}; time used = 2.6478121280670166s
epoch 35: {'train_loss': '1.38722'}; time used = 2.676295042037964s
epoch 40: {'train_loss': '1.36744'}; time used = 2.6421315670013428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.705775260925293.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.09874'}; time used = 1.2215335369110107s
epoch 10: {'train_loss': '0.82119'}; time used = 1.2429485321044922s
epoch 15: {'train_loss': '0.70543'}; time used = 1.210649013519287s
epoch 20: {'train_loss': '0.58400'}; time used = 1.217278003692627s
epoch 25: {'train_loss': '0.54342'}; time used = 1.4796416759490967s
epoch 30: {'train_loss': '0.30791'}; time used = 1.8986701965332031s
epoch 35: {'train_loss': '0.15539'}; time used = 1.9634032249450684s
epoch 40: {'train_loss': '0.08669'}; time used = 2.085599184036255s
epoch 45: {'train_loss': '0.07028'}; time used = 2.0347635746002197s
epoch 50: {'train_loss': '0.05826'}; time used = 1.1944642066955566s
epoch 55: {'train_loss': '0.04968'}; time used = 1.1654622554779053s
epoch 60: {'train_loss': '0.02340'}; time used = 1.277376413345337s
epoch 65: {'train_loss': '0.02842'}; time used = 1.140500783920288s
epoch 70: {'train_loss': '0.02942'}; time used = 1.2586562633514404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.26222848892212.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82259'}; time used = 1.2215948104858398s
epoch 10: {'train_loss': '2.66416'}; time used = 1.1089744567871094s
epoch 15: {'train_loss': '2.04933'}; time used = 0.9911913871765137s
epoch 20: {'train_loss': '1.69356'}; time used = 1.8437869548797607s
epoch 25: {'train_loss': '1.63660'}; time used = 1.860100507736206s
epoch 30: {'train_loss': '1.71458'}; time used = 1.8306388854980469s
epoch 35: {'train_loss': '1.37390'}; time used = 1.7793869972229004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.534410238265991.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 82.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 412.44 MiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.25048'}; time used = 1.8176171779632568s
epoch 10: {'train_loss': '2.80899'}; time used = 1.7166774272918701s
epoch 15: {'train_loss': '2.78500'}; time used = 1.7873847484588623s
epoch 20: {'train_loss': '2.79362'}; time used = 2.0318243503570557s
epoch 25: {'train_loss': '2.77278'}; time used = 1.9230172634124756s
epoch 30: {'train_loss': '2.77182'}; time used = 1.6999578475952148s
epoch 35: {'train_loss': '2.77149'}; time used = 1.8185148239135742s
epoch 40: {'train_loss': '2.76948'}; time used = 1.8051764965057373s
epoch 45: {'train_loss': '2.76961'}; time used = 2.02397084236145s
epoch 50: {'train_loss': '2.76653'}; time used = 2.0123190879821777s
epoch 55: {'train_loss': '2.76921'}; time used = 1.9425544738769531s
epoch 60: {'train_loss': '2.76572'}; time used = 1.8308374881744385s
epoch 65: {'train_loss': '2.76186'}; time used = 2.0227365493774414s
epoch 70: {'train_loss': '2.76115'}; time used = 2.006154775619507s
epoch 75: {'train_loss': '2.75694'}; time used = 2.1206319332122803s
epoch 80: {'train_loss': '2.75809'}; time used = 2.1309690475463867s
epoch 85: {'train_loss': '2.75705'}; time used = 1.9132561683654785s
epoch 90: {'train_loss': '2.75294'}; time used = 2.06198787689209s
epoch 95: {'train_loss': '2.75363'}; time used = 1.7989437580108643s
epoch 100: {'train_loss': '2.75623'}; time used = 1.867729902267456s
epoch 105: {'train_loss': '2.75144'}; time used = 1.8836514949798584s
epoch 110: {'train_loss': '2.75086'}; time used = 1.9435088634490967s
epoch 115: {'train_loss': '2.74366'}; time used = 1.7138476371765137s
epoch 120: {'train_loss': '2.74517'}; time used = 1.6793038845062256s
epoch 125: {'train_loss': '2.74180'}; time used = 1.7228708267211914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.96420907974243.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5179175118323192, 'samples': 0.5507246376811594, 'weighted': 0.5270306023458858, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85620'}; time used = 4.488487720489502s
epoch 10: {'train_loss': '2.78187'}; time used = 3.8982818126678467s
epoch 15: {'train_loss': '2.77542'}; time used = 5.999526023864746s
epoch 20: {'train_loss': '2.78389'}; time used = 6.377181768417358s
epoch 25: {'train_loss': '2.77568'}; time used = 4.169246196746826s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.842122077941895.
Training classifier using 80.00% nodes...
{'micro': 0.66, 'macro': 0.6594551282051282, 'samples': 0.66, 'weighted': 0.6597275641025641, 'accuracy': 0.66}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.703994512557983s
epoch 10: {'train_loss': '1.38629'}; time used = 6.545470952987671s
epoch 15: {'train_loss': '1.38629'}; time used = 6.444950103759766s
epoch 20: {'train_loss': '1.38629'}; time used = 6.564985752105713s
epoch 25: {'train_loss': '1.38629'}; time used = 6.6935319900512695s
epoch 30: {'train_loss': '1.38629'}; time used = 6.394957065582275s
epoch 35: {'train_loss': '1.38629'}; time used = 6.430412292480469s
epoch 40: {'train_loss': '1.38629'}; time used = 6.420738458633423s
epoch 45: {'train_loss': '1.38629'}; time used = 6.50663161277771s
epoch 50: {'train_loss': '1.38629'}; time used = 6.521474361419678s
epoch 55: {'train_loss': '1.38629'}; time used = 6.8508970737457275s
epoch 60: {'train_loss': '1.38629'}; time used = 6.531661033630371s
epoch 65: {'train_loss': '1.38629'}; time used = 6.670411825180054s
epoch 70: {'train_loss': '1.38629'}; time used = 6.687645196914673s
epoch 75: {'train_loss': '1.38629'}; time used = 6.439040184020996s
epoch 80: {'train_loss': '1.38629'}; time used = 6.4305737018585205s
epoch 85: {'train_loss': '1.38629'}; time used = 6.467263460159302s
epoch 90: {'train_loss': '1.38629'}; time used = 6.581190824508667s
epoch 95: {'train_loss': '1.38629'}; time used = 6.492820739746094s
epoch 100: {'train_loss': '1.38629'}; time used = 6.621242046356201s
epoch 105: {'train_loss': '1.38629'}; time used = 6.515950441360474s
epoch 110: {'train_loss': '1.38629'}; time used = 6.402146100997925s
epoch 115: {'train_loss': '1.38629'}; time used = 6.455886602401733s
epoch 120: {'train_loss': '1.38629'}; time used = 6.449753761291504s
epoch 125: {'train_loss': '1.38629'}; time used = 6.3866965770721436s
epoch 130: {'train_loss': '1.38629'}; time used = 6.569213151931763s
epoch 135: {'train_loss': '1.38629'}; time used = 6.566529750823975s
epoch 140: {'train_loss': '1.38629'}; time used = 6.348570823669434s
epoch 145: {'train_loss': '1.38629'}; time used = 6.427998065948486s
epoch 150: {'train_loss': '1.38629'}; time used = 6.412465810775757s
epoch 155: {'train_loss': '1.38629'}; time used = 6.4469053745269775s
epoch 160: {'train_loss': '1.38629'}; time used = 6.552920818328857s
epoch 165: {'train_loss': '1.38629'}; time used = 6.717771530151367s
epoch 170: {'train_loss': '1.38629'}; time used = 6.441403388977051s
epoch 175: {'train_loss': '1.38629'}; time used = 6.530158519744873s
epoch 180: {'train_loss': '1.38629'}; time used = 6.428751707077026s
epoch 185: {'train_loss': '1.38629'}; time used = 6.479919672012329s
epoch 190: {'train_loss': '1.38629'}; time used = 6.475179672241211s
epoch 195: {'train_loss': '1.38629'}; time used = 6.382561922073364s
epoch 200: {'train_loss': '1.38629'}; time used = 6.715763807296753s
epoch 205: {'train_loss': '1.38629'}; time used = 6.582004547119141s
epoch 210: {'train_loss': '1.38629'}; time used = 6.397549629211426s
epoch 215: {'train_loss': '1.38629'}; time used = 6.364041566848755s
epoch 220: {'train_loss': '1.38629'}; time used = 6.402785301208496s
epoch 225: {'train_loss': '1.38629'}; time used = 6.298691987991333s
epoch 230: {'train_loss': '1.38629'}; time used = 6.822296857833862s
epoch 235: {'train_loss': '1.38629'}; time used = 6.669894695281982s
epoch 240: {'train_loss': '1.38629'}; time used = 6.422554969787598s
epoch 245: {'train_loss': '1.38629'}; time used = 6.346922397613525s
epoch 250: {'train_loss': '1.38629'}; time used = 6.377868413925171s
epoch 255: {'train_loss': '1.38629'}; time used = 6.825681447982788s
epoch 260: {'train_loss': '1.38629'}; time used = 6.410818099975586s
epoch 265: {'train_loss': '1.38629'}; time used = 6.377786636352539s
epoch 270: {'train_loss': '1.38629'}; time used = 6.354490756988525s
epoch 275: {'train_loss': '1.38629'}; time used = 6.6021888256073s
epoch 280: {'train_loss': '1.38629'}; time used = 6.4030678272247314s
epoch 285: {'train_loss': '1.38629'}; time used = 6.632046699523926s
epoch 290: {'train_loss': '1.38629'}; time used = 6.568569183349609s
epoch 295: {'train_loss': '1.38629'}; time used = 6.377303600311279s
epoch 300: {'train_loss': '1.38629'}; time used = 6.436799764633179s
epoch 305: {'train_loss': '1.38629'}; time used = 6.418367624282837s
epoch 310: {'train_loss': '1.38629'}; time used = 6.4190919399261475s
epoch 315: {'train_loss': '1.38629'}; time used = 6.411659240722656s
epoch 320: {'train_loss': '1.38629'}; time used = 6.991464853286743s
epoch 325: {'train_loss': '1.38629'}; time used = 6.40251612663269s
epoch 330: {'train_loss': '1.38629'}; time used = 6.425255060195923s
epoch 335: {'train_loss': '1.38629'}; time used = 6.339905261993408s
epoch 340: {'train_loss': '1.38629'}; time used = 6.390587329864502s
epoch 345: {'train_loss': '1.38629'}; time used = 6.444519519805908s
epoch 350: {'train_loss': '1.38629'}; time used = 6.351361274719238s
epoch 355: {'train_loss': '1.38629'}; time used = 6.419642448425293s
epoch 360: {'train_loss': '1.38629'}; time used = 6.415346145629883s
epoch 365: {'train_loss': '1.38629'}; time used = 6.467423915863037s
epoch 370: {'train_loss': '1.38629'}; time used = 6.440850019454956s
epoch 375: {'train_loss': '1.38629'}; time used = 6.63874626159668s
epoch 380: {'train_loss': '1.38629'}; time used = 6.403156042098999s
epoch 385: {'train_loss': '1.38629'}; time used = 6.688143014907837s
epoch 390: {'train_loss': '1.38629'}; time used = 6.56373143196106s
epoch 395: {'train_loss': '1.38629'}; time used = 6.417177677154541s
epoch 400: {'train_loss': '1.38629'}; time used = 6.40968656539917s
epoch 405: {'train_loss': '1.38629'}; time used = 6.494190454483032s
epoch 410: {'train_loss': '1.38629'}; time used = 8.263222932815552s
epoch 415: {'train_loss': '1.38629'}; time used = 8.702054977416992s
epoch 420: {'train_loss': '1.38629'}; time used = 7.0975494384765625s
epoch 425: {'train_loss': '1.38629'}; time used = 6.620757579803467s
epoch 430: {'train_loss': '1.38629'}; time used = 6.5524187088012695s
epoch 435: {'train_loss': '1.38629'}; time used = 6.585760831832886s
epoch 440: {'train_loss': '1.38629'}; time used = 6.522330045700073s
epoch 445: {'train_loss': '1.38629'}; time used = 6.457030534744263s
epoch 450: {'train_loss': '1.38629'}; time used = 6.4151670932769775s
epoch 455: {'train_loss': '1.38629'}; time used = 7.032688617706299s
epoch 460: {'train_loss': '1.38629'}; time used = 7.394609689712524s
epoch 465: {'train_loss': '1.38629'}; time used = 6.59305214881897s
epoch 470: {'train_loss': '1.38629'}; time used = 6.520898818969727s
epoch 475: {'train_loss': '1.38629'}; time used = 6.375285863876343s
epoch 480: {'train_loss': '1.38629'}; time used = 6.3401453495025635s
epoch 485: {'train_loss': '1.38629'}; time used = 6.438680410385132s
epoch 490: {'train_loss': '1.38629'}; time used = 6.450838804244995s
epoch 495: {'train_loss': '1.38629'}; time used = 6.5195934772491455s
epoch 500: {'train_loss': '1.38629'}; time used = 6.411081552505493s
Finished training. Time used = 663.6064736843109.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.94833'}; time used = 1.7991199493408203s
epoch 10: {'train_loss': '0.84098'}; time used = 1.627526044845581s
epoch 15: {'train_loss': '0.70682'}; time used = 1.7387964725494385s
epoch 20: {'train_loss': '0.11588'}; time used = 2.412909507751465s
epoch 25: {'train_loss': '0.06825'}; time used = 4.0397789478302s
epoch 30: {'train_loss': '0.00311'}; time used = 2.4080913066864014s
epoch 35: {'train_loss': '0.00000'}; time used = 1.5361337661743164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.00606107711792.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.99647'}; time used = 1.2890162467956543s
epoch 10: {'train_loss': '2.85763'}; time used = 1.4143328666687012s
epoch 15: {'train_loss': '2.82675'}; time used = 1.3619890213012695s
epoch 20: {'train_loss': '2.81376'}; time used = 1.1758396625518799s
epoch 25: {'train_loss': '2.79810'}; time used = 1.1371500492095947s
epoch 30: {'train_loss': '2.80572'}; time used = 1.1413135528564453s
epoch 35: {'train_loss': '2.79180'}; time used = 1.1562912464141846s
epoch 40: {'train_loss': '2.79548'}; time used = 1.0976262092590332s
epoch 45: {'train_loss': '2.79685'}; time used = 1.1951603889465332s
epoch 50: {'train_loss': '2.78753'}; time used = 1.1949419975280762s
epoch 55: {'train_loss': '2.78482'}; time used = 1.2263095378875732s
epoch 60: {'train_loss': '2.78482'}; time used = 1.3246655464172363s
epoch 65: {'train_loss': '2.78183'}; time used = 1.3364291191101074s
epoch 70: {'train_loss': '2.77405'}; time used = 1.2845871448516846s
epoch 75: {'train_loss': '2.78088'}; time used = 1.173893690109253s
epoch 80: {'train_loss': '2.77749'}; time used = 1.1245200634002686s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.603185176849365.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86823'}; time used = 1.4201579093933105s
epoch 10: {'train_loss': '2.78859'}; time used = 1.2406096458435059s
epoch 15: {'train_loss': '2.73960'}; time used = 1.2111237049102783s
epoch 20: {'train_loss': '2.65874'}; time used = 1.2505362033843994s
epoch 25: {'train_loss': '2.42551'}; time used = 1.1671032905578613s
epoch 30: {'train_loss': '2.11354'}; time used = 1.1813867092132568s
epoch 35: {'train_loss': '2.10378'}; time used = 1.160224199295044s
epoch 40: {'train_loss': '2.00809'}; time used = 1.1693131923675537s
epoch 45: {'train_loss': '1.95229'}; time used = 1.0873398780822754s
epoch 50: {'train_loss': '1.95821'}; time used = 0.9478185176849365s
epoch 55: {'train_loss': '1.88161'}; time used = 0.9500784873962402s
epoch 60: {'train_loss': '1.81085'}; time used = 1.0480129718780518s
epoch 65: {'train_loss': '1.84029'}; time used = 0.9250199794769287s
epoch 70: {'train_loss': '1.79162'}; time used = 0.9455676078796387s
epoch 75: {'train_loss': '1.75270'}; time used = 1.1713652610778809s
epoch 80: {'train_loss': '1.81054'}; time used = 1.1341547966003418s
epoch 85: {'train_loss': '1.81609'}; time used = 1.135425090789795s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.18110728263855.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.93 GiB already allocated; 124.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11367'}; time used = 1.195589542388916s
epoch 10: {'train_loss': '2.77355'}; time used = 1.0335543155670166s
epoch 15: {'train_loss': '2.77357'}; time used = 1.0407369136810303s
epoch 20: {'train_loss': '2.77346'}; time used = 1.0099828243255615s
epoch 25: {'train_loss': '2.77805'}; time used = 1.0396170616149902s
epoch 30: {'train_loss': '2.78053'}; time used = 0.9983077049255371s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.53530216217041.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34701'}; time used = 1.2941789627075195s
epoch 10: {'train_loss': '1.27933'}; time used = 1.2114064693450928s
epoch 15: {'train_loss': '1.16532'}; time used = 1.185145378112793s
epoch 20: {'train_loss': '1.21130'}; time used = 1.1262106895446777s
epoch 25: {'train_loss': '1.07209'}; time used = 1.057302474975586s
epoch 30: {'train_loss': '0.89419'}; time used = 1.087003231048584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.025908946990967.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.01 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 82.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90505'}; time used = 1.3132872581481934s
epoch 10: {'train_loss': '2.79868'}; time used = 1.2221338748931885s
epoch 15: {'train_loss': '2.77298'}; time used = 1.1578900814056396s
epoch 20: {'train_loss': '2.78064'}; time used = 1.1838107109069824s
epoch 25: {'train_loss': '2.77820'}; time used = 1.2943949699401855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.365878105163574.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.4317048853439681, 'samples': 0.6052631578947368, 'weighted': 0.48129296321561627, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77178'}; time used = 1.8876738548278809s
epoch 10: {'train_loss': '2.77034'}; time used = 2.519105911254883s
epoch 15: {'train_loss': '2.76785'}; time used = 2.051363468170166s
epoch 20: {'train_loss': '2.76370'}; time used = 1.9045639038085938s
epoch 25: {'train_loss': '2.76110'}; time used = 1.988020658493042s
epoch 30: {'train_loss': '2.75552'}; time used = 1.8068957328796387s
epoch 35: {'train_loss': '2.75161'}; time used = 1.7046103477478027s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.029755115509033.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6166666666666667, 'samples': 0.6231884057971014, 'weighted': 0.6202898550724637, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35564'}; time used = 1.739386796951294s
epoch 10: {'train_loss': '1.24849'}; time used = 1.634176254272461s
epoch 15: {'train_loss': '1.17605'}; time used = 1.6219971179962158s
epoch 20: {'train_loss': '1.19465'}; time used = 1.776137351989746s
epoch 25: {'train_loss': '1.09811'}; time used = 1.779073715209961s
epoch 30: {'train_loss': '0.94253'}; time used = 1.7053496837615967s
epoch 35: {'train_loss': '0.99837'}; time used = 1.7241384983062744s
epoch 40: {'train_loss': '0.92184'}; time used = 1.7365269660949707s
epoch 45: {'train_loss': '0.90852'}; time used = 1.7446014881134033s
epoch 50: {'train_loss': '0.70808'}; time used = 1.7903532981872559s
epoch 55: {'train_loss': '0.58442'}; time used = 1.9425272941589355s
epoch 60: {'train_loss': '0.58893'}; time used = 1.90733003616333s
epoch 65: {'train_loss': '0.85276'}; time used = 1.789611577987671s
epoch 70: {'train_loss': '0.69891'}; time used = 1.7199475765228271s
epoch 75: {'train_loss': '0.56285'}; time used = 2.799785614013672s
epoch 80: {'train_loss': '0.35285'}; time used = 1.7643187046051025s
epoch 85: {'train_loss': '0.42858'}; time used = 1.8815011978149414s
epoch 90: {'train_loss': '0.05368'}; time used = 1.796349287033081s
epoch 95: {'train_loss': '0.15729'}; time used = 1.7538466453552246s
epoch 100: {'train_loss': '0.00663'}; time used = 1.8636834621429443s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.29199147224426.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 380.44 MiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01930'}; time used = 1.962294101715088s
epoch 10: {'train_loss': '0.63757'}; time used = 1.9563429355621338s
epoch 15: {'train_loss': '0.00940'}; time used = 1.8229360580444336s
epoch 20: {'train_loss': '0.00295'}; time used = 1.824903964996338s
epoch 25: {'train_loss': '0.02243'}; time used = 1.921421766281128s
epoch 30: {'train_loss': '0.07659'}; time used = 1.8173203468322754s
epoch 35: {'train_loss': '0.16376'}; time used = 1.87705397605896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.174432039260864.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6044973544973544, 'samples': 0.6231884057971014, 'weighted': 0.6107277049306035, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.90978'}; time used = 1.7762818336486816s
epoch 10: {'train_loss': '2.81058'}; time used = 1.7984442710876465s
epoch 15: {'train_loss': '2.78819'}; time used = 1.8932595252990723s
epoch 20: {'train_loss': '2.77523'}; time used = 1.7238664627075195s
epoch 25: {'train_loss': '2.76946'}; time used = 1.8777360916137695s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.110543012619019.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 352.44 MiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36449'}; time used = 2.137316942214966s
epoch 10: {'train_loss': '1.24413'}; time used = 1.784134864807129s
epoch 15: {'train_loss': '1.04565'}; time used = 1.788468360900879s
epoch 20: {'train_loss': '0.87695'}; time used = 1.8018014430999756s
epoch 25: {'train_loss': '0.19016'}; time used = 1.9074294567108154s
epoch 30: {'train_loss': '0.49479'}; time used = 1.8029389381408691s
epoch 35: {'train_loss': '0.19481'}; time used = 1.8174512386322021s
epoch 40: {'train_loss': '0.02337'}; time used = 1.781517744064331s
epoch 45: {'train_loss': '0.14986'}; time used = 1.848029613494873s
epoch 50: {'train_loss': '0.24452'}; time used = 1.8792376518249512s
epoch 55: {'train_loss': '0.15197'}; time used = 1.798889398574829s
epoch 60: {'train_loss': '0.06605'}; time used = 1.8854262828826904s
epoch 65: {'train_loss': '0.09237'}; time used = 1.8531064987182617s
epoch 70: {'train_loss': '0.05704'}; time used = 1.8131296634674072s
epoch 75: {'train_loss': '0.03630'}; time used = 2.11956787109375s
epoch 80: {'train_loss': '0.01551'}; time used = 1.7766802310943604s
epoch 85: {'train_loss': '0.01252'}; time used = 1.833181381225586s
epoch 90: {'train_loss': '0.00696'}; time used = 1.8371336460113525s
epoch 95: {'train_loss': '0.01058'}; time used = 1.7688801288604736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.31363606452942.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5367121507472385, 'samples': 0.5507246376811594, 'weighted': 0.5425506869697055, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 352.44 MiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 188.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.34043'}; time used = 1.7331945896148682s
epoch 10: {'train_loss': '2.81467'}; time used = 1.6402840614318848s
epoch 15: {'train_loss': '2.72100'}; time used = 1.611849069595337s
epoch 20: {'train_loss': '2.72562'}; time used = 1.597059965133667s
epoch 25: {'train_loss': '2.69155'}; time used = 1.6632215976715088s
epoch 30: {'train_loss': '2.67081'}; time used = 1.6239840984344482s
epoch 35: {'train_loss': '2.66299'}; time used = 3.141667366027832s
epoch 40: {'train_loss': '2.64528'}; time used = 3.1268343925476074s
epoch 45: {'train_loss': '2.61409'}; time used = 1.8102915287017822s
epoch 50: {'train_loss': '2.57670'}; time used = 1.6535944938659668s
epoch 55: {'train_loss': '2.56145'}; time used = 1.7841038703918457s
epoch 60: {'train_loss': '2.55192'}; time used = 1.6942205429077148s
epoch 65: {'train_loss': '2.52320'}; time used = 2.796820640563965s
epoch 70: {'train_loss': '2.49333'}; time used = 2.087095260620117s
epoch 75: {'train_loss': '2.49545'}; time used = 1.6470632553100586s
epoch 80: {'train_loss': '2.46624'}; time used = 1.8373329639434814s
epoch 85: {'train_loss': '2.46971'}; time used = 2.0454418659210205s
epoch 90: {'train_loss': '2.45948'}; time used = 1.8499200344085693s
epoch 95: {'train_loss': '2.43917'}; time used = 1.8358800411224365s
epoch 100: {'train_loss': '2.42469'}; time used = 2.9778401851654053s
epoch 105: {'train_loss': '2.40989'}; time used = 3.1047353744506836s
epoch 110: {'train_loss': '2.39099'}; time used = 2.9092838764190674s
epoch 115: {'train_loss': '2.38886'}; time used = 2.425849676132202s
epoch 120: {'train_loss': '2.37339'}; time used = 1.8658208847045898s
epoch 125: {'train_loss': '2.37030'}; time used = 1.6929898262023926s
epoch 130: {'train_loss': '2.35788'}; time used = 1.851822853088379s
epoch 135: {'train_loss': '2.37095'}; time used = 1.870966911315918s
epoch 140: {'train_loss': '2.36316'}; time used = 1.724412202835083s
epoch 145: {'train_loss': '2.34854'}; time used = 1.592033863067627s
epoch 150: {'train_loss': '2.34941'}; time used = 1.584329605102539s
epoch 155: {'train_loss': '2.32107'}; time used = 1.691901445388794s
epoch 160: {'train_loss': '2.32092'}; time used = 1.7267401218414307s
epoch 165: {'train_loss': '2.31477'}; time used = 1.7213826179504395s
epoch 170: {'train_loss': '2.33866'}; time used = 1.713994026184082s
epoch 175: {'train_loss': '2.31406'}; time used = 1.650378942489624s
epoch 180: {'train_loss': '2.30686'}; time used = 1.9075381755828857s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 75.60733580589294.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5337837837837838, 'samples': 0.5362318840579711, 'weighted': 0.5362318840579711, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85293'}; time used = 1.3559341430664062s
epoch 10: {'train_loss': '2.80898'}; time used = 1.168738842010498s
epoch 15: {'train_loss': '2.78677'}; time used = 1.38348388671875s
epoch 20: {'train_loss': '2.77282'}; time used = 2.294220447540283s
epoch 25: {'train_loss': '2.77342'}; time used = 3.0118370056152344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.409687042236328.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77835'}; time used = 3.5562164783477783s
epoch 10: {'train_loss': '2.76130'}; time used = 3.506244659423828s
epoch 15: {'train_loss': '2.75038'}; time used = 2.1421279907226562s
epoch 20: {'train_loss': '2.72940'}; time used = 1.918102502822876s
epoch 25: {'train_loss': '2.68933'}; time used = 2.162140369415283s
epoch 30: {'train_loss': '2.65237'}; time used = 1.9497485160827637s
epoch 35: {'train_loss': '2.60096'}; time used = 1.7062227725982666s
epoch 40: {'train_loss': '2.51891'}; time used = 1.6028947830200195s
epoch 45: {'train_loss': '2.48048'}; time used = 1.6157512664794922s
epoch 50: {'train_loss': '2.50325'}; time used = 1.5987358093261719s
epoch 55: {'train_loss': '2.45863'}; time used = 1.7703320980072021s
epoch 60: {'train_loss': '2.42076'}; time used = 1.6562271118164062s
epoch 65: {'train_loss': '2.34508'}; time used = 1.8533635139465332s
epoch 70: {'train_loss': '2.29469'}; time used = 1.6249451637268066s
epoch 75: {'train_loss': '2.27827'}; time used = 1.8302478790283203s
epoch 80: {'train_loss': '2.29581'}; time used = 1.7413172721862793s
epoch 85: {'train_loss': '2.31226'}; time used = 1.8529505729675293s
epoch 90: {'train_loss': '2.24067'}; time used = 1.7095508575439453s
epoch 95: {'train_loss': '2.20841'}; time used = 1.665083885192871s
epoch 100: {'train_loss': '2.17124'}; time used = 1.6699738502502441s
epoch 105: {'train_loss': '2.21677'}; time used = 1.7379186153411865s
epoch 110: {'train_loss': '2.12805'}; time used = 1.7202861309051514s
epoch 115: {'train_loss': '2.16738'}; time used = 1.6385443210601807s
epoch 120: {'train_loss': '2.12959'}; time used = 1.769874095916748s
epoch 125: {'train_loss': '2.10225'}; time used = 1.6331818103790283s
epoch 130: {'train_loss': '2.06616'}; time used = 1.655301809310913s
epoch 135: {'train_loss': '2.14396'}; time used = 1.9702949523925781s
epoch 140: {'train_loss': '2.02829'}; time used = 2.1549973487854004s
epoch 145: {'train_loss': '1.98148'}; time used = 2.3939926624298096s
epoch 150: {'train_loss': '1.98877'}; time used = 1.816861867904663s
epoch 155: {'train_loss': '1.94482'}; time used = 1.6981613636016846s
epoch 160: {'train_loss': '1.99758'}; time used = 1.7437713146209717s
epoch 165: {'train_loss': '2.06075'}; time used = 1.7214033603668213s
epoch 170: {'train_loss': '2.01984'}; time used = 1.6647164821624756s
epoch 175: {'train_loss': '1.93611'}; time used = 1.7902207374572754s
epoch 180: {'train_loss': '1.88878'}; time used = 1.7900190353393555s
epoch 185: {'train_loss': '1.91260'}; time used = 1.8387975692749023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 76.30267477035522.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.600300364728599, 'samples': 0.6086956521739131, 'weighted': 0.6044980084512561, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38043'}; time used = 2.0800349712371826s
epoch 10: {'train_loss': '1.25693'}; time used = 2.348641872406006s
epoch 15: {'train_loss': '1.14522'}; time used = 2.170205593109131s
epoch 20: {'train_loss': '1.35858'}; time used = 2.0130393505096436s
epoch 25: {'train_loss': '1.24208'}; time used = 2.0110795497894287s
epoch 30: {'train_loss': '1.11767'}; time used = 2.2105910778045654s
epoch 35: {'train_loss': '1.19521'}; time used = 2.0803918838500977s
epoch 40: {'train_loss': '1.15173'}; time used = 2.0183849334716797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.54581332206726.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79659'}; time used = 2.0443813800811768s
epoch 10: {'train_loss': '2.76599'}; time used = 1.8146321773529053s
epoch 15: {'train_loss': '2.77023'}; time used = 2.6292684078216553s
epoch 20: {'train_loss': '2.75727'}; time used = 1.930342435836792s
epoch 25: {'train_loss': '2.73014'}; time used = 2.053941011428833s
epoch 30: {'train_loss': '2.70989'}; time used = 1.9485681056976318s
epoch 35: {'train_loss': '2.69716'}; time used = 1.9642884731292725s
epoch 40: {'train_loss': '2.69590'}; time used = 1.9244863986968994s
epoch 45: {'train_loss': '2.69172'}; time used = 2.7985806465148926s
epoch 50: {'train_loss': '2.68692'}; time used = 3.5777065753936768s
epoch 55: {'train_loss': '2.69341'}; time used = 2.629403829574585s
epoch 60: {'train_loss': '2.67591'}; time used = 2.063159942626953s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.55658936500549.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.45238095238095244, 'samples': 0.5362318840579711, 'weighted': 0.46790890269151136, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 380.44 MiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.20611'}; time used = 1.3603596687316895s
epoch 10: {'train_loss': '0.20873'}; time used = 1.1664729118347168s
epoch 15: {'train_loss': '0.10664'}; time used = 1.0506401062011719s
epoch 20: {'train_loss': '0.12548'}; time used = 1.2597110271453857s
epoch 25: {'train_loss': '0.14398'}; time used = 1.1080446243286133s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.676266431808472.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29638'}; time used = 2.672360420227051s
epoch 10: {'train_loss': '1.19393'}; time used = 2.387587070465088s
epoch 15: {'train_loss': '1.01247'}; time used = 2.272819757461548s
epoch 20: {'train_loss': '0.83308'}; time used = 2.0862600803375244s
epoch 25: {'train_loss': '0.71107'}; time used = 2.212501049041748s
epoch 30: {'train_loss': '0.47107'}; time used = 1.9756572246551514s
epoch 35: {'train_loss': '0.40068'}; time used = 2.1278491020202637s
epoch 40: {'train_loss': '0.17675'}; time used = 2.0498733520507812s
epoch 45: {'train_loss': '0.16054'}; time used = 2.1587092876434326s
epoch 50: {'train_loss': '0.09380'}; time used = 2.038109540939331s
epoch 55: {'train_loss': '0.10662'}; time used = 2.0448670387268066s
epoch 60: {'train_loss': '0.13671'}; time used = 2.0085201263427734s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.084485054016113.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.29539'}; time used = 1.9757864475250244s
epoch 10: {'train_loss': '1.20603'}; time used = 1.7633821964263916s
epoch 15: {'train_loss': '1.14910'}; time used = 2.0687272548675537s
epoch 20: {'train_loss': '1.01411'}; time used = 1.9001679420471191s
epoch 25: {'train_loss': '0.91558'}; time used = 1.8300068378448486s
epoch 30: {'train_loss': '0.78658'}; time used = 3.337000608444214s
epoch 35: {'train_loss': '0.62984'}; time used = 5.168174982070923s
epoch 40: {'train_loss': '0.50384'}; time used = 5.454524040222168s
epoch 45: {'train_loss': '0.34040'}; time used = 6.0046422481536865s
epoch 50: {'train_loss': '0.17605'}; time used = 5.450982332229614s
epoch 55: {'train_loss': '0.16749'}; time used = 3.756089448928833s
epoch 60: {'train_loss': '0.18478'}; time used = 2.206042528152466s
epoch 65: {'train_loss': '0.08289'}; time used = 1.8264703750610352s
epoch 70: {'train_loss': '0.24931'}; time used = 1.7288763523101807s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.525808572769165.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39816'}; time used = 1.6573238372802734s
epoch 10: {'train_loss': '1.40364'}; time used = 1.3730010986328125s
epoch 15: {'train_loss': '1.37862'}; time used = 1.3552939891815186s
epoch 20: {'train_loss': '1.38296'}; time used = 1.405073642730713s
epoch 25: {'train_loss': '1.28959'}; time used = 2.227555751800537s
epoch 30: {'train_loss': '1.21164'}; time used = 1.37913179397583s
epoch 35: {'train_loss': '1.16347'}; time used = 1.3688395023345947s
epoch 40: {'train_loss': '1.15998'}; time used = 1.3745908737182617s
epoch 45: {'train_loss': '0.89572'}; time used = 1.50398850440979s
epoch 50: {'train_loss': '0.89264'}; time used = 1.3612561225891113s
epoch 55: {'train_loss': '1.00669'}; time used = 1.3613979816436768s
epoch 60: {'train_loss': '0.94340'}; time used = 1.3803074359893799s
epoch 65: {'train_loss': '0.66588'}; time used = 1.3759660720825195s
epoch 70: {'train_loss': '0.80883'}; time used = 2.1242504119873047s
epoch 75: {'train_loss': '0.76771'}; time used = 2.8084044456481934s
epoch 80: {'train_loss': '0.68454'}; time used = 1.7222635746002197s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.30558133125305.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5529411764705883, 'samples': 0.6052631578947368, 'weighted': 0.5770897832817338, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.37561'}; time used = 2.5676956176757812s
epoch 10: {'train_loss': '0.18871'}; time used = 3.07474422454834s
epoch 15: {'train_loss': '0.20386'}; time used = 3.007565498352051s
epoch 20: {'train_loss': '0.20602'}; time used = 2.872354745864868s
epoch 25: {'train_loss': '0.27953'}; time used = 1.807955265045166s
epoch 30: {'train_loss': '0.35081'}; time used = 1.7765121459960938s
epoch 35: {'train_loss': '0.24203'}; time used = 1.7059056758880615s
epoch 40: {'train_loss': '0.27311'}; time used = 1.585000991821289s
epoch 45: {'train_loss': '0.17292'}; time used = 1.6998865604400635s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.458316326141357.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.75859'}; time used = 3.889878273010254s
epoch 10: {'train_loss': '2.73691'}; time used = 3.1384575366973877s
epoch 15: {'train_loss': '2.71328'}; time used = 2.8118531703948975s
epoch 20: {'train_loss': '2.68204'}; time used = 2.842630624771118s
epoch 25: {'train_loss': '2.64347'}; time used = 1.8982548713684082s
epoch 30: {'train_loss': '2.62288'}; time used = 1.687535285949707s
epoch 35: {'train_loss': '2.60346'}; time used = 1.6549012660980225s
epoch 40: {'train_loss': '2.57612'}; time used = 1.6413171291351318s
epoch 45: {'train_loss': '2.54246'}; time used = 2.4525113105773926s
epoch 50: {'train_loss': '2.49807'}; time used = 1.8737156391143799s
epoch 55: {'train_loss': '2.52719'}; time used = 1.643277883529663s
epoch 60: {'train_loss': '2.48937'}; time used = 1.6076006889343262s
epoch 65: {'train_loss': '2.45026'}; time used = 1.6125988960266113s
epoch 70: {'train_loss': '2.40065'}; time used = 1.7827191352844238s
epoch 75: {'train_loss': '2.39236'}; time used = 1.8899040222167969s
epoch 80: {'train_loss': '2.36968'}; time used = 1.7576344013214111s
epoch 85: {'train_loss': '2.38041'}; time used = 2.5433237552642822s
epoch 90: {'train_loss': '2.38858'}; time used = 2.462721347808838s
epoch 95: {'train_loss': '2.37201'}; time used = 1.5660157203674316s
epoch 100: {'train_loss': '2.34659'}; time used = 1.6724627017974854s
epoch 105: {'train_loss': '2.35825'}; time used = 2.6875078678131104s
epoch 110: {'train_loss': '2.33842'}; time used = 2.5942912101745605s
epoch 115: {'train_loss': '2.34315'}; time used = 1.775040626525879s
epoch 120: {'train_loss': '2.34175'}; time used = 1.6429576873779297s
epoch 125: {'train_loss': '2.32216'}; time used = 1.8891406059265137s
epoch 130: {'train_loss': '2.31927'}; time used = 1.8219175338745117s
epoch 135: {'train_loss': '2.33864'}; time used = 1.8645200729370117s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 63.21815061569214.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14969'}; time used = 2.459101676940918s
epoch 10: {'train_loss': '0.73417'}; time used = 2.3763439655303955s
epoch 15: {'train_loss': '0.51183'}; time used = 2.3825042247772217s
epoch 20: {'train_loss': '0.40390'}; time used = 2.36018967628479s
epoch 25: {'train_loss': '0.36348'}; time used = 2.474843978881836s
epoch 30: {'train_loss': '0.49621'}; time used = 2.4160828590393066s
epoch 35: {'train_loss': '0.36511'}; time used = 2.593499183654785s
epoch 40: {'train_loss': '0.32575'}; time used = 2.563023328781128s
epoch 45: {'train_loss': '0.34850'}; time used = 2.476879835128784s
epoch 50: {'train_loss': '0.28859'}; time used = 2.4295244216918945s
epoch 55: {'train_loss': '0.37172'}; time used = 2.519228458404541s
epoch 60: {'train_loss': '0.37404'}; time used = 2.4683752059936523s
epoch 65: {'train_loss': '0.38428'}; time used = 2.75604248046875s
epoch 70: {'train_loss': '0.29556'}; time used = 3.5132381916046143s
epoch 75: {'train_loss': '0.27442'}; time used = 3.4793221950531006s
epoch 80: {'train_loss': '0.36197'}; time used = 2.836669445037842s
epoch 85: {'train_loss': '0.34263'}; time used = 2.4316086769104004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.76486825942993.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80859'}; time used = 1.8859071731567383s
epoch 10: {'train_loss': '2.77691'}; time used = 1.8810341358184814s
epoch 15: {'train_loss': '2.77176'}; time used = 1.728261947631836s
epoch 20: {'train_loss': '2.77655'}; time used = 1.7275450229644775s
epoch 25: {'train_loss': '2.77206'}; time used = 2.041353225708008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.338887691497803.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79608'}; time used = 1.5016100406646729s
epoch 10: {'train_loss': '2.74794'}; time used = 1.3432281017303467s
epoch 15: {'train_loss': '2.75057'}; time used = 1.2974238395690918s
epoch 20: {'train_loss': '2.66941'}; time used = 1.359287977218628s
epoch 25: {'train_loss': '2.59107'}; time used = 1.3231010437011719s
epoch 30: {'train_loss': '2.44521'}; time used = 1.308239221572876s
epoch 35: {'train_loss': '2.25162'}; time used = 1.3898942470550537s
epoch 40: {'train_loss': '2.14822'}; time used = 1.452134132385254s
epoch 45: {'train_loss': '2.10668'}; time used = 1.3034460544586182s
epoch 50: {'train_loss': '2.09758'}; time used = 1.4221277236938477s
epoch 55: {'train_loss': '2.05220'}; time used = 1.3083374500274658s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.948533058166504.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17392'}; time used = 1.6648926734924316s
epoch 10: {'train_loss': '2.85923'}; time used = 1.7937562465667725s
epoch 15: {'train_loss': '2.76584'}; time used = 1.8081843852996826s
epoch 20: {'train_loss': '2.76360'}; time used = 1.6919286251068115s
epoch 25: {'train_loss': '2.74233'}; time used = 1.6740658283233643s
epoch 30: {'train_loss': '2.68649'}; time used = 2.4905166625976562s
epoch 35: {'train_loss': '2.62527'}; time used = 2.1174376010894775s
epoch 40: {'train_loss': '2.57605'}; time used = 2.012921094894409s
epoch 45: {'train_loss': '2.52532'}; time used = 3.3864505290985107s
epoch 50: {'train_loss': '2.44108'}; time used = 3.2352497577667236s
epoch 55: {'train_loss': '2.38787'}; time used = 2.8459887504577637s
epoch 60: {'train_loss': '2.31206'}; time used = 1.6895995140075684s
epoch 65: {'train_loss': '2.20653'}; time used = 1.7740392684936523s
epoch 70: {'train_loss': '2.14364'}; time used = 1.7443246841430664s
epoch 75: {'train_loss': '2.04397'}; time used = 1.717824935913086s
epoch 80: {'train_loss': '1.97342'}; time used = 1.8555316925048828s
epoch 85: {'train_loss': '1.94649'}; time used = 1.6688954830169678s
epoch 90: {'train_loss': '2.03947'}; time used = 1.6945586204528809s
epoch 95: {'train_loss': '2.06971'}; time used = 1.6762423515319824s
epoch 100: {'train_loss': '1.96100'}; time used = 1.6488077640533447s
epoch 105: {'train_loss': '1.89342'}; time used = 1.846327304840088s
epoch 110: {'train_loss': '1.78260'}; time used = 1.7621691226959229s
epoch 115: {'train_loss': '1.75546'}; time used = 1.8920259475708008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.96623682975769.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 466.44 MiB free; 26.26 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79944'}; time used = 1.8725175857543945s
epoch 10: {'train_loss': '2.70082'}; time used = 1.7822041511535645s
epoch 15: {'train_loss': '2.66792'}; time used = 1.6948630809783936s
epoch 20: {'train_loss': '2.65773'}; time used = 1.6563491821289062s
epoch 25: {'train_loss': '2.65157'}; time used = 2.448652744293213s
epoch 30: {'train_loss': '2.63579'}; time used = 1.982588529586792s
epoch 35: {'train_loss': '2.63191'}; time used = 2.083488941192627s
epoch 40: {'train_loss': '2.63034'}; time used = 2.023378849029541s
epoch 45: {'train_loss': '2.62154'}; time used = 2.056039810180664s
epoch 50: {'train_loss': '2.60225'}; time used = 2.033717155456543s
epoch 55: {'train_loss': '2.59620'}; time used = 1.837123155593872s
epoch 60: {'train_loss': '2.59604'}; time used = 1.8104808330535889s
epoch 65: {'train_loss': '2.58800'}; time used = 1.8413784503936768s
epoch 70: {'train_loss': '2.56768'}; time used = 1.7040455341339111s
epoch 75: {'train_loss': '2.56040'}; time used = 1.7796618938446045s
epoch 80: {'train_loss': '2.56170'}; time used = 1.8226032257080078s
epoch 85: {'train_loss': '2.55880'}; time used = 1.8284893035888672s
epoch 90: {'train_loss': '2.56496'}; time used = 1.7891993522644043s
epoch 95: {'train_loss': '2.56446'}; time used = 1.819753885269165s
epoch 100: {'train_loss': '2.55411'}; time used = 1.7064769268035889s
epoch 105: {'train_loss': '2.55678'}; time used = 1.9017579555511475s
epoch 110: {'train_loss': '2.55615'}; time used = 1.9471659660339355s
epoch 115: {'train_loss': '2.55342'}; time used = 1.9650967121124268s
epoch 120: {'train_loss': '2.55503'}; time used = 1.6598625183105469s
epoch 125: {'train_loss': '2.55325'}; time used = 1.9271833896636963s
epoch 130: {'train_loss': '2.55938'}; time used = 1.6544685363769531s
epoch 135: {'train_loss': '2.55152'}; time used = 1.8829972743988037s
epoch 140: {'train_loss': '2.54828'}; time used = 1.7444398403167725s
epoch 145: {'train_loss': '2.54499'}; time used = 2.8279192447662354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.45397448539734.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6073761854583772, 'samples': 0.6086956521739131, 'weighted': 0.609025518852797, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 184.44 MiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 82.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80220'}; time used = 1.8628349304199219s
epoch 10: {'train_loss': '2.76870'}; time used = 1.8257217407226562s
epoch 15: {'train_loss': '2.76086'}; time used = 4.206012010574341s
epoch 20: {'train_loss': '2.74912'}; time used = 1.8720130920410156s
epoch 25: {'train_loss': '2.73605'}; time used = 1.768908977508545s
epoch 30: {'train_loss': '2.72590'}; time used = 1.704162359237671s
epoch 35: {'train_loss': '2.71952'}; time used = 1.6846528053283691s
epoch 40: {'train_loss': '2.71621'}; time used = 1.6819665431976318s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.539504528045654.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5793567374395627, 'samples': 0.5797101449275363, 'weighted': 0.5802402561594965, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.44697'}; time used = 1.3360843658447266s
epoch 10: {'train_loss': '0.29863'}; time used = 1.3138306140899658s
epoch 15: {'train_loss': '0.16792'}; time used = 1.135152816772461s
epoch 20: {'train_loss': '0.04388'}; time used = 1.2496223449707031s
epoch 25: {'train_loss': '0.04982'}; time used = 1.323394775390625s
epoch 30: {'train_loss': '0.15906'}; time used = 1.1834495067596436s
epoch 35: {'train_loss': '0.13605'}; time used = 1.243504285812378s
epoch 40: {'train_loss': '0.09594'}; time used = 1.1980628967285156s
epoch 45: {'train_loss': '0.18087'}; time used = 1.2138142585754395s
epoch 50: {'train_loss': '0.14118'}; time used = 1.292074203491211s
epoch 55: {'train_loss': '0.04786'}; time used = 1.3213300704956055s
epoch 60: {'train_loss': '0.06729'}; time used = 1.2688090801239014s
epoch 65: {'train_loss': '0.05379'}; time used = 1.1724188327789307s
epoch 70: {'train_loss': '0.02255'}; time used = 1.0759391784667969s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.9490385055542.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.58 GiB already allocated; 478.44 MiB free; 25.01 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33256'}; time used = 1.821573257446289s
epoch 10: {'train_loss': '1.67490'}; time used = 2.9908485412597656s
epoch 15: {'train_loss': '1.12562'}; time used = 2.0765998363494873s
epoch 20: {'train_loss': '1.66817'}; time used = 1.1148464679718018s
epoch 25: {'train_loss': '0.75449'}; time used = 1.1647028923034668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.723032474517822.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_convc.py", line 51, in forward
    pre_sup = torch.mm(x, getattr(self, 'weights'))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 5; 10.76 GiB total capacity; 9.06 GiB already allocated; 8.44 MiB free; 6.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 466.44 MiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86823'}; time used = 1.06351900100708s
epoch 10: {'train_loss': '2.78859'}; time used = 0.8728063106536865s
epoch 15: {'train_loss': '2.73960'}; time used = 1.001481294631958s
epoch 20: {'train_loss': '2.65874'}; time used = 0.9312527179718018s
epoch 25: {'train_loss': '2.42551'}; time used = 0.9355511665344238s
epoch 30: {'train_loss': '2.11354'}; time used = 0.8963167667388916s
epoch 35: {'train_loss': '2.10378'}; time used = 1.714888095855713s
epoch 40: {'train_loss': '2.00809'}; time used = 1.7803642749786377s
epoch 45: {'train_loss': '1.95229'}; time used = 2.001082420349121s
epoch 50: {'train_loss': '1.95821'}; time used = 1.8494291305541992s
epoch 55: {'train_loss': '1.88161'}; time used = 1.7435462474822998s
epoch 60: {'train_loss': '1.81085'}; time used = 1.7892589569091797s
epoch 65: {'train_loss': '1.84029'}; time used = 1.6066842079162598s
epoch 70: {'train_loss': '1.79162'}; time used = 0.9604156017303467s
epoch 75: {'train_loss': '1.75270'}; time used = 0.9912219047546387s
epoch 80: {'train_loss': '1.81054'}; time used = 0.9321367740631104s
epoch 85: {'train_loss': '1.81609'}; time used = 0.924365758895874s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.957096576690674.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 466.44 MiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76608'}; time used = 1.8431241512298584s
epoch 10: {'train_loss': '2.72424'}; time used = 1.7828466892242432s
epoch 15: {'train_loss': '2.69711'}; time used = 1.7852258682250977s
epoch 20: {'train_loss': '2.66782'}; time used = 1.8344411849975586s
epoch 25: {'train_loss': '2.60695'}; time used = 1.8810224533081055s
epoch 30: {'train_loss': '2.54684'}; time used = 1.7895896434783936s
epoch 35: {'train_loss': '2.50029'}; time used = 1.797774314880371s
epoch 40: {'train_loss': '2.38565'}; time used = 1.8182387351989746s
epoch 45: {'train_loss': '2.33394'}; time used = 1.8416383266448975s
epoch 50: {'train_loss': '2.24605'}; time used = 1.8399291038513184s
epoch 55: {'train_loss': '2.23812'}; time used = 1.8422634601593018s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.596940755844116.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 300.44 MiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.06939'}; time used = 1.9123985767364502s
epoch 10: {'train_loss': '0.81483'}; time used = 1.7420611381530762s
epoch 15: {'train_loss': '0.83622'}; time used = 1.7551264762878418s
epoch 20: {'train_loss': '0.88522'}; time used = 1.7836835384368896s
epoch 25: {'train_loss': '1.34384'}; time used = 1.6737122535705566s
epoch 30: {'train_loss': '1.09114'}; time used = 1.6361463069915771s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.77318549156189.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.84 GiB already allocated; 228.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.33083'}; time used = 1.8189959526062012s
epoch 10: {'train_loss': '1.18693'}; time used = 1.7828240394592285s
epoch 15: {'train_loss': '1.07682'}; time used = 1.846325397491455s
epoch 20: {'train_loss': '1.07269'}; time used = 1.8974964618682861s
epoch 25: {'train_loss': '0.98356'}; time used = 1.9801826477050781s
epoch 30: {'train_loss': '0.93481'}; time used = 1.9860002994537354s
epoch 35: {'train_loss': '0.93292'}; time used = 1.8597891330718994s
epoch 40: {'train_loss': '0.77538'}; time used = 2.776609420776367s
epoch 45: {'train_loss': '0.73910'}; time used = 3.5469911098480225s
epoch 50: {'train_loss': '0.56188'}; time used = 3.6278483867645264s
epoch 55: {'train_loss': '0.46030'}; time used = 2.427604913711548s
epoch 60: {'train_loss': '0.58108'}; time used = 1.8638713359832764s
epoch 65: {'train_loss': '0.62322'}; time used = 1.7648029327392578s
epoch 70: {'train_loss': '0.59333'}; time used = 2.0292656421661377s
epoch 75: {'train_loss': '0.27871'}; time used = 2.2101387977600098s
epoch 80: {'train_loss': '0.15531'}; time used = 2.37502121925354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.545780420303345.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.22140'}; time used = 1.028914451599121s
epoch 10: {'train_loss': '0.12612'}; time used = 1.0640640258789062s
epoch 15: {'train_loss': '0.18276'}; time used = 1.124025583267212s
epoch 20: {'train_loss': '0.06237'}; time used = 0.9962854385375977s
epoch 25: {'train_loss': '0.06444'}; time used = 1.11720609664917s
epoch 30: {'train_loss': '0.07560'}; time used = 1.1155905723571777s
epoch 35: {'train_loss': '0.06851'}; time used = 1.038677453994751s
epoch 40: {'train_loss': '0.05031'}; time used = 1.0228662490844727s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.13918399810791.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39629'}; time used = 1.1465330123901367s
epoch 10: {'train_loss': '1.38047'}; time used = 1.0288641452789307s
epoch 15: {'train_loss': '1.26667'}; time used = 1.0514025688171387s
epoch 20: {'train_loss': '1.26339'}; time used = 1.0595877170562744s
epoch 25: {'train_loss': '1.09779'}; time used = 1.0888361930847168s
epoch 30: {'train_loss': '0.99034'}; time used = 1.0672602653503418s
epoch 35: {'train_loss': '0.96121'}; time used = 1.0595958232879639s
epoch 40: {'train_loss': '0.94946'}; time used = 1.2637786865234375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.936910390853882.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03656'}; time used = 1.0513739585876465s
epoch 10: {'train_loss': '0.69703'}; time used = 1.01051664352417s
epoch 15: {'train_loss': '0.50154'}; time used = 1.0951244831085205s
epoch 20: {'train_loss': '0.35973'}; time used = 0.9411735534667969s
epoch 25: {'train_loss': '0.30834'}; time used = 1.32413649559021s
epoch 30: {'train_loss': '0.22283'}; time used = 1.834404468536377s
epoch 35: {'train_loss': '0.21572'}; time used = 1.6727705001831055s
epoch 40: {'train_loss': '0.14129'}; time used = 1.854112148284912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.360400915145874.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 412.44 MiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.00429'}; time used = 1.12563157081604s
epoch 10: {'train_loss': '0.70189'}; time used = 0.9053986072540283s
epoch 15: {'train_loss': '0.57454'}; time used = 0.9133062362670898s
epoch 20: {'train_loss': '0.45827'}; time used = 0.9263477325439453s
epoch 25: {'train_loss': '0.43562'}; time used = 0.9298503398895264s
epoch 30: {'train_loss': '0.32670'}; time used = 1.0609703063964844s
epoch 35: {'train_loss': '0.32069'}; time used = 1.0590944290161133s
epoch 40: {'train_loss': '0.26065'}; time used = 1.027965784072876s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.143421411514282.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38177'}; time used = 2.1263389587402344s
epoch 10: {'train_loss': '1.33433'}; time used = 2.0689003467559814s
epoch 15: {'train_loss': '1.37166'}; time used = 2.209245204925537s
epoch 20: {'train_loss': '1.45535'}; time used = 2.2953879833221436s
epoch 25: {'train_loss': '1.42983'}; time used = 2.3066859245300293s
epoch 30: {'train_loss': '1.38858'}; time used = 2.0725433826446533s
epoch 35: {'train_loss': '1.36941'}; time used = 2.0133707523345947s
epoch 40: {'train_loss': '0.64515'}; time used = 1.9973468780517578s
epoch 45: {'train_loss': '0.00000'}; time used = 2.0042834281921387s
epoch 50: {'train_loss': '0.00000'}; time used = 2.343583345413208s
epoch 55: {'train_loss': '0.00000'}; time used = 2.0739569664001465s
epoch 60: {'train_loss': '0.00000'}; time used = 2.0801680088043213s
epoch 65: {'train_loss': '0.70135'}; time used = 2.18961238861084s
epoch 70: {'train_loss': '0.00000'}; time used = 2.1683576107025146s
epoch 75: {'train_loss': '0.00000'}; time used = 2.1518428325653076s
epoch 80: {'train_loss': '0.00000'}; time used = 2.098759174346924s
epoch 85: {'train_loss': '0.00000'}; time used = 2.0557308197021484s
epoch 90: {'train_loss': '0.00000'}; time used = 1.9952178001403809s
epoch 95: {'train_loss': '0.00000'}; time used = 2.0021135807037354s
epoch 100: {'train_loss': '0.00000'}; time used = 2.0939321517944336s
epoch 105: {'train_loss': '0.00000'}; time used = 2.0382113456726074s
epoch 110: {'train_loss': '0.00000'}; time used = 2.009547710418701s
epoch 115: {'train_loss': '0.00000'}; time used = 2.1279923915863037s
epoch 120: {'train_loss': '0.00000'}; time used = 2.087629556655884s
epoch 125: {'train_loss': '0.00000'}; time used = 2.0344443321228027s
epoch 130: {'train_loss': '0.00000'}; time used = 2.2184133529663086s
epoch 135: {'train_loss': '0.00000'}; time used = 2.0162980556488037s
epoch 140: {'train_loss': '0.72022'}; time used = 2.0799028873443604s
epoch 145: {'train_loss': '0.00000'}; time used = 2.1556990146636963s
epoch 150: {'train_loss': '0.00000'}; time used = 1.9912269115447998s
epoch 155: {'train_loss': '0.00000'}; time used = 2.032909870147705s
epoch 160: {'train_loss': '0.00000'}; time used = 2.015104293823242s
epoch 165: {'train_loss': '0.00000'}; time used = 1.9952361583709717s
epoch 170: {'train_loss': '0.00000'}; time used = 2.011868953704834s
epoch 175: {'train_loss': '0.66542'}; time used = 1.9982471466064453s
epoch 180: {'train_loss': '0.00000'}; time used = 2.0755794048309326s
epoch 185: {'train_loss': '0.00000'}; time used = 2.0463969707489014s
epoch 190: {'train_loss': '0.00000'}; time used = 2.0362229347229004s
epoch 195: {'train_loss': '0.00000'}; time used = 2.0096282958984375s
epoch 200: {'train_loss': '0.00000'}; time used = 2.0683419704437256s
epoch 205: {'train_loss': '0.00000'}; time used = 2.5419907569885254s
epoch 210: {'train_loss': '0.70070'}; time used = 3.6772682666778564s
epoch 215: {'train_loss': '0.00000'}; time used = 3.634814500808716s
epoch 220: {'train_loss': '0.00000'}; time used = 2.483311176300049s
epoch 225: {'train_loss': '0.70330'}; time used = 2.1732161045074463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 102.48613452911377.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 452.44 MiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35317'}; time used = 1.8173737525939941s
epoch 10: {'train_loss': '0.88597'}; time used = 1.8168327808380127s
epoch 15: {'train_loss': '0.75574'}; time used = 1.8938512802124023s
epoch 20: {'train_loss': '0.52487'}; time used = 2.121567964553833s
epoch 25: {'train_loss': '0.37474'}; time used = 2.054888963699341s
epoch 30: {'train_loss': '0.07809'}; time used = 1.7716538906097412s
epoch 35: {'train_loss': '0.03080'}; time used = 1.7804949283599854s
epoch 40: {'train_loss': '0.10695'}; time used = 3.58488392829895s
epoch 45: {'train_loss': '0.11418'}; time used = 3.63287353515625s
epoch 50: {'train_loss': '0.21407'}; time used = 1.9898948669433594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.092882871627808.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '0.40015'}; time used = 1.996241569519043s
epoch 10: {'train_loss': '0.29181'}; time used = 1.8626422882080078s
epoch 15: {'train_loss': '0.19405'}; time used = 1.8640222549438477s
epoch 20: {'train_loss': '0.31317'}; time used = 1.6639478206634521s
epoch 25: {'train_loss': '0.86483'}; time used = 1.8570318222045898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.742469072341919.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.59666'}; time used = 1.927159309387207s
epoch 10: {'train_loss': '0.13485'}; time used = 1.7199387550354004s
epoch 15: {'train_loss': '0.10586'}; time used = 1.2260355949401855s
epoch 20: {'train_loss': '0.06759'}; time used = 0.9588809013366699s
epoch 25: {'train_loss': '0.06649'}; time used = 1.1343882083892822s
epoch 30: {'train_loss': '0.06051'}; time used = 1.1290488243103027s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.409551858901978.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39557'}; time used = 1.1855592727661133s
epoch 10: {'train_loss': '1.40233'}; time used = 1.0938472747802734s
epoch 15: {'train_loss': '1.15832'}; time used = 1.0437135696411133s
epoch 20: {'train_loss': '1.43581'}; time used = 1.178069829940796s
epoch 25: {'train_loss': '0.95048'}; time used = 1.0857148170471191s
epoch 30: {'train_loss': '0.78396'}; time used = 1.0989065170288086s
epoch 35: {'train_loss': '0.94525'}; time used = 1.0708858966827393s
epoch 40: {'train_loss': '0.65789'}; time used = 1.095430850982666s
epoch 45: {'train_loss': '0.96162'}; time used = 1.0885140895843506s
epoch 50: {'train_loss': '0.94952'}; time used = 2.235140562057495s
epoch 55: {'train_loss': '0.88327'}; time used = 1.611905574798584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.8176212310791.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6761363636363636, 'samples': 0.6842105263157895, 'weighted': 0.6842105263157895, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.24548'}; time used = 2.1654856204986572s
epoch 10: {'train_loss': '0.20615'}; time used = 1.9824926853179932s
epoch 15: {'train_loss': '0.46704'}; time used = 1.9971206188201904s
epoch 20: {'train_loss': '0.04655'}; time used = 1.8741669654846191s
epoch 25: {'train_loss': '0.00012'}; time used = 1.9662668704986572s
epoch 30: {'train_loss': '0.00012'}; time used = 2.0178544521331787s
epoch 35: {'train_loss': '0.00000'}; time used = 2.044095993041992s
epoch 40: {'train_loss': '0.00015'}; time used = 2.0392751693725586s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.60617685317993.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 142.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81332'}; time used = 1.4252474308013916s
epoch 10: {'train_loss': '2.57135'}; time used = 1.1360514163970947s
epoch 15: {'train_loss': '1.96089'}; time used = 1.1670784950256348s
epoch 20: {'train_loss': '1.75094'}; time used = 1.0057861804962158s
epoch 25: {'train_loss': '1.56447'}; time used = 1.0662884712219238s
epoch 30: {'train_loss': '1.47576'}; time used = 1.0858988761901855s
epoch 35: {'train_loss': '1.42951'}; time used = 1.0714139938354492s
epoch 40: {'train_loss': '1.68376'}; time used = 0.9970753192901611s
epoch 45: {'train_loss': '1.48240'}; time used = 0.9826438426971436s
epoch 50: {'train_loss': '1.27181'}; time used = 0.9694809913635254s
epoch 55: {'train_loss': '1.25471'}; time used = 1.0617704391479492s
epoch 60: {'train_loss': '1.19304'}; time used = 1.301513910293579s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.67261815071106.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.67 GiB already allocated; 380.44 MiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.25430'}; time used = 3.360996961593628s
epoch 10: {'train_loss': '1.14738'}; time used = 3.150155544281006s
epoch 15: {'train_loss': '0.96616'}; time used = 3.751328945159912s
epoch 20: {'train_loss': '0.81602'}; time used = 3.4111838340759277s
epoch 25: {'train_loss': '0.67486'}; time used = 3.353268623352051s
epoch 30: {'train_loss': '0.59836'}; time used = 2.8634426593780518s
epoch 35: {'train_loss': '0.62922'}; time used = 2.025519371032715s
epoch 40: {'train_loss': '0.54273'}; time used = 1.9862306118011475s
epoch 45: {'train_loss': '0.55112'}; time used = 2.058225154876709s
epoch 50: {'train_loss': '0.60319'}; time used = 1.9620025157928467s
epoch 55: {'train_loss': '0.55153'}; time used = 2.0560734272003174s
epoch 60: {'train_loss': '0.51203'}; time used = 2.1897714138031006s
epoch 65: {'train_loss': '0.47154'}; time used = 1.969299077987671s
epoch 70: {'train_loss': '0.45369'}; time used = 1.9601693153381348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.71998691558838.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.3994197292069632, 'samples': 0.4782608695652174, 'weighted': 0.415187957278614, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38919'}; time used = 1.7276954650878906s
epoch 10: {'train_loss': '1.31047'}; time used = 1.7143933773040771s
epoch 15: {'train_loss': '1.26423'}; time used = 1.7293972969055176s
epoch 20: {'train_loss': '1.29330'}; time used = 1.785780429840088s
epoch 25: {'train_loss': '1.17484'}; time used = 1.8616583347320557s
epoch 30: {'train_loss': '1.07679'}; time used = 1.8240983486175537s
epoch 35: {'train_loss': '1.21238'}; time used = 1.7050011157989502s
epoch 40: {'train_loss': '1.10214'}; time used = 1.671891212463379s
epoch 45: {'train_loss': '1.18542'}; time used = 1.745351791381836s
epoch 50: {'train_loss': '1.14039'}; time used = 1.7697336673736572s
epoch 55: {'train_loss': '1.01561'}; time used = 1.685723066329956s
epoch 60: {'train_loss': '1.06376'}; time used = 1.7362425327301025s
epoch 65: {'train_loss': '1.21080'}; time used = 1.79441237449646s
epoch 70: {'train_loss': '1.12662'}; time used = 1.7791283130645752s
epoch 75: {'train_loss': '1.36662'}; time used = 1.8769941329956055s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.477043867111206.
Training classifier using 80.00% nodes...
{'micro': 0.4492753623188406, 'macro': 0.4349137931034483, 'samples': 0.4492753623188406, 'weighted': 0.4414417791104448, 'accuracy': 0.4492753623188406}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '0.40015'}; time used = 1.8940708637237549s
epoch 10: {'train_loss': '0.29181'}; time used = 1.8288824558258057s
epoch 15: {'train_loss': '0.19405'}; time used = 1.818319320678711s
epoch 20: {'train_loss': '0.31317'}; time used = 1.7581462860107422s
epoch 25: {'train_loss': '0.86483'}; time used = 1.7870543003082275s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.564496040344238.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78494'}; time used = 1.856515645980835s
epoch 10: {'train_loss': '2.76571'}; time used = 1.6992583274841309s
epoch 15: {'train_loss': '2.67318'}; time used = 1.7086007595062256s
epoch 20: {'train_loss': '2.63335'}; time used = 1.749349594116211s
epoch 25: {'train_loss': '2.61245'}; time used = 1.753293514251709s
epoch 30: {'train_loss': '2.59145'}; time used = 1.6656343936920166s
epoch 35: {'train_loss': '2.55913'}; time used = 1.745600938796997s
epoch 40: {'train_loss': '2.51861'}; time used = 1.6836957931518555s
epoch 45: {'train_loss': '2.48563'}; time used = 1.6561198234558105s
epoch 50: {'train_loss': '2.40973'}; time used = 1.6950912475585938s
epoch 55: {'train_loss': '2.39740'}; time used = 1.7247400283813477s
epoch 60: {'train_loss': '2.50563'}; time used = 1.6690866947174072s
epoch 65: {'train_loss': '2.38772'}; time used = 1.7098970413208008s
epoch 70: {'train_loss': '2.32497'}; time used = 1.7306175231933594s
epoch 75: {'train_loss': '2.28148'}; time used = 1.7528016567230225s
epoch 80: {'train_loss': '2.27755'}; time used = 2.0637166500091553s
epoch 85: {'train_loss': '2.23566'}; time used = 2.5909836292266846s
epoch 90: {'train_loss': '2.22568'}; time used = 3.911489963531494s
epoch 95: {'train_loss': '2.18117'}; time used = 2.4989192485809326s
epoch 100: {'train_loss': '2.40031'}; time used = 1.7013213634490967s
epoch 105: {'train_loss': '2.51791'}; time used = 2.0130703449249268s
epoch 110: {'train_loss': '2.44046'}; time used = 1.7250936031341553s
epoch 115: {'train_loss': '2.37938'}; time used = 1.7390046119689941s
epoch 120: {'train_loss': '2.34670'}; time used = 1.6070778369903564s
epoch 125: {'train_loss': '2.26532'}; time used = 2.7151224613189697s
epoch 130: {'train_loss': '2.25348'}; time used = 3.0852396488189697s
epoch 135: {'train_loss': '2.22719'}; time used = 3.0016915798187256s
epoch 140: {'train_loss': '2.16818'}; time used = 2.0222599506378174s
epoch 145: {'train_loss': '2.14521'}; time used = 1.9164910316467285s
epoch 150: {'train_loss': '2.15599'}; time used = 1.9263496398925781s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 64.72986721992493.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.94970'}; time used = 2.215243339538574s
epoch 10: {'train_loss': '2.83549'}; time used = 2.020704507827759s
epoch 15: {'train_loss': '2.80472'}; time used = 1.8366146087646484s
epoch 20: {'train_loss': '2.78072'}; time used = 2.005859375s
epoch 25: {'train_loss': '2.77036'}; time used = 1.898021936416626s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.117942810058594.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 332.44 MiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.26471'}; time used = 1.115182638168335s
epoch 10: {'train_loss': '2.80964'}; time used = 0.9981381893157959s
epoch 15: {'train_loss': '2.80960'}; time used = 1.0185410976409912s
epoch 20: {'train_loss': '2.81810'}; time used = 1.0271527767181396s
epoch 25: {'train_loss': '2.81257'}; time used = 1.0159344673156738s
epoch 30: {'train_loss': '2.79832'}; time used = 1.0026609897613525s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.398743629455566.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11367'}; time used = 1.298663854598999s
epoch 10: {'train_loss': '2.77355'}; time used = 1.0902962684631348s
epoch 15: {'train_loss': '2.77357'}; time used = 1.269956350326538s
epoch 20: {'train_loss': '2.77346'}; time used = 1.1993658542633057s
epoch 25: {'train_loss': '2.77805'}; time used = 1.1211037635803223s
epoch 30: {'train_loss': '2.78053'}; time used = 1.1116623878479004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.150285243988037.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 458.44 MiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 352.44 MiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.15109'}; time used = 1.1741409301757812s
epoch 10: {'train_loss': '2.81316'}; time used = 0.9083065986633301s
epoch 15: {'train_loss': '2.67057'}; time used = 0.9068281650543213s
epoch 20: {'train_loss': '2.49759'}; time used = 0.9477179050445557s
epoch 25: {'train_loss': '2.06840'}; time used = 1.0531601905822754s
epoch 30: {'train_loss': '1.57022'}; time used = 0.8977503776550293s
epoch 35: {'train_loss': '1.42054'}; time used = 0.9297606945037842s
epoch 40: {'train_loss': '1.32235'}; time used = 0.9347877502441406s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.597027063369751.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.32360'}; time used = 10.21866250038147s
epoch 10: {'train_loss': '1.31825'}; time used = 7.094888210296631s
epoch 15: {'train_loss': '1.27960'}; time used = 7.978850603103638s
epoch 20: {'train_loss': '1.20312'}; time used = 10.585034370422363s
epoch 25: {'train_loss': '1.08980'}; time used = 7.290612697601318s
epoch 30: {'train_loss': '1.20978'}; time used = 8.09813904762268s
epoch 35: {'train_loss': '1.19837'}; time used = 6.798211336135864s
epoch 40: {'train_loss': '1.13443'}; time used = 6.981454849243164s
epoch 45: {'train_loss': '1.12784'}; time used = 7.070454120635986s
epoch 50: {'train_loss': '1.05885'}; time used = 8.20897126197815s
epoch 55: {'train_loss': '1.27613'}; time used = 9.9917631149292s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 112.92591547966003.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.5031087785491111, 'samples': 0.5166666666666667, 'weighted': 0.4986903618184046, 'accuracy': 0.5166666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 300.44 MiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76089'}; time used = 1.4638519287109375s
epoch 10: {'train_loss': '2.75429'}; time used = 1.2637791633605957s
epoch 15: {'train_loss': '2.73332'}; time used = 1.3104212284088135s
epoch 20: {'train_loss': '2.66584'}; time used = 1.283033847808838s
epoch 25: {'train_loss': '2.51826'}; time used = 1.4622297286987305s
epoch 30: {'train_loss': '2.31545'}; time used = 1.9400529861450195s
epoch 35: {'train_loss': '2.19687'}; time used = 1.9543287754058838s
epoch 40: {'train_loss': '2.09701'}; time used = 1.943033218383789s
epoch 45: {'train_loss': '2.16540'}; time used = 2.0973756313323975s
epoch 50: {'train_loss': '2.18655'}; time used = 1.6378264427185059s
epoch 55: {'train_loss': '2.10641'}; time used = 1.3914577960968018s
epoch 60: {'train_loss': '2.03695'}; time used = 1.6824867725372314s
epoch 65: {'train_loss': '1.96784'}; time used = 1.5454745292663574s
epoch 70: {'train_loss': '1.93964'}; time used = 1.618863582611084s
epoch 75: {'train_loss': '1.82049'}; time used = 2.031207323074341s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.64132785797119.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90086'}; time used = 2.552525758743286s
epoch 10: {'train_loss': '2.81202'}; time used = 1.8420934677124023s
epoch 15: {'train_loss': '2.81486'}; time used = 1.808579921722412s
epoch 20: {'train_loss': '2.80136'}; time used = 1.928962230682373s
epoch 25: {'train_loss': '2.79042'}; time used = 1.9287996292114258s
epoch 30: {'train_loss': '2.78381'}; time used = 2.0224902629852295s
epoch 35: {'train_loss': '2.77922'}; time used = 2.037015676498413s
epoch 40: {'train_loss': '2.77634'}; time used = 1.8549649715423584s
epoch 45: {'train_loss': '2.77419'}; time used = 1.832150936126709s
epoch 50: {'train_loss': '2.77299'}; time used = 1.8649556636810303s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.491479873657227.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.47630'}; time used = 5.0667173862457275s
epoch 10: {'train_loss': '2.85854'}; time used = 4.427675008773804s
epoch 15: {'train_loss': '2.85065'}; time used = 4.608034372329712s
epoch 20: {'train_loss': '2.85271'}; time used = 5.455620527267456s
epoch 25: {'train_loss': '2.82833'}; time used = 5.03968071937561s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.592137813568115.
Training classifier using 80.00% nodes...
{'micro': 0.7, 'macro': 0.6999699969997, 'samples': 0.7, 'weighted': 0.7000300030002999, 'accuracy': 0.7}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.22909'}; time used = 1.5996713638305664s
epoch 10: {'train_loss': '3.01154'}; time used = 1.2494416236877441s
epoch 15: {'train_loss': '2.89038'}; time used = 1.3238747119903564s
epoch 20: {'train_loss': '2.79573'}; time used = 1.290351390838623s
epoch 25: {'train_loss': '2.66391'}; time used = 1.2842895984649658s
epoch 30: {'train_loss': '2.55488'}; time used = 1.440119981765747s
epoch 35: {'train_loss': '2.44227'}; time used = 1.3327467441558838s
epoch 40: {'train_loss': '2.34257'}; time used = 1.291365623474121s
epoch 45: {'train_loss': '2.31452'}; time used = 1.267669439315796s
epoch 50: {'train_loss': '2.30848'}; time used = 1.3228442668914795s
epoch 55: {'train_loss': '2.25327'}; time used = 1.198734998703003s
epoch 60: {'train_loss': '2.21803'}; time used = 1.247748613357544s
epoch 65: {'train_loss': '2.20922'}; time used = 1.8426873683929443s
epoch 70: {'train_loss': '2.21013'}; time used = 2.0638206005096436s
epoch 75: {'train_loss': '2.13423'}; time used = 2.129025936126709s
epoch 80: {'train_loss': '2.11624'}; time used = 2.0381107330322266s
epoch 85: {'train_loss': '2.13605'}; time used = 1.898860216140747s
epoch 90: {'train_loss': '2.10845'}; time used = 1.8300013542175293s
epoch 95: {'train_loss': '2.15137'}; time used = 1.1287033557891846s
epoch 100: {'train_loss': '2.11018'}; time used = 1.1234667301177979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.72659468650818.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38930'}; time used = 2.6552045345306396s
epoch 10: {'train_loss': '1.35146'}; time used = 2.60313081741333s
epoch 15: {'train_loss': '1.38316'}; time used = 2.5135645866394043s
epoch 20: {'train_loss': '1.44782'}; time used = 2.773984432220459s
epoch 25: {'train_loss': '1.42530'}; time used = 2.554741144180298s
epoch 30: {'train_loss': '1.38806'}; time used = 2.5675511360168457s
epoch 35: {'train_loss': '1.37899'}; time used = 2.4675631523132324s
epoch 40: {'train_loss': '1.36118'}; time used = 5.581017971038818s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.857317209243774.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 4.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.62635'}; time used = 1.2168824672698975s
epoch 10: {'train_loss': '0.14194'}; time used = 1.085374355316162s
epoch 15: {'train_loss': '0.10532'}; time used = 1.2029237747192383s
epoch 20: {'train_loss': '0.06336'}; time used = 1.1110453605651855s
epoch 25: {'train_loss': '0.06711'}; time used = 1.1282968521118164s
epoch 30: {'train_loss': '0.05874'}; time used = 1.0561916828155518s
epoch 35: {'train_loss': '0.04240'}; time used = 1.0480577945709229s
epoch 40: {'train_loss': '0.06149'}; time used = 1.0123577117919922s
epoch 45: {'train_loss': '0.06211'}; time used = 1.2265982627868652s
epoch 50: {'train_loss': '0.05919'}; time used = 1.071336269378662s
epoch 55: {'train_loss': '0.04254'}; time used = 1.1748437881469727s
epoch 60: {'train_loss': '0.03408'}; time used = 1.2350668907165527s
epoch 65: {'train_loss': '0.04834'}; time used = 1.1823523044586182s
epoch 70: {'train_loss': '0.04104'}; time used = 1.168213129043579s
epoch 75: {'train_loss': '0.04070'}; time used = 1.3016984462738037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.99056100845337.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39035'}; time used = 1.2604920864105225s
epoch 10: {'train_loss': '1.35799'}; time used = 0.9452576637268066s
epoch 15: {'train_loss': '1.28885'}; time used = 0.9767580032348633s
epoch 20: {'train_loss': '1.35105'}; time used = 1.0499529838562012s
epoch 25: {'train_loss': '1.22014'}; time used = 0.9917049407958984s
epoch 30: {'train_loss': '1.22029'}; time used = 0.9985835552215576s
epoch 35: {'train_loss': '1.26005'}; time used = 0.9840645790100098s
epoch 40: {'train_loss': '1.19354'}; time used = 0.9824399948120117s
epoch 45: {'train_loss': '1.05509'}; time used = 1.056565523147583s
epoch 50: {'train_loss': '1.13936'}; time used = 1.04417085647583s
epoch 55: {'train_loss': '1.13262'}; time used = 0.9679920673370361s
epoch 60: {'train_loss': '1.26119'}; time used = 0.9712326526641846s
epoch 65: {'train_loss': '1.12083'}; time used = 0.955254077911377s
epoch 70: {'train_loss': '1.25936'}; time used = 1.0336663722991943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.470306396484375.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.41416'}; time used = 1.3149387836456299s
epoch 10: {'train_loss': '1.40068'}; time used = 1.1585745811462402s
epoch 15: {'train_loss': '1.38468'}; time used = 1.2019636631011963s
epoch 20: {'train_loss': '1.39197'}; time used = 1.1956541538238525s
epoch 25: {'train_loss': '1.37672'}; time used = 1.1127965450286865s
epoch 30: {'train_loss': '1.38074'}; time used = 1.129340648651123s
epoch 35: {'train_loss': '1.41484'}; time used = 1.1398231983184814s
epoch 40: {'train_loss': '1.37316'}; time used = 2.704463243484497s
epoch 45: {'train_loss': '1.35845'}; time used = 2.526747703552246s
epoch 50: {'train_loss': '1.39424'}; time used = 1.7211380004882812s
epoch 55: {'train_loss': '1.36754'}; time used = 3.2432870864868164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.582616329193115.
Training classifier using 80.00% nodes...
{'micro': 0.5263157894736842, 'macro': 0.4519230769230769, 'samples': 0.5263157894736842, 'weighted': 0.4838056680161944, 'accuracy': 0.5263157894736842}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.65 GiB already allocated; 412.44 MiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85279'}; time used = 2.953010320663452s
epoch 10: {'train_loss': '2.78885'}; time used = 2.8849902153015137s
epoch 15: {'train_loss': '2.75420'}; time used = 2.9230146408081055s
epoch 20: {'train_loss': '2.71192'}; time used = 1.7749292850494385s
epoch 25: {'train_loss': '2.66510'}; time used = 1.9619016647338867s
epoch 30: {'train_loss': '2.62191'}; time used = 1.777296543121338s
epoch 35: {'train_loss': '2.59785'}; time used = 1.9054012298583984s
epoch 40: {'train_loss': '2.54053'}; time used = 1.8496153354644775s
epoch 45: {'train_loss': '2.50836'}; time used = 1.755577564239502s
epoch 50: {'train_loss': '2.45465'}; time used = 1.681838035583496s
epoch 55: {'train_loss': '2.43399'}; time used = 1.8267254829406738s
epoch 60: {'train_loss': '2.42883'}; time used = 1.8875000476837158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.89954161643982.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5644143090951601, 'samples': 0.6086956521739131, 'weighted': 0.5744782507039676, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17392'}; time used = 1.938960075378418s
epoch 10: {'train_loss': '2.85923'}; time used = 1.6464955806732178s
epoch 15: {'train_loss': '2.76584'}; time used = 1.7288501262664795s
epoch 20: {'train_loss': '2.76360'}; time used = 1.6478612422943115s
epoch 25: {'train_loss': '2.74233'}; time used = 1.726663589477539s
epoch 30: {'train_loss': '2.68649'}; time used = 1.8492143154144287s
epoch 35: {'train_loss': '2.62527'}; time used = 1.7623100280761719s
epoch 40: {'train_loss': '2.57605'}; time used = 1.7261042594909668s
epoch 45: {'train_loss': '2.52532'}; time used = 1.6578552722930908s
epoch 50: {'train_loss': '2.44108'}; time used = 1.6728484630584717s
epoch 55: {'train_loss': '2.38787'}; time used = 1.689971685409546s
epoch 60: {'train_loss': '2.31206'}; time used = 1.6211395263671875s
epoch 65: {'train_loss': '2.20653'}; time used = 1.6274497509002686s
epoch 70: {'train_loss': '2.14364'}; time used = 1.6636607646942139s
epoch 75: {'train_loss': '2.04397'}; time used = 1.6218817234039307s
epoch 80: {'train_loss': '1.97342'}; time used = 1.694307565689087s
epoch 85: {'train_loss': '1.94649'}; time used = 1.7393748760223389s
epoch 90: {'train_loss': '2.03947'}; time used = 1.6396124362945557s
epoch 95: {'train_loss': '2.06971'}; time used = 1.740659475326538s
epoch 100: {'train_loss': '1.96100'}; time used = 1.6618013381958008s
epoch 105: {'train_loss': '1.89342'}; time used = 1.9450483322143555s
epoch 110: {'train_loss': '1.78260'}; time used = 1.8518311977386475s
epoch 115: {'train_loss': '1.75546'}; time used = 1.7460432052612305s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.96417188644409.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83233'}; time used = 3.389666795730591s
epoch 10: {'train_loss': '2.75990'}; time used = 3.1392555236816406s
epoch 15: {'train_loss': '2.75292'}; time used = 2.9740102291107178s
epoch 20: {'train_loss': '2.73638'}; time used = 2.3357958793640137s
epoch 25: {'train_loss': '2.70407'}; time used = 2.1465976238250732s
epoch 30: {'train_loss': '2.63242'}; time used = 2.2927474975585938s
epoch 35: {'train_loss': '2.58058'}; time used = 2.8257200717926025s
epoch 40: {'train_loss': '2.52791'}; time used = 1.9458072185516357s
epoch 45: {'train_loss': '2.50264'}; time used = 2.028534412384033s
epoch 50: {'train_loss': '2.46652'}; time used = 1.8916759490966797s
epoch 55: {'train_loss': '2.46946'}; time used = 1.9278807640075684s
epoch 60: {'train_loss': '2.45595'}; time used = 1.8387539386749268s
epoch 65: {'train_loss': '2.43397'}; time used = 1.8717575073242188s
epoch 70: {'train_loss': '2.41950'}; time used = 1.8446252346038818s
epoch 75: {'train_loss': '2.41967'}; time used = 1.847930908203125s
epoch 80: {'train_loss': '2.38142'}; time used = 2.030599594116211s
epoch 85: {'train_loss': '2.38229'}; time used = 2.0596139430999756s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.65974044799805.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37198'}; time used = 1.547480583190918s
epoch 10: {'train_loss': '1.56281'}; time used = 1.4218997955322266s
epoch 15: {'train_loss': '1.41738'}; time used = 1.5461697578430176s
epoch 20: {'train_loss': '1.30375'}; time used = 1.4693756103515625s
epoch 25: {'train_loss': '1.39160'}; time used = 1.481905460357666s
epoch 30: {'train_loss': '1.34575'}; time used = 1.3876569271087646s
epoch 35: {'train_loss': '1.38029'}; time used = 1.3581418991088867s
epoch 40: {'train_loss': '1.35413'}; time used = 1.7144317626953125s
epoch 45: {'train_loss': '1.39376'}; time used = 2.1562561988830566s
epoch 50: {'train_loss': '1.44929'}; time used = 1.4294180870056152s
epoch 55: {'train_loss': '1.35557'}; time used = 1.4113500118255615s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.76425075531006.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.09375'}; time used = 1.255828857421875s
epoch 10: {'train_loss': '0.43240'}; time used = 1.109567642211914s
epoch 15: {'train_loss': '0.34771'}; time used = 1.1012442111968994s
epoch 20: {'train_loss': '0.31146'}; time used = 0.9716382026672363s
epoch 25: {'train_loss': '0.35721'}; time used = 0.9829070568084717s
epoch 30: {'train_loss': '0.28641'}; time used = 1.1763951778411865s
epoch 35: {'train_loss': '0.31732'}; time used = 1.0311458110809326s
epoch 40: {'train_loss': '0.28453'}; time used = 0.9494330883026123s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.848088264465332.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40406'}; time used = 3.5900683403015137s
epoch 10: {'train_loss': '1.23037'}; time used = 1.9090697765350342s
epoch 15: {'train_loss': '0.82081'}; time used = 1.9719462394714355s
epoch 20: {'train_loss': '0.84504'}; time used = 1.7964897155761719s
epoch 25: {'train_loss': '0.32495'}; time used = 1.793323278427124s
epoch 30: {'train_loss': '0.20406'}; time used = 1.7404687404632568s
epoch 35: {'train_loss': '0.74298'}; time used = 1.731355905532837s
epoch 40: {'train_loss': '0.49227'}; time used = 1.777784824371338s
epoch 45: {'train_loss': '0.38853'}; time used = 1.728318214416504s
epoch 50: {'train_loss': '0.60713'}; time used = 1.8870365619659424s
epoch 55: {'train_loss': '0.13324'}; time used = 1.7678654193878174s
epoch 60: {'train_loss': '0.13913'}; time used = 1.753319263458252s
epoch 65: {'train_loss': '0.14055'}; time used = 1.778019905090332s
epoch 70: {'train_loss': '0.07747'}; time used = 1.7846426963806152s
epoch 75: {'train_loss': '0.02589'}; time used = 1.961564540863037s
epoch 80: {'train_loss': '0.02342'}; time used = 2.0494110584259033s
epoch 85: {'train_loss': '0.55516'}; time used = 2.0460855960845947s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.14709973335266.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.96012'}; time used = 1.7867488861083984s
epoch 10: {'train_loss': '0.00752'}; time used = 1.7050738334655762s
epoch 15: {'train_loss': '0.00001'}; time used = 1.64750337600708s
epoch 20: {'train_loss': '0.00005'}; time used = 1.6189913749694824s
epoch 25: {'train_loss': '0.00000'}; time used = 1.7185697555541992s
epoch 30: {'train_loss': '0.00000'}; time used = 1.6152279376983643s
epoch 35: {'train_loss': '0.00000'}; time used = 1.6035480499267578s
epoch 40: {'train_loss': '1.38629'}; time used = 1.6260490417480469s
epoch 45: {'train_loss': '0.00000'}; time used = 1.7051475048065186s
epoch 50: {'train_loss': '0.00000'}; time used = 2.0178604125976562s
epoch 55: {'train_loss': '1.38629'}; time used = 2.159106969833374s
epoch 60: {'train_loss': '0.00000'}; time used = 2.0830371379852295s
epoch 65: {'train_loss': '1.36608'}; time used = 2.1326894760131836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.906436920166016.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 64.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.27972'}; time used = 1.808652639389038s
epoch 10: {'train_loss': '1.07342'}; time used = 1.6915316581726074s
epoch 15: {'train_loss': '0.98309'}; time used = 1.8671190738677979s
epoch 20: {'train_loss': '0.89340'}; time used = 2.9863362312316895s
epoch 25: {'train_loss': '0.69903'}; time used = 3.3582711219787598s
epoch 30: {'train_loss': '0.40496'}; time used = 3.22031307220459s
epoch 35: {'train_loss': '0.19222'}; time used = 2.469677209854126s
epoch 40: {'train_loss': '0.21150'}; time used = 1.9166934490203857s
epoch 45: {'train_loss': '0.27263'}; time used = 1.66245436668396s
epoch 50: {'train_loss': '0.19283'}; time used = 1.6534042358398438s
epoch 55: {'train_loss': '0.32562'}; time used = 1.7073686122894287s
epoch 60: {'train_loss': '0.24371'}; time used = 1.691659688949585s
epoch 65: {'train_loss': '0.13592'}; time used = 2.0433666706085205s
epoch 70: {'train_loss': '0.03174'}; time used = 2.110039234161377s
epoch 75: {'train_loss': '0.00776'}; time used = 2.1397294998168945s
epoch 80: {'train_loss': '0.08554'}; time used = 2.263526201248169s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.45642828941345.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.48187084316670237, 'samples': 0.4927536231884058, 'weighted': 0.48731223317755407, 'accuracy': 0.4927536231884058}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85597'}; time used = 1.8899290561676025s
epoch 10: {'train_loss': '2.78138'}; time used = 1.8308162689208984s
epoch 15: {'train_loss': '2.76900'}; time used = 1.865039587020874s
epoch 20: {'train_loss': '2.77034'}; time used = 1.8597803115844727s
epoch 25: {'train_loss': '2.76843'}; time used = 1.8775334358215332s
epoch 30: {'train_loss': '2.76102'}; time used = 1.795060634613037s
epoch 35: {'train_loss': '2.76004'}; time used = 1.783797025680542s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.16562271118164.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 106.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 466.44 MiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.33325'}; time used = 1.8069226741790771s
epoch 10: {'train_loss': '1.24425'}; time used = 1.9416098594665527s
epoch 15: {'train_loss': '1.13348'}; time used = 1.809999704360962s
epoch 20: {'train_loss': '1.19157'}; time used = 1.7878448963165283s
epoch 25: {'train_loss': '1.06912'}; time used = 1.7814114093780518s
epoch 30: {'train_loss': '0.85283'}; time used = 1.6743943691253662s
epoch 35: {'train_loss': '0.94141'}; time used = 1.785937786102295s
epoch 40: {'train_loss': '0.80315'}; time used = 1.7555015087127686s
epoch 45: {'train_loss': '0.71052'}; time used = 2.5907485485076904s
epoch 50: {'train_loss': '0.54206'}; time used = 3.5679547786712646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.66706657409668.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 426.44 MiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.84946'}; time used = 1.8561317920684814s
epoch 10: {'train_loss': '2.78129'}; time used = 1.7448763847351074s
epoch 15: {'train_loss': '2.75771'}; time used = 1.6204869747161865s
epoch 20: {'train_loss': '2.72970'}; time used = 1.6088552474975586s
epoch 25: {'train_loss': '2.70227'}; time used = 1.8615827560424805s
epoch 30: {'train_loss': '2.68178'}; time used = 1.6974642276763916s
epoch 35: {'train_loss': '2.66206'}; time used = 1.6186528205871582s
epoch 40: {'train_loss': '2.64047'}; time used = 1.5897648334503174s
epoch 45: {'train_loss': '2.61025'}; time used = 1.6944551467895508s
epoch 50: {'train_loss': '2.58040'}; time used = 1.59493088722229s
epoch 55: {'train_loss': '2.58311'}; time used = 1.6988515853881836s
epoch 60: {'train_loss': '2.56349'}; time used = 1.5909812450408936s
epoch 65: {'train_loss': '2.54872'}; time used = 1.5774147510528564s
epoch 70: {'train_loss': '2.51847'}; time used = 1.5912559032440186s
epoch 75: {'train_loss': '2.50637'}; time used = 1.5882482528686523s
epoch 80: {'train_loss': '2.47841'}; time used = 1.6326525211334229s
epoch 85: {'train_loss': '2.48278'}; time used = 1.8783602714538574s
epoch 90: {'train_loss': '2.45379'}; time used = 1.6394298076629639s
epoch 95: {'train_loss': '2.46509'}; time used = 1.5422005653381348s
epoch 100: {'train_loss': '2.43924'}; time used = 1.5671420097351074s
epoch 105: {'train_loss': '2.44387'}; time used = 1.6595079898834229s
epoch 110: {'train_loss': '2.43407'}; time used = 1.5696134567260742s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.436036348342896.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 352.44 MiB free; 24.67 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.91 GiB already allocated; 150.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.39937'}; time used = 1.32071852684021s
epoch 10: {'train_loss': '2.86339'}; time used = 1.2326669692993164s
epoch 15: {'train_loss': '2.83209'}; time used = 1.1698856353759766s
epoch 20: {'train_loss': '2.82442'}; time used = 1.1584768295288086s
epoch 25: {'train_loss': '2.81090'}; time used = 1.2473955154418945s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.12514352798462.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6266061980347695, 'samples': 0.6578947368421053, 'weighted': 0.6436726737478617, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.98 GiB already allocated; 64.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76806'}; time used = 1.0884935855865479s
epoch 10: {'train_loss': '2.49435'}; time used = 0.9758491516113281s
epoch 15: {'train_loss': '1.90971'}; time used = 0.9410908222198486s
epoch 20: {'train_loss': '1.78958'}; time used = 0.9387350082397461s
epoch 25: {'train_loss': '1.66222'}; time used = 0.949852705001831s
epoch 30: {'train_loss': '1.59251'}; time used = 0.9718518257141113s
epoch 35: {'train_loss': '1.48152'}; time used = 1.022059440612793s
epoch 40: {'train_loss': '1.45903'}; time used = 1.153343677520752s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.35267949104309.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 82.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.20207'}; time used = 1.8113343715667725s
epoch 10: {'train_loss': '0.53286'}; time used = 1.5989656448364258s
epoch 15: {'train_loss': '0.44735'}; time used = 1.635740041732788s
epoch 20: {'train_loss': '0.37196'}; time used = 1.6329765319824219s
epoch 25: {'train_loss': '0.30563'}; time used = 1.6908230781555176s
epoch 30: {'train_loss': '0.26443'}; time used = 1.6002178192138672s
epoch 35: {'train_loss': '0.27122'}; time used = 1.7433161735534668s
epoch 40: {'train_loss': '0.27595'}; time used = 1.6449966430664062s
epoch 45: {'train_loss': '0.29079'}; time used = 1.650862455368042s
epoch 50: {'train_loss': '0.28948'}; time used = 1.5614001750946045s
epoch 55: {'train_loss': '0.24069'}; time used = 1.8210978507995605s
epoch 60: {'train_loss': '0.27113'}; time used = 1.583813190460205s
epoch 65: {'train_loss': '0.22061'}; time used = 2.6148197650909424s
epoch 70: {'train_loss': '0.29784'}; time used = 2.8921730518341064s
epoch 75: {'train_loss': '0.19235'}; time used = 3.1792080402374268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.40529918670654.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.99836'}; time used = 1.2075610160827637s
epoch 10: {'train_loss': '2.64606'}; time used = 1.0854814052581787s
epoch 15: {'train_loss': '2.55235'}; time used = 1.1200029850006104s
epoch 20: {'train_loss': '2.48735'}; time used = 1.0106711387634277s
epoch 25: {'train_loss': '2.46509'}; time used = 1.0113871097564697s
epoch 30: {'train_loss': '2.36834'}; time used = 1.0192413330078125s
epoch 35: {'train_loss': '2.29552'}; time used = 1.0295581817626953s
epoch 40: {'train_loss': '2.19426'}; time used = 1.011281967163086s
epoch 45: {'train_loss': '2.14451'}; time used = 1.4402766227722168s
epoch 50: {'train_loss': '2.15310'}; time used = 1.4228687286376953s
epoch 55: {'train_loss': '2.13352'}; time used = 1.262951135635376s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.601086854934692.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 130.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.24207'}; time used = 1.834827184677124s
epoch 10: {'train_loss': '2.77308'}; time used = 1.7561485767364502s
epoch 15: {'train_loss': '2.76376'}; time used = 1.8390014171600342s
epoch 20: {'train_loss': '2.73999'}; time used = 1.8238706588745117s
epoch 25: {'train_loss': '2.69393'}; time used = 1.8685152530670166s
epoch 30: {'train_loss': '2.58740'}; time used = 1.425368309020996s
epoch 35: {'train_loss': '2.32533'}; time used = 0.9309961795806885s
epoch 40: {'train_loss': '2.25445'}; time used = 0.9087295532226562s
epoch 45: {'train_loss': '2.04637'}; time used = 1.0387780666351318s
epoch 50: {'train_loss': '2.06652'}; time used = 0.854485034942627s
epoch 55: {'train_loss': '2.11464'}; time used = 0.8771045207977295s
epoch 60: {'train_loss': '1.95763'}; time used = 0.9185605049133301s
epoch 65: {'train_loss': '1.89745'}; time used = 0.8674137592315674s
epoch 70: {'train_loss': '1.88560'}; time used = 1.7144320011138916s
epoch 75: {'train_loss': '1.80520'}; time used = 1.0464305877685547s
epoch 80: {'train_loss': '1.89146'}; time used = 0.9154906272888184s
epoch 85: {'train_loss': '1.88539'}; time used = 0.945913553237915s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.51350712776184.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.45589'}; time used = 4.562060117721558s
epoch 10: {'train_loss': '2.84591'}; time used = 4.391119718551636s
epoch 15: {'train_loss': '2.83529'}; time used = 4.9917521476745605s
epoch 20: {'train_loss': '2.84115'}; time used = 4.452866077423096s
epoch 25: {'train_loss': '2.82535'}; time used = 4.443491220474243s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.106274366378784.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39748'}; time used = 1.1153900623321533s
epoch 10: {'train_loss': '1.38228'}; time used = 1.0374670028686523s
epoch 15: {'train_loss': '1.29866'}; time used = 1.7710621356964111s
epoch 20: {'train_loss': '1.30379'}; time used = 2.8173890113830566s
epoch 25: {'train_loss': '1.14184'}; time used = 1.9155051708221436s
epoch 30: {'train_loss': '1.11752'}; time used = 0.9950377941131592s
epoch 35: {'train_loss': '0.97928'}; time used = 0.9477195739746094s
epoch 40: {'train_loss': '1.24023'}; time used = 0.9669039249420166s
epoch 45: {'train_loss': '0.96694'}; time used = 0.9416587352752686s
epoch 50: {'train_loss': '0.99408'}; time used = 0.9450697898864746s
epoch 55: {'train_loss': '0.85809'}; time used = 0.9397060871124268s
epoch 60: {'train_loss': '1.05316'}; time used = 0.9334208965301514s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.675125122070312.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7564102564102564, 'samples': 0.7894736842105263, 'weighted': 0.7705802968960862, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.55377'}; time used = 1.3269827365875244s
epoch 10: {'train_loss': '0.32714'}; time used = 1.1464614868164062s
epoch 15: {'train_loss': '0.19876'}; time used = 1.1310234069824219s
epoch 20: {'train_loss': '0.15353'}; time used = 1.1702907085418701s
epoch 25: {'train_loss': '0.21343'}; time used = 1.1744205951690674s
epoch 30: {'train_loss': '0.13208'}; time used = 1.1698918342590332s
epoch 35: {'train_loss': '0.14723'}; time used = 1.1598892211914062s
epoch 40: {'train_loss': '0.18601'}; time used = 1.1709973812103271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.167190313339233.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.04 GiB already allocated; 4.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.22742'}; time used = 1.584965467453003s
epoch 10: {'train_loss': '2.81674'}; time used = 1.3626165390014648s
epoch 15: {'train_loss': '2.72405'}; time used = 1.269669532775879s
epoch 20: {'train_loss': '2.72919'}; time used = 1.2785027027130127s
epoch 25: {'train_loss': '2.66783'}; time used = 1.2832324504852295s
epoch 30: {'train_loss': '2.56848'}; time used = 1.3069636821746826s
epoch 35: {'train_loss': '2.45545'}; time used = 1.3144748210906982s
epoch 40: {'train_loss': '2.34170'}; time used = 1.2797574996948242s
epoch 45: {'train_loss': '2.23209'}; time used = 1.3003010749816895s
epoch 50: {'train_loss': '2.19594'}; time used = 1.3728532791137695s
epoch 55: {'train_loss': '2.17207'}; time used = 1.3122446537017822s
epoch 60: {'train_loss': '2.13683'}; time used = 1.3922858238220215s
epoch 65: {'train_loss': '2.15524'}; time used = 1.3918535709381104s
epoch 70: {'train_loss': '2.11140'}; time used = 1.3000812530517578s
epoch 75: {'train_loss': '2.02465'}; time used = 1.3348510265350342s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.648629903793335.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.5128205128205128, 'samples': 0.5789473684210527, 'weighted': 0.5411605937921727, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83248'}; time used = 7.312979459762573s
epoch 10: {'train_loss': '2.80120'}; time used = 6.831167221069336s
epoch 15: {'train_loss': '2.78457'}; time used = 6.725529670715332s
epoch 20: {'train_loss': '2.77603'}; time used = 6.655483961105347s
epoch 25: {'train_loss': '2.76843'}; time used = 6.821305990219116s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.31523132324219.
Training classifier using 80.00% nodes...
{'micro': 0.4666666666666667, 'macro': 0.46399826781583203, 'samples': 0.4666666666666667, 'weighted': 0.4619009798798792, 'accuracy': 0.4666666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.64321'}; time used = 2.3105831146240234s
epoch 10: {'train_loss': '2.48884'}; time used = 1.5227725505828857s
epoch 15: {'train_loss': '2.31156'}; time used = 0.9452154636383057s
epoch 20: {'train_loss': '2.25897'}; time used = 0.9606063365936279s
epoch 25: {'train_loss': '2.06666'}; time used = 1.028594970703125s
epoch 30: {'train_loss': '2.30994'}; time used = 1.0240581035614014s
epoch 35: {'train_loss': '1.80603'}; time used = 1.915653944015503s
epoch 40: {'train_loss': '1.85011'}; time used = 0.9825165271759033s
epoch 45: {'train_loss': '1.61844'}; time used = 0.9324572086334229s
epoch 50: {'train_loss': '1.60378'}; time used = 0.9841346740722656s
epoch 55: {'train_loss': '1.56232'}; time used = 1.0364882946014404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.993066787719727.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7301136363636364, 'samples': 0.7368421052631579, 'weighted': 0.7368421052631579, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.38258'}; time used = 1.1551756858825684s
epoch 10: {'train_loss': '1.38953'}; time used = 1.8163743019104004s
epoch 15: {'train_loss': '1.32397'}; time used = 2.337246894836426s
epoch 20: {'train_loss': '1.34949'}; time used = 2.4474401473999023s
epoch 25: {'train_loss': '1.28711'}; time used = 2.431333065032959s
epoch 30: {'train_loss': '1.26874'}; time used = 2.0933573246002197s
epoch 35: {'train_loss': '1.19288'}; time used = 1.0212678909301758s
epoch 40: {'train_loss': '1.04312'}; time used = 1.0893549919128418s
epoch 45: {'train_loss': '0.93490'}; time used = 1.0471386909484863s
epoch 50: {'train_loss': '1.09181'}; time used = 0.9446561336517334s
epoch 55: {'train_loss': '1.17681'}; time used = 0.9692366123199463s
epoch 60: {'train_loss': '0.97543'}; time used = 1.2726986408233643s
epoch 65: {'train_loss': '0.76948'}; time used = 0.9867429733276367s
epoch 70: {'train_loss': '0.68660'}; time used = 0.9872860908508301s
epoch 75: {'train_loss': '0.80486'}; time used = 1.1743896007537842s
epoch 80: {'train_loss': '0.61606'}; time used = 0.989246129989624s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.66524362564087.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.92649'}; time used = 1.6475496292114258s
epoch 10: {'train_loss': '2.89219'}; time used = 1.3205251693725586s
epoch 15: {'train_loss': '2.87158'}; time used = 1.162212610244751s
epoch 20: {'train_loss': '2.81575'}; time used = 1.064826488494873s
epoch 25: {'train_loss': '2.78740'}; time used = 1.0960798263549805s
epoch 30: {'train_loss': '2.77451'}; time used = 1.0916061401367188s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.913536548614502.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.44557'}; time used = 1.6729602813720703s
epoch 10: {'train_loss': '0.15774'}; time used = 1.4111669063568115s
epoch 15: {'train_loss': '0.05582'}; time used = 1.5379831790924072s
epoch 20: {'train_loss': '0.14414'}; time used = 1.4877910614013672s
epoch 25: {'train_loss': '0.21284'}; time used = 1.4341132640838623s
epoch 30: {'train_loss': '0.10733'}; time used = 1.3927001953125s
epoch 35: {'train_loss': '0.05907'}; time used = 1.447643518447876s
epoch 40: {'train_loss': '0.02978'}; time used = 1.4124774932861328s
epoch 45: {'train_loss': '0.01118'}; time used = 1.448951244354248s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.63622784614563.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.94970'}; time used = 3.7325236797332764s
epoch 10: {'train_loss': '2.83549'}; time used = 2.5424952507019043s
epoch 15: {'train_loss': '2.80472'}; time used = 1.836803913116455s
epoch 20: {'train_loss': '2.78072'}; time used = 1.818981647491455s
epoch 25: {'train_loss': '2.77036'}; time used = 1.8800299167633057s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.050020456314087.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83499'}; time used = 2.3132684230804443s
epoch 10: {'train_loss': '2.78071'}; time used = 1.9842731952667236s
epoch 15: {'train_loss': '2.77559'}; time used = 2.0511252880096436s
epoch 20: {'train_loss': '2.77133'}; time used = 2.007485866546631s
epoch 25: {'train_loss': '2.76236'}; time used = 2.095539093017578s
epoch 30: {'train_loss': '2.75280'}; time used = 2.0044667720794678s
epoch 35: {'train_loss': '2.72605'}; time used = 2.04069447517395s
epoch 40: {'train_loss': '2.67303'}; time used = 2.063397169113159s
epoch 45: {'train_loss': '2.61082'}; time used = 2.093932628631592s
epoch 50: {'train_loss': '2.54063'}; time used = 2.0371806621551514s
epoch 55: {'train_loss': '2.54309'}; time used = 2.155581474304199s
epoch 60: {'train_loss': '2.53510'}; time used = 1.9566929340362549s
epoch 65: {'train_loss': '2.50127'}; time used = 2.051813840866089s
epoch 70: {'train_loss': '2.47307'}; time used = 2.068702459335327s
epoch 75: {'train_loss': '2.42935'}; time used = 2.21571683883667s
epoch 80: {'train_loss': '2.43965'}; time used = 2.205707311630249s
epoch 85: {'train_loss': '2.45173'}; time used = 2.1940131187438965s
epoch 90: {'train_loss': '2.48099'}; time used = 2.3370537757873535s
epoch 95: {'train_loss': '2.45311'}; time used = 3.2543675899505615s
epoch 100: {'train_loss': '2.40835'}; time used = 3.3272786140441895s
epoch 105: {'train_loss': '2.42402'}; time used = 3.3223745822906494s
epoch 110: {'train_loss': '2.39353'}; time used = 2.313220500946045s
epoch 115: {'train_loss': '2.37189'}; time used = 2.183995485305786s
epoch 120: {'train_loss': '2.38077'}; time used = 2.09505558013916s
epoch 125: {'train_loss': '2.76533'}; time used = 2.1829049587249756s
epoch 130: {'train_loss': '2.51400'}; time used = 1.971059799194336s
epoch 135: {'train_loss': '2.50031'}; time used = 2.064548969268799s
epoch 140: {'train_loss': '2.47613'}; time used = 1.989685297012329s
epoch 145: {'train_loss': '2.45447'}; time used = 2.0100157260894775s
epoch 150: {'train_loss': '2.44350'}; time used = 1.9926612377166748s
epoch 155: {'train_loss': '2.41017'}; time used = 1.9810798168182373s
epoch 160: {'train_loss': '2.40005'}; time used = 2.1056978702545166s
epoch 165: {'train_loss': '2.38032'}; time used = 2.049983024597168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 76.52489972114563.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77576'}; time used = 1.7600634098052979s
epoch 10: {'train_loss': '2.77405'}; time used = 1.5911140441894531s
epoch 15: {'train_loss': '2.78055'}; time used = 2.273853302001953s
epoch 20: {'train_loss': '2.77517'}; time used = 2.6659436225891113s
epoch 25: {'train_loss': '2.77331'}; time used = 2.7096049785614014s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.54228639602661.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.35371'}; time used = 1.3448452949523926s
epoch 10: {'train_loss': '0.24694'}; time used = 1.2969751358032227s
epoch 15: {'train_loss': '0.24278'}; time used = 0.9370956420898438s
epoch 20: {'train_loss': '0.24256'}; time used = 1.0605649948120117s
epoch 25: {'train_loss': '0.29010'}; time used = 1.2016022205352783s
epoch 30: {'train_loss': '0.24238'}; time used = 0.9541418552398682s
epoch 35: {'train_loss': '0.27743'}; time used = 0.93918776512146s
epoch 40: {'train_loss': '0.21970'}; time used = 0.9316270351409912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.993513584136963.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86262'}; time used = 1.767096757888794s
epoch 10: {'train_loss': '2.78911'}; time used = 1.833169937133789s
epoch 15: {'train_loss': '2.74535'}; time used = 1.7184979915618896s
epoch 20: {'train_loss': '2.73760'}; time used = 2.139533042907715s
epoch 25: {'train_loss': '2.71617'}; time used = 3.133267879486084s
epoch 30: {'train_loss': '2.68996'}; time used = 2.9472553730010986s
epoch 35: {'train_loss': '2.66700'}; time used = 2.6391408443450928s
epoch 40: {'train_loss': '2.62832'}; time used = 1.8741769790649414s
epoch 45: {'train_loss': '2.58247'}; time used = 1.852811574935913s
epoch 50: {'train_loss': '2.51367'}; time used = 1.8331379890441895s
epoch 55: {'train_loss': '2.48999'}; time used = 1.9359452724456787s
epoch 60: {'train_loss': '2.44826'}; time used = 1.8526079654693604s
epoch 65: {'train_loss': '2.35623'}; time used = 1.9172074794769287s
epoch 70: {'train_loss': '2.49209'}; time used = 2.2892327308654785s
epoch 75: {'train_loss': '2.43575'}; time used = 2.153475522994995s
epoch 80: {'train_loss': '2.39420'}; time used = 1.828012228012085s
epoch 85: {'train_loss': '2.37355'}; time used = 1.8903594017028809s
epoch 90: {'train_loss': '2.36764'}; time used = 1.7274093627929688s
epoch 95: {'train_loss': '2.30157'}; time used = 1.7096819877624512s
epoch 100: {'train_loss': '2.27345'}; time used = 1.7739651203155518s
epoch 105: {'train_loss': '2.25921'}; time used = 1.7776684761047363s
epoch 110: {'train_loss': '2.20495'}; time used = 1.703009843826294s
epoch 115: {'train_loss': '2.21688'}; time used = 1.671522855758667s
epoch 120: {'train_loss': '2.16040'}; time used = 1.6548080444335938s
epoch 125: {'train_loss': '2.14039'}; time used = 1.6961948871612549s
epoch 130: {'train_loss': '2.11564'}; time used = 1.7042405605316162s
epoch 135: {'train_loss': '2.18957'}; time used = 1.715500831604004s
epoch 140: {'train_loss': '2.14357'}; time used = 1.7143902778625488s
epoch 145: {'train_loss': '2.21126'}; time used = 1.7020525932312012s
epoch 150: {'train_loss': '2.18774'}; time used = 1.7056488990783691s
epoch 155: {'train_loss': '2.13755'}; time used = 1.6862483024597168s
epoch 160: {'train_loss': '2.10482'}; time used = 1.7552800178527832s
epoch 165: {'train_loss': '2.06525'}; time used = 1.6875431537628174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 67.54647254943848.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.04058'}; time used = 1.5456960201263428s
epoch 10: {'train_loss': '0.65607'}; time used = 1.3622066974639893s
epoch 15: {'train_loss': '0.42071'}; time used = 1.3416643142700195s
epoch 20: {'train_loss': '0.30596'}; time used = 1.3509337902069092s
epoch 25: {'train_loss': '0.21425'}; time used = 1.4505457878112793s
epoch 30: {'train_loss': '0.28246'}; time used = 1.3447175025939941s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.854143857955933.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77252'}; time used = 1.3739547729492188s
epoch 10: {'train_loss': '2.78421'}; time used = 1.215383768081665s
epoch 15: {'train_loss': '2.78172'}; time used = 1.2256112098693848s
epoch 20: {'train_loss': '2.77309'}; time used = 1.2059094905853271s
epoch 25: {'train_loss': '2.77593'}; time used = 1.2175474166870117s
epoch 30: {'train_loss': '2.77341'}; time used = 1.2245428562164307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.929578304290771.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.592857142857143, 'samples': 0.6842105263157895, 'weighted': 0.6233082706766918, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84872'}; time used = 1.0534594058990479s
epoch 10: {'train_loss': '2.78237'}; time used = 1.0399680137634277s
epoch 15: {'train_loss': '2.77881'}; time used = 1.0196294784545898s
epoch 20: {'train_loss': '2.77988'}; time used = 0.9251487255096436s
epoch 25: {'train_loss': '2.77259'}; time used = 0.960451602935791s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.987083911895752.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 184.44 MiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.56 GiB already allocated; 498.44 MiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.00161'}; time used = 2.781697988510132s
epoch 10: {'train_loss': '2.92272'}; time used = 1.765815258026123s
epoch 15: {'train_loss': '2.79479'}; time used = 1.7403285503387451s
epoch 20: {'train_loss': '2.75444'}; time used = 1.7220284938812256s
epoch 25: {'train_loss': '2.73024'}; time used = 1.957876205444336s
epoch 30: {'train_loss': '2.70484'}; time used = 1.7899432182312012s
epoch 35: {'train_loss': '2.68399'}; time used = 1.7926254272460938s
epoch 40: {'train_loss': '2.65292'}; time used = 1.7883436679840088s
epoch 45: {'train_loss': '2.62053'}; time used = 1.8069159984588623s
epoch 50: {'train_loss': '2.58028'}; time used = 1.8140652179718018s
epoch 55: {'train_loss': '2.57271'}; time used = 2.067735195159912s
epoch 60: {'train_loss': '2.55574'}; time used = 1.7995109558105469s
epoch 65: {'train_loss': '2.51729'}; time used = 1.897911548614502s
epoch 70: {'train_loss': '2.47525'}; time used = 1.7992477416992188s
epoch 75: {'train_loss': '2.46896'}; time used = 2.034872531890869s
epoch 80: {'train_loss': '2.42648'}; time used = 1.9521961212158203s
epoch 85: {'train_loss': '2.43030'}; time used = 1.8628451824188232s
epoch 90: {'train_loss': '2.43214'}; time used = 1.7575197219848633s
epoch 95: {'train_loss': '2.41314'}; time used = 1.7668311595916748s
epoch 100: {'train_loss': '2.39206'}; time used = 1.8168513774871826s
epoch 105: {'train_loss': '2.40156'}; time used = 1.833693027496338s
epoch 110: {'train_loss': '2.36959'}; time used = 1.79555082321167s
epoch 115: {'train_loss': '2.37911'}; time used = 1.9455609321594238s
epoch 120: {'train_loss': '2.35983'}; time used = 1.8776662349700928s
epoch 125: {'train_loss': '2.33497'}; time used = 1.863795280456543s
epoch 130: {'train_loss': '2.35132'}; time used = 1.8498826026916504s
epoch 135: {'train_loss': '2.33486'}; time used = 1.9483675956726074s
epoch 140: {'train_loss': '2.33663'}; time used = 1.763033390045166s
epoch 145: {'train_loss': '2.31590'}; time used = 1.8553011417388916s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 58.40457892417908.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.35576'}; time used = 1.1193301677703857s
epoch 10: {'train_loss': '1.34995'}; time used = 1.0863769054412842s
epoch 15: {'train_loss': '0.63964'}; time used = 1.2307360172271729s
epoch 20: {'train_loss': '0.67049'}; time used = 1.021289348602295s
epoch 25: {'train_loss': '0.17568'}; time used = 0.9867351055145264s
epoch 30: {'train_loss': '0.24515'}; time used = 0.9980106353759766s
epoch 35: {'train_loss': '0.16505'}; time used = 0.9936699867248535s
epoch 40: {'train_loss': '0.21751'}; time used = 0.9882214069366455s
epoch 45: {'train_loss': '0.05346'}; time used = 0.9766595363616943s
epoch 50: {'train_loss': '0.04718'}; time used = 1.0694379806518555s
epoch 55: {'train_loss': '0.00805'}; time used = 1.0474112033843994s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.39461898803711.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.68 GiB already allocated; 352.44 MiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.26516'}; time used = 2.4528517723083496s
epoch 10: {'train_loss': '1.19452'}; time used = 2.431060552597046s
epoch 15: {'train_loss': '1.13887'}; time used = 2.37534499168396s
epoch 20: {'train_loss': '1.04810'}; time used = 2.5824103355407715s
epoch 25: {'train_loss': '0.83066'}; time used = 3.0968973636627197s
epoch 30: {'train_loss': '0.59386'}; time used = 3.6897943019866943s
epoch 35: {'train_loss': '0.45596'}; time used = 3.4634180068969727s
epoch 40: {'train_loss': '0.24230'}; time used = 2.9304559230804443s
epoch 45: {'train_loss': '0.17591'}; time used = 2.3902838230133057s
epoch 50: {'train_loss': '0.10677'}; time used = 2.366213798522949s
epoch 55: {'train_loss': '0.12488'}; time used = 2.40375018119812s
epoch 60: {'train_loss': '0.06333'}; time used = 2.5201621055603027s
epoch 65: {'train_loss': '0.04349'}; time used = 2.370807647705078s
epoch 70: {'train_loss': '0.05841'}; time used = 2.40380859375s
epoch 75: {'train_loss': '0.01746'}; time used = 2.3948814868927s
epoch 80: {'train_loss': '0.05139'}; time used = 2.452476978302002s
epoch 85: {'train_loss': '0.02430'}; time used = 2.4185333251953125s
epoch 90: {'train_loss': '0.03105'}; time used = 2.4347448348999023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.3819534778595.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.00439'}; time used = 1.2113831043243408s
epoch 10: {'train_loss': '0.70272'}; time used = 1.1716279983520508s
epoch 15: {'train_loss': '0.57685'}; time used = 1.0206248760223389s
epoch 20: {'train_loss': '0.46185'}; time used = 1.0740125179290771s
epoch 25: {'train_loss': '0.44195'}; time used = 0.9671869277954102s
epoch 30: {'train_loss': '0.34037'}; time used = 0.9291632175445557s
epoch 35: {'train_loss': '0.34824'}; time used = 1.0874390602111816s
epoch 40: {'train_loss': '0.30622'}; time used = 1.1797113418579102s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.88694715499878.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30682'}; time used = 2.0140435695648193s
epoch 10: {'train_loss': '1.08113'}; time used = 2.2722387313842773s
epoch 15: {'train_loss': '0.87740'}; time used = 1.859041452407837s
epoch 20: {'train_loss': '0.73961'}; time used = 1.9141192436218262s
epoch 25: {'train_loss': '0.65123'}; time used = 1.989356517791748s
epoch 30: {'train_loss': '0.57956'}; time used = 2.1151440143585205s
epoch 35: {'train_loss': '0.51387'}; time used = 2.258159637451172s
epoch 40: {'train_loss': '0.39097'}; time used = 2.0148329734802246s
epoch 45: {'train_loss': '0.33409'}; time used = 1.8796443939208984s
epoch 50: {'train_loss': '0.19269'}; time used = 2.098329544067383s
epoch 55: {'train_loss': '0.09857'}; time used = 1.9295566082000732s
epoch 60: {'train_loss': '0.24791'}; time used = 2.2146036624908447s
epoch 65: {'train_loss': '0.35160'}; time used = 1.967716932296753s
epoch 70: {'train_loss': '0.45376'}; time used = 1.968172311782837s
epoch 75: {'train_loss': '0.37101'}; time used = 2.0201094150543213s
epoch 80: {'train_loss': '0.21732'}; time used = 1.8975038528442383s
epoch 85: {'train_loss': '0.13814'}; time used = 1.8961296081542969s
epoch 90: {'train_loss': '0.13598'}; time used = 2.6982150077819824s
epoch 95: {'train_loss': '0.05901'}; time used = 2.9638917446136475s
epoch 100: {'train_loss': '0.13023'}; time used = 1.9651095867156982s
epoch 105: {'train_loss': '0.18498'}; time used = 1.8828437328338623s
epoch 110: {'train_loss': '0.08091'}; time used = 1.9833853244781494s
epoch 115: {'train_loss': '0.08114'}; time used = 2.113619089126587s
epoch 120: {'train_loss': '0.09259'}; time used = 1.9405057430267334s
epoch 125: {'train_loss': '0.04830'}; time used = 1.8226571083068848s
epoch 130: {'train_loss': '0.01565'}; time used = 1.9136481285095215s
epoch 135: {'train_loss': '0.01453'}; time used = 1.8816123008728027s
epoch 140: {'train_loss': '0.00047'}; time used = 1.9394290447235107s
epoch 145: {'train_loss': '0.19099'}; time used = 1.8758518695831299s
epoch 150: {'train_loss': '0.06949'}; time used = 1.9058825969696045s
epoch 155: {'train_loss': '0.05273'}; time used = 1.922882080078125s
epoch 160: {'train_loss': '0.04100'}; time used = 1.8436634540557861s
epoch 165: {'train_loss': '0.00927'}; time used = 3.082141160964966s
epoch 170: {'train_loss': '0.06888'}; time used = 1.939448595046997s
epoch 175: {'train_loss': '0.00161'}; time used = 2.1456971168518066s
epoch 180: {'train_loss': '0.00860'}; time used = 1.9742400646209717s
epoch 185: {'train_loss': '0.00912'}; time used = 1.8690176010131836s
epoch 190: {'train_loss': '0.00005'}; time used = 3.5838308334350586s
epoch 195: {'train_loss': '0.00768'}; time used = 2.0295488834381104s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 86.52748942375183.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5922727272727273, 'samples': 0.6231884057971014, 'weighted': 0.6004084321475626, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77937'}; time used = 1.9348821640014648s
epoch 10: {'train_loss': '2.77319'}; time used = 1.7944180965423584s
epoch 15: {'train_loss': '2.76981'}; time used = 3.2128922939300537s
epoch 20: {'train_loss': '2.76480'}; time used = 4.098613500595093s
epoch 25: {'train_loss': '2.76318'}; time used = 4.232261657714844s
epoch 30: {'train_loss': '2.75683'}; time used = 2.5184812545776367s
epoch 35: {'train_loss': '2.75364'}; time used = 1.7049875259399414s
epoch 40: {'train_loss': '2.75125'}; time used = 1.7177460193634033s
epoch 45: {'train_loss': '2.74574'}; time used = 1.7547156810760498s
epoch 50: {'train_loss': '2.74652'}; time used = 1.7867166996002197s
epoch 55: {'train_loss': '2.74437'}; time used = 3.871795177459717s
epoch 60: {'train_loss': '2.73301'}; time used = 2.570650100708008s
epoch 65: {'train_loss': '2.73018'}; time used = 1.8313913345336914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.24496078491211.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5251942286348501, 'samples': 0.5507246376811594, 'weighted': 0.5331724814618218, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03128'}; time used = 2.657654047012329s
epoch 10: {'train_loss': '2.91840'}; time used = 2.4520626068115234s
epoch 15: {'train_loss': '2.85992'}; time used = 2.661552906036377s
epoch 20: {'train_loss': '2.82369'}; time used = 3.3602256774902344s
epoch 25: {'train_loss': '2.80099'}; time used = 4.142082214355469s
epoch 30: {'train_loss': '2.79198'}; time used = 2.4514288902282715s
epoch 35: {'train_loss': '2.79632'}; time used = 2.428974151611328s
epoch 40: {'train_loss': '2.78516'}; time used = 2.6185975074768066s
epoch 45: {'train_loss': '2.77688'}; time used = 2.667886257171631s
epoch 50: {'train_loss': '2.76403'}; time used = 2.6580381393432617s
epoch 55: {'train_loss': '2.75355'}; time used = 2.5187482833862305s
epoch 60: {'train_loss': '2.73527'}; time used = 2.8427369594573975s
epoch 65: {'train_loss': '2.73331'}; time used = 2.6373131275177s
epoch 70: {'train_loss': '2.73924'}; time used = 3.8174149990081787s
epoch 75: {'train_loss': '2.71477'}; time used = 4.220221757888794s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.292539834976196.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 352.44 MiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.84728'}; time used = 1.198693037033081s
epoch 10: {'train_loss': '0.57332'}; time used = 0.97237229347229s
epoch 15: {'train_loss': '0.39693'}; time used = 0.975640058517456s
epoch 20: {'train_loss': '0.27231'}; time used = 1.0536787509918213s
epoch 25: {'train_loss': '0.24132'}; time used = 0.9653832912445068s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.926232099533081.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37475'}; time used = 1.535309076309204s
epoch 10: {'train_loss': '1.29825'}; time used = 1.4989733695983887s
epoch 15: {'train_loss': '1.19115'}; time used = 2.0340230464935303s
epoch 20: {'train_loss': '1.41152'}; time used = 1.5818796157836914s
epoch 25: {'train_loss': '1.37191'}; time used = 1.571580410003662s
epoch 30: {'train_loss': '1.38604'}; time used = 1.5814156532287598s
epoch 35: {'train_loss': '1.39415'}; time used = 1.7310914993286133s
epoch 40: {'train_loss': '1.37596'}; time used = 1.6178483963012695s
epoch 45: {'train_loss': '1.35495'}; time used = 1.4065322875976562s
epoch 50: {'train_loss': '1.38715'}; time used = 1.3596522808074951s
epoch 55: {'train_loss': '1.37860'}; time used = 1.3532838821411133s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.60987901687622.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40127'}; time used = 3.1056575775146484s
epoch 10: {'train_loss': '1.41017'}; time used = 3.1302924156188965s
epoch 15: {'train_loss': '1.38865'}; time used = 3.3536641597747803s
epoch 20: {'train_loss': '1.39510'}; time used = 3.131460666656494s
epoch 25: {'train_loss': '1.41536'}; time used = 2.7662110328674316s
epoch 30: {'train_loss': '1.37398'}; time used = 2.7005579471588135s
epoch 35: {'train_loss': '1.39234'}; time used = 2.309385299682617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.78107762336731.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84817'}; time used = 11.82391619682312s
epoch 10: {'train_loss': '2.77709'}; time used = 8.328484773635864s
epoch 15: {'train_loss': '2.78165'}; time used = 6.835077285766602s
epoch 20: {'train_loss': '2.77764'}; time used = 6.8662660121917725s
epoch 25: {'train_loss': '2.77375'}; time used = 6.312223434448242s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.0706512928009.
Training classifier using 80.00% nodes...
{'micro': 0.45, 'macro': 0.3644725086193194, 'samples': 0.45, 'weighted': 0.35353833336073975, 'accuracy': 0.45}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.26939'}; time used = 1.112121343612671s
epoch 10: {'train_loss': '1.39359'}; time used = 0.9889373779296875s
epoch 15: {'train_loss': '1.38421'}; time used = 0.9972114562988281s
epoch 20: {'train_loss': '1.38083'}; time used = 0.9900145530700684s
epoch 25: {'train_loss': '1.35247'}; time used = 0.9894466400146484s
epoch 30: {'train_loss': '1.38256'}; time used = 1.1481637954711914s
epoch 35: {'train_loss': '1.40194'}; time used = 0.9929642677307129s
epoch 40: {'train_loss': '1.37569'}; time used = 0.9672818183898926s
epoch 45: {'train_loss': '1.32547'}; time used = 1.1244604587554932s
epoch 50: {'train_loss': '1.40105'}; time used = 0.9901478290557861s
epoch 55: {'train_loss': '1.37275'}; time used = 0.9907760620117188s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.343111515045166.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82160'}; time used = 2.4111716747283936s
epoch 10: {'train_loss': '2.78956'}; time used = 2.3115298748016357s
epoch 15: {'train_loss': '2.77277'}; time used = 2.340181827545166s
epoch 20: {'train_loss': '2.77946'}; time used = 2.3025197982788086s
epoch 25: {'train_loss': '2.77310'}; time used = 2.411464214324951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.378068208694458.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.566247582205029, 'samples': 0.6231884057971014, 'weighted': 0.5776357469234434, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.87 GiB already allocated; 188.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 208.44 MiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.13303'}; time used = 2.9700138568878174s
epoch 10: {'train_loss': '1.06821'}; time used = 3.1606192588806152s
epoch 15: {'train_loss': '1.01867'}; time used = 2.9177591800689697s
epoch 20: {'train_loss': '0.97529'}; time used = 1.685107946395874s
epoch 25: {'train_loss': '0.95227'}; time used = 1.8362410068511963s
epoch 30: {'train_loss': '0.86013'}; time used = 1.6675934791564941s
epoch 35: {'train_loss': '0.83059'}; time used = 2.337958335876465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.19197368621826.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.486815415821501, 'samples': 0.5217391304347826, 'weighted': 0.4965164476585237, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87525'}; time used = 1.7674262523651123s
epoch 10: {'train_loss': '2.81846'}; time used = 1.7680788040161133s
epoch 15: {'train_loss': '2.80463'}; time used = 1.7893550395965576s
epoch 20: {'train_loss': '2.79125'}; time used = 1.7730779647827148s
epoch 25: {'train_loss': '2.78255'}; time used = 1.932746410369873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.098974227905273.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.89 GiB already allocated; 170.44 MiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.24951'}; time used = 1.8246681690216064s
epoch 10: {'train_loss': '1.18270'}; time used = 1.9570598602294922s
epoch 15: {'train_loss': '1.14995'}; time used = 1.773313283920288s
epoch 20: {'train_loss': '1.12008'}; time used = 2.0958383083343506s
epoch 25: {'train_loss': '1.08103'}; time used = 2.2073726654052734s
epoch 30: {'train_loss': '1.06100'}; time used = 2.1885640621185303s
epoch 35: {'train_loss': '1.03172'}; time used = 2.1606931686401367s
epoch 40: {'train_loss': '0.84032'}; time used = 2.025766372680664s
epoch 45: {'train_loss': '0.61686'}; time used = 2.057892084121704s
epoch 50: {'train_loss': '0.53779'}; time used = 1.705127477645874s
epoch 55: {'train_loss': '0.35418'}; time used = 1.753037929534912s
epoch 60: {'train_loss': '0.35029'}; time used = 1.7478058338165283s
epoch 65: {'train_loss': '0.48020'}; time used = 1.6303791999816895s
epoch 70: {'train_loss': '0.35719'}; time used = 1.6894843578338623s
epoch 75: {'train_loss': '0.39705'}; time used = 1.7846856117248535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.773195505142212.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.46215740507920544, 'samples': 0.5507246376811594, 'weighted': 0.4779729823295543, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 9.00 GiB already allocated; 46.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 208.44 MiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.5197248458862305s
epoch 10: {'train_loss': '1.38629'}; time used = 4.400979280471802s
epoch 15: {'train_loss': '1.38629'}; time used = 4.650022745132446s
epoch 20: {'train_loss': '1.38629'}; time used = 4.630479335784912s
epoch 25: {'train_loss': '1.38629'}; time used = 5.776995658874512s
epoch 30: {'train_loss': '1.38629'}; time used = 7.684335231781006s
epoch 35: {'train_loss': '1.38629'}; time used = 8.249143838882446s
epoch 40: {'train_loss': '1.38629'}; time used = 5.983504295349121s
epoch 45: {'train_loss': '1.38629'}; time used = 4.502874374389648s
epoch 50: {'train_loss': '1.38629'}; time used = 4.990732192993164s
epoch 55: {'train_loss': '1.38629'}; time used = 4.441296815872192s
epoch 60: {'train_loss': '1.38629'}; time used = 4.5945446491241455s
epoch 65: {'train_loss': '1.38629'}; time used = 4.615407943725586s
epoch 70: {'train_loss': '1.38629'}; time used = 4.542571306228638s
epoch 75: {'train_loss': '1.38629'}; time used = 4.48991584777832s
epoch 80: {'train_loss': '1.38629'}; time used = 4.644435405731201s
epoch 85: {'train_loss': '1.38629'}; time used = 4.8610053062438965s
epoch 90: {'train_loss': '1.38629'}; time used = 4.295021295547485s
epoch 95: {'train_loss': '1.38629'}; time used = 4.642961740493774s
epoch 100: {'train_loss': '1.38629'}; time used = 5.4666101932525635s
epoch 105: {'train_loss': '1.38629'}; time used = 4.653218030929565s
epoch 110: {'train_loss': '1.38629'}; time used = 7.988017320632935s
epoch 115: {'train_loss': '1.38629'}; time used = 7.8785481452941895s
epoch 120: {'train_loss': '1.38629'}; time used = 7.4128735065460205s
epoch 125: {'train_loss': '1.38629'}; time used = 4.7739646434783936s
epoch 130: {'train_loss': '1.38629'}; time used = 5.916923999786377s
epoch 135: {'train_loss': '1.38629'}; time used = 7.285191297531128s
epoch 140: {'train_loss': '1.38629'}; time used = 5.526996850967407s
epoch 145: {'train_loss': '1.38629'}; time used = 4.742255687713623s
epoch 150: {'train_loss': '1.38629'}; time used = 4.607359886169434s
epoch 155: {'train_loss': '1.38629'}; time used = 4.29590630531311s
epoch 160: {'train_loss': '1.38629'}; time used = 4.469789028167725s
epoch 165: {'train_loss': '1.38629'}; time used = 4.577388048171997s
epoch 170: {'train_loss': '1.38629'}; time used = 7.204445123672485s
epoch 175: {'train_loss': '1.38629'}; time used = 4.44244647026062s
epoch 180: {'train_loss': '1.38629'}; time used = 5.1454949378967285s
epoch 185: {'train_loss': '1.38629'}; time used = 8.01319694519043s
epoch 190: {'train_loss': '1.38629'}; time used = 7.9007251262664795s
epoch 195: {'train_loss': '1.38629'}; time used = 7.887733697891235s
epoch 200: {'train_loss': '1.38629'}; time used = 5.668671369552612s
epoch 205: {'train_loss': '1.38629'}; time used = 4.4980247020721436s
epoch 210: {'train_loss': '1.38629'}; time used = 4.148137331008911s
epoch 215: {'train_loss': '1.38629'}; time used = 4.030497789382935s
epoch 220: {'train_loss': '1.38629'}; time used = 4.129891395568848s
epoch 225: {'train_loss': '1.38629'}; time used = 4.22926664352417s
epoch 230: {'train_loss': '1.38629'}; time used = 4.368783473968506s
epoch 235: {'train_loss': '1.38629'}; time used = 4.125002861022949s
epoch 240: {'train_loss': '1.38629'}; time used = 4.428998708724976s
epoch 245: {'train_loss': '1.38629'}; time used = 4.233487367630005s
epoch 250: {'train_loss': '1.38629'}; time used = 4.244043350219727s
epoch 255: {'train_loss': '1.38629'}; time used = 4.272691011428833s
epoch 260: {'train_loss': '1.38629'}; time used = 4.297130823135376s
epoch 265: {'train_loss': '1.38629'}; time used = 4.117490530014038s
epoch 270: {'train_loss': '1.38629'}; time used = 4.376138687133789s
epoch 275: {'train_loss': '1.38629'}; time used = 4.240928411483765s
epoch 280: {'train_loss': '1.38629'}; time used = 4.155060768127441s
epoch 285: {'train_loss': '1.38629'}; time used = 4.313161611557007s
epoch 290: {'train_loss': '1.38629'}; time used = 4.107703447341919s
epoch 295: {'train_loss': '1.38629'}; time used = 4.109885931015015s
epoch 300: {'train_loss': '1.38629'}; time used = 4.096208810806274s
epoch 305: {'train_loss': '1.38629'}; time used = 4.1520867347717285s
epoch 310: {'train_loss': '1.38629'}; time used = 4.147069931030273s
epoch 315: {'train_loss': '1.38629'}; time used = 4.14836311340332s
epoch 320: {'train_loss': '1.38629'}; time used = 6.913306951522827s
epoch 325: {'train_loss': '1.38629'}; time used = 5.193277835845947s
epoch 330: {'train_loss': '1.38629'}; time used = 4.142929553985596s
epoch 335: {'train_loss': '1.38629'}; time used = 4.122152805328369s
epoch 340: {'train_loss': '1.38629'}; time used = 4.144711971282959s
epoch 345: {'train_loss': '1.38629'}; time used = 4.185914754867554s
epoch 350: {'train_loss': '1.38629'}; time used = 4.096493244171143s
epoch 355: {'train_loss': '1.38629'}; time used = 4.038414239883423s
epoch 360: {'train_loss': '1.38629'}; time used = 4.091161489486694s
epoch 365: {'train_loss': '1.38629'}; time used = 4.108234167098999s
epoch 370: {'train_loss': '1.38629'}; time used = 4.106194972991943s
epoch 375: {'train_loss': '1.38629'}; time used = 4.1228251457214355s
epoch 380: {'train_loss': '1.38629'}; time used = 4.136182546615601s
epoch 385: {'train_loss': '1.38629'}; time used = 4.153302907943726s
epoch 390: {'train_loss': '1.38629'}; time used = 4.208717346191406s
epoch 395: {'train_loss': '1.38629'}; time used = 4.04594612121582s
epoch 400: {'train_loss': '1.38629'}; time used = 4.102304458618164s
epoch 405: {'train_loss': '1.38629'}; time used = 4.143820762634277s
epoch 410: {'train_loss': '1.38629'}; time used = 4.157193660736084s
epoch 415: {'train_loss': '1.38629'}; time used = 4.065110206604004s
epoch 420: {'train_loss': '1.38629'}; time used = 4.125677108764648s
epoch 425: {'train_loss': '1.38629'}; time used = 4.071414232254028s
epoch 430: {'train_loss': '1.38629'}; time used = 7.744464635848999s
epoch 435: {'train_loss': '1.38629'}; time used = 5.2632365226745605s
epoch 440: {'train_loss': '1.38629'}; time used = 4.6631598472595215s
epoch 445: {'train_loss': '1.38629'}; time used = 4.3112952709198s
epoch 450: {'train_loss': '1.38629'}; time used = 4.169424772262573s
epoch 455: {'train_loss': '1.38629'}; time used = 4.197268009185791s
epoch 460: {'train_loss': '1.38629'}; time used = 4.270134925842285s
epoch 465: {'train_loss': '1.38629'}; time used = 4.224513292312622s
epoch 470: {'train_loss': '1.38629'}; time used = 4.4326136112213135s
epoch 475: {'train_loss': '1.38629'}; time used = 5.4076151847839355s
epoch 480: {'train_loss': '1.38629'}; time used = 4.384300708770752s
epoch 485: {'train_loss': '1.38629'}; time used = 4.394301414489746s
epoch 490: {'train_loss': '1.38629'}; time used = 4.192143678665161s
epoch 495: {'train_loss': '1.38629'}; time used = 4.382437229156494s
epoch 500: {'train_loss': '1.38629'}; time used = 4.188695907592773s
Finished training. Time used = 493.183963060379.
Training classifier using 80.00% nodes...
{'micro': 0.625, 'macro': 0.6190476190476191, 'samples': 0.625, 'weighted': 0.6180952380952381, 'accuracy': 0.625}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.86 GiB already allocated; 208.44 MiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 466.44 MiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76608'}; time used = 2.1399896144866943s
epoch 10: {'train_loss': '2.72424'}; time used = 2.0360326766967773s
epoch 15: {'train_loss': '2.69711'}; time used = 1.9657044410705566s
epoch 20: {'train_loss': '2.66782'}; time used = 1.7023372650146484s
epoch 25: {'train_loss': '2.60695'}; time used = 1.8135440349578857s
epoch 30: {'train_loss': '2.54684'}; time used = 1.8000118732452393s
epoch 35: {'train_loss': '2.50029'}; time used = 1.7524733543395996s
epoch 40: {'train_loss': '2.38565'}; time used = 1.695326328277588s
epoch 45: {'train_loss': '2.33394'}; time used = 1.68135666847229s
epoch 50: {'train_loss': '2.24605'}; time used = 1.7192025184631348s
epoch 55: {'train_loss': '2.23812'}; time used = 1.916076421737671s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.922237634658813.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92372'}; time used = 2.655395269393921s
epoch 10: {'train_loss': '2.88972'}; time used = 2.172548294067383s
epoch 15: {'train_loss': '2.84413'}; time used = 1.1626172065734863s
epoch 20: {'train_loss': '2.81104'}; time used = 1.3293201923370361s
epoch 25: {'train_loss': '2.79528'}; time used = 1.2148222923278809s
epoch 30: {'train_loss': '2.79860'}; time used = 1.1426801681518555s
epoch 35: {'train_loss': '2.78958'}; time used = 1.16941237449646s
epoch 40: {'train_loss': '2.79143'}; time used = 1.1553871631622314s
epoch 45: {'train_loss': '2.79118'}; time used = 1.1582310199737549s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.86604332923889.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36556'}; time used = 2.5880351066589355s
epoch 10: {'train_loss': '1.21283'}; time used = 2.4563052654266357s
epoch 15: {'train_loss': '1.04532'}; time used = 2.6828713417053223s
epoch 20: {'train_loss': '0.85109'}; time used = 2.718752861022949s
epoch 25: {'train_loss': '0.74009'}; time used = 2.6310696601867676s
epoch 30: {'train_loss': '0.58724'}; time used = 2.511538505554199s
epoch 35: {'train_loss': '0.65857'}; time used = 2.458799362182617s
epoch 40: {'train_loss': '0.54305'}; time used = 2.405942440032959s
epoch 45: {'train_loss': '0.55863'}; time used = 2.4364678859710693s
epoch 50: {'train_loss': '0.54080'}; time used = 2.4619522094726562s
epoch 55: {'train_loss': '0.28273'}; time used = 2.4301342964172363s
epoch 60: {'train_loss': '0.23922'}; time used = 2.548126697540283s
epoch 65: {'train_loss': '0.26262'}; time used = 2.4551095962524414s
epoch 70: {'train_loss': '0.39521'}; time used = 2.4397387504577637s
epoch 75: {'train_loss': '0.20421'}; time used = 2.663912296295166s
epoch 80: {'train_loss': '0.14976'}; time used = 2.483508825302124s
epoch 85: {'train_loss': '0.19643'}; time used = 2.4707794189453125s
epoch 90: {'train_loss': '0.02348'}; time used = 3.025897264480591s
epoch 95: {'train_loss': '0.02461'}; time used = 3.469534158706665s
epoch 100: {'train_loss': '0.36901'}; time used = 2.552694320678711s
epoch 105: {'train_loss': '0.51155'}; time used = 2.4455106258392334s
epoch 110: {'train_loss': '0.28326'}; time used = 2.5322766304016113s
epoch 115: {'train_loss': '0.21155'}; time used = 3.1583385467529297s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 66.53758668899536.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.75 GiB already allocated; 300.44 MiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17021'}; time used = 1.093574047088623s
epoch 10: {'train_loss': '2.83463'}; time used = 1.1555092334747314s
epoch 15: {'train_loss': '2.68806'}; time used = 0.9484407901763916s
epoch 20: {'train_loss': '2.42839'}; time used = 0.9265642166137695s
epoch 25: {'train_loss': '1.84738'}; time used = 1.008714199066162s
epoch 30: {'train_loss': '1.46755'}; time used = 0.9264235496520996s
epoch 35: {'train_loss': '1.38517'}; time used = 0.9214422702789307s
epoch 40: {'train_loss': '1.32043'}; time used = 0.9444460868835449s
epoch 45: {'train_loss': '1.23965'}; time used = 0.9927613735198975s
epoch 50: {'train_loss': '1.13769'}; time used = 0.9271945953369141s
epoch 55: {'train_loss': '1.54216'}; time used = 0.938795804977417s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.468053579330444.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.63 GiB already allocated; 420.44 MiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98843'}; time used = 1.774670124053955s
epoch 10: {'train_loss': '2.78480'}; time used = 1.6713871955871582s
epoch 15: {'train_loss': '2.74778'}; time used = 1.712991714477539s
epoch 20: {'train_loss': '2.72421'}; time used = 1.6109437942504883s
epoch 25: {'train_loss': '2.70666'}; time used = 1.8221595287322998s
epoch 30: {'train_loss': '2.69054'}; time used = 1.7208666801452637s
epoch 35: {'train_loss': '2.67187'}; time used = 1.694957971572876s
epoch 40: {'train_loss': '2.63527'}; time used = 1.7182700634002686s
epoch 45: {'train_loss': '2.61920'}; time used = 1.6602752208709717s
epoch 50: {'train_loss': '2.58483'}; time used = 1.7285881042480469s
epoch 55: {'train_loss': '2.57867'}; time used = 2.312910556793213s
epoch 60: {'train_loss': '2.55649'}; time used = 1.6665725708007812s
epoch 65: {'train_loss': '2.52846'}; time used = 1.661067247390747s
epoch 70: {'train_loss': '2.50742'}; time used = 1.648669958114624s
epoch 75: {'train_loss': '2.46801'}; time used = 1.651860237121582s
epoch 80: {'train_loss': '2.47590'}; time used = 1.7073307037353516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.84139060974121.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.40665742024965323, 'samples': 0.5507246376811594, 'weighted': 0.42784377575428645, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.52 GiB already allocated; 554.44 MiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39173'}; time used = 1.1329154968261719s
epoch 10: {'train_loss': '1.36188'}; time used = 1.0345876216888428s
epoch 15: {'train_loss': '1.26067'}; time used = 0.9817135334014893s
epoch 20: {'train_loss': '1.28189'}; time used = 0.9585151672363281s
epoch 25: {'train_loss': '1.18657'}; time used = 0.9514122009277344s
epoch 30: {'train_loss': '1.05412'}; time used = 0.9683418273925781s
epoch 35: {'train_loss': '1.13107'}; time used = 0.984236478805542s
epoch 40: {'train_loss': '1.13537'}; time used = 0.9465610980987549s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.162542343139648.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.70 GiB already allocated; 332.44 MiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.59 GiB already allocated; 452.44 MiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94453'}; time used = 1.3272907733917236s
epoch 10: {'train_loss': '2.82469'}; time used = 1.00773024559021s
epoch 15: {'train_loss': '2.79906'}; time used = 1.0117030143737793s
epoch 20: {'train_loss': '2.78504'}; time used = 1.0299091339111328s
epoch 25: {'train_loss': '2.77826'}; time used = 1.0136146545410156s
epoch 30: {'train_loss': '2.77349'}; time used = 1.1027204990386963s
epoch 35: {'train_loss': '2.77233'}; time used = 1.0706708431243896s
epoch 40: {'train_loss': '2.77245'}; time used = 1.0163230895996094s
epoch 45: {'train_loss': '2.77292'}; time used = 1.0473780632019043s
epoch 50: {'train_loss': '2.77239'}; time used = 1.0421819686889648s
epoch 55: {'train_loss': '2.77234'}; time used = 1.0238943099975586s
epoch 60: {'train_loss': '2.77180'}; time used = 1.0341603755950928s
epoch 65: {'train_loss': '2.77206'}; time used = 1.178873062133789s
epoch 70: {'train_loss': '2.77237'}; time used = 3.5587387084960938s
epoch 75: {'train_loss': '2.77215'}; time used = 4.0153539180755615s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.834977626800537.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12764'}; time used = 2.095513343811035s
epoch 10: {'train_loss': '0.90596'}; time used = 1.700011968612671s
epoch 15: {'train_loss': '0.62179'}; time used = 1.719040870666504s
epoch 20: {'train_loss': '0.31773'}; time used = 1.7249364852905273s
epoch 25: {'train_loss': '0.21748'}; time used = 1.8227119445800781s
epoch 30: {'train_loss': '0.17307'}; time used = 1.9853460788726807s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.270508527755737.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.47550675675675674, 'samples': 0.4782608695652174, 'weighted': 0.4782608695652174, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01829'}; time used = 1.4097473621368408s
epoch 10: {'train_loss': '0.54877'}; time used = 1.1833422183990479s
epoch 15: {'train_loss': '0.36443'}; time used = 1.0914154052734375s
epoch 20: {'train_loss': '0.23689'}; time used = 1.0898618698120117s
epoch 25: {'train_loss': '0.15849'}; time used = 1.0854358673095703s
epoch 30: {'train_loss': '0.10828'}; time used = 1.102900743484497s
epoch 35: {'train_loss': '0.06876'}; time used = 1.081963062286377s
epoch 40: {'train_loss': '0.05584'}; time used = 1.0786361694335938s
epoch 45: {'train_loss': '0.05533'}; time used = 1.0920538902282715s
epoch 50: {'train_loss': '0.04537'}; time used = 1.0749077796936035s
epoch 55: {'train_loss': '0.03158'}; time used = 1.0870404243469238s
epoch 60: {'train_loss': '0.02388'}; time used = 1.1996397972106934s
epoch 65: {'train_loss': '0.03369'}; time used = 1.1500513553619385s
epoch 70: {'train_loss': '0.02296'}; time used = 1.1255240440368652s
epoch 75: {'train_loss': '0.02310'}; time used = 1.270880937576294s
epoch 80: {'train_loss': '0.02134'}; time used = 0.9247477054595947s
epoch 85: {'train_loss': '0.02298'}; time used = 0.8874404430389404s
epoch 90: {'train_loss': '0.02677'}; time used = 0.9985601902008057s
epoch 95: {'train_loss': '0.03140'}; time used = 0.9815821647644043s
epoch 100: {'train_loss': '0.03463'}; time used = 0.9828698635101318s
epoch 105: {'train_loss': '0.01364'}; time used = 0.9624571800231934s
epoch 110: {'train_loss': '0.01491'}; time used = 0.9752109050750732s
epoch 115: {'train_loss': '0.01870'}; time used = 0.9331483840942383s
epoch 120: {'train_loss': '0.01980'}; time used = 1.0778520107269287s
epoch 125: {'train_loss': '0.02197'}; time used = 1.0156641006469727s
epoch 130: {'train_loss': '0.01342'}; time used = 0.9915258884429932s
epoch 135: {'train_loss': '0.01567'}; time used = 1.0425584316253662s
epoch 140: {'train_loss': '0.02848'}; time used = 0.9340291023254395s
epoch 145: {'train_loss': '0.01461'}; time used = 1.7836549282073975s
epoch 150: {'train_loss': '0.01444'}; time used = 1.1278636455535889s
epoch 155: {'train_loss': '0.01440'}; time used = 1.0946121215820312s
epoch 160: {'train_loss': '0.00973'}; time used = 1.129786729812622s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.73565173149109.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7840909090909092, 'samples': 0.7894736842105263, 'weighted': 0.7894736842105263, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40860'}; time used = 1.2799959182739258s
epoch 10: {'train_loss': '1.37551'}; time used = 1.071671485900879s
epoch 15: {'train_loss': '1.32501'}; time used = 1.0909101963043213s
epoch 20: {'train_loss': '1.31487'}; time used = 1.0376508235931396s
epoch 25: {'train_loss': '1.25231'}; time used = 1.044219732284546s
epoch 30: {'train_loss': '1.28009'}; time used = 1.0381221771240234s
epoch 35: {'train_loss': '1.31137'}; time used = 1.0471422672271729s
epoch 40: {'train_loss': '1.28273'}; time used = 1.1378026008605957s
epoch 45: {'train_loss': '1.16837'}; time used = 1.053307294845581s
epoch 50: {'train_loss': '1.20251'}; time used = 1.0872581005096436s
epoch 55: {'train_loss': '1.18520'}; time used = 1.1366314888000488s
epoch 60: {'train_loss': '1.23547'}; time used = 1.069059133529663s
epoch 65: {'train_loss': '1.13305'}; time used = 2.092198133468628s
epoch 70: {'train_loss': '1.26294'}; time used = 1.4291317462921143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.11040234565735.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.60 GiB already allocated; 466.44 MiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.94 GiB already allocated; 130.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.30125'}; time used = 1.0537445545196533s
epoch 10: {'train_loss': '1.49651'}; time used = 1.07259202003479s
epoch 15: {'train_loss': '1.35363'}; time used = 0.9762804508209229s
epoch 20: {'train_loss': '1.37161'}; time used = 0.9504590034484863s
epoch 25: {'train_loss': '1.30351'}; time used = 0.9472012519836426s
epoch 30: {'train_loss': '1.31264'}; time used = 0.9765467643737793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.390971183776855.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39958'}; time used = 1.159266710281372s
epoch 10: {'train_loss': '1.39691'}; time used = 1.2519536018371582s
epoch 15: {'train_loss': '1.38470'}; time used = 1.1687886714935303s
epoch 20: {'train_loss': '1.39008'}; time used = 2.2676591873168945s
epoch 25: {'train_loss': '1.38910'}; time used = 3.4981918334960938s
epoch 30: {'train_loss': '1.38569'}; time used = 3.0344643592834473s
epoch 35: {'train_loss': '1.39402'}; time used = 1.9382469654083252s
epoch 40: {'train_loss': '1.37468'}; time used = 0.986396312713623s
epoch 45: {'train_loss': '1.34329'}; time used = 1.104048490524292s
epoch 50: {'train_loss': '1.40986'}; time used = 1.02089524269104s
epoch 55: {'train_loss': '1.38003'}; time used = 1.0470857620239258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.76766538619995.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.35456'}; time used = 8.734848976135254s
epoch 10: {'train_loss': '1.32258'}; time used = 8.570773363113403s
epoch 15: {'train_loss': '1.24641'}; time used = 9.106935501098633s
epoch 20: {'train_loss': '1.12525'}; time used = 9.120656251907349s
epoch 25: {'train_loss': '0.93089'}; time used = 8.984252452850342s
epoch 30: {'train_loss': '0.88318'}; time used = 7.361023187637329s
epoch 35: {'train_loss': '0.70576'}; time used = 7.810350179672241s
epoch 40: {'train_loss': '0.69694'}; time used = 7.146696329116821s
epoch 45: {'train_loss': '0.88132'}; time used = 7.256208181381226s
epoch 50: {'train_loss': '0.55964'}; time used = 7.031508684158325s
epoch 55: {'train_loss': '0.54716'}; time used = 10.682029962539673s
epoch 60: {'train_loss': '0.50880'}; time used = 7.409557342529297s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 138.7336549758911.
Training classifier using 80.00% nodes...
{'micro': 0.51, 'macro': 0.4985994383443244, 'samples': 0.51, 'weighted': 0.4944198983077672, 'accuracy': 0.51}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38826'}; time used = 1.3566985130310059s
epoch 10: {'train_loss': '1.38044'}; time used = 1.2085785865783691s
epoch 15: {'train_loss': '1.33123'}; time used = 1.2296240329742432s
epoch 20: {'train_loss': '1.34158'}; time used = 1.1895272731781006s
epoch 25: {'train_loss': '1.30208'}; time used = 1.243474006652832s
epoch 30: {'train_loss': '1.31376'}; time used = 1.2182817459106445s
epoch 35: {'train_loss': '1.29237'}; time used = 1.2365593910217285s
epoch 40: {'train_loss': '1.20985'}; time used = 1.2810652256011963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.887607336044312.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.29539'}; time used = 1.757101058959961s
epoch 10: {'train_loss': '1.20603'}; time used = 1.8414480686187744s
epoch 15: {'train_loss': '1.14910'}; time used = 1.731905221939087s
epoch 20: {'train_loss': '1.01411'}; time used = 1.8625705242156982s
epoch 25: {'train_loss': '0.91558'}; time used = 1.788536548614502s
epoch 30: {'train_loss': '0.78658'}; time used = 1.6648907661437988s
epoch 35: {'train_loss': '0.62984'}; time used = 1.6602191925048828s
epoch 40: {'train_loss': '0.50384'}; time used = 1.7156760692596436s
epoch 45: {'train_loss': '0.34040'}; time used = 1.7505993843078613s
epoch 50: {'train_loss': '0.17605'}; time used = 1.7591369152069092s
epoch 55: {'train_loss': '0.16749'}; time used = 1.8812315464019775s
epoch 60: {'train_loss': '0.18478'}; time used = 1.6994500160217285s
epoch 65: {'train_loss': '0.08289'}; time used = 1.7096648216247559s
epoch 70: {'train_loss': '0.24931'}; time used = 1.6795885562896729s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.47918462753296.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.78 GiB already allocated; 294.44 MiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85129'}; time used = 11.012700080871582s
epoch 10: {'train_loss': '2.77797'}; time used = 7.825066804885864s
epoch 15: {'train_loss': '2.77956'}; time used = 7.144227504730225s
epoch 20: {'train_loss': '2.78609'}; time used = 6.6211676597595215s
epoch 25: {'train_loss': '2.77362'}; time used = 7.007087230682373s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.53827357292175.
Training classifier using 80.00% nodes...
{'micro': 0.49666666666666665, 'macro': 0.4290110410113157, 'samples': 0.49666666666666665, 'weighted': 0.41921763285789937, 'accuracy': 0.49666666666666665}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01880'}; time used = 1.2051656246185303s
epoch 10: {'train_loss': '0.51527'}; time used = 1.0025670528411865s
epoch 15: {'train_loss': '0.35322'}; time used = 1.0090060234069824s
epoch 20: {'train_loss': '0.24692'}; time used = 0.9954962730407715s
epoch 25: {'train_loss': '0.18056'}; time used = 0.9737145900726318s
epoch 30: {'train_loss': '0.10972'}; time used = 0.9693751335144043s
epoch 35: {'train_loss': '0.08257'}; time used = 0.9899210929870605s
epoch 40: {'train_loss': '0.05007'}; time used = 1.0587317943572998s
epoch 45: {'train_loss': '0.04393'}; time used = 1.043919563293457s
epoch 50: {'train_loss': '0.02516'}; time used = 1.0116708278656006s
epoch 55: {'train_loss': '0.01631'}; time used = 1.0207605361938477s
epoch 60: {'train_loss': '0.01409'}; time used = 1.0626120567321777s
epoch 65: {'train_loss': '0.01777'}; time used = 1.066993236541748s
epoch 70: {'train_loss': '0.01004'}; time used = 1.013577938079834s
epoch 75: {'train_loss': '0.00859'}; time used = 0.988778829574585s
epoch 80: {'train_loss': '0.00903'}; time used = 1.093062400817871s
epoch 85: {'train_loss': '0.00717'}; time used = 1.001093864440918s
epoch 90: {'train_loss': '0.00652'}; time used = 1.2426648139953613s
epoch 95: {'train_loss': '0.00990'}; time used = 1.2097365856170654s
epoch 100: {'train_loss': '0.45568'}; time used = 1.1803615093231201s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.2403781414032.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 5; 10.76 GiB total capacity; 8.53 GiB already allocated; 534.44 MiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.72367'}; time used = 1.188474416732788s
epoch 10: {'train_loss': '2.65552'}; time used = 1.1758899688720703s
epoch 15: {'train_loss': '2.61933'}; time used = 1.054065465927124s
epoch 20: {'train_loss': '2.57044'}; time used = 1.0742225646972656s
epoch 25: {'train_loss': '2.51230'}; time used = 1.0707306861877441s
epoch 30: {'train_loss': '2.42982'}; time used = 1.0864589214324951s
epoch 35: {'train_loss': '2.35362'}; time used = 1.0847504138946533s
epoch 40: {'train_loss': '2.30672'}; time used = 1.0835015773773193s
epoch 45: {'train_loss': '2.25711'}; time used = 1.0893781185150146s
epoch 50: {'train_loss': '2.23820'}; time used = 1.0809895992279053s
epoch 55: {'train_loss': '2.20648'}; time used = 1.0816779136657715s
epoch 60: {'train_loss': '2.15134'}; time used = 1.1378681659698486s
epoch 65: {'train_loss': '2.12164'}; time used = 1.1673080921173096s
epoch 70: {'train_loss': '2.14360'}; time used = 1.2724268436431885s
epoch 75: {'train_loss': '2.11470'}; time used = 1.1888988018035889s
epoch 80: {'train_loss': '2.12011'}; time used = 1.125394582748413s
epoch 85: {'train_loss': '2.15931'}; time used = 1.0671827793121338s
epoch 90: {'train_loss': '2.12012'}; time used = 1.0614187717437744s
epoch 95: {'train_loss': '2.31167'}; time used = 1.060056447982788s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.49557089805603.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.07905'}; time used = 1.3097481727600098s
epoch 10: {'train_loss': '0.00240'}; time used = 2.327745199203491s
epoch 15: {'train_loss': '0.00031'}; time used = 2.4783055782318115s
epoch 20: {'train_loss': '0.00000'}; time used = 1.2606055736541748s
epoch 25: {'train_loss': '0.00892'}; time used = 0.9636285305023193s
epoch 30: {'train_loss': '0.00073'}; time used = 0.9715039730072021s
epoch 35: {'train_loss': '0.00000'}; time used = 1.0955944061279297s
epoch 40: {'train_loss': '0.00002'}; time used = 0.9937684535980225s
epoch 45: {'train_loss': '0.00742'}; time used = 0.9206805229187012s
epoch 50: {'train_loss': '0.00000'}; time used = 1.2236998081207275s
epoch 55: {'train_loss': '0.00000'}; time used = 0.9447660446166992s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.598143577575684.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.672156862745098, 'samples': 0.7105263157894737, 'weighted': 0.6898658410732714, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.96 GiB already allocated; 82.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 5; 10.76 GiB total capacity; 8.76 GiB already allocated; 314.44 MiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.14873'}; time used = 1.3913242816925049s
epoch 10: {'train_loss': '2.73244'}; time used = 1.254490852355957s
epoch 15: {'train_loss': '2.59489'}; time used = 1.1703135967254639s
epoch 20: {'train_loss': '2.47031'}; time used = 0.9838521480560303s
epoch 25: {'train_loss': '2.38043'}; time used = 1.0882389545440674s
epoch 30: {'train_loss': '2.29840'}; time used = 0.9968874454498291s
epoch 35: {'train_loss': '2.24611'}; time used = 0.9958803653717041s
epoch 40: {'train_loss': '2.18306'}; time used = 1.2574186325073242s
epoch 45: {'train_loss': '2.08072'}; time used = 1.7963099479675293s
epoch 50: {'train_loss': '1.94963'}; time used = 1.9529578685760498s
epoch 55: {'train_loss': '1.82332'}; time used = 2.217349052429199s
epoch 60: {'train_loss': '1.68566'}; time used = 2.076761245727539s
epoch 65: {'train_loss': '1.62341'}; time used = 2.1113204956054688s
epoch 70: {'train_loss': '1.86601'}; time used = 2.0251142978668213s
epoch 75: {'train_loss': '1.68572'}; time used = 1.0590660572052002s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.022997617721558.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [5], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
