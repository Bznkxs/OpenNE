actual args: {'cpu': False, 'devices': [0], 'model': 'deepwalk', 'dataset': 'blogcatalog', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.9, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\DeepWalk
Loading BlogCatalog Dataset from root dir: D:\Documents\GitHub\OpenNE\data\BlogCatalog
Executing task UnsupervisedNodeClassification.
Creating test set using 90.0% nodes as training set...finished
Start training...
Walk iteration:
Run epoch 0
Epoch 0 ends in 9.56889796257019 seconds.
Run epoch 1
Epoch 1 ends in 8.343251705169678 seconds.
Run epoch 2
Epoch 2 ends in 8.243945837020874 seconds.
Run epoch 3
Epoch 3 ends in 7.900973081588745 seconds.
Run epoch 4
Epoch 4 ends in 7.557563066482544 seconds.
Run epoch 5
Epoch 5 ends in 7.430406808853149 seconds.
Run epoch 6
Epoch 6 ends in 8.804891347885132 seconds.
Run epoch 7
Epoch 7 ends in 10.088871955871582 seconds.
Run epoch 8
Epoch 8 ends in 10.329310417175293 seconds.
Run epoch 9
Epoch 9 ends in 8.8331778049469 seconds.
training Word2Vec model...
Obtaining vectors...
Time used = 498.09437918663025s
Finished training. Time used = 585.20667552948.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\DeepWalk\DeepWalk_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\DeepWalk\DeepWalk_model.txt...
Training classifier using 90.00% nodes...
{'micro': 0.4090909090909091, 'macro': 0.2801170838149461, 'samples': 0.40938538205980063, 'weighted': 0.3818768307258358}
