actual args: {'cpu': False, 'devices': [0], 'model': 'deepwalk', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.9, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\DeepWalk
Loading Cora Dataset from root dir: D:\Documents\GitHub\OpenNE\data\Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 90.0% nodes as training set...finished
Start training...
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.45853590965270996 seconds.
Run epoch 1
Epoch 1 ends in 0.44580626487731934 seconds.
Run epoch 2
Epoch 2 ends in 0.44039177894592285 seconds.
Run epoch 3
Epoch 3 ends in 0.41979241371154785 seconds.
Run epoch 4
Epoch 4 ends in 0.4209580421447754 seconds.
Run epoch 5
Epoch 5 ends in 0.46974873542785645 seconds.
Run epoch 6
Epoch 6 ends in 0.4441356658935547 seconds.
Run epoch 7
Epoch 7 ends in 0.42978620529174805 seconds.
Run epoch 8
Epoch 8 ends in 0.44216442108154297 seconds.
Run epoch 9
Epoch 9 ends in 0.4322664737701416 seconds.
training Word2Vec model...
Obtaining vectors...
Time used = 63.96108365058899s
Finished training. Time used = 68.3746452331543.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\DeepWalk\DeepWalk_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\DeepWalk\DeepWalk_model.txt...
Training classifier using 90.00% nodes...
{'micro': 0.8450184501845017, 'macro': 0.8278200414666778, 'samples': 0.8450184501845018, 'weighted': 0.845060602724417}
