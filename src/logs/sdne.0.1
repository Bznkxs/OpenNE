actual args: {'cpu': False, 'devices': [0], 'model': 'sdne', 'dataset': 'blogcatalog', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.1, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\SDNE
Loading BlogCatalog Dataset from root dir: D:\Documents\GitHub\OpenNE\data\BlogCatalog
Executing task UnsupervisedNodeClassification.
Creating test set using 10.0% nodes as training set...finished
Start training...
total iter: 200
epoch 5: total loss: 220626.92188, l1 loss: 47.06163, l2 loss: 219685.64062; time used = 1.2052433490753174s
epoch 10: total loss: 486996.59375, l1 loss: 1360.17627, l2 loss: 459793.00000; time used = 1.2827661037445068s
epoch 15: total loss: 522830.65625, l1 loss: 9555.03711, l2 loss: 331729.84375; time used = 1.260495901107788s
epoch 20: total loss: 361050.84375, l1 loss: 250.77634, l2 loss: 356035.25000; time used = 1.247750997543335s
epoch 25: total loss: 380249.81250, l1 loss: 2054.04053, l2 loss: 339168.93750; time used = 1.2916600704193115s
epoch 30: total loss: 370769.78125, l1 loss: 314.96518, l2 loss: 364470.40625; time used = 1.286668300628662s
epoch 35: total loss: 396968.84375, l1 loss: 1462.21619, l2 loss: 367724.43750; time used = 1.282172441482544s
epoch 40: total loss: 256870.59375, l1 loss: 376.41559, l2 loss: 249342.18750; time used = 1.3183979988098145s
epoch 45: total loss: 235271.81250, l1 loss: 1202.89099, l2 loss: 211213.90625; time used = 1.298905372619629s
epoch 50: total loss: 197589.45312, l1 loss: 429.28421, l2 loss: 189003.65625; time used = 1.3804731369018555s
epoch 55: total loss: 244171.96875, l1 loss: 1761.04492, l2 loss: 208950.93750; time used = 1.3899662494659424s
epoch 60: total loss: 192347.17188, l1 loss: 884.54889, l2 loss: 174656.06250; time used = 1.4317176342010498s
epoch 65: total loss: 170751.85938, l1 loss: 1317.88403, l2 loss: 144394.03125; time used = 1.4622385501861572s
epoch 70: total loss: 161192.75000, l1 loss: 1339.78296, l2 loss: 134396.93750; time used = 1.4496452808380127s
epoch 75: total loss: 150895.43750, l1 loss: 1158.22498, l2 loss: 127730.77344; time used = 1.4393408298492432s
epoch 80: total loss: 157290.84375, l1 loss: 868.29913, l2 loss: 139924.70312; time used = 1.4308679103851318s
epoch 85: total loss: 201548.98438, l1 loss: 2330.29639, l2 loss: 154942.89062; time used = 1.5977866649627686s
epoch 90: total loss: 181267.50000, l1 loss: 1583.80994, l2 loss: 149591.12500; time used = 1.6215064525604248s
epoch 95: total loss: 135066.46875, l1 loss: 649.26855, l2 loss: 122080.90625; time used = 1.5803306102752686s
epoch 100: total loss: 331859.75000, l1 loss: 6183.71143, l2 loss: 208185.34375; time used = 1.5913217067718506s
epoch 105: total loss: 139173.59375, l1 loss: 351.47083, l2 loss: 132143.98438; time used = 1.5683021545410156s
epoch 110: total loss: 165948.26562, l1 loss: 1280.14062, l2 loss: 140345.26562; time used = 1.4332902431488037s
epoch 115: total loss: 137880.62500, l1 loss: 453.08411, l2 loss: 128818.71875; time used = 1.3079743385314941s
epoch 120: total loss: 176083.04688, l1 loss: 1381.13391, l2 loss: 148460.15625; time used = 1.1719491481781006s
epoch 125: total loss: 125570.63281, l1 loss: 453.09882, l2 loss: 116508.43750; time used = 1.1352779865264893s
epoch 130: total loss: 140130.40625, l1 loss: 649.63757, l2 loss: 127137.42188; time used = 1.093247413635254s
epoch 135: total loss: 142679.34375, l1 loss: 744.27966, l2 loss: 127793.49219; time used = 1.0705924034118652s
epoch 140: total loss: 143637.67188, l1 loss: 1329.25635, l2 loss: 117052.28906; time used = 1.0455505847930908s
epoch 145: total loss: 102294.37500, l1 loss: 298.71460, l2 loss: 96319.83594; time used = 1.0519797801971436s
epoch 150: total loss: 96617.03125, l1 loss: 140.60197, l2 loss: 93804.73438; time used = 1.0306241512298584s
epoch 155: total loss: 104545.34375, l1 loss: 162.25385, l2 loss: 101300.00000; time used = 1.017915964126587s
epoch 160: total loss: 140989.98438, l1 loss: 610.06317, l2 loss: 128788.45312; time used = 0.9821357727050781s
epoch 165: total loss: 120198.83594, l1 loss: 519.62347, l2 loss: 109806.09375; time used = 0.9706182479858398s
epoch 170: total loss: 179282.70312, l1 loss: 1263.42261, l2 loss: 154013.96875; time used = 0.9589114189147949s
epoch 175: total loss: 150413.95312, l1 loss: 723.76306, l2 loss: 135938.40625; time used = 1.0049731731414795s
epoch 180: total loss: 133572.51562, l1 loss: 675.08984, l2 loss: 120070.43750; time used = 0.9918186664581299s
epoch 185: total loss: 131796.40625, l1 loss: 703.02557, l2 loss: 117735.59375; time used = 1.0050339698791504s
epoch 190: total loss: 119331.58594, l1 loss: 480.08539, l2 loss: 109729.57031; time used = 0.982017993927002s
epoch 195: total loss: 143442.82812, l1 loss: 641.82892, l2 loss: 130605.95312; time used = 1.0106332302093506s
epoch 200: total loss: 99357.37500, l1 loss: 231.47771, l2 loss: 94727.50781; time used = 1.0150642395019531s
Finished training. Time used = 55.756927490234375.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_model.txt...
Training classifier using 10.00% nodes...
{'micro': 0.1990470335075315, 'macro': 0.05499797426870344, 'samples': 0.18948672542843428, 'weighted': 0.13310914239071706}
