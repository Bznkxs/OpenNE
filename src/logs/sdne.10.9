actual args: {'cpu': False, 'devices': [0], 'model': 'sdne', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.9, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\SDNE
Loading Cora Dataset from root dir: D:\Documents\GitHub\OpenNE\data\Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 90.0% nodes as training set...finished
Start training...
total iter: 200
epoch 5: total loss: 19128.02930, l1 loss: 18.02121, l2 loss: 18767.55859; time used = 0.23987150192260742s
epoch 10: total loss: 18016.27539, l1 loss: 4.64489, l2 loss: 17923.33203; time used = 0.2410752773284912s
epoch 15: total loss: 23379.65039, l1 loss: 46.00565, l2 loss: 22459.49219; time used = 0.23986506462097168s
epoch 20: total loss: 18114.05273, l1 loss: 10.55287, l2 loss: 17902.94922; time used = 0.23125076293945312s
epoch 25: total loss: 19216.97656, l1 loss: 13.87242, l2 loss: 18939.48047; time used = 0.2398684024810791s
epoch 30: total loss: 19180.92188, l1 loss: 18.55650, l2 loss: 18809.74414; time used = 0.24102568626403809s
epoch 35: total loss: 17934.13281, l1 loss: 13.71004, l2 loss: 17659.88281; time used = 0.23987674713134766s
epoch 40: total loss: 23967.15625, l1 loss: 39.21219, l2 loss: 23182.86133; time used = 0.2298893928527832s
epoch 45: total loss: 16395.71680, l1 loss: 15.51254, l2 loss: 16085.41211; time used = 0.2498483657836914s
epoch 50: total loss: 15308.19824, l1 loss: 15.97470, l2 loss: 14988.64746; time used = 0.2410135269165039s
epoch 55: total loss: 16425.63086, l1 loss: 31.02312, l2 loss: 15805.10840; time used = 0.2432112693786621s
epoch 60: total loss: 17622.15430, l1 loss: 60.22849, l2 loss: 16417.51953; time used = 0.24469351768493652s
epoch 65: total loss: 12645.70703, l1 loss: 12.25493, l2 loss: 12400.53906; time used = 0.2403569221496582s
epoch 70: total loss: 11968.89062, l1 loss: 21.68756, l2 loss: 11535.06445; time used = 0.24833440780639648s
epoch 75: total loss: 16534.21875, l1 loss: 79.24738, l2 loss: 14949.18945; time used = 0.25033044815063477s
epoch 80: total loss: 12851.13965, l1 loss: 47.39974, l2 loss: 11903.05566; time used = 0.24009394645690918s
epoch 85: total loss: 14729.64551, l1 loss: 92.83043, l2 loss: 12872.94043; time used = 0.24098849296569824s
epoch 90: total loss: 9828.92773, l1 loss: 30.36729, l2 loss: 9221.47656; time used = 0.23990654945373535s
epoch 95: total loss: 9233.50195, l1 loss: 46.09356, l2 loss: 8311.51562; time used = 0.23103857040405273s
epoch 100: total loss: 10409.18359, l1 loss: 99.11539, l2 loss: 8426.75195; time used = 0.23990583419799805s
epoch 105: total loss: 7876.28857, l1 loss: 44.67336, l2 loss: 6982.68652; time used = 0.22988176345825195s
epoch 110: total loss: 14132.06543, l1 loss: 223.22580, l2 loss: 9667.40430; time used = 0.24982690811157227s
epoch 115: total loss: 8605.18555, l1 loss: 87.45740, l2 loss: 6855.88135; time used = 0.2341136932373047s
epoch 120: total loss: 8448.73535, l1 loss: 106.01949, l2 loss: 6328.17822; time used = 0.23937726020812988s
epoch 125: total loss: 6416.55176, l1 loss: 89.54911, l2 loss: 4625.39307; time used = 0.23337554931640625s
epoch 130: total loss: 7480.04492, l1 loss: 101.91904, l2 loss: 5441.47656; time used = 0.22838830947875977s
epoch 135: total loss: 5849.27002, l1 loss: 54.40744, l2 loss: 4760.92285; time used = 0.24138855934143066s
epoch 140: total loss: 5617.27539, l1 loss: 56.54808, l2 loss: 4486.10547; time used = 0.23161983489990234s
epoch 145: total loss: 6081.90039, l1 loss: 84.80207, l2 loss: 4385.64062; time used = 0.2311544418334961s
epoch 150: total loss: 5744.78516, l1 loss: 78.43927, l2 loss: 4175.77246; time used = 0.22982048988342285s
epoch 155: total loss: 4625.33887, l1 loss: 47.07798, l2 loss: 3683.54248; time used = 0.23101592063903809s
epoch 160: total loss: 4385.78271, l1 loss: 54.23793, l2 loss: 3300.77808; time used = 0.24104833602905273s
epoch 165: total loss: 4908.71387, l1 loss: 65.81564, l2 loss: 3592.14624; time used = 0.24094772338867188s
epoch 170: total loss: 5566.67285, l1 loss: 114.19427, l2 loss: 3282.52393; time used = 0.22987985610961914s
epoch 175: total loss: 5136.30273, l1 loss: 98.95203, l2 loss: 3156.98950; time used = 0.22987794876098633s
epoch 180: total loss: 3886.89282, l1 loss: 57.09337, l2 loss: 2744.74512; time used = 0.23510956764221191s
epoch 185: total loss: 4246.57520, l1 loss: 73.70865, l2 loss: 2772.11377; time used = 0.2354123592376709s
epoch 190: total loss: 3373.77295, l1 loss: 40.81134, l2 loss: 2557.24951; time used = 0.23137998580932617s
epoch 195: total loss: 5840.38477, l1 loss: 96.82733, l2 loss: 3903.53320; time used = 0.23038268089294434s
epoch 200: total loss: 3862.28760, l1 loss: 68.87933, l2 loss: 2484.38916; time used = 0.23936009407043457s
Finished training. Time used = 9.726500749588013.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_model.txt...
Training classifier using 90.00% nodes...
{'micro': 0.7527675276752768, 'macro': 0.7414996771171366, 'samples': 0.7527675276752768, 'weighted': 0.747715847841528}
