actual args: {'cpu': False, 'devices': [0], 'model': 'node2vec', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.9, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\Node2vec
Loading Cora Dataset from root dir: D:\Documents\GitHub\OpenNE\data\Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 90.0% nodes as training set...finished
Start training...
Preprocess transition probs...
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.5577812194824219 seconds.
Run epoch 1
Epoch 1 ends in 0.5996794700622559 seconds.
Run epoch 2
Epoch 2 ends in 0.5895106792449951 seconds.
Run epoch 3
Epoch 3 ends in 0.6009137630462646 seconds.
Run epoch 4
Epoch 4 ends in 0.5697042942047119 seconds.
Run epoch 5
Epoch 5 ends in 0.5939335823059082 seconds.
Run epoch 6
Epoch 6 ends in 0.5896275043487549 seconds.
Run epoch 7
Epoch 7 ends in 0.5760483741760254 seconds.
Run epoch 8
Epoch 8 ends in 0.5910451412200928 seconds.
Run epoch 9
Epoch 9 ends in 0.5810799598693848 seconds.
training Word2Vec model...
Obtaining vectors...
Time used = 28.515121698379517s
Finished training. Time used = 34.69425177574158.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\Node2vec\Node2vec_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\Node2vec\Node2vec_model.txt...
Training classifier using 90.00% nodes...
{'micro': 0.8302583025830258, 'macro': 0.8261681803329386, 'samples': 0.8302583025830258, 'weighted': 0.8285228237876955}
