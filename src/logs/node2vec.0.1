actual args: {'cpu': False, 'devices': [0], 'model': 'node2vec', 'dataset': 'blogcatalog', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.1, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\Node2vec
Loading BlogCatalog Dataset from root dir: D:\Documents\GitHub\OpenNE\data\BlogCatalog
Executing task UnsupervisedNodeClassification.
Creating test set using 10.0% nodes as training set...finished
Start training...
Preprocess transition probs...
Walk iteration:
Run epoch 0
Epoch 0 ends in 16.063814640045166 seconds.
Run epoch 1
Epoch 1 ends in 13.583685874938965 seconds.
Run epoch 2
Epoch 2 ends in 12.04567813873291 seconds.
Run epoch 3
Epoch 3 ends in 11.154688119888306 seconds.
Run epoch 4
Epoch 4 ends in 11.084742069244385 seconds.
Run epoch 5
Epoch 5 ends in 10.329978704452515 seconds.
Run epoch 6
Epoch 6 ends in 9.301407098770142 seconds.
Run epoch 7
Epoch 7 ends in 9.445204257965088 seconds.
Run epoch 8
Epoch 8 ends in 8.922237873077393 seconds.
Run epoch 9
Epoch 9 ends in 8.856312036514282 seconds.
training Word2Vec model...
Obtaining vectors...
Time used = 193.97228384017944s
Finished training. Time used = 1501.404646396637.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\Node2vec\Node2vec_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\Node2vec\Node2vec_model.txt...
Training classifier using 10.00% nodes...
{'micro': 0.34322521279043017, 'macro': 0.2056546988601202, 'samples': 0.3455125585903519, 'weighted': 0.3159900822972899}
