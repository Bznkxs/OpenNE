actual args: {'cpu': False, 'devices': [0], 'model': 'vgae', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.1, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\VGAE
Loading Cora Dataset from root dir: D:\Documents\GitHub\OpenNE\data\Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 10.0% nodes as training set...finished
Start training...
total iter: 300
epoch 5: train_loss = 0.75330; time used = 1.0830373764038086s
epoch 10: train_loss = 1.37862; time used = 1.0818803310394287s
epoch 15: train_loss = 0.78127; time used = 1.071789026260376s
epoch 20: train_loss = 0.73316; time used = 1.0839064121246338s
epoch 25: train_loss = 0.70062; time used = 1.0605742931365967s
epoch 30: train_loss = 0.67531; time used = 1.0750911235809326s
epoch 35: train_loss = 0.61188; time used = 1.052110195159912s
epoch 40: train_loss = 0.56698; time used = 1.0630435943603516s
epoch 45: train_loss = 0.54492; time used = 1.0967135429382324s
epoch 50: train_loss = 0.51966; time used = 1.0518803596496582s
epoch 55: train_loss = 0.50554; time used = 1.0843815803527832s
epoch 60: train_loss = 0.49596; time used = 1.079124927520752s
epoch 65: train_loss = 0.48573; time used = 1.0681862831115723s
epoch 70: train_loss = 0.47860; time used = 1.094731330871582s
epoch 75: train_loss = 0.47330; time used = 1.1339349746704102s
epoch 80: train_loss = 0.46895; time used = 1.1605236530303955s
epoch 85: train_loss = 0.46529; time used = 1.1636266708374023s
epoch 90: train_loss = 0.46149; time used = 1.1455423831939697s
epoch 95: train_loss = 0.45780; time used = 1.1519196033477783s
epoch 100: train_loss = 0.45607; time used = 1.125915288925171s
epoch 105: train_loss = 0.45341; time used = 1.109663486480713s
epoch 110: train_loss = 0.45192; time used = 1.3282549381256104s
epoch 115: train_loss = 0.45079; time used = 1.296354055404663s
epoch 120: train_loss = 0.44902; time used = 1.2924952507019043s
epoch 125: train_loss = 0.44772; time used = 1.2279589176177979s
epoch 130: train_loss = 0.44625; time used = 1.2206683158874512s
epoch 135: train_loss = 0.44497; time used = 1.187582015991211s
epoch 140: train_loss = 0.44384; time used = 1.195434808731079s
epoch 145: train_loss = 0.44239; time used = 1.1841027736663818s
epoch 150: train_loss = 0.44156; time used = 1.1920490264892578s
epoch 155: train_loss = 0.44105; time used = 1.1905558109283447s
epoch 160: train_loss = 0.44068; time used = 1.242767095565796s
epoch 165: train_loss = 0.43974; time used = 1.166083574295044s
epoch 170: train_loss = 0.43913; time used = 1.135528564453125s
epoch 175: train_loss = 0.43888; time used = 1.1414237022399902s
epoch 180: train_loss = 0.43839; time used = 1.124004602432251s
epoch 185: train_loss = 0.43806; time used = 1.1277985572814941s
epoch 190: train_loss = 0.43731; time used = 1.0799827575683594s
epoch 195: train_loss = 0.43678; time used = 1.1309633255004883s
epoch 200: train_loss = 0.43668; time used = 1.1043062210083008s
epoch 205: train_loss = 0.43619; time used = 1.1247735023498535s
epoch 210: train_loss = 0.43548; time used = 1.0819811820983887s
epoch 215: train_loss = 0.43536; time used = 1.0814597606658936s
epoch 220: train_loss = 0.43495; time used = 1.1274995803833008s
epoch 225: train_loss = 0.43500; time used = 1.1014511585235596s
epoch 230: train_loss = 0.43468; time used = 1.1176679134368896s
epoch 235: train_loss = 0.43425; time used = 1.1306331157684326s
epoch 240: train_loss = 0.43453; time used = 1.1048305034637451s
epoch 245: train_loss = 0.43422; time used = 1.104372262954712s
epoch 250: train_loss = 0.43410; time used = 1.1119163036346436s
epoch 255: train_loss = 0.43365; time used = 1.1341726779937744s
epoch 260: train_loss = 0.43308; time used = 1.1448869705200195s
epoch 265: train_loss = 0.43334; time used = 1.1116611957550049s
epoch 270: train_loss = 0.43265; time used = 1.0976128578186035s
epoch 275: train_loss = 0.43235; time used = 1.1227469444274902s
epoch 280: train_loss = 0.43197; time used = 1.1217961311340332s
epoch 285: train_loss = 0.43150; time used = 1.1056427955627441s
epoch 290: train_loss = 0.43114; time used = 1.141157627105713s
epoch 295: train_loss = 0.43071; time used = 1.1294264793395996s
epoch 300: train_loss = 0.43041; time used = 1.0903911590576172s
Finished training. Time used = 68.32789349555969.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\VGAE\VGAE_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\VGAE\VGAE_model.txt...
Training classifier using 10.00% nodes...
{'micro': 0.7981952420016407, 'macro': 0.7852293847774108, 'samples': 0.7981952420016407, 'weighted': 0.796652970244632}
