actual args: {'cpu': False, 'devices': [0], 'model': 'sdne', 'dataset': 'blogcatalog', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.9, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\SDNE
Loading BlogCatalog Dataset from root dir: D:\Documents\GitHub\OpenNE\data\BlogCatalog
Executing task UnsupervisedNodeClassification.
Creating test set using 90.0% nodes as training set...finished
Start training...
total iter: 200
epoch 5: total loss: 256883.87500, l1 loss: 33.05273, l2 loss: 256222.78125; time used = 0.8366010189056396s
epoch 10: total loss: 455539.87500, l1 loss: 67.79408, l2 loss: 454183.93750; time used = 0.8462064266204834s
epoch 15: total loss: 361618.50000, l1 loss: 139.43684, l2 loss: 358829.68750; time used = 0.8042902946472168s
epoch 20: total loss: 425715.50000, l1 loss: 100.50901, l2 loss: 423705.25000; time used = 0.8447673320770264s
epoch 25: total loss: 348682.93750, l1 loss: 296.27890, l2 loss: 342757.31250; time used = 0.8230500221252441s
epoch 30: total loss: 229771.76562, l1 loss: 5.68093, l2 loss: 229658.06250; time used = 0.7807469367980957s
epoch 35: total loss: 316757.84375, l1 loss: 2143.20386, l2 loss: 273893.68750; time used = 0.7818329334259033s
epoch 40: total loss: 331163.00000, l1 loss: 1543.05945, l2 loss: 300301.71875; time used = 0.7959520816802979s
epoch 45: total loss: 246509.39062, l1 loss: 27.30282, l2 loss: 245963.21875; time used = 0.7796716690063477s
epoch 50: total loss: 233330.21875, l1 loss: 976.40149, l2 loss: 213802.07812; time used = 0.760979175567627s
epoch 55: total loss: 320900.12500, l1 loss: 4803.05371, l2 loss: 224838.90625; time used = 0.773205041885376s
epoch 60: total loss: 195328.95312, l1 loss: 112.47330, l2 loss: 193079.34375; time used = 0.7787692546844482s
epoch 65: total loss: 180386.23438, l1 loss: 99.55899, l2 loss: 178394.90625; time used = 0.7657303810119629s
epoch 70: total loss: 199590.40625, l1 loss: 711.80042, l2 loss: 185354.25000; time used = 0.7807338237762451s
epoch 75: total loss: 171071.59375, l1 loss: 311.57697, l2 loss: 164839.90625; time used = 0.7654118537902832s
epoch 80: total loss: 223237.53125, l1 loss: 2242.23169, l2 loss: 178392.70312; time used = 0.8045058250427246s
epoch 85: total loss: 224743.75000, l1 loss: 2191.37842, l2 loss: 180916.00000; time used = 0.7989511489868164s
epoch 90: total loss: 133341.10938, l1 loss: 151.15646, l2 loss: 130317.79688; time used = 0.7908928394317627s
epoch 95: total loss: 132943.93750, l1 loss: 266.08130, l2 loss: 127622.10938; time used = 0.8005053997039795s
epoch 100: total loss: 115189.40625, l1 loss: 279.40805, l2 loss: 109601.04688; time used = 0.8008570671081543s
epoch 105: total loss: 159585.60938, l1 loss: 1052.27930, l2 loss: 138539.81250; time used = 0.798433780670166s
epoch 110: total loss: 146939.28125, l1 loss: 472.46454, l2 loss: 137489.76562; time used = 0.8030614852905273s
epoch 115: total loss: 122482.91406, l1 loss: 287.49719, l2 loss: 116732.75000; time used = 0.797950267791748s
epoch 120: total loss: 145838.50000, l1 loss: 849.06848, l2 loss: 128856.90625; time used = 0.7908532619476318s
epoch 125: total loss: 149178.96875, l1 loss: 843.34967, l2 loss: 132311.73438; time used = 0.8109517097473145s
epoch 130: total loss: 136552.78125, l1 loss: 623.37659, l2 loss: 124085.01562; time used = 0.7808845043182373s
epoch 135: total loss: 124111.15625, l1 loss: 340.01941, l2 loss: 117310.53125; time used = 0.8146383762359619s
epoch 140: total loss: 142125.46875, l1 loss: 774.66589, l2 loss: 126631.89844; time used = 0.8114643096923828s
epoch 145: total loss: 122388.79688, l1 loss: 440.14609, l2 loss: 113585.62500; time used = 0.8007445335388184s
epoch 150: total loss: 123516.05469, l1 loss: 345.39490, l2 loss: 116607.90625; time used = 0.7854511737823486s
epoch 155: total loss: 111134.28906, l1 loss: 183.61963, l2 loss: 107461.64062; time used = 0.8165042400360107s
epoch 160: total loss: 150747.45312, l1 loss: 925.87927, l2 loss: 132229.59375; time used = 0.7969534397125244s
epoch 165: total loss: 161844.64062, l1 loss: 1055.66211, l2 loss: 140731.12500; time used = 0.770864725112915s
epoch 170: total loss: 105064.82031, l1 loss: 216.15901, l2 loss: 100741.35938; time used = 0.8050415515899658s
epoch 175: total loss: 116531.69531, l1 loss: 431.08087, l2 loss: 107909.78906; time used = 0.7893366813659668s
epoch 180: total loss: 138713.90625, l1 loss: 679.20557, l2 loss: 125129.51562; time used = 0.7853469848632812s
epoch 185: total loss: 114905.46875, l1 loss: 276.14429, l2 loss: 109382.29688; time used = 0.7808270454406738s
epoch 190: total loss: 128040.03125, l1 loss: 432.54755, l2 loss: 119388.78125; time used = 0.7894892692565918s
epoch 195: total loss: 127989.10156, l1 loss: 309.13586, l2 loss: 121806.08594; time used = 0.7849006652832031s
epoch 200: total loss: 151141.09375, l1 loss: 743.24091, l2 loss: 136275.98438; time used = 0.7758026123046875s
Finished training. Time used = 36.882396936416626.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_model.txt...
Training classifier using 90.00% nodes...
{'micro': 0.23521224773834376, 'macro': 0.0702895720885259, 'samples': 0.22012735326688815, 'weighted': 0.16170392517428728}
