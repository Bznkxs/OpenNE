actual args: {'cpu': False, 'devices': [0], 'model': 'sdne', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.1, '_validate': False, '_no_validate': False, 'dim': 128, 'validation_interval': 5, 'debug_output_interval': 5, 'save': True, 'silent': False, 'sparse': False, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'negative_ratio': 5, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'path_length': 80, 'num_paths': 10, 'p': 1.0, 'q': 1.0, 'window': 10, 'workers': 8}
output path =  D:\Documents\GitHub\OpenNE\results\SDNE
Loading Cora Dataset from root dir: D:\Documents\GitHub\OpenNE\data\Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 10.0% nodes as training set...finished
Start training...
total iter: 200
epoch 5: total loss: 18333.49609, l1 loss: 16.18834, l2 loss: 18009.68164; time used = 0.2298436164855957s
epoch 10: total loss: 25014.66992, l1 loss: 180.65747, l2 loss: 21401.47656; time used = 0.25101256370544434s
epoch 15: total loss: 19927.69922, l1 loss: 19.30465, l2 loss: 19541.56055; time used = 0.2448740005493164s
epoch 20: total loss: 16178.37207, l1 loss: 4.86850, l2 loss: 16080.95703; time used = 0.23988866806030273s
epoch 25: total loss: 17703.89844, l1 loss: 11.06771, l2 loss: 17482.49805; time used = 0.22986078262329102s
epoch 30: total loss: 18445.67383, l1 loss: 10.32121, l2 loss: 18239.20312; time used = 0.24103641510009766s
epoch 35: total loss: 20786.17188, l1 loss: 18.48676, l2 loss: 20416.38867; time used = 0.24986672401428223s
epoch 40: total loss: 20354.90820, l1 loss: 15.84413, l2 loss: 20037.97266; time used = 0.22987627983093262s
epoch 45: total loss: 15894.78906, l1 loss: 20.73767, l2 loss: 15479.98242; time used = 0.22988200187683105s
epoch 50: total loss: 19137.97852, l1 loss: 24.11918, l2 loss: 18655.54102; time used = 0.24406051635742188s
epoch 55: total loss: 15145.41504, l1 loss: 18.29663, l2 loss: 14779.42188; time used = 0.26291370391845703s
epoch 60: total loss: 15782.10645, l1 loss: 31.45786, l2 loss: 15152.88477; time used = 0.2453451156616211s
epoch 65: total loss: 13697.01562, l1 loss: 35.94733, l2 loss: 12978.00098; time used = 0.23437142372131348s
epoch 70: total loss: 18882.68945, l1 loss: 60.95484, l2 loss: 17663.51758; time used = 0.24035930633544922s
epoch 75: total loss: 14514.93164, l1 loss: 57.27697, l2 loss: 13369.31152; time used = 0.2506098747253418s
epoch 80: total loss: 12282.85059, l1 loss: 39.49046, l2 loss: 11492.95215; time used = 0.24986529350280762s
epoch 85: total loss: 13994.42480, l1 loss: 82.77687, l2 loss: 12338.79199; time used = 0.24986934661865234s
epoch 90: total loss: 11145.99609, l1 loss: 62.59192, l2 loss: 9894.05273; time used = 0.23103880882263184s
epoch 95: total loss: 8538.46094, l1 loss: 24.62544, l2 loss: 8045.83789; time used = 0.23987460136413574s
epoch 100: total loss: 9136.84766, l1 loss: 51.40501, l2 loss: 8108.62354; time used = 0.23987436294555664s
epoch 105: total loss: 14225.44727, l1 loss: 109.49120, l2 loss: 12035.48926; time used = 0.2598543167114258s
epoch 110: total loss: 9312.58789, l1 loss: 101.59937, l2 loss: 7280.45605; time used = 0.2616856098175049s
epoch 115: total loss: 9105.36426, l1 loss: 116.30250, l2 loss: 6779.15967; time used = 0.25936079025268555s
epoch 120: total loss: 8021.33398, l1 loss: 91.73776, l2 loss: 6186.41309; time used = 0.24933362007141113s
epoch 125: total loss: 6192.20996, l1 loss: 53.19188, l2 loss: 5128.19629; time used = 0.2483358383178711s
epoch 130: total loss: 7472.68945, l1 loss: 86.00519, l2 loss: 5752.39893; time used = 0.25232386589050293s
epoch 135: total loss: 6272.67334, l1 loss: 67.10485, l2 loss: 4930.37988; time used = 0.2287437915802002s
epoch 140: total loss: 6149.70703, l1 loss: 98.42348, l2 loss: 4181.03076; time used = 0.22987627983093262s
epoch 145: total loss: 6340.25781, l1 loss: 92.40009, l2 loss: 4492.03906; time used = 0.22990775108337402s
epoch 150: total loss: 5159.71436, l1 loss: 52.06567, l2 loss: 4118.17432; time used = 0.24124646186828613s
epoch 155: total loss: 4476.59717, l1 loss: 41.10164, l2 loss: 3654.32837; time used = 0.22987675666809082s
epoch 160: total loss: 7343.50488, l1 loss: 164.11179, l2 loss: 4061.02393; time used = 0.219879150390625s
epoch 165: total loss: 5659.90479, l1 loss: 82.66502, l2 loss: 4006.35034; time used = 0.23987483978271484s
epoch 170: total loss: 4528.55078, l1 loss: 71.51537, l2 loss: 3097.97974; time used = 0.22987651824951172s
epoch 175: total loss: 5678.44434, l1 loss: 105.70006, l2 loss: 3564.17114; time used = 0.23407888412475586s
epoch 180: total loss: 6155.31445, l1 loss: 120.82585, l2 loss: 3738.51660; time used = 0.24017858505249023s
epoch 185: total loss: 4852.74805, l1 loss: 92.58718, l2 loss: 3000.71558; time used = 0.2323775291442871s
epoch 190: total loss: 6071.67236, l1 loss: 129.55522, l2 loss: 3480.27100; time used = 0.24335050582885742s
epoch 195: total loss: 10421.07324, l1 loss: 275.65765, l2 loss: 4907.61572; time used = 0.23836135864257812s
epoch 200: total loss: 15244.06543, l1 loss: 358.99786, l2 loss: 8063.79736; time used = 0.23972082138061523s
Finished training. Time used = 9.864478349685669.
Saving embeddings to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_embeddings.txt...
Saving model to D:\Documents\GitHub\OpenNE\results\SDNE\SDNE_model.txt...
Training classifier using 10.00% nodes...
{'micro': 0.6357670221493027, 'macro': 0.6188059748612194, 'samples': 0.6357670221493027, 'weighted': 0.6310140231427898}
