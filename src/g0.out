actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.48258'}; time used = 2.3591580390930176s
epoch 10: {'train_loss': '0.25099'}; time used = 1.9140138626098633s
epoch 15: {'train_loss': '0.25567'}; time used = 2.062230348587036s
epoch 20: {'train_loss': '0.15116'}; time used = 2.020261287689209s
epoch 25: {'train_loss': '0.18497'}; time used = 1.6499943733215332s
epoch 30: {'train_loss': '0.18789'}; time used = 1.330453634262085s
epoch 35: {'train_loss': '0.17837'}; time used = 1.3857312202453613s
epoch 40: {'train_loss': '0.10940'}; time used = 1.2649180889129639s
epoch 45: {'train_loss': '0.09890'}; time used = 1.281886339187622s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.855746030807495.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84706'}; time used = 5.4425458908081055s
epoch 10: {'train_loss': '2.77679'}; time used = 6.041493892669678s
epoch 15: {'train_loss': '2.78119'}; time used = 5.047697067260742s
epoch 20: {'train_loss': '2.77708'}; time used = 5.069079399108887s
epoch 25: {'train_loss': '2.77352'}; time used = 5.112759828567505s
epoch 30: {'train_loss': '2.77457'}; time used = 5.63393497467041s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.929338693618774.
Training classifier using 80.00% nodes...
{'micro': 0.66, 'macro': 0.65996599659966, 'samples': 0.66, 'weighted': 0.66003400340034, 'accuracy': 0.66}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.518016576766968s
epoch 10: {'train_loss': '1.38629'}; time used = 7.133033990859985s
epoch 15: {'train_loss': '1.38629'}; time used = 6.614983081817627s
epoch 20: {'train_loss': '1.38629'}; time used = 6.241426229476929s
epoch 25: {'train_loss': '1.38629'}; time used = 6.34825325012207s
epoch 30: {'train_loss': '1.38629'}; time used = 6.1471943855285645s
epoch 35: {'train_loss': '1.38629'}; time used = 6.246952533721924s
epoch 40: {'train_loss': '1.38629'}; time used = 6.3723978996276855s
epoch 45: {'train_loss': '1.38629'}; time used = 6.925796270370483s
epoch 50: {'train_loss': '1.38629'}; time used = 6.156895637512207s
epoch 55: {'train_loss': '1.38629'}; time used = 6.114607572555542s
epoch 60: {'train_loss': '1.38629'}; time used = 6.141998529434204s
epoch 65: {'train_loss': '1.38629'}; time used = 6.10141396522522s
epoch 70: {'train_loss': '1.38629'}; time used = 5.998854160308838s
epoch 75: {'train_loss': '1.38629'}; time used = 5.9949281215667725s
epoch 80: {'train_loss': '1.38629'}; time used = 6.036149740219116s
epoch 85: {'train_loss': '1.38629'}; time used = 5.9137327671051025s
epoch 90: {'train_loss': '1.38629'}; time used = 6.035529136657715s
epoch 95: {'train_loss': '1.38629'}; time used = 5.951907634735107s
epoch 100: {'train_loss': '1.38629'}; time used = 6.165616273880005s
epoch 105: {'train_loss': '1.38629'}; time used = 7.089354753494263s
epoch 110: {'train_loss': '1.38629'}; time used = 8.288848638534546s
epoch 115: {'train_loss': '1.38629'}; time used = 6.182559013366699s
epoch 120: {'train_loss': '1.38629'}; time used = 5.921264410018921s
epoch 125: {'train_loss': '1.38629'}; time used = 5.946664333343506s
epoch 130: {'train_loss': '1.38629'}; time used = 5.9230358600616455s
epoch 135: {'train_loss': '1.38629'}; time used = 5.98189640045166s
epoch 140: {'train_loss': '1.38629'}; time used = 7.021235227584839s
epoch 145: {'train_loss': '1.38629'}; time used = 6.031380891799927s
epoch 150: {'train_loss': '1.38629'}; time used = 5.972399473190308s
epoch 155: {'train_loss': '1.38629'}; time used = 6.019187927246094s
epoch 160: {'train_loss': '1.38629'}; time used = 6.14775013923645s
epoch 165: {'train_loss': '1.38629'}; time used = 7.160603046417236s
epoch 170: {'train_loss': '1.38629'}; time used = 6.535402059555054s
epoch 175: {'train_loss': '1.38629'}; time used = 9.162931203842163s
epoch 180: {'train_loss': '1.38629'}; time used = 6.080851793289185s
epoch 185: {'train_loss': '1.38629'}; time used = 6.008012294769287s
epoch 190: {'train_loss': '1.38629'}; time used = 6.056478261947632s
epoch 195: {'train_loss': '1.38629'}; time used = 6.044543981552124s
epoch 200: {'train_loss': '1.38629'}; time used = 6.600710868835449s
epoch 205: {'train_loss': '1.38629'}; time used = 6.05377984046936s
epoch 210: {'train_loss': '1.38629'}; time used = 6.011489629745483s
epoch 215: {'train_loss': '1.38629'}; time used = 6.0245020389556885s
epoch 220: {'train_loss': '1.38629'}; time used = 6.078783750534058s
epoch 225: {'train_loss': '1.38629'}; time used = 6.1373772621154785s
epoch 230: {'train_loss': '1.38629'}; time used = 8.539844751358032s
epoch 235: {'train_loss': '1.38629'}; time used = 7.867569923400879s
epoch 240: {'train_loss': '1.38629'}; time used = 6.4745917320251465s
epoch 245: {'train_loss': '1.38629'}; time used = 8.692508220672607s
epoch 250: {'train_loss': '1.38629'}; time used = 7.436882019042969s
epoch 255: {'train_loss': '1.38629'}; time used = 6.436842679977417s
epoch 260: {'train_loss': '1.38629'}; time used = 5.982314348220825s
epoch 265: {'train_loss': '1.38629'}; time used = 5.924016952514648s
epoch 270: {'train_loss': '1.38629'}; time used = 6.172862529754639s
epoch 275: {'train_loss': '1.38629'}; time used = 6.237600564956665s
epoch 280: {'train_loss': '1.38629'}; time used = 6.724269151687622s
epoch 285: {'train_loss': '1.38629'}; time used = 5.995292901992798s
epoch 290: {'train_loss': '1.38629'}; time used = 6.116641521453857s
epoch 295: {'train_loss': '1.38629'}; time used = 6.009768724441528s
epoch 300: {'train_loss': '1.38629'}; time used = 6.380874156951904s
epoch 305: {'train_loss': '1.38629'}; time used = 5.954035997390747s
epoch 310: {'train_loss': '1.38629'}; time used = 5.949497938156128s
epoch 315: {'train_loss': '1.38629'}; time used = 5.967451572418213s
epoch 320: {'train_loss': '1.38629'}; time used = 6.271508693695068s
epoch 325: {'train_loss': '1.38629'}; time used = 6.218311309814453s
epoch 330: {'train_loss': '1.38629'}; time used = 6.174888610839844s
epoch 335: {'train_loss': '1.38629'}; time used = 5.964722156524658s
epoch 340: {'train_loss': '1.38629'}; time used = 5.9191977977752686s
epoch 345: {'train_loss': '1.38629'}; time used = 5.970224618911743s
epoch 350: {'train_loss': '1.38629'}; time used = 6.0037665367126465s
epoch 355: {'train_loss': '1.38629'}; time used = 5.993997097015381s
epoch 360: {'train_loss': '1.38629'}; time used = 6.025219440460205s
epoch 365: {'train_loss': '1.38629'}; time used = 5.995146036148071s
epoch 370: {'train_loss': '1.38629'}; time used = 6.090223789215088s
epoch 375: {'train_loss': '1.38629'}; time used = 6.061031818389893s
epoch 380: {'train_loss': '1.38629'}; time used = 5.995283126831055s
epoch 385: {'train_loss': '1.38629'}; time used = 7.360438108444214s
epoch 390: {'train_loss': '1.38629'}; time used = 6.246973514556885s
epoch 395: {'train_loss': '1.38629'}; time used = 8.265242576599121s
epoch 400: {'train_loss': '1.38629'}; time used = 7.872803211212158s
epoch 405: {'train_loss': '1.38629'}; time used = 6.165842056274414s
epoch 410: {'train_loss': '1.38629'}; time used = 9.625919103622437s
epoch 415: {'train_loss': '1.38629'}; time used = 7.647243499755859s
epoch 420: {'train_loss': '1.38629'}; time used = 6.205139636993408s
epoch 425: {'train_loss': '1.38629'}; time used = 6.079491853713989s
epoch 430: {'train_loss': '1.38629'}; time used = 6.0199055671691895s
epoch 435: {'train_loss': '1.38629'}; time used = 6.193501710891724s
epoch 440: {'train_loss': '1.38629'}; time used = 7.879427433013916s
epoch 445: {'train_loss': '1.38629'}; time used = 10.306791543960571s
epoch 450: {'train_loss': '1.38629'}; time used = 8.420151472091675s
epoch 455: {'train_loss': '1.38629'}; time used = 6.269273281097412s
epoch 460: {'train_loss': '1.38629'}; time used = 6.168990612030029s
epoch 465: {'train_loss': '1.38629'}; time used = 6.214573383331299s
epoch 470: {'train_loss': '1.38629'}; time used = 6.2277679443359375s
epoch 475: {'train_loss': '1.38629'}; time used = 6.153344631195068s
epoch 480: {'train_loss': '1.38629'}; time used = 6.6727588176727295s
epoch 485: {'train_loss': '1.38629'}; time used = 6.110377788543701s
epoch 490: {'train_loss': '1.38629'}; time used = 7.400536775588989s
epoch 495: {'train_loss': '1.38629'}; time used = 6.311832427978516s
epoch 500: {'train_loss': '1.38629'}; time used = 6.140362501144409s
Finished training. Time used = 660.7580263614655.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.01432'}; time used = 1.0716354846954346s
epoch 10: {'train_loss': '0.74265'}; time used = 1.0017058849334717s
epoch 15: {'train_loss': '0.58850'}; time used = 0.9278976917266846s
epoch 20: {'train_loss': '0.41183'}; time used = 0.9345285892486572s
epoch 25: {'train_loss': '0.30101'}; time used = 0.9421792030334473s
epoch 30: {'train_loss': '0.26712'}; time used = 0.9471392631530762s
epoch 35: {'train_loss': '0.20666'}; time used = 0.9763996601104736s
epoch 40: {'train_loss': '0.13428'}; time used = 0.9254138469696045s
epoch 45: {'train_loss': '0.10493'}; time used = 0.9120643138885498s
epoch 50: {'train_loss': '0.09780'}; time used = 0.9374871253967285s
epoch 55: {'train_loss': '0.08614'}; time used = 0.916043758392334s
epoch 60: {'train_loss': '0.07452'}; time used = 1.0633089542388916s
epoch 65: {'train_loss': '0.06973'}; time used = 0.898306131362915s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.202494382858276.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78117'}; time used = 1.2711405754089355s
epoch 10: {'train_loss': '2.67588'}; time used = 1.092686653137207s
epoch 15: {'train_loss': '2.52994'}; time used = 1.0590219497680664s
epoch 20: {'train_loss': '2.35026'}; time used = 1.0418877601623535s
epoch 25: {'train_loss': '2.23407'}; time used = 1.0260744094848633s
epoch 30: {'train_loss': '2.11276'}; time used = 0.8795526027679443s
epoch 35: {'train_loss': '2.05548'}; time used = 0.9208254814147949s
epoch 40: {'train_loss': '2.01871'}; time used = 0.8663289546966553s
epoch 45: {'train_loss': '2.02024'}; time used = 0.8541395664215088s
epoch 50: {'train_loss': '1.98256'}; time used = 0.8711566925048828s
epoch 55: {'train_loss': '1.95376'}; time used = 0.8670775890350342s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.040525436401367.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.78437'}; time used = 1.798466682434082s
epoch 10: {'train_loss': '2.72946'}; time used = 1.7223937511444092s
epoch 15: {'train_loss': '2.70004'}; time used = 1.6085047721862793s
epoch 20: {'train_loss': '2.68697'}; time used = 1.6085495948791504s
epoch 25: {'train_loss': '2.67678'}; time used = 1.7119133472442627s
epoch 30: {'train_loss': '2.66696'}; time used = 1.6122968196868896s
epoch 35: {'train_loss': '2.66252'}; time used = 1.6204025745391846s
epoch 40: {'train_loss': '2.65682'}; time used = 1.617814064025879s
epoch 45: {'train_loss': '2.65035'}; time used = 1.77506422996521s
epoch 50: {'train_loss': '2.63820'}; time used = 1.6796529293060303s
epoch 55: {'train_loss': '2.63375'}; time used = 1.995166301727295s
epoch 60: {'train_loss': '2.63754'}; time used = 1.754235029220581s
epoch 65: {'train_loss': '2.62171'}; time used = 1.6834461688995361s
epoch 70: {'train_loss': '2.61019'}; time used = 1.635432243347168s
epoch 75: {'train_loss': '2.59868'}; time used = 1.7812752723693848s
epoch 80: {'train_loss': '2.59358'}; time used = 1.9351351261138916s
epoch 85: {'train_loss': '2.59141'}; time used = 1.8724699020385742s
epoch 90: {'train_loss': '2.59606'}; time used = 2.7416017055511475s
epoch 95: {'train_loss': '2.59195'}; time used = 1.7412679195404053s
epoch 100: {'train_loss': '2.58538'}; time used = 1.770153522491455s
epoch 105: {'train_loss': '2.58371'}; time used = 1.691957950592041s
epoch 110: {'train_loss': '2.58277'}; time used = 1.719346284866333s
epoch 115: {'train_loss': '2.58067'}; time used = 1.6555485725402832s
epoch 120: {'train_loss': '2.58265'}; time used = 1.7979180812835693s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.97439360618591.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.47787204769548264, 'samples': 0.5217391304347826, 'weighted': 0.4888388183803076, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.75178'}; time used = 1.75947904586792s
epoch 10: {'train_loss': '2.70868'}; time used = 1.6565096378326416s
epoch 15: {'train_loss': '2.69641'}; time used = 1.691133737564087s
epoch 20: {'train_loss': '2.66593'}; time used = 1.6898066997528076s
epoch 25: {'train_loss': '2.65313'}; time used = 1.7685084342956543s
epoch 30: {'train_loss': '2.64406'}; time used = 1.6632654666900635s
epoch 35: {'train_loss': '2.63883'}; time used = 1.6639790534973145s
epoch 40: {'train_loss': '2.63706'}; time used = 1.6747441291809082s
epoch 45: {'train_loss': '2.63089'}; time used = 1.6965701580047607s
epoch 50: {'train_loss': '2.61788'}; time used = 1.6902482509613037s
epoch 55: {'train_loss': '2.61625'}; time used = 1.7935385704040527s
epoch 60: {'train_loss': '2.61839'}; time used = 1.7868688106536865s
epoch 65: {'train_loss': '2.60113'}; time used = 1.713731288909912s
epoch 70: {'train_loss': '2.59104'}; time used = 1.6726415157318115s
epoch 75: {'train_loss': '2.58223'}; time used = 1.6654491424560547s
epoch 80: {'train_loss': '2.57768'}; time used = 1.7117714881896973s
epoch 85: {'train_loss': '2.57747'}; time used = 1.6580891609191895s
epoch 90: {'train_loss': '2.58006'}; time used = 1.6506571769714355s
epoch 95: {'train_loss': '2.57878'}; time used = 1.6622157096862793s
epoch 100: {'train_loss': '2.56572'}; time used = 1.653876781463623s
epoch 105: {'train_loss': '2.56749'}; time used = 1.7146718502044678s
epoch 110: {'train_loss': '2.56484'}; time used = 1.6652789115905762s
epoch 115: {'train_loss': '2.56104'}; time used = 1.6543104648590088s
epoch 120: {'train_loss': '2.56067'}; time used = 1.7686522006988525s
epoch 125: {'train_loss': '2.55451'}; time used = 1.8786101341247559s
epoch 130: {'train_loss': '2.55841'}; time used = 1.6562013626098633s
epoch 135: {'train_loss': '2.55755'}; time used = 1.9571499824523926s
epoch 140: {'train_loss': '2.55672'}; time used = 1.6882050037384033s
epoch 145: {'train_loss': '2.54964'}; time used = 1.733959436416626s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.32123827934265.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5446029380455609, 'samples': 0.5507246376811594, 'weighted': 0.5484290003178098, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37637'}; time used = 1.3310298919677734s
epoch 10: {'train_loss': '1.35431'}; time used = 1.1897664070129395s
epoch 15: {'train_loss': '1.27429'}; time used = 1.3324134349822998s
epoch 20: {'train_loss': '1.27044'}; time used = 1.3552041053771973s
epoch 25: {'train_loss': '1.08872'}; time used = 1.5575578212738037s
epoch 30: {'train_loss': '1.23114'}; time used = 1.1739122867584229s
epoch 35: {'train_loss': '1.28043'}; time used = 1.297395944595337s
epoch 40: {'train_loss': '1.23773'}; time used = 1.3214964866638184s
epoch 45: {'train_loss': '1.07266'}; time used = 1.2650649547576904s
epoch 50: {'train_loss': '1.18664'}; time used = 1.262357473373413s
epoch 55: {'train_loss': '1.24351'}; time used = 1.1808099746704102s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.12345814704895.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17530'}; time used = 1.1670069694519043s
epoch 10: {'train_loss': '2.89208'}; time used = 1.1209795475006104s
epoch 15: {'train_loss': '2.78637'}; time used = 1.0671501159667969s
epoch 20: {'train_loss': '2.78214'}; time used = 1.0871798992156982s
epoch 25: {'train_loss': '2.78763'}; time used = 1.057767629623413s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.11658239364624.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14589'}; time used = 2.630075693130493s
epoch 10: {'train_loss': '0.74239'}; time used = 2.5908477306365967s
epoch 15: {'train_loss': '0.50840'}; time used = 2.5928218364715576s
epoch 20: {'train_loss': '0.39486'}; time used = 2.7950353622436523s
epoch 25: {'train_loss': '0.36636'}; time used = 2.6142685413360596s
epoch 30: {'train_loss': '0.45320'}; time used = 2.561650276184082s
epoch 35: {'train_loss': '0.32277'}; time used = 2.566065788269043s
epoch 40: {'train_loss': '0.31233'}; time used = 3.4610564708709717s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.418062448501587.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4668181818181818, 'samples': 0.5072463768115942, 'weighted': 0.4774571805006588, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.10033'}; time used = 1.0454001426696777s
epoch 10: {'train_loss': '2.79834'}; time used = 0.9568758010864258s
epoch 15: {'train_loss': '2.79971'}; time used = 0.9622936248779297s
epoch 20: {'train_loss': '2.80011'}; time used = 0.9406888484954834s
epoch 25: {'train_loss': '2.77300'}; time used = 1.0463593006134033s
epoch 30: {'train_loss': '2.78206'}; time used = 0.9171528816223145s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.033406496047974.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77974'}; time used = 1.3187482357025146s
epoch 10: {'train_loss': '2.74066'}; time used = 1.180776834487915s
epoch 15: {'train_loss': '2.67105'}; time used = 1.0829548835754395s
epoch 20: {'train_loss': '2.49515'}; time used = 1.0879194736480713s
epoch 25: {'train_loss': '2.36117'}; time used = 1.2176568508148193s
epoch 30: {'train_loss': '2.29859'}; time used = 1.196791410446167s
epoch 35: {'train_loss': '2.24335'}; time used = 1.0859806537628174s
epoch 40: {'train_loss': '2.17989'}; time used = 1.111633062362671s
epoch 45: {'train_loss': '2.15183'}; time used = 1.0927343368530273s
epoch 50: {'train_loss': '2.12783'}; time used = 1.080916166305542s
epoch 55: {'train_loss': '2.08511'}; time used = 1.1767239570617676s
epoch 60: {'train_loss': '2.17417'}; time used = 1.1330113410949707s
epoch 65: {'train_loss': '2.07297'}; time used = 1.0163326263427734s
epoch 70: {'train_loss': '2.08543'}; time used = 1.0889689922332764s
epoch 75: {'train_loss': '2.02889'}; time used = 1.327383279800415s
epoch 80: {'train_loss': '1.98560'}; time used = 1.27559232711792s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.754645347595215.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.35456'}; time used = 11.4883873462677s
epoch 10: {'train_loss': '1.32258'}; time used = 7.8443427085876465s
epoch 15: {'train_loss': '1.24641'}; time used = 7.751410245895386s
epoch 20: {'train_loss': '1.12525'}; time used = 7.723158359527588s
epoch 25: {'train_loss': '0.93089'}; time used = 10.766878604888916s
epoch 30: {'train_loss': '0.88318'}; time used = 12.008474111557007s
epoch 35: {'train_loss': '0.70576'}; time used = 7.240160226821899s
epoch 40: {'train_loss': '0.69694'}; time used = 8.675513505935669s
epoch 45: {'train_loss': '0.88132'}; time used = 9.582850933074951s
epoch 50: {'train_loss': '0.55964'}; time used = 7.306429147720337s
epoch 55: {'train_loss': '0.54716'}; time used = 10.806009531021118s
epoch 60: {'train_loss': '0.50880'}; time used = 7.569459438323975s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 126.44650411605835.
Training classifier using 80.00% nodes...
{'micro': 0.51, 'macro': 0.4985994383443244, 'samples': 0.51, 'weighted': 0.4944198983077672, 'accuracy': 0.51}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51544'}; time used = 1.822096824645996s
epoch 10: {'train_loss': '0.25865'}; time used = 1.4867684841156006s
epoch 15: {'train_loss': '0.20821'}; time used = 1.6144201755523682s
epoch 20: {'train_loss': '0.12773'}; time used = 1.4092609882354736s
epoch 25: {'train_loss': '0.01726'}; time used = 1.4854931831359863s
epoch 30: {'train_loss': '0.00008'}; time used = 1.3468592166900635s
epoch 35: {'train_loss': '0.09175'}; time used = 1.4448049068450928s
epoch 40: {'train_loss': '0.09613'}; time used = 1.3569152355194092s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.72136378288269.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.72800'}; time used = 1.932811975479126s
epoch 10: {'train_loss': '2.75614'}; time used = 1.814030647277832s
epoch 15: {'train_loss': '2.72121'}; time used = 1.8274743556976318s
epoch 20: {'train_loss': '2.69503'}; time used = 1.8198723793029785s
epoch 25: {'train_loss': '2.66534'}; time used = 1.8708841800689697s
epoch 30: {'train_loss': '2.64423'}; time used = 1.8626186847686768s
epoch 35: {'train_loss': '2.63769'}; time used = 1.8860650062561035s
epoch 40: {'train_loss': '2.63497'}; time used = 1.7833843231201172s
epoch 45: {'train_loss': '2.63232'}; time used = 1.8756535053253174s
epoch 50: {'train_loss': '2.61941'}; time used = 1.7735919952392578s
epoch 55: {'train_loss': '2.61375'}; time used = 1.8718349933624268s
epoch 60: {'train_loss': '2.61581'}; time used = 1.9277725219726562s
epoch 65: {'train_loss': '2.59801'}; time used = 1.7242789268493652s
epoch 70: {'train_loss': '2.57919'}; time used = 1.7746198177337646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.033032417297363.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36356'}; time used = 7.086766242980957s
epoch 10: {'train_loss': '1.38118'}; time used = 6.99971604347229s
epoch 15: {'train_loss': '1.28274'}; time used = 7.0188539028167725s
epoch 20: {'train_loss': '1.11632'}; time used = 6.865863084793091s
epoch 25: {'train_loss': '1.03387'}; time used = 6.871927499771118s
epoch 30: {'train_loss': '0.93606'}; time used = 6.929973125457764s
epoch 35: {'train_loss': '0.87594'}; time used = 6.859705209732056s
epoch 40: {'train_loss': '0.74938'}; time used = 6.84685206413269s
epoch 45: {'train_loss': '0.72435'}; time used = 6.956850290298462s
epoch 50: {'train_loss': '0.55729'}; time used = 6.932715177536011s
epoch 55: {'train_loss': '0.57499'}; time used = 6.967276334762573s
epoch 60: {'train_loss': '0.47590'}; time used = 7.013981580734253s
epoch 65: {'train_loss': '0.98904'}; time used = 9.389684438705444s
epoch 70: {'train_loss': '0.54741'}; time used = 8.486055135726929s
epoch 75: {'train_loss': '0.47414'}; time used = 7.0070765018463135s
epoch 80: {'train_loss': '0.42569'}; time used = 6.806160926818848s
epoch 85: {'train_loss': '0.34419'}; time used = 7.029902935028076s
epoch 90: {'train_loss': '0.31292'}; time used = 7.242846250534058s
epoch 95: {'train_loss': '0.21504'}; time used = 9.934825420379639s
epoch 100: {'train_loss': '0.34996'}; time used = 8.064860582351685s
epoch 105: {'train_loss': '0.23002'}; time used = 7.522588729858398s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 183.27323365211487.
Training classifier using 80.00% nodes...
{'micro': 0.49666666666666665, 'macro': 0.48716451832279334, 'samples': 0.49666666666666665, 'weighted': 0.4830146990521793, 'accuracy': 0.49666666666666665}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77482'}; time used = 1.9599425792694092s
epoch 10: {'train_loss': '2.77016'}; time used = 1.8502223491668701s
epoch 15: {'train_loss': '2.76524'}; time used = 2.224714517593384s
epoch 20: {'train_loss': '2.75431'}; time used = 4.038846492767334s
epoch 25: {'train_loss': '2.75021'}; time used = 4.928261041641235s
epoch 30: {'train_loss': '2.74344'}; time used = 4.818493843078613s
epoch 35: {'train_loss': '2.74321'}; time used = 4.8333539962768555s
epoch 40: {'train_loss': '2.74386'}; time used = 4.9086339473724365s
epoch 45: {'train_loss': '2.74161'}; time used = 3.143857955932617s
epoch 50: {'train_loss': '2.73726'}; time used = 1.9720335006713867s
epoch 55: {'train_loss': '2.74150'}; time used = 1.8648886680603027s
epoch 60: {'train_loss': '2.73054'}; time used = 1.7924416065216064s
epoch 65: {'train_loss': '2.73485'}; time used = 1.65950608253479s
epoch 70: {'train_loss': '2.73775'}; time used = 1.8101749420166016s
epoch 75: {'train_loss': '2.72885'}; time used = 1.8350088596343994s
epoch 80: {'train_loss': '2.73384'}; time used = 1.6875498294830322s
epoch 85: {'train_loss': '2.73737'}; time used = 1.683821201324463s
epoch 90: {'train_loss': '2.72814'}; time used = 1.6501588821411133s
epoch 95: {'train_loss': '2.72419'}; time used = 1.7902028560638428s
epoch 100: {'train_loss': '2.73260'}; time used = 1.8099360466003418s
epoch 105: {'train_loss': '2.72869'}; time used = 1.699040412902832s
epoch 110: {'train_loss': '2.73162'}; time used = 1.6924622058868408s
epoch 115: {'train_loss': '2.71591'}; time used = 3.7588586807250977s
epoch 120: {'train_loss': '2.72083'}; time used = 3.32261323928833s
epoch 125: {'train_loss': '2.72182'}; time used = 3.319817543029785s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 70.80932879447937.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.22603'}; time used = 1.236438274383545s
epoch 10: {'train_loss': '1.73035'}; time used = 1.373898983001709s
epoch 15: {'train_loss': '1.36854'}; time used = 1.37788987159729s
epoch 20: {'train_loss': '1.56382'}; time used = 1.3707640171051025s
epoch 25: {'train_loss': '1.15426'}; time used = 2.252556085586548s
epoch 30: {'train_loss': '1.49923'}; time used = 2.454404354095459s
epoch 35: {'train_loss': '1.62213'}; time used = 2.48738431930542s
epoch 40: {'train_loss': '1.45478'}; time used = 2.5055363178253174s
epoch 45: {'train_loss': '1.29166'}; time used = 3.165330648422241s
epoch 50: {'train_loss': '1.20723'}; time used = 2.1783041954040527s
epoch 55: {'train_loss': '0.96069'}; time used = 1.0795187950134277s
epoch 60: {'train_loss': '0.92218'}; time used = 1.1238634586334229s
epoch 65: {'train_loss': '1.23855'}; time used = 1.214838981628418s
epoch 70: {'train_loss': '1.13391'}; time used = 1.0743041038513184s
epoch 75: {'train_loss': '1.29165'}; time used = 1.076538324356079s
epoch 80: {'train_loss': '1.17564'}; time used = 1.2032175064086914s
epoch 85: {'train_loss': '1.42793'}; time used = 1.0897057056427002s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.730250597000122.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.67779'}; time used = 1.0981290340423584s
epoch 10: {'train_loss': '2.59274'}; time used = 0.8929219245910645s
epoch 15: {'train_loss': '2.23043'}; time used = 0.8702297210693359s
epoch 20: {'train_loss': '2.12070'}; time used = 0.8902549743652344s
epoch 25: {'train_loss': '2.07077'}; time used = 0.9467830657958984s
epoch 30: {'train_loss': '2.00685'}; time used = 1.0365400314331055s
epoch 35: {'train_loss': '1.94451'}; time used = 1.1255204677581787s
epoch 40: {'train_loss': '1.91954'}; time used = 1.4738893508911133s
epoch 45: {'train_loss': '1.95941'}; time used = 1.8761134147644043s
epoch 50: {'train_loss': '1.92698'}; time used = 1.8158223628997803s
epoch 55: {'train_loss': '1.92411'}; time used = 1.8359270095825195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.691195011138916.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85268'}; time used = 1.1341652870178223s
epoch 10: {'train_loss': '2.80887'}; time used = 1.0581567287445068s
epoch 15: {'train_loss': '2.78665'}; time used = 1.0203757286071777s
epoch 20: {'train_loss': '2.77310'}; time used = 1.0350286960601807s
epoch 25: {'train_loss': '2.77263'}; time used = 1.1453444957733154s
epoch 30: {'train_loss': '2.77329'}; time used = 1.1162829399108887s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.566086530685425.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77868'}; time used = 2.676753282546997s
epoch 10: {'train_loss': '2.77418'}; time used = 2.283712387084961s
epoch 15: {'train_loss': '2.77290'}; time used = 2.8582987785339355s
epoch 20: {'train_loss': '2.77494'}; time used = 3.101609706878662s
epoch 25: {'train_loss': '2.77437'}; time used = 2.816983699798584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.328155040740967.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.169716119766235s
epoch 10: {'train_loss': '1.38629'}; time used = 3.8818633556365967s
epoch 15: {'train_loss': '1.38629'}; time used = 3.8838491439819336s
epoch 20: {'train_loss': '1.38629'}; time used = 4.042344331741333s
epoch 25: {'train_loss': '1.38629'}; time used = 4.2507383823394775s
epoch 30: {'train_loss': '1.38629'}; time used = 3.934415102005005s
epoch 35: {'train_loss': '1.38629'}; time used = 4.205080986022949s
epoch 40: {'train_loss': '1.38629'}; time used = 3.9153835773468018s
epoch 45: {'train_loss': '1.38629'}; time used = 4.131521463394165s
epoch 50: {'train_loss': '1.38629'}; time used = 4.567307233810425s
epoch 55: {'train_loss': '1.38629'}; time used = 4.104180335998535s
epoch 60: {'train_loss': '1.38629'}; time used = 4.226621389389038s
epoch 65: {'train_loss': '1.38629'}; time used = 5.891094923019409s
epoch 70: {'train_loss': '1.38629'}; time used = 10.316888809204102s
epoch 75: {'train_loss': '1.38629'}; time used = 9.611646890640259s
epoch 80: {'train_loss': '1.38629'}; time used = 6.644421339035034s
epoch 85: {'train_loss': '1.38629'}; time used = 4.077469825744629s
epoch 90: {'train_loss': '1.38629'}; time used = 3.9391028881073s
epoch 95: {'train_loss': '1.38629'}; time used = 3.9267022609710693s
epoch 100: {'train_loss': '1.38629'}; time used = 3.8932604789733887s
epoch 105: {'train_loss': '1.38629'}; time used = 3.948807954788208s
epoch 110: {'train_loss': '1.38629'}; time used = 3.959428310394287s
epoch 115: {'train_loss': '1.38629'}; time used = 4.080869674682617s
epoch 120: {'train_loss': '1.38629'}; time used = 6.229455471038818s
epoch 125: {'train_loss': '1.38629'}; time used = 7.699970483779907s
epoch 130: {'train_loss': '1.38629'}; time used = 7.68702507019043s
epoch 135: {'train_loss': '1.38629'}; time used = 5.536559820175171s
epoch 140: {'train_loss': '1.38629'}; time used = 4.041436672210693s
epoch 145: {'train_loss': '1.38629'}; time used = 4.313734531402588s
epoch 150: {'train_loss': '1.38629'}; time used = 6.777106285095215s
epoch 155: {'train_loss': '1.38629'}; time used = 5.40606951713562s
epoch 160: {'train_loss': '1.38629'}; time used = 4.05183219909668s
epoch 165: {'train_loss': '1.38629'}; time used = 4.074626922607422s
epoch 170: {'train_loss': '1.38629'}; time used = 5.55288290977478s
epoch 175: {'train_loss': '1.38629'}; time used = 10.261191844940186s
epoch 180: {'train_loss': '1.38629'}; time used = 9.25425124168396s
epoch 185: {'train_loss': '1.38629'}; time used = 7.2786595821380615s
epoch 190: {'train_loss': '1.38629'}; time used = 4.3827760219573975s
epoch 195: {'train_loss': '1.38629'}; time used = 4.019582509994507s
epoch 200: {'train_loss': '1.38629'}; time used = 5.136152982711792s
epoch 205: {'train_loss': '1.38629'}; time used = 6.826513051986694s
epoch 210: {'train_loss': '1.38629'}; time used = 4.174378156661987s
epoch 215: {'train_loss': '1.38629'}; time used = 3.9062912464141846s
epoch 220: {'train_loss': '1.38629'}; time used = 3.918137311935425s
epoch 225: {'train_loss': '1.38629'}; time used = 4.143537759780884s
epoch 230: {'train_loss': '1.38629'}; time used = 3.889432430267334s
epoch 235: {'train_loss': '1.38629'}; time used = 3.858996629714966s
epoch 240: {'train_loss': '1.38629'}; time used = 4.09498143196106s
epoch 245: {'train_loss': '1.38629'}; time used = 3.9753172397613525s
epoch 250: {'train_loss': '1.38629'}; time used = 4.4071502685546875s
epoch 255: {'train_loss': '1.38629'}; time used = 6.929978132247925s
epoch 260: {'train_loss': '1.38629'}; time used = 4.5793633460998535s
epoch 265: {'train_loss': '1.38629'}; time used = 4.021944284439087s
epoch 270: {'train_loss': '1.38629'}; time used = 4.036366701126099s
epoch 275: {'train_loss': '1.38629'}; time used = 4.143794775009155s
epoch 280: {'train_loss': '1.38629'}; time used = 3.941666841506958s
epoch 285: {'train_loss': '1.38629'}; time used = 4.076362609863281s
epoch 290: {'train_loss': '1.38629'}; time used = 6.623128652572632s
epoch 295: {'train_loss': '1.38629'}; time used = 4.723337650299072s
epoch 300: {'train_loss': '1.38629'}; time used = 4.217211961746216s
epoch 305: {'train_loss': '1.38629'}; time used = 4.0224363803863525s
epoch 310: {'train_loss': '1.38629'}; time used = 6.167683362960815s
epoch 315: {'train_loss': '1.38629'}; time used = 5.5350563526153564s
epoch 320: {'train_loss': '1.38629'}; time used = 4.3430962562561035s
epoch 325: {'train_loss': '1.38629'}; time used = 4.162292242050171s
epoch 330: {'train_loss': '1.38629'}; time used = 4.009652137756348s
epoch 335: {'train_loss': '1.38629'}; time used = 4.096626043319702s
epoch 340: {'train_loss': '1.38629'}; time used = 4.04846453666687s
epoch 345: {'train_loss': '1.38629'}; time used = 3.9837372303009033s
epoch 350: {'train_loss': '1.38629'}; time used = 3.8970999717712402s
epoch 355: {'train_loss': '1.38629'}; time used = 3.9004323482513428s
epoch 360: {'train_loss': '1.38629'}; time used = 4.024140119552612s
epoch 365: {'train_loss': '1.38629'}; time used = 3.9646153450012207s
epoch 370: {'train_loss': '1.38629'}; time used = 3.8168349266052246s
epoch 375: {'train_loss': '1.38629'}; time used = 3.944088935852051s
epoch 380: {'train_loss': '1.38629'}; time used = 3.9153940677642822s
epoch 385: {'train_loss': '1.38629'}; time used = 3.954338788986206s
epoch 390: {'train_loss': '1.38629'}; time used = 3.919001340866089s
epoch 395: {'train_loss': '1.38629'}; time used = 5.596759796142578s
epoch 400: {'train_loss': '1.38629'}; time used = 5.6062538623809814s
epoch 405: {'train_loss': '1.38629'}; time used = 4.8116114139556885s
epoch 410: {'train_loss': '1.38629'}; time used = 4.241588592529297s
epoch 415: {'train_loss': '1.38629'}; time used = 4.031599044799805s
epoch 420: {'train_loss': '1.38629'}; time used = 4.167303800582886s
epoch 425: {'train_loss': '1.38629'}; time used = 6.877624750137329s
epoch 430: {'train_loss': '1.38629'}; time used = 5.322886228561401s
epoch 435: {'train_loss': '1.38629'}; time used = 4.2094504833221436s
epoch 440: {'train_loss': '1.38629'}; time used = 4.085891962051392s
epoch 445: {'train_loss': '1.38629'}; time used = 6.137130260467529s
epoch 450: {'train_loss': '1.38629'}; time used = 6.156002998352051s
epoch 455: {'train_loss': '1.38629'}; time used = 4.285902500152588s
epoch 460: {'train_loss': '1.38629'}; time used = 4.660678863525391s
epoch 465: {'train_loss': '1.38629'}; time used = 4.141707897186279s
epoch 470: {'train_loss': '1.38629'}; time used = 4.1445698738098145s
epoch 475: {'train_loss': '1.38629'}; time used = 4.117932319641113s
epoch 480: {'train_loss': '1.38629'}; time used = 4.256046295166016s
epoch 485: {'train_loss': '1.38629'}; time used = 3.9463250637054443s
epoch 490: {'train_loss': '1.38629'}; time used = 4.05077052116394s
epoch 495: {'train_loss': '1.38629'}; time used = 3.953134298324585s
epoch 500: {'train_loss': '1.38629'}; time used = 4.160608768463135s
Finished training. Time used = 489.1869361400604.
Training classifier using 80.00% nodes...
{'micro': 0.625, 'macro': 0.6190476190476191, 'samples': 0.625, 'weighted': 0.6180952380952381, 'accuracy': 0.625}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.19324'}; time used = 2.9786126613616943s
epoch 10: {'train_loss': '1.03803'}; time used = 2.8434712886810303s
epoch 15: {'train_loss': '0.91616'}; time used = 1.6619527339935303s
epoch 20: {'train_loss': '0.66778'}; time used = 1.6623659133911133s
epoch 25: {'train_loss': '0.40297'}; time used = 1.6598610877990723s
epoch 30: {'train_loss': '0.36087'}; time used = 1.526196002960205s
epoch 35: {'train_loss': '0.19703'}; time used = 1.5557448863983154s
epoch 40: {'train_loss': '0.11108'}; time used = 1.5972990989685059s
epoch 45: {'train_loss': '0.08957'}; time used = 1.5868875980377197s
epoch 50: {'train_loss': '0.04991'}; time used = 1.5667202472686768s
epoch 55: {'train_loss': '0.03506'}; time used = 1.8476088047027588s
epoch 60: {'train_loss': '0.02516'}; time used = 1.6512949466705322s
epoch 65: {'train_loss': '0.03473'}; time used = 1.6283924579620361s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.730766534805298.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '3.07855'}; time used = 1.6800835132598877s
epoch 10: {'train_loss': '3.00532'}; time used = 2.8420662879943848s
epoch 15: {'train_loss': '2.94614'}; time used = 2.974369764328003s
epoch 20: {'train_loss': '2.88640'}; time used = 2.93947696685791s
epoch 25: {'train_loss': '2.82304'}; time used = 1.8263006210327148s
epoch 30: {'train_loss': '2.76701'}; time used = 1.7878878116607666s
epoch 35: {'train_loss': '2.73199'}; time used = 1.7262907028198242s
epoch 40: {'train_loss': '2.68099'}; time used = 2.065488815307617s
epoch 45: {'train_loss': '2.64409'}; time used = 2.1340951919555664s
epoch 50: {'train_loss': '2.60292'}; time used = 1.8514132499694824s
epoch 55: {'train_loss': '2.58424'}; time used = 1.783588171005249s
epoch 60: {'train_loss': '2.56843'}; time used = 1.7729003429412842s
epoch 65: {'train_loss': '2.54092'}; time used = 1.6871535778045654s
epoch 70: {'train_loss': '2.52703'}; time used = 2.8990321159362793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.33090782165527.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85901'}; time used = 4.632577657699585s
epoch 10: {'train_loss': '2.78335'}; time used = 5.282581090927124s
epoch 15: {'train_loss': '2.76834'}; time used = 2.655376672744751s
epoch 20: {'train_loss': '2.77080'}; time used = 2.549198865890503s
epoch 25: {'train_loss': '2.76165'}; time used = 2.367821216583252s
epoch 30: {'train_loss': '2.73416'}; time used = 2.417839765548706s
epoch 35: {'train_loss': '2.68995'}; time used = 2.614556312561035s
epoch 40: {'train_loss': '2.66084'}; time used = 3.355273485183716s
epoch 45: {'train_loss': '2.63886'}; time used = 3.553656578063965s
epoch 50: {'train_loss': '2.65236'}; time used = 2.6769285202026367s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.21574878692627.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4728353140916808, 'samples': 0.4782608695652174, 'weighted': 0.4767107108584927, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.22062'}; time used = 1.183887243270874s
epoch 10: {'train_loss': '1.41185'}; time used = 1.138047695159912s
epoch 15: {'train_loss': '1.38374'}; time used = 1.1832356452941895s
epoch 20: {'train_loss': '1.39511'}; time used = 1.135061502456665s
epoch 25: {'train_loss': '1.37327'}; time used = 2.8181612491607666s
epoch 30: {'train_loss': '1.36379'}; time used = 1.5859026908874512s
epoch 35: {'train_loss': '1.36588'}; time used = 1.0141654014587402s
epoch 40: {'train_loss': '1.33426'}; time used = 1.0354461669921875s
epoch 45: {'train_loss': '1.28418'}; time used = 1.0094685554504395s
epoch 50: {'train_loss': '1.35363'}; time used = 1.0592610836029053s
epoch 55: {'train_loss': '1.31395'}; time used = 1.0791447162628174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.28173518180847.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85544'}; time used = 1.1583878993988037s
epoch 10: {'train_loss': '2.78723'}; time used = 1.0971105098724365s
epoch 15: {'train_loss': '2.77278'}; time used = 0.9925503730773926s
epoch 20: {'train_loss': '2.77549'}; time used = 1.0639872550964355s
epoch 25: {'train_loss': '2.77695'}; time used = 1.0383806228637695s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.575311422348022.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.80923'}; time used = 1.0230991840362549s
epoch 10: {'train_loss': '2.77750'}; time used = 0.9913418292999268s
epoch 15: {'train_loss': '2.77381'}; time used = 1.0417864322662354s
epoch 20: {'train_loss': '2.77881'}; time used = 1.0252954959869385s
epoch 25: {'train_loss': '2.77685'}; time used = 1.1555781364440918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.540438652038574.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39428'}; time used = 1.414015293121338s
epoch 10: {'train_loss': '1.39513'}; time used = 1.3070719242095947s
epoch 15: {'train_loss': '1.29281'}; time used = 1.3231239318847656s
epoch 20: {'train_loss': '1.33984'}; time used = 1.2994298934936523s
epoch 25: {'train_loss': '1.13473'}; time used = 1.2892439365386963s
epoch 30: {'train_loss': '1.23182'}; time used = 1.3108890056610107s
epoch 35: {'train_loss': '1.26600'}; time used = 1.332822561264038s
epoch 40: {'train_loss': '1.17640'}; time used = 1.4098854064941406s
epoch 45: {'train_loss': '1.01820'}; time used = 1.0725321769714355s
epoch 50: {'train_loss': '1.14562'}; time used = 1.0372998714447021s
epoch 55: {'train_loss': '1.34888'}; time used = 1.3028273582458496s
epoch 60: {'train_loss': '1.26393'}; time used = 1.0253708362579346s
epoch 65: {'train_loss': '1.19184'}; time used = 1.2694694995880127s
epoch 70: {'train_loss': '1.25925'}; time used = 1.0660812854766846s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.767987966537476.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.89395'}; time used = 2.3650026321411133s
epoch 10: {'train_loss': '2.80060'}; time used = 3.7459280490875244s
epoch 15: {'train_loss': '2.77546'}; time used = 3.5584120750427246s
epoch 20: {'train_loss': '2.75041'}; time used = 2.51339054107666s
epoch 25: {'train_loss': '2.73415'}; time used = 1.9510455131530762s
epoch 30: {'train_loss': '2.71575'}; time used = 1.7798233032226562s
epoch 35: {'train_loss': '2.70417'}; time used = 1.8891520500183105s
epoch 40: {'train_loss': '2.68372'}; time used = 1.7283210754394531s
epoch 45: {'train_loss': '2.66333'}; time used = 1.9176313877105713s
epoch 50: {'train_loss': '2.63461'}; time used = 1.877579927444458s
epoch 55: {'train_loss': '2.63417'}; time used = 1.8257935047149658s
epoch 60: {'train_loss': '2.59938'}; time used = 2.0597496032714844s
epoch 65: {'train_loss': '2.57633'}; time used = 1.874326229095459s
epoch 70: {'train_loss': '2.59242'}; time used = 1.7934699058532715s
epoch 75: {'train_loss': '2.53696'}; time used = 1.8735454082489014s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.843488454818726.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89520'}; time used = 2.226020336151123s
epoch 10: {'train_loss': '2.81756'}; time used = 1.7355828285217285s
epoch 15: {'train_loss': '2.79545'}; time used = 1.7099103927612305s
epoch 20: {'train_loss': '2.78138'}; time used = 1.7318909168243408s
epoch 25: {'train_loss': '2.77065'}; time used = 1.7713637351989746s
epoch 30: {'train_loss': '2.76608'}; time used = 1.7671027183532715s
epoch 35: {'train_loss': '2.76518'}; time used = 1.7113356590270996s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.819132089614868.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5434782608695652, 'samples': 0.5942028985507246, 'weighted': 0.5545053560176434, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13121'}; time used = 2.5097439289093018s
epoch 10: {'train_loss': '0.21210'}; time used = 1.8521370887756348s
epoch 15: {'train_loss': '0.01252'}; time used = 1.773505449295044s
epoch 20: {'train_loss': '0.00300'}; time used = 1.7059850692749023s
epoch 25: {'train_loss': '0.00943'}; time used = 1.9516892433166504s
epoch 30: {'train_loss': '0.00011'}; time used = 1.8013436794281006s
epoch 35: {'train_loss': '0.00000'}; time used = 2.6502437591552734s
epoch 40: {'train_loss': '0.13260'}; time used = 3.049426555633545s
epoch 45: {'train_loss': '0.00000'}; time used = 2.992581844329834s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.190827131271362.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74189'}; time used = 1.2580821514129639s
epoch 10: {'train_loss': '2.68455'}; time used = 1.4007351398468018s
epoch 15: {'train_loss': '2.57938'}; time used = 1.2681207656860352s
epoch 20: {'train_loss': '2.44570'}; time used = 1.3845973014831543s
epoch 25: {'train_loss': '2.22272'}; time used = 1.6496961116790771s
epoch 30: {'train_loss': '2.36017'}; time used = 1.8935010433197021s
epoch 35: {'train_loss': '2.16890'}; time used = 1.7628772258758545s
epoch 40: {'train_loss': '2.07597'}; time used = 1.8358120918273926s
epoch 45: {'train_loss': '1.95954'}; time used = 1.7620222568511963s
epoch 50: {'train_loss': '1.92748'}; time used = 2.0329697132110596s
epoch 55: {'train_loss': '1.85427'}; time used = 1.5330133438110352s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.07196593284607.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.14634'}; time used = 2.0304112434387207s
epoch 10: {'train_loss': '2.82447'}; time used = 2.0310897827148438s
epoch 15: {'train_loss': '2.76266'}; time used = 1.9336106777191162s
epoch 20: {'train_loss': '2.72956'}; time used = 1.976313829421997s
epoch 25: {'train_loss': '2.68474'}; time used = 1.8628640174865723s
epoch 30: {'train_loss': '2.64421'}; time used = 1.7572627067565918s
epoch 35: {'train_loss': '2.60083'}; time used = 1.7879197597503662s
epoch 40: {'train_loss': '2.57094'}; time used = 1.7662584781646729s
epoch 45: {'train_loss': '2.52721'}; time used = 1.7113556861877441s
epoch 50: {'train_loss': '2.46802'}; time used = 1.7233939170837402s
epoch 55: {'train_loss': '2.42442'}; time used = 2.0701863765716553s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.183096885681152.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85126'}; time used = 4.838403224945068s
epoch 10: {'train_loss': '2.77772'}; time used = 4.646979808807373s
epoch 15: {'train_loss': '2.77997'}; time used = 4.862779140472412s
epoch 20: {'train_loss': '2.78611'}; time used = 4.878727197647095s
epoch 25: {'train_loss': '2.77357'}; time used = 5.073797225952148s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.98515605926514.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89816'}; time used = 1.1877477169036865s
epoch 10: {'train_loss': '2.79906'}; time used = 1.1515250205993652s
epoch 15: {'train_loss': '2.78481'}; time used = 1.0326077938079834s
epoch 20: {'train_loss': '2.77927'}; time used = 1.0059928894042969s
epoch 25: {'train_loss': '2.77498'}; time used = 1.1228363513946533s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.510615825653076.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84200'}; time used = 1.2397282123565674s
epoch 10: {'train_loss': '2.72678'}; time used = 1.0027246475219727s
epoch 15: {'train_loss': '2.63985'}; time used = 1.0063412189483643s
epoch 20: {'train_loss': '2.58773'}; time used = 1.0080044269561768s
epoch 25: {'train_loss': '2.52720'}; time used = 0.9950978755950928s
epoch 30: {'train_loss': '2.46643'}; time used = 1.0457637310028076s
epoch 35: {'train_loss': '2.39927'}; time used = 0.9634504318237305s
epoch 40: {'train_loss': '2.34415'}; time used = 0.9638292789459229s
epoch 45: {'train_loss': '2.29766'}; time used = 0.9303102493286133s
epoch 50: {'train_loss': '2.29668'}; time used = 0.9475815296173096s
epoch 55: {'train_loss': '2.25177'}; time used = 0.9308631420135498s
epoch 60: {'train_loss': '2.21748'}; time used = 1.0643401145935059s
epoch 65: {'train_loss': '2.20459'}; time used = 0.9495418071746826s
epoch 70: {'train_loss': '2.18190'}; time used = 1.0053553581237793s
epoch 75: {'train_loss': '2.18901'}; time used = 0.9708247184753418s
epoch 80: {'train_loss': '2.35633'}; time used = 0.9693615436553955s
epoch 85: {'train_loss': '2.30778'}; time used = 0.9761207103729248s
epoch 90: {'train_loss': '2.16609'}; time used = 0.9832828044891357s
epoch 95: {'train_loss': '2.15040'}; time used = 0.927133321762085s
epoch 100: {'train_loss': '2.13696'}; time used = 0.9586598873138428s
epoch 105: {'train_loss': '2.11793'}; time used = 1.0187056064605713s
epoch 110: {'train_loss': '2.07488'}; time used = 0.9763326644897461s
epoch 115: {'train_loss': '2.04551'}; time used = 0.960543155670166s
epoch 120: {'train_loss': '2.03244'}; time used = 1.0970838069915771s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.143434762954712.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.23468'}; time used = 1.6285133361816406s
epoch 10: {'train_loss': '1.14349'}; time used = 1.5690226554870605s
epoch 15: {'train_loss': '1.13727'}; time used = 1.6090905666351318s
epoch 20: {'train_loss': '1.01717'}; time used = 1.5977387428283691s
epoch 25: {'train_loss': '0.81724'}; time used = 1.6607730388641357s
epoch 30: {'train_loss': '0.73276'}; time used = 1.5891213417053223s
epoch 35: {'train_loss': '0.54845'}; time used = 1.5692501068115234s
epoch 40: {'train_loss': '0.37877'}; time used = 1.573763370513916s
epoch 45: {'train_loss': '0.33053'}; time used = 1.6271476745605469s
epoch 50: {'train_loss': '0.26638'}; time used = 1.5883405208587646s
epoch 55: {'train_loss': '0.15043'}; time used = 1.6087019443511963s
epoch 60: {'train_loss': '0.21682'}; time used = 1.6070177555084229s
epoch 65: {'train_loss': '0.29031'}; time used = 1.5949914455413818s
epoch 70: {'train_loss': '0.29077'}; time used = 1.5768983364105225s
epoch 75: {'train_loss': '0.16469'}; time used = 1.5796270370483398s
epoch 80: {'train_loss': '0.02962'}; time used = 1.622004747390747s
epoch 85: {'train_loss': '0.01664'}; time used = 1.6058948040008545s
epoch 90: {'train_loss': '0.05898'}; time used = 1.594142198562622s
epoch 95: {'train_loss': '0.13836'}; time used = 1.5885741710662842s
epoch 100: {'train_loss': '0.01587'}; time used = 1.6312456130981445s
epoch 105: {'train_loss': '0.01447'}; time used = 1.6023383140563965s
epoch 110: {'train_loss': '0.05669'}; time used = 1.56341552734375s
epoch 115: {'train_loss': '0.00732'}; time used = 1.6068446636199951s
epoch 120: {'train_loss': '0.01945'}; time used = 1.7355799674987793s
epoch 125: {'train_loss': '0.00492'}; time used = 1.5904438495635986s
epoch 130: {'train_loss': '0.02383'}; time used = 1.574855089187622s
epoch 135: {'train_loss': '0.00415'}; time used = 1.633969783782959s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.782488107681274.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.20 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85735'}; time used = 1.7151553630828857s
epoch 10: {'train_loss': '2.78024'}; time used = 1.582327127456665s
epoch 15: {'train_loss': '2.73976'}; time used = 1.5955979824066162s
epoch 20: {'train_loss': '2.70787'}; time used = 1.5704944133758545s
epoch 25: {'train_loss': '2.66140'}; time used = 1.6292786598205566s
epoch 30: {'train_loss': '2.62259'}; time used = 1.5864644050598145s
epoch 35: {'train_loss': '2.59077'}; time used = 1.5916833877563477s
epoch 40: {'train_loss': '2.53273'}; time used = 1.595496654510498s
epoch 45: {'train_loss': '2.49057'}; time used = 1.5985612869262695s
epoch 50: {'train_loss': '2.42517'}; time used = 1.5911152362823486s
epoch 55: {'train_loss': '2.40917'}; time used = 1.650984525680542s
epoch 60: {'train_loss': '2.38035'}; time used = 1.589081048965454s
epoch 65: {'train_loss': '2.35643'}; time used = 1.6164252758026123s
epoch 70: {'train_loss': '2.37342'}; time used = 1.589550256729126s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.575878381729126.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39430'}; time used = 1.180391788482666s
epoch 10: {'train_loss': '1.39810'}; time used = 1.075451135635376s
epoch 15: {'train_loss': '1.29130'}; time used = 0.9571597576141357s
epoch 20: {'train_loss': '1.32147'}; time used = 0.9327919483184814s
epoch 25: {'train_loss': '1.15285'}; time used = 0.9352071285247803s
epoch 30: {'train_loss': '1.21301'}; time used = 0.9310379028320312s
epoch 35: {'train_loss': '1.30688'}; time used = 0.9423825740814209s
epoch 40: {'train_loss': '1.23026'}; time used = 0.935056209564209s
epoch 45: {'train_loss': '1.06294'}; time used = 0.9284837245941162s
epoch 50: {'train_loss': '1.17394'}; time used = 0.9353656768798828s
epoch 55: {'train_loss': '1.14927'}; time used = 0.95168137550354s
epoch 60: {'train_loss': '1.15573'}; time used = 0.9412176609039307s
epoch 65: {'train_loss': '0.96313'}; time used = 0.9421734809875488s
epoch 70: {'train_loss': '1.19506'}; time used = 0.954343318939209s
epoch 75: {'train_loss': '1.23107'}; time used = 0.9746696949005127s
epoch 80: {'train_loss': '1.06562'}; time used = 0.9709336757659912s
epoch 85: {'train_loss': '1.14495'}; time used = 0.945073127746582s
epoch 90: {'train_loss': '1.15234'}; time used = 1.0871119499206543s
epoch 95: {'train_loss': '1.18551'}; time used = 0.9526519775390625s
epoch 100: {'train_loss': '1.12353'}; time used = 0.9451546669006348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.29408073425293.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85597'}; time used = 1.782651424407959s
epoch 10: {'train_loss': '2.78138'}; time used = 1.7527713775634766s
epoch 15: {'train_loss': '2.76900'}; time used = 1.726947546005249s
epoch 20: {'train_loss': '2.77034'}; time used = 1.738144874572754s
epoch 25: {'train_loss': '2.76843'}; time used = 1.8166117668151855s
epoch 30: {'train_loss': '2.76102'}; time used = 1.7356481552124023s
epoch 35: {'train_loss': '2.76004'}; time used = 1.7228219509124756s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.04738688468933.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23541'}; time used = 1.3510627746582031s
epoch 10: {'train_loss': '2.81589'}; time used = 1.2312264442443848s
epoch 15: {'train_loss': '2.71810'}; time used = 1.2987396717071533s
epoch 20: {'train_loss': '2.71514'}; time used = 1.2332298755645752s
epoch 25: {'train_loss': '2.66447'}; time used = 1.247551441192627s
epoch 30: {'train_loss': '2.55360'}; time used = 1.2512633800506592s
epoch 35: {'train_loss': '2.42875'}; time used = 1.2526843547821045s
epoch 40: {'train_loss': '2.32276'}; time used = 1.2561895847320557s
epoch 45: {'train_loss': '2.22668'}; time used = 1.2540841102600098s
epoch 50: {'train_loss': '2.18841'}; time used = 1.2648570537567139s
epoch 55: {'train_loss': '2.10693'}; time used = 1.2515342235565186s
epoch 60: {'train_loss': '2.10022'}; time used = 1.3037798404693604s
epoch 65: {'train_loss': '2.07516'}; time used = 1.2521562576293945s
epoch 70: {'train_loss': '2.05259'}; time used = 1.2523102760314941s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.66976809501648.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02877'}; time used = 1.7372102737426758s
epoch 10: {'train_loss': '0.87091'}; time used = 1.6653320789337158s
epoch 15: {'train_loss': '1.36903'}; time used = 1.6525304317474365s
epoch 20: {'train_loss': '1.03208'}; time used = 1.6597774028778076s
epoch 25: {'train_loss': '0.87903'}; time used = 1.755061388015747s
epoch 30: {'train_loss': '0.83471'}; time used = 1.658414363861084s
epoch 35: {'train_loss': '0.34677'}; time used = 1.6637928485870361s
epoch 40: {'train_loss': '0.26179'}; time used = 1.7544233798980713s
epoch 45: {'train_loss': '0.37380'}; time used = 1.6471877098083496s
epoch 50: {'train_loss': '0.21030'}; time used = 1.6520729064941406s
epoch 55: {'train_loss': '0.28068'}; time used = 1.709590196609497s
epoch 60: {'train_loss': '0.23794'}; time used = 1.6403610706329346s
epoch 65: {'train_loss': '0.27047'}; time used = 1.7142260074615479s
epoch 70: {'train_loss': '0.27469'}; time used = 1.696681022644043s
epoch 75: {'train_loss': '0.29557'}; time used = 1.7288868427276611s
epoch 80: {'train_loss': '0.17451'}; time used = 1.7417800426483154s
epoch 85: {'train_loss': '0.15998'}; time used = 1.7148168087005615s
epoch 90: {'train_loss': '0.38114'}; time used = 1.6569252014160156s
epoch 95: {'train_loss': '0.15611'}; time used = 1.6300454139709473s
epoch 100: {'train_loss': '0.14454'}; time used = 1.6648168563842773s
epoch 105: {'train_loss': '0.22969'}; time used = 1.8916306495666504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.917113304138184.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4130434782608695, 'samples': 0.4782608695652174, 'weighted': 0.4272211720226843, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39783'}; time used = 1.2603085041046143s
epoch 10: {'train_loss': '1.40760'}; time used = 1.103614330291748s
epoch 15: {'train_loss': '1.38540'}; time used = 1.1203052997589111s
epoch 20: {'train_loss': '1.39193'}; time used = 2.415865421295166s
epoch 25: {'train_loss': '1.38641'}; time used = 2.550795793533325s
epoch 30: {'train_loss': '1.38516'}; time used = 1.1870853900909424s
epoch 35: {'train_loss': '1.39226'}; time used = 1.1447243690490723s
epoch 40: {'train_loss': '1.37251'}; time used = 1.1218500137329102s
epoch 45: {'train_loss': '1.34748'}; time used = 1.4805400371551514s
epoch 50: {'train_loss': '1.40637'}; time used = 1.7100732326507568s
epoch 55: {'train_loss': '1.37694'}; time used = 1.1589491367340088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.63494896888733.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82485'}; time used = 1.1007213592529297s
epoch 10: {'train_loss': '2.77690'}; time used = 1.0259628295898438s
epoch 15: {'train_loss': '2.77674'}; time used = 1.0508160591125488s
epoch 20: {'train_loss': '2.78083'}; time used = 1.0036892890930176s
epoch 25: {'train_loss': '2.77362'}; time used = 1.0768365859985352s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.76793384552002.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05552'}; time used = 4.9198157787323s
epoch 10: {'train_loss': '2.78301'}; time used = 4.768784046173096s
epoch 15: {'train_loss': '2.79044'}; time used = 4.435661315917969s
epoch 20: {'train_loss': '2.79886'}; time used = 4.431189298629761s
epoch 25: {'train_loss': '2.77348'}; time used = 4.629022121429443s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.925514459609985.
Training classifier using 80.00% nodes...
{'micro': 0.685, 'macro': 0.6849921248031201, 'samples': 0.685, 'weighted': 0.6849606240156004, 'accuracy': 0.685}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.88142'}; time used = 2.1678404808044434s
epoch 10: {'train_loss': '2.81190'}; time used = 2.008852958679199s
epoch 15: {'train_loss': '2.79253'}; time used = 2.017369031906128s
epoch 20: {'train_loss': '2.78146'}; time used = 2.0536386966705322s
epoch 25: {'train_loss': '2.77299'}; time used = 2.120999813079834s
epoch 30: {'train_loss': '2.77107'}; time used = 2.296807289123535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.552679777145386.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37011'}; time used = 1.176332950592041s
epoch 10: {'train_loss': '1.41125'}; time used = 1.0376579761505127s
epoch 15: {'train_loss': '1.27159'}; time used = 1.0013573169708252s
epoch 20: {'train_loss': '1.32843'}; time used = 1.0293045043945312s
epoch 25: {'train_loss': '0.52043'}; time used = 1.0157499313354492s
epoch 30: {'train_loss': '1.38012'}; time used = 1.102410078048706s
epoch 35: {'train_loss': '1.38336'}; time used = 1.1089155673980713s
epoch 40: {'train_loss': '1.34718'}; time used = 1.1204044818878174s
epoch 45: {'train_loss': '1.18019'}; time used = 1.0532550811767578s
epoch 50: {'train_loss': '1.06096'}; time used = 1.0644469261169434s
epoch 55: {'train_loss': '1.20574'}; time used = 1.0629732608795166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.95107889175415.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6266061980347695, 'samples': 0.6578947368421053, 'weighted': 0.6436726737478617, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39710'}; time used = 1.2123868465423584s
epoch 10: {'train_loss': '1.38891'}; time used = 1.150564193725586s
epoch 15: {'train_loss': '1.33753'}; time used = 1.076552152633667s
epoch 20: {'train_loss': '1.28712'}; time used = 1.0561246871948242s
epoch 25: {'train_loss': '1.13888'}; time used = 1.0759410858154297s
epoch 30: {'train_loss': '1.12803'}; time used = 1.0660548210144043s
epoch 35: {'train_loss': '1.14407'}; time used = 1.063927173614502s
epoch 40: {'train_loss': '1.14963'}; time used = 1.0583257675170898s
epoch 45: {'train_loss': '0.92170'}; time used = 1.077014684677124s
epoch 50: {'train_loss': '0.96276'}; time used = 1.0910687446594238s
epoch 55: {'train_loss': '1.09443'}; time used = 1.0576281547546387s
epoch 60: {'train_loss': '1.14216'}; time used = 1.0794100761413574s
epoch 65: {'train_loss': '0.85313'}; time used = 1.1005067825317383s
epoch 70: {'train_loss': '0.98953'}; time used = 1.082930326461792s
epoch 75: {'train_loss': '0.88338'}; time used = 1.0485951900482178s
epoch 80: {'train_loss': '0.69549'}; time used = 1.1707732677459717s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.48632502555847.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6607142857142858, 'samples': 0.6842105263157895, 'weighted': 0.6748120300751881, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.20 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.22213'}; time used = 1.2182667255401611s
epoch 10: {'train_loss': '0.03842'}; time used = 0.9819028377532959s
epoch 15: {'train_loss': '0.00113'}; time used = 1.0442039966583252s
epoch 20: {'train_loss': '0.01744'}; time used = 0.9794588088989258s
epoch 25: {'train_loss': '0.00524'}; time used = 1.0060367584228516s
epoch 30: {'train_loss': '0.00068'}; time used = 0.9867877960205078s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.333770751953125.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90476'}; time used = 1.838531255722046s
epoch 10: {'train_loss': '2.80534'}; time used = 1.6397874355316162s
epoch 15: {'train_loss': '2.77154'}; time used = 1.6861071586608887s
epoch 20: {'train_loss': '2.76349'}; time used = 1.68282151222229s
epoch 25: {'train_loss': '2.76564'}; time used = 1.7299377918243408s
epoch 30: {'train_loss': '2.75762'}; time used = 1.6776068210601807s
epoch 35: {'train_loss': '2.75390'}; time used = 1.668405294418335s
epoch 40: {'train_loss': '2.75231'}; time used = 1.6645047664642334s
epoch 45: {'train_loss': '2.75027'}; time used = 1.7175991535186768s
epoch 50: {'train_loss': '2.74647'}; time used = 1.7505276203155518s
epoch 55: {'train_loss': '2.74807'}; time used = 1.6892664432525635s
epoch 60: {'train_loss': '2.73946'}; time used = 1.6973390579223633s
epoch 65: {'train_loss': '2.74079'}; time used = 1.6817915439605713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.51740312576294.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82735'}; time used = 2.209932327270508s
epoch 10: {'train_loss': '2.78821'}; time used = 2.276989698410034s
epoch 15: {'train_loss': '2.77095'}; time used = 2.220501661300659s
epoch 20: {'train_loss': '2.77626'}; time used = 2.2796289920806885s
epoch 25: {'train_loss': '2.76753'}; time used = 2.302172899246216s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.218090534210205.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.36392'}; time used = 4.813321828842163s
epoch 10: {'train_loss': '1.38621'}; time used = 4.587260723114014s
epoch 15: {'train_loss': '1.34830'}; time used = 4.488044023513794s
epoch 20: {'train_loss': '1.34302'}; time used = 4.753132104873657s
epoch 25: {'train_loss': '1.28354'}; time used = 4.649431943893433s
epoch 30: {'train_loss': '1.24445'}; time used = 4.5408947467803955s
epoch 35: {'train_loss': '1.19675'}; time used = 4.570687770843506s
epoch 40: {'train_loss': '1.37614'}; time used = 4.47260856628418s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.13315153121948.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049336100622641, 'samples': 0.705, 'weighted': 0.7050221299792454, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84706'}; time used = 5.188036203384399s
epoch 10: {'train_loss': '2.77679'}; time used = 4.871374130249023s
epoch 15: {'train_loss': '2.78119'}; time used = 6.0933287143707275s
epoch 20: {'train_loss': '2.77708'}; time used = 4.826708555221558s
epoch 25: {'train_loss': '2.77352'}; time used = 7.444955825805664s
epoch 30: {'train_loss': '2.77457'}; time used = 6.094860792160034s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.2494854927063.
Training classifier using 80.00% nodes...
{'micro': 0.66, 'macro': 0.65996599659966, 'samples': 0.66, 'weighted': 0.66003400340034, 'accuracy': 0.66}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.43377'}; time used = 5.664379835128784s
epoch 10: {'train_loss': '2.82810'}; time used = 5.796362400054932s
epoch 15: {'train_loss': '2.83169'}; time used = 5.505999326705933s
epoch 20: {'train_loss': '2.84284'}; time used = 5.067450046539307s
epoch 25: {'train_loss': '2.82812'}; time used = 5.465860843658447s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.21391201019287.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38750'}; time used = 1.2194712162017822s
epoch 10: {'train_loss': '1.41398'}; time used = 1.1553359031677246s
epoch 15: {'train_loss': '1.34485'}; time used = 1.0658800601959229s
epoch 20: {'train_loss': '1.38726'}; time used = 1.0233690738677979s
epoch 25: {'train_loss': '1.32376'}; time used = 1.0501956939697266s
epoch 30: {'train_loss': '1.37300'}; time used = 0.9656872749328613s
epoch 35: {'train_loss': '1.41807'}; time used = 1.1827149391174316s
epoch 40: {'train_loss': '1.32277'}; time used = 1.2236196994781494s
epoch 45: {'train_loss': '1.27515'}; time used = 1.0696861743927002s
epoch 50: {'train_loss': '1.31480'}; time used = 1.0898051261901855s
epoch 55: {'train_loss': '1.27297'}; time used = 0.9404387474060059s
epoch 60: {'train_loss': '1.19537'}; time used = 0.9394299983978271s
epoch 65: {'train_loss': '1.13361'}; time used = 1.320631742477417s
epoch 70: {'train_loss': '1.07668'}; time used = 2.3131792545318604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.720272064208984.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90107'}; time used = 2.2616684436798096s
epoch 10: {'train_loss': '2.79540'}; time used = 2.3680028915405273s
epoch 15: {'train_loss': '2.77236'}; time used = 2.25689959526062s
epoch 20: {'train_loss': '2.77833'}; time used = 1.8119852542877197s
epoch 25: {'train_loss': '2.77701'}; time used = 1.2946662902832031s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.81233048439026.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04840'}; time used = 7.787039279937744s
epoch 10: {'train_loss': '2.77767'}; time used = 4.395938873291016s
epoch 15: {'train_loss': '2.80837'}; time used = 4.508711338043213s
epoch 20: {'train_loss': '2.79512'}; time used = 4.231506824493408s
epoch 25: {'train_loss': '2.77346'}; time used = 4.306432247161865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.46949887275696.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16464'}; time used = 1.9473741054534912s
epoch 10: {'train_loss': '1.06972'}; time used = 1.7482030391693115s
epoch 15: {'train_loss': '0.95769'}; time used = 2.5324628353118896s
epoch 20: {'train_loss': '0.67046'}; time used = 3.374875068664551s
epoch 25: {'train_loss': '0.44830'}; time used = 3.0160553455352783s
epoch 30: {'train_loss': '0.29450'}; time used = 2.196375608444214s
epoch 35: {'train_loss': '0.17286'}; time used = 1.72135329246521s
epoch 40: {'train_loss': '0.10402'}; time used = 2.949713706970215s
epoch 45: {'train_loss': '0.07045'}; time used = 2.773595094680786s
epoch 50: {'train_loss': '0.05863'}; time used = 2.785341262817383s
epoch 55: {'train_loss': '0.09491'}; time used = 2.3190042972564697s
epoch 60: {'train_loss': '0.09939'}; time used = 1.6239845752716064s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.066903829574585.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.94833'}; time used = 1.6161253452301025s
epoch 10: {'train_loss': '0.84098'}; time used = 1.5050592422485352s
epoch 15: {'train_loss': '0.70682'}; time used = 1.5636441707611084s
epoch 20: {'train_loss': '0.11588'}; time used = 1.548959493637085s
epoch 25: {'train_loss': '0.06825'}; time used = 1.6165571212768555s
epoch 30: {'train_loss': '0.00311'}; time used = 1.6279230117797852s
epoch 35: {'train_loss': '0.00000'}; time used = 1.5246796607971191s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.147351503372192.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89287'}; time used = 1.0731472969055176s
epoch 10: {'train_loss': '2.81230'}; time used = 1.0053801536560059s
epoch 15: {'train_loss': '2.79347'}; time used = 1.1574945449829102s
epoch 20: {'train_loss': '2.78047'}; time used = 1.1642248630523682s
epoch 25: {'train_loss': '2.77323'}; time used = 0.9792699813842773s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.895503759384155.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.37561'}; time used = 2.0501160621643066s
epoch 10: {'train_loss': '0.18871'}; time used = 1.9305195808410645s
epoch 15: {'train_loss': '0.20386'}; time used = 1.9517149925231934s
epoch 20: {'train_loss': '0.20602'}; time used = 1.9377450942993164s
epoch 25: {'train_loss': '0.27953'}; time used = 2.0345489978790283s
epoch 30: {'train_loss': '0.35081'}; time used = 1.951423168182373s
epoch 35: {'train_loss': '0.24203'}; time used = 1.9234507083892822s
epoch 40: {'train_loss': '0.27311'}; time used = 1.944068193435669s
epoch 45: {'train_loss': '0.17292'}; time used = 1.9631965160369873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.825165510177612.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77576'}; time used = 1.499258279800415s
epoch 10: {'train_loss': '2.77405'}; time used = 1.3511080741882324s
epoch 15: {'train_loss': '2.78055'}; time used = 1.3259172439575195s
epoch 20: {'train_loss': '2.77517'}; time used = 1.33967924118042s
epoch 25: {'train_loss': '2.77331'}; time used = 1.3247835636138916s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.095233917236328.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36928'}; time used = 1.3286654949188232s
epoch 10: {'train_loss': '1.22427'}; time used = 1.1509084701538086s
epoch 15: {'train_loss': '1.04666'}; time used = 1.181783676147461s
epoch 20: {'train_loss': '0.68947'}; time used = 1.1652562618255615s
epoch 25: {'train_loss': '0.56184'}; time used = 1.1785199642181396s
epoch 30: {'train_loss': '0.45609'}; time used = 1.1877498626708984s
epoch 35: {'train_loss': '0.49123'}; time used = 1.6201045513153076s
epoch 40: {'train_loss': '0.82835'}; time used = 2.82087779045105s
epoch 45: {'train_loss': '0.60742'}; time used = 1.2768120765686035s
epoch 50: {'train_loss': '0.74927'}; time used = 1.1560695171356201s
epoch 55: {'train_loss': '0.62583'}; time used = 1.2534370422363281s
epoch 60: {'train_loss': '0.42948'}; time used = 1.3296194076538086s
epoch 65: {'train_loss': '0.40982'}; time used = 1.2465009689331055s
epoch 70: {'train_loss': '0.36341'}; time used = 1.1270725727081299s
epoch 75: {'train_loss': '0.69781'}; time used = 1.1447999477386475s
epoch 80: {'train_loss': '0.39115'}; time used = 1.1356761455535889s
epoch 85: {'train_loss': '0.40786'}; time used = 1.1327691078186035s
epoch 90: {'train_loss': '0.52736'}; time used = 1.1386840343475342s
epoch 95: {'train_loss': '0.34440'}; time used = 1.1960029602050781s
epoch 100: {'train_loss': '0.59279'}; time used = 1.1199352741241455s
epoch 105: {'train_loss': '0.68500'}; time used = 1.1419775485992432s
epoch 110: {'train_loss': '0.65640'}; time used = 1.1411120891571045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.219003200531006.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7194421657095981, 'samples': 0.7631578947368421, 'weighted': 0.7369284573204957, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36150'}; time used = 1.1092102527618408s
epoch 10: {'train_loss': '1.49742'}; time used = 1.0886354446411133s
epoch 15: {'train_loss': '0.88624'}; time used = 0.9408767223358154s
epoch 20: {'train_loss': '1.04699'}; time used = 0.945817232131958s
epoch 25: {'train_loss': '0.24166'}; time used = 1.0213220119476318s
epoch 30: {'train_loss': '0.35624'}; time used = 0.9443762302398682s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.803166627883911.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04752'}; time used = 6.051243782043457s
epoch 10: {'train_loss': '2.77762'}; time used = 5.1656880378723145s
epoch 15: {'train_loss': '2.80961'}; time used = 4.939616918563843s
epoch 20: {'train_loss': '2.79435'}; time used = 4.881546497344971s
epoch 25: {'train_loss': '2.77230'}; time used = 4.964667081832886s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.00085663795471.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.475212574005127s
epoch 10: {'train_loss': '1.38629'}; time used = 4.474837303161621s
epoch 15: {'train_loss': '1.38629'}; time used = 4.629932641983032s
epoch 20: {'train_loss': '1.38629'}; time used = 4.571847677230835s
epoch 25: {'train_loss': '1.38629'}; time used = 4.7334840297698975s
epoch 30: {'train_loss': '1.38629'}; time used = 4.906307935714722s
epoch 35: {'train_loss': '1.38629'}; time used = 4.9572203159332275s
epoch 40: {'train_loss': '1.38629'}; time used = 4.507744312286377s
epoch 45: {'train_loss': '1.38629'}; time used = 4.706043481826782s
epoch 50: {'train_loss': '1.38629'}; time used = 4.797149658203125s
epoch 55: {'train_loss': '1.38629'}; time used = 4.760354995727539s
epoch 60: {'train_loss': '1.38629'}; time used = 4.805077075958252s
epoch 65: {'train_loss': '1.38629'}; time used = 4.728571653366089s
epoch 70: {'train_loss': '1.38629'}; time used = 4.520101547241211s
epoch 75: {'train_loss': '1.38629'}; time used = 4.86447548866272s
epoch 80: {'train_loss': '1.38629'}; time used = 4.7649664878845215s
epoch 85: {'train_loss': '1.38629'}; time used = 5.065833568572998s
epoch 90: {'train_loss': '1.38629'}; time used = 4.236770153045654s
epoch 95: {'train_loss': '1.38629'}; time used = 4.212923049926758s
epoch 100: {'train_loss': '1.38629'}; time used = 4.205795049667358s
epoch 105: {'train_loss': '1.38629'}; time used = 4.261218786239624s
epoch 110: {'train_loss': '1.38629'}; time used = 4.3424293994903564s
epoch 115: {'train_loss': '1.38629'}; time used = 4.389899969100952s
epoch 120: {'train_loss': '1.38629'}; time used = 6.4713499546051025s
epoch 125: {'train_loss': '1.38629'}; time used = 6.409978866577148s
epoch 130: {'train_loss': '1.38629'}; time used = 4.222829341888428s
epoch 135: {'train_loss': '1.38629'}; time used = 4.406532049179077s
epoch 140: {'train_loss': '1.38629'}; time used = 4.152223587036133s
epoch 145: {'train_loss': '1.38629'}; time used = 4.080096960067749s
epoch 150: {'train_loss': '1.38629'}; time used = 4.152801513671875s
epoch 155: {'train_loss': '1.38629'}; time used = 4.227990388870239s
epoch 160: {'train_loss': '1.38629'}; time used = 4.272392988204956s
epoch 165: {'train_loss': '1.38629'}; time used = 4.876528739929199s
epoch 170: {'train_loss': '1.38629'}; time used = 4.2189860343933105s
epoch 175: {'train_loss': '1.38629'}; time used = 4.250229597091675s
epoch 180: {'train_loss': '1.38629'}; time used = 4.207354307174683s
epoch 185: {'train_loss': '1.38629'}; time used = 4.264840602874756s
epoch 190: {'train_loss': '1.38629'}; time used = 5.8293962478637695s
epoch 195: {'train_loss': '1.38629'}; time used = 4.467423439025879s
epoch 200: {'train_loss': '1.38629'}; time used = 4.310618162155151s
epoch 205: {'train_loss': '1.38629'}; time used = 4.26785135269165s
epoch 210: {'train_loss': '1.38629'}; time used = 4.307726621627808s
epoch 215: {'train_loss': '1.38629'}; time used = 4.910773992538452s
epoch 220: {'train_loss': '1.38629'}; time used = 5.276512622833252s
epoch 225: {'train_loss': '1.38629'}; time used = 4.915963172912598s
epoch 230: {'train_loss': '1.38629'}; time used = 5.808008909225464s
epoch 235: {'train_loss': '1.38629'}; time used = 7.142319440841675s
epoch 240: {'train_loss': '1.38629'}; time used = 4.758389472961426s
epoch 245: {'train_loss': '1.38629'}; time used = 5.258046627044678s
epoch 250: {'train_loss': '1.38629'}; time used = 5.027785301208496s
epoch 255: {'train_loss': '1.38629'}; time used = 4.994481086730957s
epoch 260: {'train_loss': '1.38629'}; time used = 5.020936965942383s
epoch 265: {'train_loss': '1.38629'}; time used = 4.568824052810669s
epoch 270: {'train_loss': '1.38629'}; time used = 4.182952642440796s
epoch 275: {'train_loss': '1.38629'}; time used = 4.13042950630188s
epoch 280: {'train_loss': '1.38629'}; time used = 4.063656330108643s
epoch 285: {'train_loss': '1.38629'}; time used = 4.142515420913696s
epoch 290: {'train_loss': '1.38629'}; time used = 4.234124183654785s
epoch 295: {'train_loss': '1.38629'}; time used = 4.1701133251190186s
epoch 300: {'train_loss': '1.38629'}; time used = 4.1905035972595215s
epoch 305: {'train_loss': '1.38629'}; time used = 4.157507658004761s
epoch 310: {'train_loss': '1.38629'}; time used = 4.199202299118042s
epoch 315: {'train_loss': '1.38629'}; time used = 4.553703308105469s
epoch 320: {'train_loss': '1.38629'}; time used = 4.382931470870972s
epoch 325: {'train_loss': '1.38629'}; time used = 4.893771171569824s
epoch 330: {'train_loss': '1.38629'}; time used = 4.814521074295044s
epoch 335: {'train_loss': '1.38629'}; time used = 4.430756330490112s
epoch 340: {'train_loss': '1.38629'}; time used = 6.619891881942749s
epoch 345: {'train_loss': '1.38629'}; time used = 5.881643056869507s
epoch 350: {'train_loss': '1.38629'}; time used = 5.283217191696167s
epoch 355: {'train_loss': '1.38629'}; time used = 4.3606226444244385s
epoch 360: {'train_loss': '1.38629'}; time used = 4.176656246185303s
epoch 365: {'train_loss': '1.38629'}; time used = 4.301656246185303s
epoch 370: {'train_loss': '1.38629'}; time used = 4.1354615688323975s
epoch 375: {'train_loss': '1.38629'}; time used = 4.182386875152588s
epoch 380: {'train_loss': '1.38629'}; time used = 4.2250683307647705s
epoch 385: {'train_loss': '1.38629'}; time used = 4.172778367996216s
epoch 390: {'train_loss': '1.38629'}; time used = 4.152291297912598s
epoch 395: {'train_loss': '1.38629'}; time used = 4.346562623977661s
epoch 400: {'train_loss': '1.38629'}; time used = 4.2986743450164795s
epoch 405: {'train_loss': '1.38629'}; time used = 4.333086729049683s
epoch 410: {'train_loss': '1.38629'}; time used = 7.937461614608765s
epoch 415: {'train_loss': '1.38629'}; time used = 4.394703388214111s
epoch 420: {'train_loss': '1.38629'}; time used = 4.39487361907959s
epoch 425: {'train_loss': '1.38629'}; time used = 4.142468452453613s
epoch 430: {'train_loss': '1.38629'}; time used = 4.169143199920654s
epoch 435: {'train_loss': '1.38629'}; time used = 4.255899906158447s
epoch 440: {'train_loss': '1.38629'}; time used = 4.190999984741211s
epoch 445: {'train_loss': '1.38629'}; time used = 4.176124095916748s
epoch 450: {'train_loss': '1.38629'}; time used = 4.292840242385864s
epoch 455: {'train_loss': '1.38629'}; time used = 4.254084348678589s
epoch 460: {'train_loss': '1.38629'}; time used = 6.76782751083374s
epoch 465: {'train_loss': '1.38629'}; time used = 5.822753667831421s
epoch 470: {'train_loss': '1.38629'}; time used = 6.127180814743042s
epoch 475: {'train_loss': '1.38629'}; time used = 4.2839367389678955s
epoch 480: {'train_loss': '1.38629'}; time used = 6.481878042221069s
epoch 485: {'train_loss': '1.38629'}; time used = 6.494244337081909s
epoch 490: {'train_loss': '1.38629'}; time used = 4.404448986053467s
epoch 495: {'train_loss': '1.38629'}; time used = 4.45252537727356s
epoch 500: {'train_loss': '1.38629'}; time used = 4.2366039752960205s
Finished training. Time used = 479.20530462265015.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78978'}; time used = 1.7811355590820312s
epoch 10: {'train_loss': '2.68236'}; time used = 1.7986586093902588s
epoch 15: {'train_loss': '2.67230'}; time used = 1.9011962413787842s
epoch 20: {'train_loss': '2.61988'}; time used = 1.6808743476867676s
epoch 25: {'train_loss': '2.59338'}; time used = 1.9562735557556152s
epoch 30: {'train_loss': '2.55547'}; time used = 1.6476564407348633s
epoch 35: {'train_loss': '2.52429'}; time used = 1.639388084411621s
epoch 40: {'train_loss': '2.47102'}; time used = 2.5407462120056152s
epoch 45: {'train_loss': '2.40121'}; time used = 1.9138545989990234s
epoch 50: {'train_loss': '2.63545'}; time used = 1.8130292892456055s
epoch 55: {'train_loss': '2.48781'}; time used = 2.034271001815796s
epoch 60: {'train_loss': '2.47753'}; time used = 1.9266669750213623s
epoch 65: {'train_loss': '2.41611'}; time used = 1.809868574142456s
epoch 70: {'train_loss': '2.36208'}; time used = 1.9146625995635986s
epoch 75: {'train_loss': '2.31962'}; time used = 1.740962028503418s
epoch 80: {'train_loss': '2.30789'}; time used = 2.0772571563720703s
epoch 85: {'train_loss': '2.28124'}; time used = 2.295881509780884s
epoch 90: {'train_loss': '2.28331'}; time used = 2.1376607418060303s
epoch 95: {'train_loss': '2.23736'}; time used = 2.14076828956604s
epoch 100: {'train_loss': '2.19517'}; time used = 2.158170700073242s
epoch 105: {'train_loss': '2.20012'}; time used = 2.1135413646698s
epoch 110: {'train_loss': '2.18934'}; time used = 1.9031424522399902s
epoch 115: {'train_loss': '2.17128'}; time used = 1.821854591369629s
epoch 120: {'train_loss': '2.16390'}; time used = 2.5356945991516113s
epoch 125: {'train_loss': '2.13974'}; time used = 1.6947860717773438s
epoch 130: {'train_loss': '2.20656'}; time used = 1.6792736053466797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.08000636100769.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5063131313131313, 'samples': 0.5072463768115942, 'weighted': 0.5078685404772362, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83437'}; time used = 1.499835729598999s
epoch 10: {'train_loss': '2.74573'}; time used = 1.4642901420593262s
epoch 15: {'train_loss': '2.66200'}; time used = 1.443014144897461s
epoch 20: {'train_loss': '2.56995'}; time used = 1.3189733028411865s
epoch 25: {'train_loss': '2.52522'}; time used = 1.403245210647583s
epoch 30: {'train_loss': '2.44656'}; time used = 1.3783576488494873s
epoch 35: {'train_loss': '2.32116'}; time used = 1.2563419342041016s
epoch 40: {'train_loss': '2.32428'}; time used = 1.376823902130127s
epoch 45: {'train_loss': '2.26259'}; time used = 1.2861621379852295s
epoch 50: {'train_loss': '2.22764'}; time used = 1.4471490383148193s
epoch 55: {'train_loss': '2.12797'}; time used = 1.4125401973724365s
epoch 60: {'train_loss': '2.11878'}; time used = 1.5062801837921143s
epoch 65: {'train_loss': '2.10444'}; time used = 1.3873145580291748s
epoch 70: {'train_loss': '2.05776'}; time used = 1.5033929347991943s
epoch 75: {'train_loss': '2.02685'}; time used = 1.3160912990570068s
epoch 80: {'train_loss': '2.00950'}; time used = 1.3114464282989502s
epoch 85: {'train_loss': '1.99113'}; time used = 1.3338396549224854s
epoch 90: {'train_loss': '2.13133'}; time used = 1.9465186595916748s
epoch 95: {'train_loss': '2.16547'}; time used = 1.3051719665527344s
epoch 100: {'train_loss': '2.09229'}; time used = 1.4039595127105713s
epoch 105: {'train_loss': '1.99164'}; time used = 1.4745991230010986s
epoch 110: {'train_loss': '1.99405'}; time used = 1.418501377105713s
epoch 115: {'train_loss': '1.97328'}; time used = 1.3848888874053955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.9437370300293.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86262'}; time used = 3.428212881088257s
epoch 10: {'train_loss': '2.78911'}; time used = 1.966139316558838s
epoch 15: {'train_loss': '2.74535'}; time used = 2.283646821975708s
epoch 20: {'train_loss': '2.73760'}; time used = 2.138144016265869s
epoch 25: {'train_loss': '2.71617'}; time used = 2.2589776515960693s
epoch 30: {'train_loss': '2.68996'}; time used = 1.7399518489837646s
epoch 35: {'train_loss': '2.66700'}; time used = 1.8848791122436523s
epoch 40: {'train_loss': '2.62832'}; time used = 1.9235975742340088s
epoch 45: {'train_loss': '2.58247'}; time used = 1.908172369003296s
epoch 50: {'train_loss': '2.51367'}; time used = 1.6379859447479248s
epoch 55: {'train_loss': '2.48999'}; time used = 1.709045171737671s
epoch 60: {'train_loss': '2.44826'}; time used = 1.6869943141937256s
epoch 65: {'train_loss': '2.35623'}; time used = 1.5888330936431885s
epoch 70: {'train_loss': '2.49209'}; time used = 1.7173199653625488s
epoch 75: {'train_loss': '2.43575'}; time used = 1.6054368019104004s
epoch 80: {'train_loss': '2.39420'}; time used = 1.8483893871307373s
epoch 85: {'train_loss': '2.37355'}; time used = 1.8062074184417725s
epoch 90: {'train_loss': '2.36764'}; time used = 1.579772710800171s
epoch 95: {'train_loss': '2.30157'}; time used = 1.8403260707855225s
epoch 100: {'train_loss': '2.27345'}; time used = 1.76198410987854s
epoch 105: {'train_loss': '2.25921'}; time used = 1.947718620300293s
epoch 110: {'train_loss': '2.20495'}; time used = 1.9279510974884033s
epoch 115: {'train_loss': '2.21688'}; time used = 2.6783246994018555s
epoch 120: {'train_loss': '2.16040'}; time used = 2.869056463241577s
epoch 125: {'train_loss': '2.14039'}; time used = 3.1998040676116943s
epoch 130: {'train_loss': '2.11564'}; time used = 1.727612018585205s
epoch 135: {'train_loss': '2.18957'}; time used = 1.7225477695465088s
epoch 140: {'train_loss': '2.14357'}; time used = 1.7303485870361328s
epoch 145: {'train_loss': '2.21126'}; time used = 1.62034010887146s
epoch 150: {'train_loss': '2.18774'}; time used = 2.020270824432373s
epoch 155: {'train_loss': '2.13755'}; time used = 3.1561436653137207s
epoch 160: {'train_loss': '2.10482'}; time used = 3.1813302040100098s
epoch 165: {'train_loss': '2.06525'}; time used = 2.397880792617798s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 73.3347373008728.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39021'}; time used = 1.1456794738769531s
epoch 10: {'train_loss': '1.36489'}; time used = 1.0052387714385986s
epoch 15: {'train_loss': '1.28931'}; time used = 0.9803292751312256s
epoch 20: {'train_loss': '1.27973'}; time used = 1.6654512882232666s
epoch 25: {'train_loss': '1.16847'}; time used = 2.937520742416382s
epoch 30: {'train_loss': '1.21232'}; time used = 1.2102980613708496s
epoch 35: {'train_loss': '1.27352'}; time used = 1.2961149215698242s
epoch 40: {'train_loss': '1.17365'}; time used = 1.1155471801757812s
epoch 45: {'train_loss': '1.01424'}; time used = 1.0326194763183594s
epoch 50: {'train_loss': '1.12781'}; time used = 1.0003957748413086s
epoch 55: {'train_loss': '1.15078'}; time used = 1.0128672122955322s
epoch 60: {'train_loss': '1.16095'}; time used = 1.2752504348754883s
epoch 65: {'train_loss': '0.88295'}; time used = 1.0287082195281982s
epoch 70: {'train_loss': '1.27561'}; time used = 1.0560495853424072s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.109498262405396.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.28102'}; time used = 9.288169860839844s
epoch 10: {'train_loss': '1.08024'}; time used = 7.113285064697266s
epoch 15: {'train_loss': '0.54303'}; time used = 10.799898386001587s
epoch 20: {'train_loss': '0.48067'}; time used = 9.44721794128418s
epoch 25: {'train_loss': '0.25754'}; time used = 9.846961736679077s
epoch 30: {'train_loss': '0.11256'}; time used = 8.037349462509155s
epoch 35: {'train_loss': '0.01606'}; time used = 6.756490468978882s
epoch 40: {'train_loss': '0.02386'}; time used = 6.8456878662109375s
epoch 45: {'train_loss': '0.87383'}; time used = 7.069549083709717s
epoch 50: {'train_loss': '0.20077'}; time used = 6.959437131881714s
epoch 55: {'train_loss': '0.24892'}; time used = 6.798882961273193s
epoch 60: {'train_loss': '0.10955'}; time used = 6.570187568664551s
epoch 65: {'train_loss': '0.50105'}; time used = 6.549773693084717s
epoch 70: {'train_loss': '0.16726'}; time used = 6.826702833175659s
epoch 75: {'train_loss': '0.20318'}; time used = 6.815927505493164s
epoch 80: {'train_loss': '0.26409'}; time used = 16.738845348358154s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 169.96685361862183.
Training classifier using 80.00% nodes...
{'micro': 0.5, 'macro': 0.4900246181442129, 'samples': 0.5, 'weighted': 0.48585019538936025, 'accuracy': 0.5}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87633'}; time used = 2.542618989944458s
epoch 10: {'train_loss': '2.79824'}; time used = 3.428410768508911s
epoch 15: {'train_loss': '2.78754'}; time used = 3.4976725578308105s
epoch 20: {'train_loss': '2.77772'}; time used = 2.894483804702759s
epoch 25: {'train_loss': '2.76955'}; time used = 2.4640095233917236s
epoch 30: {'train_loss': '2.75599'}; time used = 2.5190634727478027s
epoch 35: {'train_loss': '2.73796'}; time used = 2.338183879852295s
epoch 40: {'train_loss': '2.72071'}; time used = 2.4254465103149414s
epoch 45: {'train_loss': '2.68439'}; time used = 2.3225553035736084s
epoch 50: {'train_loss': '2.63660'}; time used = 2.3094489574432373s
epoch 55: {'train_loss': '2.60096'}; time used = 2.511077404022217s
epoch 60: {'train_loss': '2.57744'}; time used = 2.5501224994659424s
epoch 65: {'train_loss': '2.50504'}; time used = 2.4110329151153564s
epoch 70: {'train_loss': '2.47451'}; time used = 2.475644111633301s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.258912086486816.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.66858'}; time used = 1.1460597515106201s
epoch 10: {'train_loss': '2.56593'}; time used = 0.9424474239349365s
epoch 15: {'train_loss': '2.52626'}; time used = 0.9413464069366455s
epoch 20: {'train_loss': '2.47307'}; time used = 0.9642808437347412s
epoch 25: {'train_loss': '2.42154'}; time used = 0.9677505493164062s
epoch 30: {'train_loss': '2.34511'}; time used = 0.9672033786773682s
epoch 35: {'train_loss': '2.31748'}; time used = 0.9484131336212158s
epoch 40: {'train_loss': '2.28954'}; time used = 0.9670798778533936s
epoch 45: {'train_loss': '2.26589'}; time used = 0.9689364433288574s
epoch 50: {'train_loss': '2.23006'}; time used = 0.9531128406524658s
epoch 55: {'train_loss': '2.17900'}; time used = 1.0289664268493652s
epoch 60: {'train_loss': '2.14203'}; time used = 1.1275913715362549s
epoch 65: {'train_loss': '2.13349'}; time used = 0.9457747936248779s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.28655242919922.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.92649'}; time used = 1.4267127513885498s
epoch 10: {'train_loss': '2.89219'}; time used = 1.3020124435424805s
epoch 15: {'train_loss': '2.87158'}; time used = 1.2696847915649414s
epoch 20: {'train_loss': '2.81575'}; time used = 1.0665631294250488s
epoch 25: {'train_loss': '2.78740'}; time used = 1.0803003311157227s
epoch 30: {'train_loss': '2.77451'}; time used = 1.1671912670135498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.310221195220947.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36644'}; time used = 1.462775468826294s
epoch 10: {'train_loss': '1.27584'}; time used = 1.332176685333252s
epoch 15: {'train_loss': '0.29215'}; time used = 1.3399608135223389s
epoch 20: {'train_loss': '0.26542'}; time used = 1.33766508102417s
epoch 25: {'train_loss': '0.14040'}; time used = 1.3374078273773193s
epoch 30: {'train_loss': '0.03495'}; time used = 1.3283030986785889s
epoch 35: {'train_loss': '0.06233'}; time used = 1.4199681282043457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.867909908294678.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.700358422939068, 'samples': 0.7105263157894737, 'weighted': 0.709073759667987, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.33325'}; time used = 1.846348524093628s
epoch 10: {'train_loss': '1.24425'}; time used = 1.7957603931427002s
epoch 15: {'train_loss': '1.13348'}; time used = 1.7728378772735596s
epoch 20: {'train_loss': '1.19157'}; time used = 1.7927558422088623s
epoch 25: {'train_loss': '1.06912'}; time used = 2.0567786693573s
epoch 30: {'train_loss': '0.85283'}; time used = 2.0373027324676514s
epoch 35: {'train_loss': '0.94141'}; time used = 1.9649460315704346s
epoch 40: {'train_loss': '0.80315'}; time used = 1.9139378070831299s
epoch 45: {'train_loss': '0.71052'}; time used = 2.0070784091949463s
epoch 50: {'train_loss': '0.54206'}; time used = 2.051255226135254s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.989638805389404.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86017'}; time used = 1.6072194576263428s
epoch 10: {'train_loss': '2.77852'}; time used = 1.5557494163513184s
epoch 15: {'train_loss': '2.73906'}; time used = 1.6105432510375977s
epoch 20: {'train_loss': '2.71816'}; time used = 1.605355978012085s
epoch 25: {'train_loss': '2.68979'}; time used = 1.7059977054595947s
epoch 30: {'train_loss': '2.66131'}; time used = 1.591221809387207s
epoch 35: {'train_loss': '2.63948'}; time used = 1.6780476570129395s
epoch 40: {'train_loss': '2.59561'}; time used = 1.5595941543579102s
epoch 45: {'train_loss': '2.57901'}; time used = 1.595984697341919s
epoch 50: {'train_loss': '2.54019'}; time used = 1.6012327671051025s
epoch 55: {'train_loss': '2.52949'}; time used = 1.6662640571594238s
epoch 60: {'train_loss': '2.55471'}; time used = 1.5667953491210938s
epoch 65: {'train_loss': '2.51580'}; time used = 1.6456780433654785s
epoch 70: {'train_loss': '2.46931'}; time used = 1.584416151046753s
epoch 75: {'train_loss': '2.43679'}; time used = 1.5657269954681396s
epoch 80: {'train_loss': '2.42289'}; time used = 1.6609351634979248s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.014740228652954.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6515151515151516, 'samples': 0.6521739130434783, 'weighted': 0.6526130873956961, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.20243'}; time used = 1.9728116989135742s
epoch 10: {'train_loss': '1.15372'}; time used = 1.609673023223877s
epoch 15: {'train_loss': '1.14734'}; time used = 1.8458585739135742s
epoch 20: {'train_loss': '1.13403'}; time used = 1.6992859840393066s
epoch 25: {'train_loss': '1.02058'}; time used = 1.8093256950378418s
epoch 30: {'train_loss': '0.70238'}; time used = 1.8301961421966553s
epoch 35: {'train_loss': '0.47367'}; time used = 1.7882375717163086s
epoch 40: {'train_loss': '0.52081'}; time used = 1.9245073795318604s
epoch 45: {'train_loss': '0.30528'}; time used = 1.806112289428711s
epoch 50: {'train_loss': '0.31959'}; time used = 1.8129785060882568s
epoch 55: {'train_loss': '0.12496'}; time used = 1.8467309474945068s
epoch 60: {'train_loss': '0.18056'}; time used = 1.7846455574035645s
epoch 65: {'train_loss': '0.01122'}; time used = 1.7793655395507812s
epoch 70: {'train_loss': '0.09676'}; time used = 1.7901637554168701s
epoch 75: {'train_loss': '0.00572'}; time used = 1.7717394828796387s
epoch 80: {'train_loss': '0.00496'}; time used = 1.848214864730835s
epoch 85: {'train_loss': '0.00452'}; time used = 1.7780447006225586s
epoch 90: {'train_loss': '0.08871'}; time used = 1.8186135292053223s
epoch 95: {'train_loss': '0.15397'}; time used = 1.805206298828125s
epoch 100: {'train_loss': '0.04636'}; time used = 1.794008493423462s
epoch 105: {'train_loss': '0.03044'}; time used = 1.8499324321746826s
epoch 110: {'train_loss': '0.01917'}; time used = 1.793832778930664s
epoch 115: {'train_loss': '0.02009'}; time used = 1.8098714351654053s
epoch 120: {'train_loss': '0.00994'}; time used = 1.8981554508209229s
epoch 125: {'train_loss': '0.81280'}; time used = 1.792776107788086s
epoch 130: {'train_loss': '0.00542'}; time used = 1.7944235801696777s
epoch 135: {'train_loss': '0.00466'}; time used = 1.9573042392730713s
epoch 140: {'train_loss': '0.00398'}; time used = 1.8249552249908447s
epoch 145: {'train_loss': '0.00357'}; time used = 1.7861878871917725s
epoch 150: {'train_loss': '0.00307'}; time used = 1.610205888748169s
epoch 155: {'train_loss': '0.00288'}; time used = 1.7254455089569092s
epoch 160: {'train_loss': '0.00261'}; time used = 1.9962701797485352s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.68212842941284.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.24044'}; time used = 1.3208425045013428s
epoch 10: {'train_loss': '0.10364'}; time used = 1.0942647457122803s
epoch 15: {'train_loss': '0.08149'}; time used = 1.1143321990966797s
epoch 20: {'train_loss': '0.03630'}; time used = 1.1991934776306152s
epoch 25: {'train_loss': '0.03894'}; time used = 1.302353858947754s
epoch 30: {'train_loss': '0.02390'}; time used = 1.1586329936981201s
epoch 35: {'train_loss': '0.02690'}; time used = 1.2783222198486328s
epoch 40: {'train_loss': '0.02188'}; time used = 1.1564483642578125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.693847179412842.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80643'}; time used = 1.289560317993164s
epoch 10: {'train_loss': '2.66815'}; time used = 1.205841302871704s
epoch 15: {'train_loss': '2.58287'}; time used = 0.9598314762115479s
epoch 20: {'train_loss': '2.48571'}; time used = 1.0346176624298096s
epoch 25: {'train_loss': '2.34622'}; time used = 1.0117461681365967s
epoch 30: {'train_loss': '2.19689'}; time used = 1.0663695335388184s
epoch 35: {'train_loss': '2.06657'}; time used = 1.0424494743347168s
epoch 40: {'train_loss': '2.01237'}; time used = 0.9798471927642822s
epoch 45: {'train_loss': '1.87461'}; time used = 0.975665807723999s
epoch 50: {'train_loss': '2.14025'}; time used = 0.9598853588104248s
epoch 55: {'train_loss': '2.02199'}; time used = 0.9684751033782959s
epoch 60: {'train_loss': '1.92862'}; time used = 1.2045977115631104s
epoch 65: {'train_loss': '1.90544'}; time used = 1.1896378993988037s
epoch 70: {'train_loss': '1.83653'}; time used = 1.207223892211914s
epoch 75: {'train_loss': '1.77885'}; time used = 1.2000823020935059s
epoch 80: {'train_loss': '1.82993'}; time used = 1.1931331157684326s
epoch 85: {'train_loss': '1.82008'}; time used = 1.183509111404419s
epoch 90: {'train_loss': '1.77811'}; time used = 1.1573033332824707s
epoch 95: {'train_loss': '1.80491'}; time used = 1.0139288902282715s
epoch 100: {'train_loss': '1.80197'}; time used = 1.169780969619751s
epoch 105: {'train_loss': '1.77936'}; time used = 1.2406346797943115s
epoch 110: {'train_loss': '1.76375'}; time used = 1.189784049987793s
epoch 115: {'train_loss': '1.73480'}; time used = 1.1951439380645752s
epoch 120: {'train_loss': '1.75254'}; time used = 1.031259536743164s
epoch 125: {'train_loss': '1.82728'}; time used = 1.0040643215179443s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.47296643257141.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.23933'}; time used = 1.284731388092041s
epoch 10: {'train_loss': '0.10613'}; time used = 1.1517398357391357s
epoch 15: {'train_loss': '0.07750'}; time used = 1.1084873676300049s
epoch 20: {'train_loss': '0.03424'}; time used = 1.0542964935302734s
epoch 25: {'train_loss': '0.03214'}; time used = 0.9695918560028076s
epoch 30: {'train_loss': '0.02124'}; time used = 0.9791808128356934s
epoch 35: {'train_loss': '0.02186'}; time used = 0.9644613265991211s
epoch 40: {'train_loss': '0.01948'}; time used = 0.9581203460693359s
epoch 45: {'train_loss': '0.02452'}; time used = 0.9669151306152344s
epoch 50: {'train_loss': '0.01611'}; time used = 0.9600048065185547s
epoch 55: {'train_loss': '0.01463'}; time used = 0.969757080078125s
epoch 60: {'train_loss': '0.01827'}; time used = 1.0387403964996338s
epoch 65: {'train_loss': '0.02388'}; time used = 1.108335256576538s
epoch 70: {'train_loss': '0.01456'}; time used = 1.2417962551116943s
epoch 75: {'train_loss': '0.41964'}; time used = 1.0949113368988037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.856292963027954.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40162'}; time used = 1.331303358078003s
epoch 10: {'train_loss': '1.34981'}; time used = 1.2470312118530273s
epoch 15: {'train_loss': '1.39770'}; time used = 1.1516461372375488s
epoch 20: {'train_loss': '1.37498'}; time used = 1.3119652271270752s
epoch 25: {'train_loss': '1.34000'}; time used = 1.2298617362976074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.367181777954102.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34936'}; time used = 5.389626502990723s
epoch 10: {'train_loss': '1.33867'}; time used = 6.066481828689575s
epoch 15: {'train_loss': '1.31032'}; time used = 5.581208229064941s
epoch 20: {'train_loss': '1.29284'}; time used = 5.399065256118774s
epoch 25: {'train_loss': '1.23314'}; time used = 5.061387062072754s
epoch 30: {'train_loss': '1.14887'}; time used = 5.745723247528076s
epoch 35: {'train_loss': '1.10404'}; time used = 6.177271604537964s
epoch 40: {'train_loss': '0.96033'}; time used = 6.019506931304932s
epoch 45: {'train_loss': '0.85188'}; time used = 5.941713333129883s
epoch 50: {'train_loss': '0.88447'}; time used = 5.852851629257202s
epoch 55: {'train_loss': '0.81088'}; time used = 5.091917276382446s
epoch 60: {'train_loss': '0.85587'}; time used = 5.028885841369629s
epoch 65: {'train_loss': '0.78356'}; time used = 5.234781742095947s
epoch 70: {'train_loss': '0.50769'}; time used = 5.2623450756073s
epoch 75: {'train_loss': '0.59299'}; time used = 6.1066505908966064s
epoch 80: {'train_loss': '0.88110'}; time used = 5.264430522918701s
epoch 85: {'train_loss': '0.65511'}; time used = 5.150503396987915s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 114.27437376976013.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.71374'}; time used = 1.1684753894805908s
epoch 10: {'train_loss': '0.46392'}; time used = 1.1710436344146729s
epoch 15: {'train_loss': '0.34292'}; time used = 1.1282353401184082s
epoch 20: {'train_loss': '0.20059'}; time used = 1.0082111358642578s
epoch 25: {'train_loss': '0.17785'}; time used = 1.0301015377044678s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.433700561523438.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38225'}; time used = 2.175867795944214s
epoch 10: {'train_loss': '1.35245'}; time used = 2.1375021934509277s
epoch 15: {'train_loss': '1.37976'}; time used = 2.1136257648468018s
epoch 20: {'train_loss': '1.43833'}; time used = 2.1687493324279785s
epoch 25: {'train_loss': '1.40452'}; time used = 2.184382915496826s
epoch 30: {'train_loss': '1.34453'}; time used = 2.109387159347534s
epoch 35: {'train_loss': '1.31188'}; time used = 2.0905542373657227s
epoch 40: {'train_loss': '1.26139'}; time used = 2.076953649520874s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.048227310180664.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77418'}; time used = 1.783562421798706s
epoch 10: {'train_loss': '2.74192'}; time used = 1.7524197101593018s
epoch 15: {'train_loss': '2.65173'}; time used = 1.6761376857757568s
epoch 20: {'train_loss': '2.64058'}; time used = 1.6515467166900635s
epoch 25: {'train_loss': '2.61906'}; time used = 1.84904146194458s
epoch 30: {'train_loss': '2.58713'}; time used = 1.7841660976409912s
epoch 35: {'train_loss': '2.55200'}; time used = 1.707585096359253s
epoch 40: {'train_loss': '2.51125'}; time used = 1.969531774520874s
epoch 45: {'train_loss': '2.46760'}; time used = 1.6618521213531494s
epoch 50: {'train_loss': '2.46883'}; time used = 1.6689131259918213s
epoch 55: {'train_loss': '2.43303'}; time used = 1.7281670570373535s
epoch 60: {'train_loss': '2.43991'}; time used = 1.669039011001587s
epoch 65: {'train_loss': '2.38014'}; time used = 1.7373900413513184s
epoch 70: {'train_loss': '2.33362'}; time used = 1.672631025314331s
epoch 75: {'train_loss': '2.27836'}; time used = 1.6383614540100098s
epoch 80: {'train_loss': '2.28132'}; time used = 1.7142670154571533s
epoch 85: {'train_loss': '2.25386'}; time used = 1.6472914218902588s
epoch 90: {'train_loss': '2.23843'}; time used = 1.7259461879730225s
epoch 95: {'train_loss': '2.39117'}; time used = 1.6245076656341553s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.599063873291016.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4668181818181818, 'samples': 0.5072463768115942, 'weighted': 0.4774571805006588, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09899'}; time used = 2.0486092567443848s
epoch 10: {'train_loss': '2.84885'}; time used = 2.2369375228881836s
epoch 15: {'train_loss': '2.77630'}; time used = 2.22440505027771s
epoch 20: {'train_loss': '2.79146'}; time used = 2.2062485218048096s
epoch 25: {'train_loss': '2.78349'}; time used = 2.3247315883636475s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.102121591567993.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.72010'}; time used = 2.746764659881592s
epoch 10: {'train_loss': '2.64433'}; time used = 2.9469501972198486s
epoch 15: {'train_loss': '2.63450'}; time used = 2.906545639038086s
epoch 20: {'train_loss': '2.60990'}; time used = 1.7187819480895996s
epoch 25: {'train_loss': '2.59379'}; time used = 2.124948740005493s
epoch 30: {'train_loss': '2.56228'}; time used = 3.0038669109344482s
epoch 35: {'train_loss': '2.53128'}; time used = 2.9846489429473877s
epoch 40: {'train_loss': '2.49378'}; time used = 2.1960110664367676s
epoch 45: {'train_loss': '2.49968'}; time used = 1.71567964553833s
epoch 50: {'train_loss': '2.37487'}; time used = 1.6172938346862793s
epoch 55: {'train_loss': '2.38991'}; time used = 1.7209932804107666s
epoch 60: {'train_loss': '2.36288'}; time used = 1.6161513328552246s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.067293882369995.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.568874359130859s
epoch 10: {'train_loss': '1.38629'}; time used = 8.676513671875s
epoch 15: {'train_loss': '1.38629'}; time used = 6.479841232299805s
epoch 20: {'train_loss': '1.38629'}; time used = 6.481473445892334s
epoch 25: {'train_loss': '1.38629'}; time used = 7.244747877120972s
epoch 30: {'train_loss': '1.38629'}; time used = 7.825083017349243s
epoch 35: {'train_loss': '1.38629'}; time used = 9.641000270843506s
epoch 40: {'train_loss': '1.38629'}; time used = 8.488948345184326s
epoch 45: {'train_loss': '1.38629'}; time used = 7.694015741348267s
epoch 50: {'train_loss': '1.38629'}; time used = 6.952641487121582s
epoch 55: {'train_loss': '1.38629'}; time used = 6.627929210662842s
epoch 60: {'train_loss': '1.38629'}; time used = 6.440859794616699s
epoch 65: {'train_loss': '1.38629'}; time used = 7.194662094116211s
epoch 70: {'train_loss': '1.38629'}; time used = 6.32955002784729s
epoch 75: {'train_loss': '1.38629'}; time used = 6.346285820007324s
epoch 80: {'train_loss': '1.38629'}; time used = 6.330993890762329s
epoch 85: {'train_loss': '1.38629'}; time used = 6.553968906402588s
epoch 90: {'train_loss': '1.38629'}; time used = 7.175615549087524s
epoch 95: {'train_loss': '1.38629'}; time used = 6.765407085418701s
epoch 100: {'train_loss': '1.38629'}; time used = 6.705284595489502s
epoch 105: {'train_loss': '1.38629'}; time used = 7.856716156005859s
epoch 110: {'train_loss': '1.38629'}; time used = 6.4714789390563965s
epoch 115: {'train_loss': '1.38629'}; time used = 10.072740316390991s
epoch 120: {'train_loss': '1.38629'}; time used = 6.6724841594696045s
epoch 125: {'train_loss': '1.38629'}; time used = 7.193817853927612s
epoch 130: {'train_loss': '1.38629'}; time used = 6.632456064224243s
epoch 135: {'train_loss': '1.38629'}; time used = 9.138632535934448s
epoch 140: {'train_loss': '1.38629'}; time used = 8.3923020362854s
epoch 145: {'train_loss': '1.38629'}; time used = 6.632231712341309s
epoch 150: {'train_loss': '1.38629'}; time used = 11.166566133499146s
epoch 155: {'train_loss': '1.38629'}; time used = 6.823652744293213s
epoch 160: {'train_loss': '1.38629'}; time used = 8.519035577774048s
epoch 165: {'train_loss': '1.38629'}; time used = 8.605961084365845s
epoch 170: {'train_loss': '1.38629'}; time used = 7.258819580078125s
epoch 175: {'train_loss': '1.38629'}; time used = 6.522217750549316s
epoch 180: {'train_loss': '1.38629'}; time used = 6.402765989303589s
epoch 185: {'train_loss': '1.38629'}; time used = 6.393760919570923s
epoch 190: {'train_loss': '1.38629'}; time used = 6.416279554367065s
epoch 195: {'train_loss': '1.38629'}; time used = 6.5931878089904785s
epoch 200: {'train_loss': '1.38629'}; time used = 6.454564094543457s
epoch 205: {'train_loss': '1.38629'}; time used = 6.626049518585205s
epoch 210: {'train_loss': '1.38629'}; time used = 6.620806455612183s
epoch 215: {'train_loss': '1.38629'}; time used = 6.530282497406006s
epoch 220: {'train_loss': '1.38629'}; time used = 7.082713603973389s
epoch 225: {'train_loss': '1.38629'}; time used = 9.703184604644775s
epoch 230: {'train_loss': '1.38629'}; time used = 6.621628046035767s
epoch 235: {'train_loss': '1.38629'}; time used = 6.599791765213013s
epoch 240: {'train_loss': '1.38629'}; time used = 6.3969244956970215s
epoch 245: {'train_loss': '1.38629'}; time used = 6.343894720077515s
epoch 250: {'train_loss': '1.38629'}; time used = 6.720060586929321s
epoch 255: {'train_loss': '1.38629'}; time used = 6.74718976020813s
epoch 260: {'train_loss': '1.38629'}; time used = 6.845102548599243s
epoch 265: {'train_loss': '1.38629'}; time used = 6.720967531204224s
epoch 270: {'train_loss': '1.38629'}; time used = 6.515943288803101s
epoch 275: {'train_loss': '1.38629'}; time used = 6.532191753387451s
epoch 280: {'train_loss': '1.38629'}; time used = 6.448036193847656s
epoch 285: {'train_loss': '1.38629'}; time used = 6.459259033203125s
epoch 290: {'train_loss': '1.38629'}; time used = 6.3573219776153564s
epoch 295: {'train_loss': '1.38629'}; time used = 6.34876275062561s
epoch 300: {'train_loss': '1.38629'}; time used = 6.3931663036346436s
epoch 305: {'train_loss': '1.38629'}; time used = 6.276415586471558s
epoch 310: {'train_loss': '1.38629'}; time used = 6.387705564498901s
epoch 315: {'train_loss': '1.38629'}; time used = 6.435103893280029s
epoch 320: {'train_loss': '1.38629'}; time used = 6.681439399719238s
epoch 325: {'train_loss': '1.38629'}; time used = 6.523335218429565s
epoch 330: {'train_loss': '1.38629'}; time used = 6.408902883529663s
epoch 335: {'train_loss': '1.38629'}; time used = 6.4557061195373535s
epoch 340: {'train_loss': '1.38629'}; time used = 7.021680116653442s
epoch 345: {'train_loss': '1.38629'}; time used = 6.497081279754639s
epoch 350: {'train_loss': '1.38629'}; time used = 6.313985347747803s
epoch 355: {'train_loss': '1.38629'}; time used = 6.4248411655426025s
epoch 360: {'train_loss': '1.38629'}; time used = 6.302931308746338s
epoch 365: {'train_loss': '1.38629'}; time used = 6.356839179992676s
epoch 370: {'train_loss': '1.38629'}; time used = 6.5440356731414795s
epoch 375: {'train_loss': '1.38629'}; time used = 6.414440870285034s
epoch 380: {'train_loss': '1.38629'}; time used = 6.148696660995483s
epoch 385: {'train_loss': '1.38629'}; time used = 6.240687131881714s
epoch 390: {'train_loss': '1.38629'}; time used = 6.401071548461914s
epoch 395: {'train_loss': '1.38629'}; time used = 6.4201319217681885s
epoch 400: {'train_loss': '1.38629'}; time used = 6.20792555809021s
epoch 405: {'train_loss': '1.38629'}; time used = 6.23163914680481s
epoch 410: {'train_loss': '1.38629'}; time used = 6.192017555236816s
epoch 415: {'train_loss': '1.38629'}; time used = 7.064283132553101s
epoch 420: {'train_loss': '1.38629'}; time used = 6.495465993881226s
epoch 425: {'train_loss': '1.38629'}; time used = 6.330234050750732s
epoch 430: {'train_loss': '1.38629'}; time used = 6.299067974090576s
epoch 435: {'train_loss': '1.38629'}; time used = 6.39242959022522s
epoch 440: {'train_loss': '1.38629'}; time used = 6.406786203384399s
epoch 445: {'train_loss': '1.38629'}; time used = 7.581961154937744s
epoch 450: {'train_loss': '1.38629'}; time used = 6.9508044719696045s
epoch 455: {'train_loss': '1.38629'}; time used = 6.43060302734375s
epoch 460: {'train_loss': '1.38629'}; time used = 6.464729070663452s
epoch 465: {'train_loss': '1.38629'}; time used = 6.4191038608551025s
epoch 470: {'train_loss': '1.38629'}; time used = 6.487915754318237s
epoch 475: {'train_loss': '1.38629'}; time used = 6.510659217834473s
epoch 480: {'train_loss': '1.38629'}; time used = 6.264005422592163s
epoch 485: {'train_loss': '1.38629'}; time used = 6.367081165313721s
epoch 490: {'train_loss': '1.38629'}; time used = 6.287732839584351s
epoch 495: {'train_loss': '1.38629'}; time used = 6.654332637786865s
epoch 500: {'train_loss': '1.38629'}; time used = 6.329297780990601s
Finished training. Time used = 696.7570602893829.
Training classifier using 80.00% nodes...
{'micro': 0.49, 'macro': 0.4512628096506092, 'samples': 0.49, 'weighted': 0.44390139594932615, 'accuracy': 0.49}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.35004'}; time used = 1.8760266304016113s
epoch 10: {'train_loss': '1.08026'}; time used = 1.8294918537139893s
epoch 15: {'train_loss': '0.67850'}; time used = 1.8435232639312744s
epoch 20: {'train_loss': '0.31638'}; time used = 1.795067548751831s
epoch 25: {'train_loss': '0.46017'}; time used = 1.9663779735565186s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.920006275177002.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92348'}; time used = 1.6401610374450684s
epoch 10: {'train_loss': '2.80450'}; time used = 1.598520040512085s
epoch 15: {'train_loss': '2.79079'}; time used = 1.8506138324737549s
epoch 20: {'train_loss': '2.78506'}; time used = 1.7875428199768066s
epoch 25: {'train_loss': '2.77614'}; time used = 1.8425343036651611s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.316207885742188.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35604'}; time used = 4.841639280319214s
epoch 10: {'train_loss': '1.35545'}; time used = 5.301900863647461s
epoch 15: {'train_loss': '1.33720'}; time used = 5.600712060928345s
epoch 20: {'train_loss': '1.34158'}; time used = 4.9933881759643555s
epoch 25: {'train_loss': '1.32650'}; time used = 4.918720722198486s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.92290377616882.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7300000000000001, 'samples': 0.73, 'weighted': 0.73, 'accuracy': 0.73}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05031'}; time used = 1.7292418479919434s
epoch 10: {'train_loss': '2.82101'}; time used = 1.5551178455352783s
epoch 15: {'train_loss': '2.74434'}; time used = 2.2146270275115967s
epoch 20: {'train_loss': '2.74756'}; time used = 3.126760959625244s
epoch 25: {'train_loss': '2.73596'}; time used = 3.0427510738372803s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.753466844558716.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51918'}; time used = 1.091486930847168s
epoch 10: {'train_loss': '0.41502'}; time used = 0.9260566234588623s
epoch 15: {'train_loss': '0.28380'}; time used = 0.9492933750152588s
epoch 20: {'train_loss': '0.16241'}; time used = 1.048304796218872s
epoch 25: {'train_loss': '0.21499'}; time used = 0.9203894138336182s
epoch 30: {'train_loss': '0.12831'}; time used = 1.0570476055145264s
epoch 35: {'train_loss': '0.14849'}; time used = 0.9440033435821533s
epoch 40: {'train_loss': '0.18181'}; time used = 1.034458875656128s
epoch 45: {'train_loss': '0.15339'}; time used = 1.0996003150939941s
epoch 50: {'train_loss': '0.19612'}; time used = 1.12717866897583s
epoch 55: {'train_loss': '0.14492'}; time used = 1.1159930229187012s
epoch 60: {'train_loss': '0.11716'}; time used = 1.2839412689208984s
epoch 65: {'train_loss': '0.15732'}; time used = 1.0782606601715088s
epoch 70: {'train_loss': '0.09023'}; time used = 0.9262588024139404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.21713900566101.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.16617'}; time used = 1.7394139766693115s
epoch 10: {'train_loss': '2.86024'}; time used = 1.808215856552124s
epoch 15: {'train_loss': '2.76315'}; time used = 1.7019765377044678s
epoch 20: {'train_loss': '2.75990'}; time used = 1.6630213260650635s
epoch 25: {'train_loss': '2.73527'}; time used = 1.7972514629364014s
epoch 30: {'train_loss': '2.68223'}; time used = 1.6832730770111084s
epoch 35: {'train_loss': '2.62458'}; time used = 1.7350270748138428s
epoch 40: {'train_loss': '2.57439'}; time used = 1.7123992443084717s
epoch 45: {'train_loss': '2.52231'}; time used = 1.7066760063171387s
epoch 50: {'train_loss': '2.43258'}; time used = 1.70680570602417s
epoch 55: {'train_loss': '2.38005'}; time used = 1.7418041229248047s
epoch 60: {'train_loss': '2.31861'}; time used = 1.7047433853149414s
epoch 65: {'train_loss': '2.20207'}; time used = 1.706779956817627s
epoch 70: {'train_loss': '2.24918'}; time used = 1.6793920993804932s
epoch 75: {'train_loss': '2.09624'}; time used = 1.6932275295257568s
epoch 80: {'train_loss': '1.99236'}; time used = 1.8349359035491943s
epoch 85: {'train_loss': '1.99829'}; time used = 1.650630235671997s
epoch 90: {'train_loss': '2.00962'}; time used = 1.8060035705566406s
epoch 95: {'train_loss': '1.92470'}; time used = 1.649595022201538s
epoch 100: {'train_loss': '1.95421'}; time used = 1.7628591060638428s
epoch 105: {'train_loss': '1.89914'}; time used = 1.7444508075714111s
epoch 110: {'train_loss': '1.85241'}; time used = 1.9100217819213867s
epoch 115: {'train_loss': '1.84751'}; time used = 2.0297820568084717s
epoch 120: {'train_loss': '1.77726'}; time used = 2.000880479812622s
epoch 125: {'train_loss': '1.83471'}; time used = 1.6655206680297852s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.09618020057678.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4888888888888889, 'samples': 0.4927536231884058, 'weighted': 0.492109500805153, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79791'}; time used = 2.110349655151367s
epoch 10: {'train_loss': '2.77335'}; time used = 2.033228635787964s
epoch 15: {'train_loss': '2.78522'}; time used = 2.0492537021636963s
epoch 20: {'train_loss': '2.78396'}; time used = 1.99312424659729s
epoch 25: {'train_loss': '2.77314'}; time used = 2.0231266021728516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.596056461334229.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.24605'}; time used = 2.0643231868743896s
epoch 10: {'train_loss': '0.29931'}; time used = 1.9221928119659424s
epoch 15: {'train_loss': '0.23419'}; time used = 1.9317631721496582s
epoch 20: {'train_loss': '0.00619'}; time used = 1.9123826026916504s
epoch 25: {'train_loss': '0.00009'}; time used = 1.9695141315460205s
epoch 30: {'train_loss': '0.00055'}; time used = 1.910963773727417s
epoch 35: {'train_loss': '0.00002'}; time used = 1.9077861309051514s
epoch 40: {'train_loss': '0.00002'}; time used = 1.941741704940796s
epoch 45: {'train_loss': '0.00000'}; time used = 1.9506826400756836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.8334059715271.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87724'}; time used = 1.9765067100524902s
epoch 10: {'train_loss': '2.79986'}; time used = 1.8265020847320557s
epoch 15: {'train_loss': '2.77879'}; time used = 1.8484537601470947s
epoch 20: {'train_loss': '2.77263'}; time used = 1.722893476486206s
epoch 25: {'train_loss': '2.77165'}; time used = 2.205582618713379s
epoch 30: {'train_loss': '2.76853'}; time used = 2.02801513671875s
epoch 35: {'train_loss': '2.76830'}; time used = 1.930110216140747s
epoch 40: {'train_loss': '2.76775'}; time used = 1.7924549579620361s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.009577989578247.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81414'}; time used = 1.4250574111938477s
epoch 10: {'train_loss': '2.21158'}; time used = 1.4232244491577148s
epoch 15: {'train_loss': '1.59489'}; time used = 1.4587514400482178s
epoch 20: {'train_loss': '1.57543'}; time used = 1.2413275241851807s
epoch 25: {'train_loss': '1.39826'}; time used = 1.0997340679168701s
epoch 30: {'train_loss': '1.30952'}; time used = 0.9966211318969727s
epoch 35: {'train_loss': '1.14161'}; time used = 0.986518383026123s
epoch 40: {'train_loss': '1.43790'}; time used = 1.0956041812896729s
epoch 45: {'train_loss': '1.23236'}; time used = 1.0340218544006348s
epoch 50: {'train_loss': '1.18277'}; time used = 1.1877870559692383s
epoch 55: {'train_loss': '1.13396'}; time used = 1.1273691654205322s
epoch 60: {'train_loss': '1.07543'}; time used = 1.07481050491333s
epoch 65: {'train_loss': '1.02938'}; time used = 1.0054373741149902s
epoch 70: {'train_loss': '0.96544'}; time used = 1.1542229652404785s
epoch 75: {'train_loss': '0.89287'}; time used = 1.0246362686157227s
epoch 80: {'train_loss': '0.99287'}; time used = 1.0432970523834229s
epoch 85: {'train_loss': '0.98341'}; time used = 1.0825557708740234s
epoch 90: {'train_loss': '0.92832'}; time used = 1.09189772605896s
epoch 95: {'train_loss': '0.95426'}; time used = 1.183424949645996s
epoch 100: {'train_loss': '1.08315'}; time used = 1.1442291736602783s
epoch 105: {'train_loss': '0.90874'}; time used = 1.0575191974639893s
epoch 110: {'train_loss': '0.91904'}; time used = 1.1688077449798584s
epoch 115: {'train_loss': '0.89831'}; time used = 1.038599967956543s
epoch 120: {'train_loss': '0.85685'}; time used = 1.1791276931762695s
epoch 125: {'train_loss': '0.89340'}; time used = 1.127305507659912s
epoch 130: {'train_loss': '0.80405'}; time used = 1.020848274230957s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.08358860015869.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.95254'}; time used = 1.0129764080047607s
epoch 10: {'train_loss': '2.71475'}; time used = 0.9909980297088623s
epoch 15: {'train_loss': '2.58814'}; time used = 1.0284433364868164s
epoch 20: {'train_loss': '2.38566'}; time used = 1.1603145599365234s
epoch 25: {'train_loss': '2.05329'}; time used = 1.073230266571045s
epoch 30: {'train_loss': '1.77521'}; time used = 1.0311100482940674s
epoch 35: {'train_loss': '1.57568'}; time used = 1.0184476375579834s
epoch 40: {'train_loss': '1.56184'}; time used = 1.0624752044677734s
epoch 45: {'train_loss': '1.59826'}; time used = 1.0660207271575928s
epoch 50: {'train_loss': '1.43566'}; time used = 1.0346958637237549s
epoch 55: {'train_loss': '1.44947'}; time used = 0.9134922027587891s
epoch 60: {'train_loss': '1.42285'}; time used = 0.9768800735473633s
epoch 65: {'train_loss': '1.40766'}; time used = 0.9036738872528076s
epoch 70: {'train_loss': '1.38871'}; time used = 0.9468724727630615s
epoch 75: {'train_loss': '1.28445'}; time used = 1.2042438983917236s
epoch 80: {'train_loss': '1.32348'}; time used = 1.0647683143615723s
epoch 85: {'train_loss': '1.32279'}; time used = 1.0608785152435303s
epoch 90: {'train_loss': '1.28137'}; time used = 1.0448391437530518s
epoch 95: {'train_loss': '1.27588'}; time used = 1.1778295040130615s
epoch 100: {'train_loss': '1.28565'}; time used = 1.1150412559509277s
epoch 105: {'train_loss': '1.31505'}; time used = 1.1460762023925781s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.017974615097046.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99009'}; time used = 1.1497173309326172s
epoch 10: {'train_loss': '0.59553'}; time used = 1.0070574283599854s
epoch 15: {'train_loss': '0.37015'}; time used = 1.0896363258361816s
epoch 20: {'train_loss': '0.19337'}; time used = 1.0082712173461914s
epoch 25: {'train_loss': '0.13914'}; time used = 1.1055400371551514s
epoch 30: {'train_loss': '0.09042'}; time used = 0.9915156364440918s
epoch 35: {'train_loss': '0.05315'}; time used = 1.033385992050171s
epoch 40: {'train_loss': '0.04419'}; time used = 1.0802619457244873s
epoch 45: {'train_loss': '0.03884'}; time used = 1.0028700828552246s
epoch 50: {'train_loss': '0.02852'}; time used = 0.9851043224334717s
epoch 55: {'train_loss': '0.01955'}; time used = 1.1867499351501465s
epoch 60: {'train_loss': '0.01201'}; time used = 1.0563600063323975s
epoch 65: {'train_loss': '0.02292'}; time used = 1.0015754699707031s
epoch 70: {'train_loss': '0.01524'}; time used = 0.9897916316986084s
epoch 75: {'train_loss': '0.01443'}; time used = 1.7017521858215332s
epoch 80: {'train_loss': '1.05939'}; time used = 1.8167393207550049s
epoch 85: {'train_loss': '0.33650'}; time used = 2.0509891510009766s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.073181629180908.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84171'}; time used = 2.15443754196167s
epoch 10: {'train_loss': '2.77201'}; time used = 2.0392403602600098s
epoch 15: {'train_loss': '2.79398'}; time used = 2.036938428878784s
epoch 20: {'train_loss': '2.78252'}; time used = 2.0425238609313965s
epoch 25: {'train_loss': '2.77055'}; time used = 2.098159074783325s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.133302927017212.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.34646'}; time used = 1.837388515472412s
epoch 10: {'train_loss': '1.22953'}; time used = 3.7335634231567383s
epoch 15: {'train_loss': '1.16824'}; time used = 1.789133071899414s
epoch 20: {'train_loss': '1.18026'}; time used = 2.3710055351257324s
epoch 25: {'train_loss': '1.11841'}; time used = 3.1741859912872314s
epoch 30: {'train_loss': '1.00907'}; time used = 1.919332504272461s
epoch 35: {'train_loss': '0.99752'}; time used = 1.9133284091949463s
epoch 40: {'train_loss': '0.90665'}; time used = 3.011704444885254s
epoch 45: {'train_loss': '0.90523'}; time used = 3.511852502822876s
epoch 50: {'train_loss': '0.71168'}; time used = 3.5117781162261963s
epoch 55: {'train_loss': '0.63900'}; time used = 4.125490188598633s
epoch 60: {'train_loss': '0.66906'}; time used = 3.1995468139648438s
epoch 65: {'train_loss': '0.60893'}; time used = 3.481182813644409s
epoch 70: {'train_loss': '0.73283'}; time used = 2.3199398517608643s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.53420162200928.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35127'}; time used = 1.265162467956543s
epoch 10: {'train_loss': '1.28599'}; time used = 1.2815213203430176s
epoch 15: {'train_loss': '1.17795'}; time used = 1.311187505722046s
epoch 20: {'train_loss': '1.12248'}; time used = 1.169053316116333s
epoch 25: {'train_loss': '0.91605'}; time used = 1.1498243808746338s
epoch 30: {'train_loss': '0.89191'}; time used = 1.8999783992767334s
epoch 35: {'train_loss': '1.05553'}; time used = 2.483847141265869s
epoch 40: {'train_loss': '0.95986'}; time used = 2.2518770694732666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.241984844207764.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84533'}; time used = 1.3227698802947998s
epoch 10: {'train_loss': '0.25148'}; time used = 1.175382375717163s
epoch 15: {'train_loss': '0.18011'}; time used = 1.2151165008544922s
epoch 20: {'train_loss': '0.14431'}; time used = 1.199450969696045s
epoch 25: {'train_loss': '0.16358'}; time used = 1.2025949954986572s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.801088571548462.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.29284'}; time used = 7.683028697967529s
epoch 10: {'train_loss': '1.18724'}; time used = 5.088803052902222s
epoch 15: {'train_loss': '1.01298'}; time used = 5.57448935508728s
epoch 20: {'train_loss': '0.75280'}; time used = 5.32666540145874s
epoch 25: {'train_loss': '0.75878'}; time used = 5.42985987663269s
epoch 30: {'train_loss': '0.40761'}; time used = 5.513719081878662s
epoch 35: {'train_loss': '0.10112'}; time used = 5.462509632110596s
epoch 40: {'train_loss': '0.16626'}; time used = 4.968313455581665s
epoch 45: {'train_loss': '0.03322'}; time used = 8.340256929397583s
epoch 50: {'train_loss': '1.52513'}; time used = 8.55069375038147s
epoch 55: {'train_loss': '0.53580'}; time used = 7.284754991531372s
epoch 60: {'train_loss': '0.08492'}; time used = 4.898884534835815s
epoch 65: {'train_loss': '0.00794'}; time used = 4.871883869171143s
epoch 70: {'train_loss': '0.01653'}; time used = 5.01597785949707s
epoch 75: {'train_loss': '0.00673'}; time used = 7.157001256942749s
epoch 80: {'train_loss': '0.11193'}; time used = 5.2421228885650635s
epoch 85: {'train_loss': '0.00039'}; time used = 5.436142444610596s
epoch 90: {'train_loss': '0.06786'}; time used = 4.6916913986206055s
epoch 95: {'train_loss': '0.01492'}; time used = 5.329081773757935s
epoch 100: {'train_loss': '0.26916'}; time used = 6.301615476608276s
epoch 105: {'train_loss': '0.05810'}; time used = 5.629926919937134s
epoch 110: {'train_loss': '0.00905'}; time used = 4.958014965057373s
epoch 115: {'train_loss': '1.98503'}; time used = 5.161442518234253s
epoch 120: {'train_loss': '0.00035'}; time used = 4.956145524978638s
epoch 125: {'train_loss': '0.09219'}; time used = 5.660709381103516s
epoch 130: {'train_loss': '0.79909'}; time used = 5.71569299697876s
epoch 135: {'train_loss': '0.00015'}; time used = 5.6468589305877686s
epoch 140: {'train_loss': '0.00574'}; time used = 6.13861608505249s
epoch 145: {'train_loss': '0.00217'}; time used = 5.918239116668701s
epoch 150: {'train_loss': '0.47194'}; time used = 5.4837565422058105s
epoch 155: {'train_loss': '0.11958'}; time used = 5.503184080123901s
epoch 160: {'train_loss': '0.00002'}; time used = 6.502284288406372s
epoch 165: {'train_loss': '0.01254'}; time used = 8.125117540359497s
epoch 170: {'train_loss': '0.00431'}; time used = 4.978400945663452s
epoch 175: {'train_loss': '0.21516'}; time used = 5.101138353347778s
epoch 180: {'train_loss': '0.01813'}; time used = 4.9808266162872314s
epoch 185: {'train_loss': '0.01460'}; time used = 4.793821096420288s
epoch 190: {'train_loss': '0.00071'}; time used = 4.74634313583374s
epoch 195: {'train_loss': '0.00381'}; time used = 4.758825302124023s
epoch 200: {'train_loss': '0.00269'}; time used = 4.942629337310791s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 252.82520508766174.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.17 GiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83814'}; time used = 2.5335161685943604s
epoch 10: {'train_loss': '2.77371'}; time used = 2.108516216278076s
epoch 15: {'train_loss': '2.78430'}; time used = 2.1812198162078857s
epoch 20: {'train_loss': '2.78418'}; time used = 1.4218413829803467s
epoch 25: {'train_loss': '2.77287'}; time used = 3.021575450897217s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.183597326278687.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36668'}; time used = 1.8600568771362305s
epoch 10: {'train_loss': '1.22799'}; time used = 1.8813464641571045s
epoch 15: {'train_loss': '1.04073'}; time used = 1.9960250854492188s
epoch 20: {'train_loss': '0.94235'}; time used = 2.2668910026550293s
epoch 25: {'train_loss': '1.02166'}; time used = 2.482851028442383s
epoch 30: {'train_loss': '0.83054'}; time used = 2.3888745307922363s
epoch 35: {'train_loss': '0.85143'}; time used = 2.429917812347412s
epoch 40: {'train_loss': '0.83565'}; time used = 2.3990724086761475s
epoch 45: {'train_loss': '0.55279'}; time used = 2.4775230884552s
epoch 50: {'train_loss': '0.53604'}; time used = 2.4539196491241455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.721112489700317.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5436507936507937, 'samples': 0.5652173913043478, 'weighted': 0.5508396595353117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.90779'}; time used = 1.8051650524139404s
epoch 10: {'train_loss': '2.76722'}; time used = 1.796630859375s
epoch 15: {'train_loss': '2.73792'}; time used = 1.7818729877471924s
epoch 20: {'train_loss': '2.67860'}; time used = 2.425975799560547s
epoch 25: {'train_loss': '2.61874'}; time used = 3.178637742996216s
epoch 30: {'train_loss': '2.57402'}; time used = 2.9541163444519043s
epoch 35: {'train_loss': '2.50986'}; time used = 2.8494975566864014s
epoch 40: {'train_loss': '2.41516'}; time used = 2.3802380561828613s
epoch 45: {'train_loss': '2.45275'}; time used = 1.7966089248657227s
epoch 50: {'train_loss': '2.31755'}; time used = 1.828887701034546s
epoch 55: {'train_loss': '2.28450'}; time used = 1.7487592697143555s
epoch 60: {'train_loss': '2.23592'}; time used = 1.9966859817504883s
epoch 65: {'train_loss': '2.08507'}; time used = 1.8329582214355469s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.04102611541748.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85901'}; time used = 2.7992618083953857s
epoch 10: {'train_loss': '2.78335'}; time used = 2.3609778881073s
epoch 15: {'train_loss': '2.76834'}; time used = 2.3991501331329346s
epoch 20: {'train_loss': '2.77080'}; time used = 2.3643229007720947s
epoch 25: {'train_loss': '2.76165'}; time used = 2.5152080059051514s
epoch 30: {'train_loss': '2.73416'}; time used = 2.4578328132629395s
epoch 35: {'train_loss': '2.68995'}; time used = 3.25618577003479s
epoch 40: {'train_loss': '2.66084'}; time used = 3.0111477375030518s
epoch 45: {'train_loss': '2.63886'}; time used = 2.5790767669677734s
epoch 50: {'train_loss': '2.65236'}; time used = 2.4439544677734375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.81735348701477.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4728353140916808, 'samples': 0.4782608695652174, 'weighted': 0.4767107108584927, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.65933'}; time used = 1.2341830730438232s
epoch 10: {'train_loss': '0.20226'}; time used = 1.0403411388397217s
epoch 15: {'train_loss': '0.07433'}; time used = 1.3394594192504883s
epoch 20: {'train_loss': '0.07288'}; time used = 1.2434718608856201s
epoch 25: {'train_loss': '0.02034'}; time used = 1.2343437671661377s
epoch 30: {'train_loss': '0.01753'}; time used = 1.1999847888946533s
epoch 35: {'train_loss': '0.01609'}; time used = 1.1701159477233887s
epoch 40: {'train_loss': '0.00063'}; time used = 1.8862452507019043s
epoch 45: {'train_loss': '0.00025'}; time used = 1.946850299835205s
epoch 50: {'train_loss': '0.00220'}; time used = 1.1345160007476807s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.34331703186035.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39626'}; time used = 1.9083657264709473s
epoch 10: {'train_loss': '1.22629'}; time used = 2.4891090393066406s
epoch 15: {'train_loss': '0.94528'}; time used = 4.144724369049072s
epoch 20: {'train_loss': '0.93581'}; time used = 1.9576928615570068s
epoch 25: {'train_loss': '0.62867'}; time used = 2.2819275856018066s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.427663803100586.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.91103'}; time used = 1.745877981185913s
epoch 10: {'train_loss': '2.77622'}; time used = 1.7193317413330078s
epoch 15: {'train_loss': '2.74534'}; time used = 1.752455711364746s
epoch 20: {'train_loss': '2.69150'}; time used = 1.8793532848358154s
epoch 25: {'train_loss': '2.63167'}; time used = 1.8626959323883057s
epoch 30: {'train_loss': '2.59775'}; time used = 1.7739555835723877s
epoch 35: {'train_loss': '2.53874'}; time used = 1.6423015594482422s
epoch 40: {'train_loss': '2.45608'}; time used = 1.7526402473449707s
epoch 45: {'train_loss': '2.38010'}; time used = 1.681577205657959s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.730905055999756.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.59328'}; time used = 1.1008412837982178s
epoch 10: {'train_loss': '2.46070'}; time used = 1.4600379467010498s
epoch 15: {'train_loss': '2.37415'}; time used = 2.230958938598633s
epoch 20: {'train_loss': '2.31479'}; time used = 1.282548189163208s
epoch 25: {'train_loss': '2.28622'}; time used = 0.9757647514343262s
epoch 30: {'train_loss': '2.21953'}; time used = 0.9682471752166748s
epoch 35: {'train_loss': '2.17576'}; time used = 0.9693326950073242s
epoch 40: {'train_loss': '2.15818'}; time used = 0.9425082206726074s
epoch 45: {'train_loss': '2.14570'}; time used = 0.9935991764068604s
epoch 50: {'train_loss': '2.16046'}; time used = 0.9369971752166748s
epoch 55: {'train_loss': '2.13989'}; time used = 0.9974193572998047s
epoch 60: {'train_loss': '2.12641'}; time used = 0.9658958911895752s
epoch 65: {'train_loss': '2.13482'}; time used = 0.8881235122680664s
epoch 70: {'train_loss': '2.14422'}; time used = 0.9031503200531006s
epoch 75: {'train_loss': '2.11574'}; time used = 0.9071979522705078s
epoch 80: {'train_loss': '2.13199'}; time used = 0.8968119621276855s
epoch 85: {'train_loss': '2.13700'}; time used = 0.8897051811218262s
epoch 90: {'train_loss': '2.10214'}; time used = 0.9059102535247803s
epoch 95: {'train_loss': '2.13554'}; time used = 0.9511055946350098s
epoch 100: {'train_loss': '2.15412'}; time used = 0.9192867279052734s
epoch 105: {'train_loss': '2.13302'}; time used = 1.0267002582550049s
epoch 110: {'train_loss': '2.10860'}; time used = 0.9354186058044434s
epoch 115: {'train_loss': '2.11670'}; time used = 0.9755029678344727s
epoch 120: {'train_loss': '2.10372'}; time used = 0.9521996974945068s
epoch 125: {'train_loss': '2.13040'}; time used = 0.9414033889770508s
epoch 130: {'train_loss': '2.11111'}; time used = 0.9211161136627197s
epoch 135: {'train_loss': '2.10141'}; time used = 0.942105770111084s
epoch 140: {'train_loss': '2.11728'}; time used = 0.9025149345397949s
epoch 145: {'train_loss': '2.11902'}; time used = 0.8939766883850098s
epoch 150: {'train_loss': '2.11092'}; time used = 0.9512448310852051s
epoch 155: {'train_loss': '2.13274'}; time used = 0.9518518447875977s
epoch 160: {'train_loss': '2.12703'}; time used = 0.95589280128479s
epoch 165: {'train_loss': '2.13705'}; time used = 1.0050809383392334s
epoch 170: {'train_loss': '2.14566'}; time used = 1.0209550857543945s
epoch 175: {'train_loss': '2.09569'}; time used = 1.118661642074585s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.50241255760193.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.17076'}; time used = 1.9507930278778076s
epoch 10: {'train_loss': '0.68088'}; time used = 1.7442853450775146s
epoch 15: {'train_loss': '0.45487'}; time used = 1.7980341911315918s
epoch 20: {'train_loss': '0.32267'}; time used = 1.7573435306549072s
epoch 25: {'train_loss': '0.18556'}; time used = 1.8175289630889893s
epoch 30: {'train_loss': '0.13878'}; time used = 1.770320177078247s
epoch 35: {'train_loss': '0.11053'}; time used = 1.7467427253723145s
epoch 40: {'train_loss': '0.10846'}; time used = 1.7629435062408447s
epoch 45: {'train_loss': '0.08990'}; time used = 1.9009544849395752s
epoch 50: {'train_loss': '0.10762'}; time used = 1.9623143672943115s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.36586284637451.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5208333333333333, 'samples': 0.5942028985507246, 'weighted': 0.5344202898550725, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18760'}; time used = 1.6788384914398193s
epoch 10: {'train_loss': '0.07160'}; time used = 1.0373477935791016s
epoch 15: {'train_loss': '0.08470'}; time used = 1.0362110137939453s
epoch 20: {'train_loss': '0.25589'}; time used = 1.019341230392456s
epoch 25: {'train_loss': '0.06980'}; time used = 1.0246772766113281s
epoch 30: {'train_loss': '0.05434'}; time used = 1.0393636226654053s
epoch 35: {'train_loss': '0.03826'}; time used = 1.0318477153778076s
epoch 40: {'train_loss': '0.03483'}; time used = 1.0166423320770264s
epoch 45: {'train_loss': '0.03795'}; time used = 1.0718181133270264s
epoch 50: {'train_loss': '0.03819'}; time used = 0.9785239696502686s
epoch 55: {'train_loss': '0.01953'}; time used = 0.992790937423706s
epoch 60: {'train_loss': '0.01115'}; time used = 1.0905449390411377s
epoch 65: {'train_loss': '0.02516'}; time used = 1.067805528640747s
epoch 70: {'train_loss': '0.01882'}; time used = 1.036543607711792s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.781744718551636.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.30125'}; time used = 1.148803949356079s
epoch 10: {'train_loss': '1.49651'}; time used = 1.0581202507019043s
epoch 15: {'train_loss': '1.35363'}; time used = 0.9864678382873535s
epoch 20: {'train_loss': '1.37161'}; time used = 0.9278354644775391s
epoch 25: {'train_loss': '1.30351'}; time used = 1.2106208801269531s
epoch 30: {'train_loss': '1.31264'}; time used = 1.76969313621521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.180022954940796.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.19324'}; time used = 1.8273038864135742s
epoch 10: {'train_loss': '1.03803'}; time used = 1.6722514629364014s
epoch 15: {'train_loss': '0.91616'}; time used = 1.7963569164276123s
epoch 20: {'train_loss': '0.66778'}; time used = 1.6548619270324707s
epoch 25: {'train_loss': '0.40297'}; time used = 1.8594014644622803s
epoch 30: {'train_loss': '0.36087'}; time used = 1.7407984733581543s
epoch 35: {'train_loss': '0.19703'}; time used = 1.6188933849334717s
epoch 40: {'train_loss': '0.11108'}; time used = 1.6194572448730469s
epoch 45: {'train_loss': '0.08957'}; time used = 1.6637346744537354s
epoch 50: {'train_loss': '0.04991'}; time used = 1.6703238487243652s
epoch 55: {'train_loss': '0.03506'}; time used = 1.7020041942596436s
epoch 60: {'train_loss': '0.02516'}; time used = 1.7035386562347412s
epoch 65: {'train_loss': '0.03473'}; time used = 3.0402019023895264s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.940348386764526.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.44166'}; time used = 1.4656107425689697s
epoch 10: {'train_loss': '0.18609'}; time used = 1.5522034168243408s
epoch 15: {'train_loss': '0.09349'}; time used = 1.9246916770935059s
epoch 20: {'train_loss': '0.08046'}; time used = 2.528343677520752s
epoch 25: {'train_loss': '0.21924'}; time used = 1.8533430099487305s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.464204788208008.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.96012'}; time used = 2.2897891998291016s
epoch 10: {'train_loss': '0.00752'}; time used = 2.147615432739258s
epoch 15: {'train_loss': '0.00001'}; time used = 2.107900381088257s
epoch 20: {'train_loss': '0.00005'}; time used = 1.8118233680725098s
epoch 25: {'train_loss': '0.00000'}; time used = 2.8737411499023438s
epoch 30: {'train_loss': '0.00000'}; time used = 2.760176658630371s
epoch 35: {'train_loss': '0.00000'}; time used = 2.995689868927002s
epoch 40: {'train_loss': '1.38629'}; time used = 2.447756290435791s
epoch 45: {'train_loss': '0.00000'}; time used = 2.175567388534546s
epoch 50: {'train_loss': '0.00000'}; time used = 2.1098878383636475s
epoch 55: {'train_loss': '1.38629'}; time used = 2.0269699096679688s
epoch 60: {'train_loss': '0.00000'}; time used = 2.0995492935180664s
epoch 65: {'train_loss': '1.36608'}; time used = 2.07086181640625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.90793323516846.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.84728'}; time used = 1.2920546531677246s
epoch 10: {'train_loss': '0.57332'}; time used = 1.257021427154541s
epoch 15: {'train_loss': '0.39693'}; time used = 1.0535001754760742s
epoch 20: {'train_loss': '0.27231'}; time used = 1.075920581817627s
epoch 25: {'train_loss': '0.24132'}; time used = 1.07810640335083s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.285591125488281.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78190'}; time used = 5.145424842834473s
epoch 10: {'train_loss': '2.78399'}; time used = 7.019143581390381s
epoch 15: {'train_loss': '2.77526'}; time used = 4.365488529205322s
epoch 20: {'train_loss': '2.77260'}; time used = 4.254897356033325s
epoch 25: {'train_loss': '2.77383'}; time used = 4.3061652183532715s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.43853688240051.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6943811217715874, 'samples': 0.695, 'weighted': 0.6941060647811819, 'accuracy': 0.695}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77638'}; time used = 1.2760567665100098s
epoch 10: {'train_loss': '2.74198'}; time used = 1.102400779724121s
epoch 15: {'train_loss': '2.67345'}; time used = 1.1075413227081299s
epoch 20: {'train_loss': '2.49413'}; time used = 1.0795893669128418s
epoch 25: {'train_loss': '2.35362'}; time used = 1.115828514099121s
epoch 30: {'train_loss': '2.30347'}; time used = 1.1103451251983643s
epoch 35: {'train_loss': '2.22609'}; time used = 1.1040527820587158s
epoch 40: {'train_loss': '2.16637'}; time used = 1.1097643375396729s
epoch 45: {'train_loss': '2.17436'}; time used = 1.0958561897277832s
epoch 50: {'train_loss': '2.18202'}; time used = 1.119910478591919s
epoch 55: {'train_loss': '2.10995'}; time used = 1.0918571949005127s
epoch 60: {'train_loss': '2.11747'}; time used = 1.1483533382415771s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.272216320037842.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.64 GiB already allocated; 1.25 GiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27530'}; time used = 2.0076184272766113s
epoch 10: {'train_loss': '2.96492'}; time used = 1.5174739360809326s
epoch 15: {'train_loss': '2.88044'}; time used = 1.3827223777770996s
epoch 20: {'train_loss': '2.80379'}; time used = 1.3649091720581055s
epoch 25: {'train_loss': '2.81676'}; time used = 1.4396531581878662s
epoch 30: {'train_loss': '2.80200'}; time used = 2.053236961364746s
epoch 35: {'train_loss': '2.79526'}; time used = 1.4076111316680908s
epoch 40: {'train_loss': '2.79241'}; time used = 1.3907403945922852s
epoch 45: {'train_loss': '2.79304'}; time used = 1.4033324718475342s
epoch 50: {'train_loss': '2.78845'}; time used = 1.3926894664764404s
epoch 55: {'train_loss': '2.78276'}; time used = 1.4344468116760254s
epoch 60: {'train_loss': '2.78239'}; time used = 1.4184136390686035s
epoch 65: {'train_loss': '2.77831'}; time used = 1.4530086517333984s
epoch 70: {'train_loss': '2.77659'}; time used = 1.4593701362609863s
epoch 75: {'train_loss': '2.78597'}; time used = 1.3552734851837158s
epoch 80: {'train_loss': '2.78073'}; time used = 1.4560141563415527s
epoch 85: {'train_loss': '2.78141'}; time used = 1.50386381149292s
epoch 90: {'train_loss': '2.78116'}; time used = 1.434516429901123s
epoch 95: {'train_loss': '2.77725'}; time used = 1.4102566242218018s
epoch 100: {'train_loss': '2.77569'}; time used = 1.4752123355865479s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.636011362075806.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78215'}; time used = 6.071418762207031s
epoch 10: {'train_loss': '2.78419'}; time used = 5.911037445068359s
epoch 15: {'train_loss': '2.77521'}; time used = 5.7762439250946045s
epoch 20: {'train_loss': '2.77260'}; time used = 5.83807897567749s
epoch 25: {'train_loss': '2.77374'}; time used = 5.76407527923584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.8981773853302.
Training classifier using 80.00% nodes...
{'micro': 0.44666666666666666, 'macro': 0.44224344712096536, 'samples': 0.44666666666666666, 'weighted': 0.4400209198267394, 'accuracy': 0.44666666666666666}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30235'}; time used = 1.6615126132965088s
epoch 10: {'train_loss': '1.15497'}; time used = 1.5432279109954834s
epoch 15: {'train_loss': '1.04091'}; time used = 1.5675222873687744s
epoch 20: {'train_loss': '0.98998'}; time used = 1.5418269634246826s
epoch 25: {'train_loss': '0.92926'}; time used = 1.6099696159362793s
epoch 30: {'train_loss': '0.87488'}; time used = 1.52805495262146s
epoch 35: {'train_loss': '0.85486'}; time used = 1.5379672050476074s
epoch 40: {'train_loss': '0.80617'}; time used = 1.5547268390655518s
epoch 45: {'train_loss': '0.79542'}; time used = 1.5254058837890625s
epoch 50: {'train_loss': '0.70399'}; time used = 1.549229621887207s
epoch 55: {'train_loss': '0.64107'}; time used = 1.6094329357147217s
epoch 60: {'train_loss': '0.56208'}; time used = 1.5212962627410889s
epoch 65: {'train_loss': '0.55983'}; time used = 3.023291826248169s
epoch 70: {'train_loss': '0.43613'}; time used = 3.3750805854797363s
epoch 75: {'train_loss': '0.08388'}; time used = 1.7684051990509033s
epoch 80: {'train_loss': '0.03080'}; time used = 1.6029541492462158s
epoch 85: {'train_loss': '0.01353'}; time used = 1.520228624343872s
epoch 90: {'train_loss': '0.02204'}; time used = 1.5384125709533691s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.81362581253052.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37640'}; time used = 2.2934985160827637s
epoch 10: {'train_loss': '1.32903'}; time used = 5.115824460983276s
epoch 15: {'train_loss': '1.35108'}; time used = 2.3606064319610596s
epoch 20: {'train_loss': '1.44247'}; time used = 2.178208112716675s
epoch 25: {'train_loss': '1.39925'}; time used = 2.3712687492370605s
epoch 30: {'train_loss': '1.33820'}; time used = 3.761056900024414s
epoch 35: {'train_loss': '1.23534'}; time used = 3.9659130573272705s
epoch 40: {'train_loss': '1.15300'}; time used = 4.491595983505249s
epoch 45: {'train_loss': '1.13991'}; time used = 4.061715602874756s
epoch 50: {'train_loss': '0.93577'}; time used = 3.6183109283447266s
epoch 55: {'train_loss': '0.88715'}; time used = 2.391946315765381s
epoch 60: {'train_loss': '0.80117'}; time used = 1.9696145057678223s
epoch 65: {'train_loss': '0.91708'}; time used = 2.040917158126831s
epoch 70: {'train_loss': '0.87157'}; time used = 1.8419179916381836s
epoch 75: {'train_loss': '0.85141'}; time used = 3.320228099822998s
epoch 80: {'train_loss': '0.82873'}; time used = 3.5716991424560547s
epoch 85: {'train_loss': '0.65635'}; time used = 3.652249813079834s
epoch 90: {'train_loss': '0.85774'}; time used = 2.3254363536834717s
epoch 95: {'train_loss': '0.80681'}; time used = 2.110175371170044s
epoch 100: {'train_loss': '0.66940'}; time used = 2.157104015350342s
epoch 105: {'train_loss': '0.74056'}; time used = 1.9599370956420898s
epoch 110: {'train_loss': '0.59636'}; time used = 1.9549686908721924s
epoch 115: {'train_loss': '0.86210'}; time used = 1.874530553817749s
epoch 120: {'train_loss': '0.84640'}; time used = 1.9455487728118896s
epoch 125: {'train_loss': '0.83312'}; time used = 1.856454610824585s
epoch 130: {'train_loss': '0.66255'}; time used = 1.8977327346801758s
epoch 135: {'train_loss': '0.68383'}; time used = 1.8270618915557861s
epoch 140: {'train_loss': '0.23746'}; time used = 1.9095113277435303s
epoch 145: {'train_loss': '1.49204'}; time used = 1.8976967334747314s
epoch 150: {'train_loss': '1.12657'}; time used = 1.9573495388031006s
epoch 155: {'train_loss': '0.67332'}; time used = 2.0409069061279297s
epoch 160: {'train_loss': '0.26038'}; time used = 2.269014596939087s
epoch 165: {'train_loss': '0.00935'}; time used = 1.9634485244750977s
epoch 170: {'train_loss': '0.08222'}; time used = 1.8358452320098877s
epoch 175: {'train_loss': '0.01195'}; time used = 3.584345817565918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 98.3669502735138.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91546'}; time used = 4.081776857376099s
epoch 10: {'train_loss': '2.79026'}; time used = 3.7947731018066406s
epoch 15: {'train_loss': '2.79670'}; time used = 2.3795149326324463s
epoch 20: {'train_loss': '2.79310'}; time used = 1.9238252639770508s
epoch 25: {'train_loss': '2.78091'}; time used = 1.9759609699249268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.113743782043457.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83383'}; time used = 10.515532970428467s
epoch 10: {'train_loss': '2.80236'}; time used = 7.168932199478149s
epoch 15: {'train_loss': '2.78751'}; time used = 7.9128289222717285s
epoch 20: {'train_loss': '2.77730'}; time used = 7.151501178741455s
epoch 25: {'train_loss': '2.77083'}; time used = 7.236527681350708s
epoch 30: {'train_loss': '2.76691'}; time used = 9.073149919509888s
epoch 35: {'train_loss': '2.76212'}; time used = 8.951223134994507s
epoch 40: {'train_loss': '2.75378'}; time used = 12.19475793838501s
epoch 45: {'train_loss': '2.74014'}; time used = 8.774242639541626s
epoch 50: {'train_loss': '2.73077'}; time used = 7.148229360580444s
epoch 55: {'train_loss': '2.72466'}; time used = 7.078898668289185s
epoch 60: {'train_loss': '2.72051'}; time used = 7.304119110107422s
epoch 65: {'train_loss': '2.71115'}; time used = 7.9069037437438965s
epoch 70: {'train_loss': '2.71153'}; time used = 8.768931150436401s
epoch 75: {'train_loss': '2.70352'}; time used = 11.660951614379883s
epoch 80: {'train_loss': '2.70598'}; time used = 7.605314254760742s
epoch 85: {'train_loss': '2.69618'}; time used = 7.615657567977905s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 161.2231125831604.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44394149287461043, 'samples': 0.5066666666666667, 'weighted': 0.4346568615337503, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89148'}; time used = 1.940434217453003s
epoch 10: {'train_loss': '2.81382'}; time used = 1.8533508777618408s
epoch 15: {'train_loss': '2.79422'}; time used = 1.8064990043640137s
epoch 20: {'train_loss': '2.78646'}; time used = 1.9082553386688232s
epoch 25: {'train_loss': '2.77782'}; time used = 1.9032268524169922s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.59012222290039.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.484203338623047s
epoch 10: {'train_loss': '1.38629'}; time used = 5.8019349575042725s
epoch 15: {'train_loss': '1.38629'}; time used = 4.92889404296875s
epoch 20: {'train_loss': '1.38629'}; time used = 5.8005287647247314s
epoch 25: {'train_loss': '1.38629'}; time used = 5.267044544219971s
epoch 30: {'train_loss': '1.38629'}; time used = 4.813066244125366s
epoch 35: {'train_loss': '1.38629'}; time used = 4.525623559951782s
epoch 40: {'train_loss': '1.38629'}; time used = 4.597606420516968s
epoch 45: {'train_loss': '1.38629'}; time used = 4.783884048461914s
epoch 50: {'train_loss': '1.38629'}; time used = 4.272980213165283s
epoch 55: {'train_loss': '1.38629'}; time used = 5.79770040512085s
epoch 60: {'train_loss': '1.38629'}; time used = 4.4177656173706055s
epoch 65: {'train_loss': '1.38629'}; time used = 4.372140169143677s
epoch 70: {'train_loss': '1.38629'}; time used = 7.016027450561523s
epoch 75: {'train_loss': '1.38629'}; time used = 4.758167505264282s
epoch 80: {'train_loss': '1.38629'}; time used = 4.291762351989746s
epoch 85: {'train_loss': '1.38629'}; time used = 4.305954217910767s
epoch 90: {'train_loss': '1.38629'}; time used = 4.402309417724609s
epoch 95: {'train_loss': '1.38629'}; time used = 4.319929122924805s
epoch 100: {'train_loss': '1.38629'}; time used = 4.235072374343872s
epoch 105: {'train_loss': '1.38629'}; time used = 4.37474799156189s
epoch 110: {'train_loss': '1.38629'}; time used = 4.470076560974121s
epoch 115: {'train_loss': '1.38629'}; time used = 4.312710285186768s
epoch 120: {'train_loss': '1.38629'}; time used = 4.297410488128662s
epoch 125: {'train_loss': '1.38629'}; time used = 7.895098447799683s
epoch 130: {'train_loss': '1.38629'}; time used = 8.859706401824951s
epoch 135: {'train_loss': '1.38629'}; time used = 8.586871862411499s
epoch 140: {'train_loss': '1.38629'}; time used = 5.589305877685547s
epoch 145: {'train_loss': '1.38629'}; time used = 4.258027791976929s
epoch 150: {'train_loss': '1.38629'}; time used = 4.6178672313690186s
epoch 155: {'train_loss': '1.38629'}; time used = 4.308290243148804s
epoch 160: {'train_loss': '1.38629'}; time used = 4.341649770736694s
epoch 165: {'train_loss': '1.38629'}; time used = 4.243352890014648s
epoch 170: {'train_loss': '1.38629'}; time used = 5.804556131362915s
epoch 175: {'train_loss': '1.38629'}; time used = 4.410639524459839s
epoch 180: {'train_loss': '1.38629'}; time used = 4.2846293449401855s
epoch 185: {'train_loss': '1.38629'}; time used = 4.238478660583496s
epoch 190: {'train_loss': '1.38629'}; time used = 4.766759872436523s
epoch 195: {'train_loss': '1.38629'}; time used = 4.416492462158203s
epoch 200: {'train_loss': '1.38629'}; time used = 4.276733160018921s
epoch 205: {'train_loss': '1.38629'}; time used = 4.259284257888794s
epoch 210: {'train_loss': '1.38629'}; time used = 4.327519416809082s
epoch 215: {'train_loss': '1.38629'}; time used = 4.319137096405029s
epoch 220: {'train_loss': '1.38629'}; time used = 4.368478298187256s
epoch 225: {'train_loss': '1.38629'}; time used = 4.387603759765625s
epoch 230: {'train_loss': '1.38629'}; time used = 7.590447902679443s
epoch 235: {'train_loss': '1.38629'}; time used = 6.696467876434326s
epoch 240: {'train_loss': '1.38629'}; time used = 4.572632074356079s
epoch 245: {'train_loss': '1.38629'}; time used = 4.702992916107178s
epoch 250: {'train_loss': '1.38629'}; time used = 4.330583572387695s
epoch 255: {'train_loss': '1.38629'}; time used = 4.214297533035278s
epoch 260: {'train_loss': '1.38629'}; time used = 4.26985239982605s
epoch 265: {'train_loss': '1.38629'}; time used = 4.211363315582275s
epoch 270: {'train_loss': '1.38629'}; time used = 4.352676630020142s
epoch 275: {'train_loss': '1.38629'}; time used = 4.24457311630249s
epoch 280: {'train_loss': '1.38629'}; time used = 4.186038494110107s
epoch 285: {'train_loss': '1.38629'}; time used = 4.561980724334717s
epoch 290: {'train_loss': '1.38629'}; time used = 4.234643936157227s
epoch 295: {'train_loss': '1.38629'}; time used = 4.223248481750488s
epoch 300: {'train_loss': '1.38629'}; time used = 4.251977920532227s
epoch 305: {'train_loss': '1.38629'}; time used = 4.124730825424194s
epoch 310: {'train_loss': '1.38629'}; time used = 4.271707773208618s
epoch 315: {'train_loss': '1.38629'}; time used = 4.146238327026367s
epoch 320: {'train_loss': '1.38629'}; time used = 4.151650428771973s
epoch 325: {'train_loss': '1.38629'}; time used = 4.27035665512085s
epoch 330: {'train_loss': '1.38629'}; time used = 5.05504298210144s
epoch 335: {'train_loss': '1.38629'}; time used = 4.503449201583862s
epoch 340: {'train_loss': '1.38629'}; time used = 4.45901894569397s
epoch 345: {'train_loss': '1.38629'}; time used = 5.357868432998657s
epoch 350: {'train_loss': '1.38629'}; time used = 5.693845748901367s
epoch 355: {'train_loss': '1.38629'}; time used = 4.388653993606567s
epoch 360: {'train_loss': '1.38629'}; time used = 4.34694242477417s
epoch 365: {'train_loss': '1.38629'}; time used = 4.568190336227417s
epoch 370: {'train_loss': '1.38629'}; time used = 4.221937417984009s
epoch 375: {'train_loss': '1.38629'}; time used = 4.620615720748901s
epoch 380: {'train_loss': '1.38629'}; time used = 4.510929584503174s
epoch 385: {'train_loss': '1.38629'}; time used = 4.549413204193115s
epoch 390: {'train_loss': '1.38629'}; time used = 7.200551271438599s
epoch 395: {'train_loss': '1.38629'}; time used = 5.443846225738525s
epoch 400: {'train_loss': '1.38629'}; time used = 4.4496095180511475s
epoch 405: {'train_loss': '1.38629'}; time used = 4.292931079864502s
epoch 410: {'train_loss': '1.38629'}; time used = 4.306115627288818s
epoch 415: {'train_loss': '1.38629'}; time used = 4.448104619979858s
epoch 420: {'train_loss': '1.38629'}; time used = 4.520650386810303s
epoch 425: {'train_loss': '1.38629'}; time used = 4.2615814208984375s
epoch 430: {'train_loss': '1.38629'}; time used = 4.313097715377808s
epoch 435: {'train_loss': '1.38629'}; time used = 4.3172447681427s
epoch 440: {'train_loss': '1.38629'}; time used = 4.219177722930908s
epoch 445: {'train_loss': '1.38629'}; time used = 4.328546047210693s
epoch 450: {'train_loss': '1.38629'}; time used = 4.432943344116211s
epoch 455: {'train_loss': '1.38629'}; time used = 4.256099700927734s
epoch 460: {'train_loss': '1.38629'}; time used = 4.203534841537476s
epoch 465: {'train_loss': '1.38629'}; time used = 4.37144660949707s
epoch 470: {'train_loss': '1.38629'}; time used = 4.267455577850342s
epoch 475: {'train_loss': '1.38629'}; time used = 4.336550951004028s
epoch 480: {'train_loss': '1.38629'}; time used = 6.672556400299072s
epoch 485: {'train_loss': '1.38629'}; time used = 5.150550127029419s
epoch 490: {'train_loss': '1.38629'}; time used = 4.312281370162964s
epoch 495: {'train_loss': '1.38629'}; time used = 4.290468454360962s
epoch 500: {'train_loss': '1.38629'}; time used = 4.127141714096069s
Finished training. Time used = 484.29408621788025.
Training classifier using 80.00% nodes...
{'micro': 0.625, 'macro': 0.6190476190476191, 'samples': 0.625, 'weighted': 0.6180952380952381, 'accuracy': 0.625}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29469'}; time used = 2.3149712085723877s
epoch 10: {'train_loss': '1.23119'}; time used = 2.430332660675049s
epoch 15: {'train_loss': '1.18707'}; time used = 2.192446708679199s
epoch 20: {'train_loss': '1.30900'}; time used = 2.1982827186584473s
epoch 25: {'train_loss': '1.25027'}; time used = 2.1106760501861572s
epoch 30: {'train_loss': '1.19731'}; time used = 1.9859907627105713s
epoch 35: {'train_loss': '1.32017'}; time used = 2.0268166065216064s
epoch 40: {'train_loss': '1.19617'}; time used = 2.320835828781128s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.5170316696167.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.4945615982241954, 'samples': 0.5217391304347826, 'weighted': 0.5030545770400039, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35729'}; time used = 1.3616535663604736s
epoch 10: {'train_loss': '1.68775'}; time used = 1.2491185665130615s
epoch 15: {'train_loss': '1.38657'}; time used = 1.2562894821166992s
epoch 20: {'train_loss': '1.38396'}; time used = 1.2771904468536377s
epoch 25: {'train_loss': '1.38993'}; time used = 1.2754099369049072s
epoch 30: {'train_loss': '1.37829'}; time used = 1.2516107559204102s
epoch 35: {'train_loss': '1.37760'}; time used = 1.4874091148376465s
epoch 40: {'train_loss': '1.34778'}; time used = 1.2668261528015137s
epoch 45: {'train_loss': '1.33500'}; time used = 1.3135786056518555s
epoch 50: {'train_loss': '1.38359'}; time used = 1.303412675857544s
epoch 55: {'train_loss': '1.31134'}; time used = 1.3170006275177002s
epoch 60: {'train_loss': '1.24316'}; time used = 1.382765769958496s
epoch 65: {'train_loss': '0.97195'}; time used = 1.3543474674224854s
epoch 70: {'train_loss': '1.13277'}; time used = 1.3764610290527344s
epoch 75: {'train_loss': '0.99758'}; time used = 2.351494550704956s
epoch 80: {'train_loss': '0.84725'}; time used = 2.6765940189361572s
epoch 85: {'train_loss': '0.61167'}; time used = 2.4091053009033203s
epoch 90: {'train_loss': '0.48067'}; time used = 2.328407049179077s
epoch 95: {'train_loss': '0.38014'}; time used = 1.2427253723144531s
epoch 100: {'train_loss': '0.37390'}; time used = 1.0279510021209717s
epoch 105: {'train_loss': '0.77549'}; time used = 0.9990251064300537s
epoch 110: {'train_loss': '0.02075'}; time used = 0.9822242259979248s
epoch 115: {'train_loss': '0.91975'}; time used = 1.054198980331421s
epoch 120: {'train_loss': '0.68285'}; time used = 0.9815857410430908s
epoch 125: {'train_loss': '0.29290'}; time used = 0.9881021976470947s
epoch 130: {'train_loss': '0.27525'}; time used = 0.9820656776428223s
epoch 135: {'train_loss': '0.04144'}; time used = 0.9687750339508057s
epoch 140: {'train_loss': '0.23655'}; time used = 0.9763712882995605s
epoch 145: {'train_loss': '0.01143'}; time used = 0.9825539588928223s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.132346630096436.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34707'}; time used = 7.027514457702637s
epoch 10: {'train_loss': '1.33816'}; time used = 6.883888244628906s
epoch 15: {'train_loss': '1.30503'}; time used = 6.836685419082642s
epoch 20: {'train_loss': '1.23685'}; time used = 6.833771228790283s
epoch 25: {'train_loss': '1.14630'}; time used = 6.734392881393433s
epoch 30: {'train_loss': '1.20832'}; time used = 6.821036100387573s
epoch 35: {'train_loss': '1.07752'}; time used = 7.001594543457031s
epoch 40: {'train_loss': '1.14309'}; time used = 7.448005199432373s
epoch 45: {'train_loss': '1.09774'}; time used = 6.7227582931518555s
epoch 50: {'train_loss': '1.07384'}; time used = 6.695051193237305s
epoch 55: {'train_loss': '1.20435'}; time used = 6.772250175476074s
epoch 60: {'train_loss': '1.16027'}; time used = 6.798797607421875s
epoch 65: {'train_loss': '1.30775'}; time used = 7.3386757373809814s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 117.83683347702026.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4560712300646163, 'samples': 0.5066666666666667, 'weighted': 0.4475053722324452, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39169'}; time used = 2.4017980098724365s
epoch 10: {'train_loss': '1.36842'}; time used = 1.5164170265197754s
epoch 15: {'train_loss': '1.33444'}; time used = 1.4296185970306396s
epoch 20: {'train_loss': '1.22990'}; time used = 1.3002476692199707s
epoch 25: {'train_loss': '0.90566'}; time used = 1.2629098892211914s
epoch 30: {'train_loss': '1.05256'}; time used = 1.400099515914917s
epoch 35: {'train_loss': '1.00019'}; time used = 1.2662265300750732s
epoch 40: {'train_loss': '0.80325'}; time used = 1.3761110305786133s
epoch 45: {'train_loss': '0.75433'}; time used = 1.3063023090362549s
epoch 50: {'train_loss': '0.64507'}; time used = 1.2867786884307861s
epoch 55: {'train_loss': '1.31460'}; time used = 2.321014165878296s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.169405221939087.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86132'}; time used = 2.4904541969299316s
epoch 10: {'train_loss': '2.78841'}; time used = 2.4169373512268066s
epoch 15: {'train_loss': '2.77030'}; time used = 2.3548049926757812s
epoch 20: {'train_loss': '2.77156'}; time used = 2.3499631881713867s
epoch 25: {'train_loss': '2.76938'}; time used = 2.3901119232177734s
epoch 30: {'train_loss': '2.75475'}; time used = 2.3658385276794434s
epoch 35: {'train_loss': '2.73159'}; time used = 2.5986616611480713s
epoch 40: {'train_loss': '2.71429'}; time used = 2.3873019218444824s
epoch 45: {'train_loss': '2.67678'}; time used = 2.5614328384399414s
epoch 50: {'train_loss': '2.65175'}; time used = 2.475130319595337s
epoch 55: {'train_loss': '2.67833'}; time used = 2.887639284133911s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.20373606681824.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.77226'}; time used = 1.0792264938354492s
epoch 10: {'train_loss': '2.53692'}; time used = 0.9510605335235596s
epoch 15: {'train_loss': '2.40254'}; time used = 1.0972199440002441s
epoch 20: {'train_loss': '2.21603'}; time used = 1.1637465953826904s
epoch 25: {'train_loss': '2.12540'}; time used = 1.067633867263794s
epoch 30: {'train_loss': '2.03152'}; time used = 1.008087158203125s
epoch 35: {'train_loss': '1.91862'}; time used = 0.945533275604248s
epoch 40: {'train_loss': '1.86617'}; time used = 0.9544439315795898s
epoch 45: {'train_loss': '1.85619'}; time used = 0.966299295425415s
epoch 50: {'train_loss': '1.84160'}; time used = 0.9595348834991455s
epoch 55: {'train_loss': '1.84676'}; time used = 0.9526305198669434s
epoch 60: {'train_loss': '1.84003'}; time used = 1.1067073345184326s
epoch 65: {'train_loss': '1.81483'}; time used = 1.0215671062469482s
epoch 70: {'train_loss': '1.82797'}; time used = 0.9809670448303223s
epoch 75: {'train_loss': '1.79430'}; time used = 1.055748701095581s
epoch 80: {'train_loss': '1.80846'}; time used = 1.0908880233764648s
epoch 85: {'train_loss': '1.84867'}; time used = 1.0637142658233643s
epoch 90: {'train_loss': '1.82417'}; time used = 1.0431334972381592s
epoch 95: {'train_loss': '1.82047'}; time used = 1.053091287612915s
epoch 100: {'train_loss': '1.83489'}; time used = 1.0840930938720703s
epoch 105: {'train_loss': '1.80361'}; time used = 1.1265745162963867s
epoch 110: {'train_loss': '1.80158'}; time used = 1.080228328704834s
epoch 115: {'train_loss': '1.85271'}; time used = 1.073012113571167s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.916840076446533.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.22144'}; time used = 2.3947954177856445s
epoch 10: {'train_loss': '1.17821'}; time used = 2.3455264568328857s
epoch 15: {'train_loss': '1.09368'}; time used = 2.2981224060058594s
epoch 20: {'train_loss': '0.83537'}; time used = 2.2935235500335693s
epoch 25: {'train_loss': '0.51915'}; time used = 2.3667283058166504s
epoch 30: {'train_loss': '0.34601'}; time used = 2.31479811668396s
epoch 35: {'train_loss': '0.14287'}; time used = 2.289361000061035s
epoch 40: {'train_loss': '0.10995'}; time used = 2.2989323139190674s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.54076051712036.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.13296'}; time used = 1.1867806911468506s
epoch 10: {'train_loss': '2.79589'}; time used = 1.0502760410308838s
epoch 15: {'train_loss': '2.80005'}; time used = 1.145254135131836s
epoch 20: {'train_loss': '2.79754'}; time used = 1.0753071308135986s
epoch 25: {'train_loss': '2.77560'}; time used = 1.2231838703155518s
epoch 30: {'train_loss': '2.78064'}; time used = 1.1787598133087158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.100330114364624.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84685'}; time used = 1.085500955581665s
epoch 10: {'train_loss': '0.47913'}; time used = 0.9871900081634521s
epoch 15: {'train_loss': '0.33065'}; time used = 1.00722336769104s
epoch 20: {'train_loss': '0.26141'}; time used = 0.9303421974182129s
epoch 25: {'train_loss': '0.30144'}; time used = 1.007291555404663s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.666215896606445.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.11416'}; time used = 1.9545228481292725s
epoch 10: {'train_loss': '1.04279'}; time used = 2.0800912380218506s
epoch 15: {'train_loss': '0.99459'}; time used = 1.8948090076446533s
epoch 20: {'train_loss': '0.58334'}; time used = 2.0042879581451416s
epoch 25: {'train_loss': '0.36624'}; time used = 2.0941321849823s
epoch 30: {'train_loss': '0.13040'}; time used = 2.1790833473205566s
epoch 35: {'train_loss': '0.07581'}; time used = 1.9760477542877197s
epoch 40: {'train_loss': '0.04901'}; time used = 1.8203225135803223s
epoch 45: {'train_loss': '0.05246'}; time used = 1.7972676753997803s
epoch 50: {'train_loss': '0.12552'}; time used = 1.815079689025879s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.727099418640137.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35200'}; time used = 1.4828462600708008s
epoch 10: {'train_loss': '1.28705'}; time used = 1.3520641326904297s
epoch 15: {'train_loss': '0.88087'}; time used = 1.387258529663086s
epoch 20: {'train_loss': '0.92344'}; time used = 1.3269708156585693s
epoch 25: {'train_loss': '0.22901'}; time used = 1.3051984310150146s
epoch 30: {'train_loss': '0.21444'}; time used = 1.3313591480255127s
epoch 35: {'train_loss': '0.17523'}; time used = 2.301823616027832s
epoch 40: {'train_loss': '0.34534'}; time used = 3.6184394359588623s
epoch 45: {'train_loss': '0.03729'}; time used = 1.6527292728424072s
epoch 50: {'train_loss': '0.01849'}; time used = 1.6597182750701904s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.59554696083069.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.32053'}; time used = 1.6347973346710205s
epoch 10: {'train_loss': '2.80381'}; time used = 1.6622934341430664s
epoch 15: {'train_loss': '2.72433'}; time used = 1.676314353942871s
epoch 20: {'train_loss': '2.73135'}; time used = 1.566697359085083s
epoch 25: {'train_loss': '2.68987'}; time used = 1.6903767585754395s
epoch 30: {'train_loss': '2.66985'}; time used = 1.565786600112915s
epoch 35: {'train_loss': '2.66324'}; time used = 1.566809892654419s
epoch 40: {'train_loss': '2.64748'}; time used = 1.5940427780151367s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.929412841796875.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39810'}; time used = 1.5618183612823486s
epoch 10: {'train_loss': '1.45842'}; time used = 1.3909759521484375s
epoch 15: {'train_loss': '1.27182'}; time used = 1.3455984592437744s
epoch 20: {'train_loss': '1.47370'}; time used = 1.3712282180786133s
epoch 25: {'train_loss': '1.36661'}; time used = 1.310621738433838s
epoch 30: {'train_loss': '1.38829'}; time used = 1.3212528228759766s
epoch 35: {'train_loss': '1.38871'}; time used = 1.3393290042877197s
epoch 40: {'train_loss': '1.35746'}; time used = 1.3111450672149658s
epoch 45: {'train_loss': '1.32204'}; time used = 1.3038179874420166s
epoch 50: {'train_loss': '1.36186'}; time used = 1.3513545989990234s
epoch 55: {'train_loss': '1.35256'}; time used = 1.3187944889068604s
epoch 60: {'train_loss': '1.25258'}; time used = 1.4176685810089111s
epoch 65: {'train_loss': '0.71657'}; time used = 1.3267767429351807s
epoch 70: {'train_loss': '0.75805'}; time used = 1.3107578754425049s
epoch 75: {'train_loss': '0.17467'}; time used = 1.381683111190796s
epoch 80: {'train_loss': '0.23451'}; time used = 1.4898171424865723s
epoch 85: {'train_loss': '0.29720'}; time used = 1.4250993728637695s
epoch 90: {'train_loss': '0.75433'}; time used = 1.347404956817627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.82429814338684.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38760'}; time used = 1.37611985206604s
epoch 10: {'train_loss': '1.39956'}; time used = 1.062340259552002s
epoch 15: {'train_loss': '1.31676'}; time used = 1.2284858226776123s
epoch 20: {'train_loss': '1.32178'}; time used = 1.1930134296417236s
epoch 25: {'train_loss': '1.23993'}; time used = 1.1474742889404297s
epoch 30: {'train_loss': '1.23731'}; time used = 1.2088146209716797s
epoch 35: {'train_loss': '1.21615'}; time used = 1.1543586254119873s
epoch 40: {'train_loss': '1.08371'}; time used = 1.0540618896484375s
epoch 45: {'train_loss': '0.75009'}; time used = 1.1230993270874023s
epoch 50: {'train_loss': '1.04565'}; time used = 1.0631182193756104s
epoch 55: {'train_loss': '0.84250'}; time used = 1.0456924438476562s
epoch 60: {'train_loss': '0.74611'}; time used = 1.0316767692565918s
epoch 65: {'train_loss': '0.41015'}; time used = 1.0227530002593994s
epoch 70: {'train_loss': '0.54530'}; time used = 1.0182688236236572s
epoch 75: {'train_loss': '1.08029'}; time used = 1.0107080936431885s
epoch 80: {'train_loss': '1.01271'}; time used = 1.0127968788146973s
epoch 85: {'train_loss': '0.32607'}; time used = 1.0242986679077148s
epoch 90: {'train_loss': '0.99723'}; time used = 1.0201153755187988s
epoch 95: {'train_loss': '0.32560'}; time used = 1.0061821937561035s
epoch 100: {'train_loss': '0.33355'}; time used = 0.9964935779571533s
epoch 105: {'train_loss': '0.81148'}; time used = 1.0094501972198486s
epoch 110: {'train_loss': '0.36552'}; time used = 1.8254926204681396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.40300893783569.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.36297'}; time used = 4.757749557495117s
epoch 10: {'train_loss': '1.37813'}; time used = 4.655094146728516s
epoch 15: {'train_loss': '1.34820'}; time used = 4.682383298873901s
epoch 20: {'train_loss': '1.35543'}; time used = 4.605798006057739s
epoch 25: {'train_loss': '1.33473'}; time used = 7.843704700469971s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 72.8822979927063.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7295673076923077, 'samples': 0.73, 'weighted': 0.7293509615384616, 'accuracy': 0.73}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75898'}; time used = 1.6882565021514893s
epoch 10: {'train_loss': '2.73986'}; time used = 1.6912884712219238s
epoch 15: {'train_loss': '2.71603'}; time used = 1.6133460998535156s
epoch 20: {'train_loss': '2.68694'}; time used = 1.6697814464569092s
epoch 25: {'train_loss': '2.64136'}; time used = 1.635814905166626s
epoch 30: {'train_loss': '2.59192'}; time used = 2.2363035678863525s
epoch 35: {'train_loss': '2.57027'}; time used = 3.041628837585449s
epoch 40: {'train_loss': '2.51279'}; time used = 2.720979928970337s
epoch 45: {'train_loss': '2.49821'}; time used = 1.8438878059387207s
epoch 50: {'train_loss': '2.46103'}; time used = 1.6211557388305664s
epoch 55: {'train_loss': '2.47525'}; time used = 1.8456268310546875s
epoch 60: {'train_loss': '2.47901'}; time used = 1.596940040588379s
epoch 65: {'train_loss': '2.45849'}; time used = 1.7493736743927002s
epoch 70: {'train_loss': '2.42532'}; time used = 1.5616838932037354s
epoch 75: {'train_loss': '2.39300'}; time used = 1.6080961227416992s
epoch 80: {'train_loss': '2.40193'}; time used = 1.7405271530151367s
epoch 85: {'train_loss': '2.38387'}; time used = 1.7961113452911377s
epoch 90: {'train_loss': '2.41651'}; time used = 1.7703063488006592s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.42265462875366.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.623109243697479, 'samples': 0.6231884057971014, 'weighted': 0.6235050541955912, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.62635'}; time used = 1.1254279613494873s
epoch 10: {'train_loss': '0.14194'}; time used = 1.2944653034210205s
epoch 15: {'train_loss': '0.10532'}; time used = 1.904663324356079s
epoch 20: {'train_loss': '0.06336'}; time used = 1.8385400772094727s
epoch 25: {'train_loss': '0.06711'}; time used = 1.7023274898529053s
epoch 30: {'train_loss': '0.05874'}; time used = 1.7498340606689453s
epoch 35: {'train_loss': '0.04240'}; time used = 1.515465259552002s
epoch 40: {'train_loss': '0.06149'}; time used = 1.0324382781982422s
epoch 45: {'train_loss': '0.06211'}; time used = 0.9792320728302002s
epoch 50: {'train_loss': '0.05919'}; time used = 1.0603036880493164s
epoch 55: {'train_loss': '0.04254'}; time used = 1.0343890190124512s
epoch 60: {'train_loss': '0.03408'}; time used = 1.0613696575164795s
epoch 65: {'train_loss': '0.04834'}; time used = 0.968008279800415s
epoch 70: {'train_loss': '0.04104'}; time used = 1.0989649295806885s
epoch 75: {'train_loss': '0.04070'}; time used = 0.9779634475708008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.13137149810791.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39652'}; time used = 1.2824022769927979s
epoch 10: {'train_loss': '1.39832'}; time used = 1.158860445022583s
epoch 15: {'train_loss': '1.38573'}; time used = 1.1331110000610352s
epoch 20: {'train_loss': '1.39059'}; time used = 1.1492705345153809s
epoch 25: {'train_loss': '1.38800'}; time used = 1.3158717155456543s
epoch 30: {'train_loss': '1.38517'}; time used = 1.249983549118042s
epoch 35: {'train_loss': '1.39273'}; time used = 1.1480481624603271s
epoch 40: {'train_loss': '1.37175'}; time used = 1.1361234188079834s
epoch 45: {'train_loss': '1.34001'}; time used = 1.167625904083252s
epoch 50: {'train_loss': '1.39923'}; time used = 1.1557238101959229s
epoch 55: {'train_loss': '1.37088'}; time used = 1.2119762897491455s
epoch 60: {'train_loss': '1.34661'}; time used = 1.3710169792175293s
epoch 65: {'train_loss': '1.25801'}; time used = 1.3208613395690918s
epoch 70: {'train_loss': '1.30839'}; time used = 1.276444673538208s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.629371643066406.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.34433'}; time used = 1.1275830268859863s
epoch 10: {'train_loss': '1.33999'}; time used = 0.9788703918457031s
epoch 15: {'train_loss': '1.25260'}; time used = 0.9708106517791748s
epoch 20: {'train_loss': '1.31688'}; time used = 0.9684104919433594s
epoch 25: {'train_loss': '1.18768'}; time used = 0.9603002071380615s
epoch 30: {'train_loss': '1.19451'}; time used = 0.9686610698699951s
epoch 35: {'train_loss': '1.25134'}; time used = 2.489835739135742s
epoch 40: {'train_loss': '1.19214'}; time used = 2.3095920085906982s
epoch 45: {'train_loss': '1.00178'}; time used = 1.0631661415100098s
epoch 50: {'train_loss': '1.11879'}; time used = 1.036381483078003s
epoch 55: {'train_loss': '1.14003'}; time used = 1.0044090747833252s
epoch 60: {'train_loss': '1.19738'}; time used = 0.919513463973999s
epoch 65: {'train_loss': '0.93674'}; time used = 1.0453495979309082s
epoch 70: {'train_loss': '1.21454'}; time used = 0.9894843101501465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.633381843566895.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6375641966250918, 'samples': 0.6578947368421053, 'weighted': 0.6511178901031008, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.27677'}; time used = 2.1544029712677s
epoch 10: {'train_loss': '1.18280'}; time used = 2.0377581119537354s
epoch 15: {'train_loss': '0.98631'}; time used = 2.0035414695739746s
epoch 20: {'train_loss': '0.83711'}; time used = 1.8265571594238281s
epoch 25: {'train_loss': '0.77361'}; time used = 1.8651504516601562s
epoch 30: {'train_loss': '0.75863'}; time used = 1.8315246105194092s
epoch 35: {'train_loss': '0.70148'}; time used = 1.7754580974578857s
epoch 40: {'train_loss': '0.69888'}; time used = 1.7787320613861084s
epoch 45: {'train_loss': '0.67435'}; time used = 1.6998000144958496s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.83687424659729.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.47787204769548264, 'samples': 0.5217391304347826, 'weighted': 0.4888388183803076, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.94446'}; time used = 1.0999407768249512s
epoch 10: {'train_loss': '2.80539'}; time used = 1.069225549697876s
epoch 15: {'train_loss': '2.77625'}; time used = 1.0985569953918457s
epoch 20: {'train_loss': '2.77622'}; time used = 1.0153920650482178s
epoch 25: {'train_loss': '2.77887'}; time used = 1.0207366943359375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.770327091217041.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.04862'}; time used = 2.6175670623779297s
epoch 10: {'train_loss': '0.58843'}; time used = 1.6222829818725586s
epoch 15: {'train_loss': '0.48643'}; time used = 1.8311574459075928s
epoch 20: {'train_loss': '0.46660'}; time used = 1.6553499698638916s
epoch 25: {'train_loss': '0.51087'}; time used = 1.749479055404663s
epoch 30: {'train_loss': '0.53643'}; time used = 1.6472055912017822s
epoch 35: {'train_loss': '0.47172'}; time used = 1.6168861389160156s
epoch 40: {'train_loss': '0.54196'}; time used = 1.7465763092041016s
epoch 45: {'train_loss': '0.43088'}; time used = 3.3395705223083496s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.78777050971985.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.13645'}; time used = 2.090806722640991s
epoch 10: {'train_loss': '1.05720'}; time used = 2.0060043334960938s
epoch 15: {'train_loss': '1.01594'}; time used = 2.169171094894409s
epoch 20: {'train_loss': '0.84184'}; time used = 1.7876369953155518s
epoch 25: {'train_loss': '1.24697'}; time used = 2.378701686859131s
epoch 30: {'train_loss': '0.63177'}; time used = 1.643127679824829s
epoch 35: {'train_loss': '0.43920'}; time used = 1.5700371265411377s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.02835178375244.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.09065'}; time used = 2.1540350914001465s
epoch 10: {'train_loss': '2.95774'}; time used = 2.023883104324341s
epoch 15: {'train_loss': '2.87534'}; time used = 2.0129220485687256s
epoch 20: {'train_loss': '2.85091'}; time used = 2.0198066234588623s
epoch 25: {'train_loss': '2.82017'}; time used = 2.167686939239502s
epoch 30: {'train_loss': '2.80936'}; time used = 1.9704337120056152s
epoch 35: {'train_loss': '2.79942'}; time used = 2.1130294799804688s
epoch 40: {'train_loss': '2.79225'}; time used = 2.0260140895843506s
epoch 45: {'train_loss': '2.79101'}; time used = 1.9846949577331543s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.135072708129883.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36150'}; time used = 1.1474616527557373s
epoch 10: {'train_loss': '1.49742'}; time used = 1.0399816036224365s
epoch 15: {'train_loss': '0.88624'}; time used = 1.0244054794311523s
epoch 20: {'train_loss': '1.04699'}; time used = 1.044255018234253s
epoch 25: {'train_loss': '0.24166'}; time used = 1.0473055839538574s
epoch 30: {'train_loss': '0.35624'}; time used = 1.238229513168335s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.101863384246826.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37637'}; time used = 1.7850892543792725s
epoch 10: {'train_loss': '1.31464'}; time used = 1.7559857368469238s
epoch 15: {'train_loss': '1.28636'}; time used = 1.6452810764312744s
epoch 20: {'train_loss': '1.26554'}; time used = 1.7237255573272705s
epoch 25: {'train_loss': '1.12979'}; time used = 1.7966837882995605s
epoch 30: {'train_loss': '1.05109'}; time used = 1.6873016357421875s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.111051559448242.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01829'}; time used = 1.2134010791778564s
epoch 10: {'train_loss': '0.54877'}; time used = 1.1069426536560059s
epoch 15: {'train_loss': '0.36443'}; time used = 1.2440836429595947s
epoch 20: {'train_loss': '0.23689'}; time used = 1.434208631515503s
epoch 25: {'train_loss': '0.15849'}; time used = 1.28169846534729s
epoch 30: {'train_loss': '0.10828'}; time used = 1.406304121017456s
epoch 35: {'train_loss': '0.06876'}; time used = 1.9100916385650635s
epoch 40: {'train_loss': '0.05584'}; time used = 1.8274388313293457s
epoch 45: {'train_loss': '0.05533'}; time used = 1.8520689010620117s
epoch 50: {'train_loss': '0.04537'}; time used = 1.8436858654022217s
epoch 55: {'train_loss': '0.03158'}; time used = 1.3942101001739502s
epoch 60: {'train_loss': '0.02388'}; time used = 1.2229235172271729s
epoch 65: {'train_loss': '0.03369'}; time used = 1.2014002799987793s
epoch 70: {'train_loss': '0.02296'}; time used = 1.1649727821350098s
epoch 75: {'train_loss': '0.02310'}; time used = 0.9778447151184082s
epoch 80: {'train_loss': '0.02134'}; time used = 0.9770917892456055s
epoch 85: {'train_loss': '0.02298'}; time used = 1.2199642658233643s
epoch 90: {'train_loss': '0.02677'}; time used = 1.6434564590454102s
epoch 95: {'train_loss': '0.03140'}; time used = 0.9757857322692871s
epoch 100: {'train_loss': '0.03463'}; time used = 0.9392843246459961s
epoch 105: {'train_loss': '0.01364'}; time used = 1.2053813934326172s
epoch 110: {'train_loss': '0.01491'}; time used = 1.0323066711425781s
epoch 115: {'train_loss': '0.01870'}; time used = 0.958404541015625s
epoch 120: {'train_loss': '0.01980'}; time used = 0.9651479721069336s
epoch 125: {'train_loss': '0.02197'}; time used = 1.090883493423462s
epoch 130: {'train_loss': '0.01342'}; time used = 1.0350391864776611s
epoch 135: {'train_loss': '0.01567'}; time used = 1.1191978454589844s
epoch 140: {'train_loss': '0.02848'}; time used = 0.9398252964019775s
epoch 145: {'train_loss': '0.01461'}; time used = 0.9540994167327881s
epoch 150: {'train_loss': '0.01444'}; time used = 2.3740334510803223s
epoch 155: {'train_loss': '0.01440'}; time used = 1.5982024669647217s
epoch 160: {'train_loss': '0.00973'}; time used = 0.9805905818939209s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.8371160030365.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7840909090909092, 'samples': 0.7894736842105263, 'weighted': 0.7894736842105263, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33882'}; time used = 2.1746647357940674s
epoch 10: {'train_loss': '1.15506'}; time used = 2.1676368713378906s
epoch 15: {'train_loss': '1.00274'}; time used = 3.5060579776763916s
epoch 20: {'train_loss': '0.80320'}; time used = 2.770082712173462s
epoch 25: {'train_loss': '0.76712'}; time used = 2.3002898693084717s
epoch 30: {'train_loss': '0.51661'}; time used = 2.1472041606903076s
epoch 35: {'train_loss': '0.61394'}; time used = 2.0883007049560547s
epoch 40: {'train_loss': '0.53544'}; time used = 2.1429784297943115s
epoch 45: {'train_loss': '0.34443'}; time used = 2.301048755645752s
epoch 50: {'train_loss': '0.28452'}; time used = 2.5598649978637695s
epoch 55: {'train_loss': '0.20821'}; time used = 2.9364984035491943s
epoch 60: {'train_loss': '0.02250'}; time used = 2.110954523086548s
epoch 65: {'train_loss': '1.01109'}; time used = 2.1887643337249756s
epoch 70: {'train_loss': '0.81308'}; time used = 2.367668867111206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.40446639060974.
Training classifier using 80.00% nodes...
{'micro': 0.7101449275362319, 'macro': 0.6994773519163764, 'samples': 0.7101449275362319, 'weighted': 0.7035802656163208, 'accuracy': 0.7101449275362319}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.77923'}; time used = 5.060649633407593s
epoch 10: {'train_loss': '2.78222'}; time used = 4.680710554122925s
epoch 15: {'train_loss': '2.77251'}; time used = 4.61276912689209s
epoch 20: {'train_loss': '2.77219'}; time used = 4.627587556838989s
epoch 25: {'train_loss': '2.77374'}; time used = 4.816088438034058s
epoch 30: {'train_loss': '2.77206'}; time used = 4.641634225845337s
epoch 35: {'train_loss': '2.76981'}; time used = 4.839443922042847s
epoch 40: {'train_loss': '2.76862'}; time used = 4.7911858558654785s
epoch 45: {'train_loss': '2.76729'}; time used = 4.7396721839904785s
epoch 50: {'train_loss': '2.76514'}; time used = 4.9808032512664795s
epoch 55: {'train_loss': '2.76195'}; time used = 4.824563503265381s
epoch 60: {'train_loss': '2.75685'}; time used = 4.637388467788696s
epoch 65: {'train_loss': '2.74877'}; time used = 4.720458269119263s
epoch 70: {'train_loss': '2.74308'}; time used = 4.884723663330078s
epoch 75: {'train_loss': '2.74326'}; time used = 4.7676167488098145s
epoch 80: {'train_loss': '2.74396'}; time used = 5.252826929092407s
epoch 85: {'train_loss': '2.74200'}; time used = 4.872224807739258s
epoch 90: {'train_loss': '2.74247'}; time used = 4.6893463134765625s
epoch 95: {'train_loss': '2.74710'}; time used = 4.680150508880615s
epoch 100: {'train_loss': '2.74282'}; time used = 4.664325952529907s
epoch 105: {'train_loss': '2.73895'}; time used = 4.668047189712524s
epoch 110: {'train_loss': '2.74009'}; time used = 6.293786287307739s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 124.33991026878357.
Training classifier using 80.00% nodes...
{'micro': 0.715, 'macro': 0.7149928748218706, 'samples': 0.715, 'weighted': 0.7150213755343884, 'accuracy': 0.715}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.01532'}; time used = 1.8538227081298828s
epoch 10: {'train_loss': '2.83681'}; time used = 1.7240116596221924s
epoch 15: {'train_loss': '2.78189'}; time used = 1.8319780826568604s
epoch 20: {'train_loss': '2.77256'}; time used = 1.772670030593872s
epoch 25: {'train_loss': '2.77641'}; time used = 1.841407299041748s
epoch 30: {'train_loss': '2.76975'}; time used = 1.7388064861297607s
epoch 35: {'train_loss': '2.76796'}; time used = 1.8100855350494385s
epoch 40: {'train_loss': '2.76896'}; time used = 1.7330164909362793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.515581130981445.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79564'}; time used = 1.0799810886383057s
epoch 10: {'train_loss': '2.62943'}; time used = 0.9424238204956055s
epoch 15: {'train_loss': '2.15464'}; time used = 1.438603162765503s
epoch 20: {'train_loss': '1.84618'}; time used = 1.7799067497253418s
epoch 25: {'train_loss': '1.74065'}; time used = 1.9430954456329346s
epoch 30: {'train_loss': '1.68821'}; time used = 1.671478509902954s
epoch 35: {'train_loss': '2.19384'}; time used = 1.845618724822998s
epoch 40: {'train_loss': '2.02257'}; time used = 1.734985113143921s
epoch 45: {'train_loss': '1.90970'}; time used = 1.0001411437988281s
epoch 50: {'train_loss': '1.75469'}; time used = 1.1100101470947266s
epoch 55: {'train_loss': '1.64922'}; time used = 0.9987208843231201s
epoch 60: {'train_loss': '1.62057'}; time used = 1.0366637706756592s
epoch 65: {'train_loss': '1.53269'}; time used = 0.9562592506408691s
epoch 70: {'train_loss': '1.72820'}; time used = 0.9424583911895752s
epoch 75: {'train_loss': '1.59948'}; time used = 1.5658295154571533s
epoch 80: {'train_loss': '1.56981'}; time used = 1.119835615158081s
epoch 85: {'train_loss': '1.55739'}; time used = 1.0104718208312988s
epoch 90: {'train_loss': '1.51464'}; time used = 0.989173173904419s
epoch 95: {'train_loss': '1.48682'}; time used = 0.9869110584259033s
epoch 100: {'train_loss': '1.45724'}; time used = 0.9910292625427246s
epoch 105: {'train_loss': '1.37538'}; time used = 1.063295841217041s
epoch 110: {'train_loss': '1.33376'}; time used = 1.0007646083831787s
epoch 115: {'train_loss': '1.34072'}; time used = 1.0109164714813232s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.323181867599487.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9163609684519443, 'samples': 0.9210526315789473, 'weighted': 0.9194887438699463, 'accuracy': 0.9210526315789473}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.15526'}; time used = 1.4157295227050781s
epoch 10: {'train_loss': '0.81061'}; time used = 1.2776367664337158s
epoch 15: {'train_loss': '0.63031'}; time used = 1.34344482421875s
epoch 20: {'train_loss': '0.61123'}; time used = 1.2785446643829346s
epoch 25: {'train_loss': '0.45902'}; time used = 1.290187120437622s
epoch 30: {'train_loss': '0.31248'}; time used = 1.261756181716919s
epoch 35: {'train_loss': '0.25182'}; time used = 1.2809650897979736s
epoch 40: {'train_loss': '0.18926'}; time used = 1.2747869491577148s
epoch 45: {'train_loss': '0.26940'}; time used = 1.2680573463439941s
epoch 50: {'train_loss': '0.29943'}; time used = 1.2818214893341064s
epoch 55: {'train_loss': '0.22436'}; time used = 1.2672863006591797s
epoch 60: {'train_loss': '0.16177'}; time used = 1.3603944778442383s
epoch 65: {'train_loss': '0.20081'}; time used = 1.2753827571868896s
epoch 70: {'train_loss': '0.13730'}; time used = 1.2759466171264648s
epoch 75: {'train_loss': '0.13477'}; time used = 1.2870070934295654s
epoch 80: {'train_loss': '0.12200'}; time used = 1.2750945091247559s
epoch 85: {'train_loss': '0.08882'}; time used = 1.3750216960906982s
epoch 90: {'train_loss': '0.11326'}; time used = 1.2449076175689697s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.02085590362549.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.77681'}; time used = 3.2679359912872314s
epoch 10: {'train_loss': '2.90036'}; time used = 1.7788097858428955s
epoch 15: {'train_loss': '2.81773'}; time used = 1.9392814636230469s
epoch 20: {'train_loss': '2.77059'}; time used = 1.7730109691619873s
epoch 25: {'train_loss': '2.75568'}; time used = 2.0630321502685547s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.548107624053955.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5152224824355972, 'samples': 0.5217391304347826, 'weighted': 0.5192953874350881, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.82611'}; time used = 1.2520177364349365s
epoch 10: {'train_loss': '0.78444'}; time used = 1.0573999881744385s
epoch 15: {'train_loss': '0.39401'}; time used = 0.9436995983123779s
epoch 20: {'train_loss': '0.23668'}; time used = 0.9313006401062012s
epoch 25: {'train_loss': '0.19818'}; time used = 1.2045197486877441s
epoch 30: {'train_loss': '0.16270'}; time used = 0.952690839767456s
epoch 35: {'train_loss': '0.09567'}; time used = 1.005331039428711s
epoch 40: {'train_loss': '0.06757'}; time used = 1.0086228847503662s
epoch 45: {'train_loss': '0.07765'}; time used = 0.962691068649292s
epoch 50: {'train_loss': '0.11079'}; time used = 0.9471735954284668s
epoch 55: {'train_loss': '0.10551'}; time used = 0.9449794292449951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.502943515777588.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.623712539672852s
epoch 10: {'train_loss': '1.38629'}; time used = 6.480093955993652s
epoch 15: {'train_loss': '1.38629'}; time used = 6.485157012939453s
epoch 20: {'train_loss': '1.38629'}; time used = 7.995915412902832s
epoch 25: {'train_loss': '1.38629'}; time used = 6.519749641418457s
epoch 30: {'train_loss': '1.38629'}; time used = 6.534173011779785s
epoch 35: {'train_loss': '1.38629'}; time used = 6.359917402267456s
epoch 40: {'train_loss': '1.38629'}; time used = 6.280040979385376s
epoch 45: {'train_loss': '1.38629'}; time used = 6.407561302185059s
epoch 50: {'train_loss': '1.38629'}; time used = 6.432358503341675s
epoch 55: {'train_loss': '1.38629'}; time used = 6.390960693359375s
epoch 60: {'train_loss': '1.38629'}; time used = 6.718635082244873s
epoch 65: {'train_loss': '1.38629'}; time used = 7.768509149551392s
epoch 70: {'train_loss': '1.38629'}; time used = 7.589707136154175s
epoch 75: {'train_loss': '1.38629'}; time used = 8.918032884597778s
epoch 80: {'train_loss': '1.38629'}; time used = 6.464041471481323s
epoch 85: {'train_loss': '1.38629'}; time used = 6.651218891143799s
epoch 90: {'train_loss': '1.38629'}; time used = 7.384420156478882s
epoch 95: {'train_loss': '1.38629'}; time used = 6.48507285118103s
epoch 100: {'train_loss': '1.38629'}; time used = 6.54703426361084s
epoch 105: {'train_loss': '1.38629'}; time used = 6.6209399700164795s
epoch 110: {'train_loss': '1.38629'}; time used = 7.291452407836914s
epoch 115: {'train_loss': '1.38629'}; time used = 6.553059101104736s
epoch 120: {'train_loss': '1.38629'}; time used = 6.631812572479248s
epoch 125: {'train_loss': '1.38629'}; time used = 8.817181587219238s
epoch 130: {'train_loss': '1.38629'}; time used = 7.9268412590026855s
epoch 135: {'train_loss': '1.38629'}; time used = 7.239080190658569s
epoch 140: {'train_loss': '1.38629'}; time used = 6.483981132507324s
epoch 145: {'train_loss': '1.38629'}; time used = 6.473667144775391s
epoch 150: {'train_loss': '1.38629'}; time used = 6.534960031509399s
epoch 155: {'train_loss': '1.38629'}; time used = 6.357671737670898s
epoch 160: {'train_loss': '1.38629'}; time used = 6.461374521255493s
epoch 165: {'train_loss': '1.38629'}; time used = 6.5470850467681885s
epoch 170: {'train_loss': '1.38629'}; time used = 6.549031019210815s
epoch 175: {'train_loss': '1.38629'}; time used = 9.016422510147095s
epoch 180: {'train_loss': '1.38629'}; time used = 7.933691740036011s
epoch 185: {'train_loss': '1.38629'}; time used = 6.6871044635772705s
epoch 190: {'train_loss': '1.38629'}; time used = 6.592606782913208s
epoch 195: {'train_loss': '1.38629'}; time used = 6.542670965194702s
epoch 200: {'train_loss': '1.38629'}; time used = 6.58067512512207s
epoch 205: {'train_loss': '1.38629'}; time used = 8.264386653900146s
epoch 210: {'train_loss': '1.38629'}; time used = 8.680768251419067s
epoch 215: {'train_loss': '1.38629'}; time used = 6.43025803565979s
epoch 220: {'train_loss': '1.38629'}; time used = 6.56657075881958s
epoch 225: {'train_loss': '1.38629'}; time used = 6.537943601608276s
epoch 230: {'train_loss': '1.38629'}; time used = 6.43921971321106s
epoch 235: {'train_loss': '1.38629'}; time used = 6.294981956481934s
epoch 240: {'train_loss': '1.38629'}; time used = 6.346276521682739s
epoch 245: {'train_loss': '1.38629'}; time used = 8.76508641242981s
epoch 250: {'train_loss': '1.38629'}; time used = 8.580314874649048s
epoch 255: {'train_loss': '1.38629'}; time used = 7.80616021156311s
epoch 260: {'train_loss': '1.38629'}; time used = 6.4972453117370605s
epoch 265: {'train_loss': '1.38629'}; time used = 6.406244516372681s
epoch 270: {'train_loss': '1.38629'}; time used = 6.272412538528442s
epoch 275: {'train_loss': '1.38629'}; time used = 6.3115925788879395s
epoch 280: {'train_loss': '1.38629'}; time used = 6.480668306350708s
epoch 285: {'train_loss': '1.38629'}; time used = 6.419414281845093s
epoch 290: {'train_loss': '1.38629'}; time used = 6.366795301437378s
epoch 295: {'train_loss': '1.38629'}; time used = 6.477137804031372s
epoch 300: {'train_loss': '1.38629'}; time used = 6.57367730140686s
epoch 305: {'train_loss': '1.38629'}; time used = 6.403488874435425s
epoch 310: {'train_loss': '1.38629'}; time used = 6.3564512729644775s
epoch 315: {'train_loss': '1.38629'}; time used = 6.454524993896484s
epoch 320: {'train_loss': '1.38629'}; time used = 6.4366395473480225s
epoch 325: {'train_loss': '1.38629'}; time used = 6.439300775527954s
epoch 330: {'train_loss': '1.38629'}; time used = 6.392817974090576s
epoch 335: {'train_loss': '1.38629'}; time used = 6.44145131111145s
epoch 340: {'train_loss': '1.38629'}; time used = 6.483829021453857s
epoch 345: {'train_loss': '1.38629'}; time used = 6.469378709793091s
epoch 350: {'train_loss': '1.38629'}; time used = 7.1470911502838135s
epoch 355: {'train_loss': '1.38629'}; time used = 6.505624294281006s
epoch 360: {'train_loss': '1.38629'}; time used = 6.515346527099609s
epoch 365: {'train_loss': '1.38629'}; time used = 6.398041486740112s
epoch 370: {'train_loss': '1.38629'}; time used = 6.541760206222534s
epoch 375: {'train_loss': '1.38629'}; time used = 7.021740913391113s
epoch 380: {'train_loss': '1.38629'}; time used = 6.572940111160278s
epoch 385: {'train_loss': '1.38629'}; time used = 6.839313268661499s
epoch 390: {'train_loss': '1.38629'}; time used = 6.561864614486694s
epoch 395: {'train_loss': '1.38629'}; time used = 6.449296474456787s
epoch 400: {'train_loss': '1.38629'}; time used = 10.34732437133789s
epoch 405: {'train_loss': '1.38629'}; time used = 6.791817665100098s
epoch 410: {'train_loss': '1.38629'}; time used = 7.186126470565796s
epoch 415: {'train_loss': '1.38629'}; time used = 9.841367244720459s
epoch 420: {'train_loss': '1.38629'}; time used = 6.814549207687378s
epoch 425: {'train_loss': '1.38629'}; time used = 8.397571325302124s
epoch 430: {'train_loss': '1.38629'}; time used = 8.18508768081665s
epoch 435: {'train_loss': '1.38629'}; time used = 6.536585807800293s
epoch 440: {'train_loss': '1.38629'}; time used = 6.502473831176758s
epoch 445: {'train_loss': '1.38629'}; time used = 6.5188679695129395s
epoch 450: {'train_loss': '1.38629'}; time used = 6.962568998336792s
epoch 455: {'train_loss': '1.38629'}; time used = 6.699678182601929s
epoch 460: {'train_loss': '1.38629'}; time used = 7.336245536804199s
epoch 465: {'train_loss': '1.38629'}; time used = 6.566910028457642s
epoch 470: {'train_loss': '1.38629'}; time used = 6.786736011505127s
epoch 475: {'train_loss': '1.38629'}; time used = 6.618794679641724s
epoch 480: {'train_loss': '1.38629'}; time used = 6.649937152862549s
epoch 485: {'train_loss': '1.38629'}; time used = 6.751553058624268s
epoch 490: {'train_loss': '1.38629'}; time used = 7.795885801315308s
epoch 495: {'train_loss': '1.38629'}; time used = 7.256737470626831s
epoch 500: {'train_loss': '1.38629'}; time used = 6.562565565109253s
Finished training. Time used = 701.3442649841309.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37667'}; time used = 1.9054155349731445s
epoch 10: {'train_loss': '1.25019'}; time used = 1.8111488819122314s
epoch 15: {'train_loss': '1.21500'}; time used = 1.7960901260375977s
epoch 20: {'train_loss': '1.15651'}; time used = 2.2024688720703125s
epoch 25: {'train_loss': '1.14388'}; time used = 2.1131954193115234s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.665692567825317.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.30239'}; time used = 1.1854369640350342s
epoch 10: {'train_loss': '2.91457'}; time used = 1.2426397800445557s
epoch 15: {'train_loss': '2.84955'}; time used = 1.3086237907409668s
epoch 20: {'train_loss': '2.82495'}; time used = 1.0912437438964844s
epoch 25: {'train_loss': '2.80375'}; time used = 1.0708434581756592s
epoch 30: {'train_loss': '2.79554'}; time used = 1.094102144241333s
epoch 35: {'train_loss': '2.80112'}; time used = 1.0732204914093018s
epoch 40: {'train_loss': '2.79249'}; time used = 1.0746476650238037s
epoch 45: {'train_loss': '2.79089'}; time used = 1.0767524242401123s
epoch 50: {'train_loss': '2.78234'}; time used = 1.0950050354003906s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.345564603805542.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81359'}; time used = 1.7865219116210938s
epoch 10: {'train_loss': '2.80231'}; time used = 1.9199657440185547s
epoch 15: {'train_loss': '2.78671'}; time used = 1.8480167388916016s
epoch 20: {'train_loss': '2.77822'}; time used = 1.7342262268066406s
epoch 25: {'train_loss': '2.77254'}; time used = 1.895324468612671s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.226088523864746.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6393728222996516, 'samples': 0.6521739130434783, 'weighted': 0.644296318739585, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35365'}; time used = 2.001955032348633s
epoch 10: {'train_loss': '1.23887'}; time used = 1.695223331451416s
epoch 15: {'train_loss': '1.18815'}; time used = 1.7005507946014404s
epoch 20: {'train_loss': '1.30286'}; time used = 1.6751995086669922s
epoch 25: {'train_loss': '1.22251'}; time used = 1.7990217208862305s
epoch 30: {'train_loss': '1.11797'}; time used = 1.9294137954711914s
epoch 35: {'train_loss': '1.23958'}; time used = 2.254805088043213s
epoch 40: {'train_loss': '1.15184'}; time used = 1.9959135055541992s
epoch 45: {'train_loss': '1.23323'}; time used = 1.9980847835540771s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.8009352684021.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5361344537815126, 'samples': 0.5362318840579711, 'weighted': 0.5366216051638046, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.34073'}; time used = 5.189799547195435s
epoch 10: {'train_loss': '1.33175'}; time used = 5.2039101123809814s
epoch 15: {'train_loss': '1.29788'}; time used = 5.232005596160889s
epoch 20: {'train_loss': '1.25568'}; time used = 5.246953248977661s
epoch 25: {'train_loss': '1.23917'}; time used = 5.353487253189087s
epoch 30: {'train_loss': '1.14263'}; time used = 5.848513126373291s
epoch 35: {'train_loss': '0.99573'}; time used = 5.041245698928833s
epoch 40: {'train_loss': '1.04744'}; time used = 5.656338214874268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 92.33472418785095.
Training classifier using 80.00% nodes...
{'micro': 0.715, 'macro': 0.714935860568628, 'samples': 0.715, 'weighted': 0.7150213798104573, 'accuracy': 0.715}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.20815'}; time used = 0.9702069759368896s
epoch 10: {'train_loss': '0.12148'}; time used = 0.85980224609375s
epoch 15: {'train_loss': '0.08466'}; time used = 0.8550937175750732s
epoch 20: {'train_loss': '0.11762'}; time used = 0.9951448440551758s
epoch 25: {'train_loss': '0.14389'}; time used = 0.99070143699646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.139549255371094.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.89395'}; time used = 2.1636626720428467s
epoch 10: {'train_loss': '2.80060'}; time used = 2.1052255630493164s
epoch 15: {'train_loss': '2.77546'}; time used = 1.8712069988250732s
epoch 20: {'train_loss': '2.75041'}; time used = 1.801804780960083s
epoch 25: {'train_loss': '2.73415'}; time used = 1.8938579559326172s
epoch 30: {'train_loss': '2.71575'}; time used = 1.934818983078003s
epoch 35: {'train_loss': '2.70417'}; time used = 1.7201406955718994s
epoch 40: {'train_loss': '2.68372'}; time used = 2.2165474891662598s
epoch 45: {'train_loss': '2.66333'}; time used = 3.559567451477051s
epoch 50: {'train_loss': '2.63461'}; time used = 3.63336443901062s
epoch 55: {'train_loss': '2.63417'}; time used = 2.5495975017547607s
epoch 60: {'train_loss': '2.59938'}; time used = 1.8957645893096924s
epoch 65: {'train_loss': '2.57633'}; time used = 1.723099946975708s
epoch 70: {'train_loss': '2.59242'}; time used = 1.7546436786651611s
epoch 75: {'train_loss': '2.53696'}; time used = 1.8065588474273682s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.327908992767334.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94984'}; time used = 1.4400763511657715s
epoch 10: {'train_loss': '2.84253'}; time used = 1.936628818511963s
epoch 15: {'train_loss': '2.81684'}; time used = 1.5182535648345947s
epoch 20: {'train_loss': '2.79039'}; time used = 1.3195607662200928s
epoch 25: {'train_loss': '2.79676'}; time used = 1.3246467113494873s
epoch 30: {'train_loss': '2.78777'}; time used = 1.300438404083252s
epoch 35: {'train_loss': '2.78633'}; time used = 1.4141662120819092s
epoch 40: {'train_loss': '2.78579'}; time used = 1.3248872756958008s
epoch 45: {'train_loss': '2.78890'}; time used = 1.2643358707427979s
epoch 50: {'train_loss': '2.78523'}; time used = 1.2819006443023682s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.721784353256226.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.70079'}; time used = 1.7978262901306152s
epoch 10: {'train_loss': '2.63747'}; time used = 1.9383690357208252s
epoch 15: {'train_loss': '2.58828'}; time used = 1.953423023223877s
epoch 20: {'train_loss': '2.51112'}; time used = 1.865443229675293s
epoch 25: {'train_loss': '2.44205'}; time used = 1.3302319049835205s
epoch 30: {'train_loss': '2.36548'}; time used = 0.953357458114624s
epoch 35: {'train_loss': '2.32188'}; time used = 0.9571611881256104s
epoch 40: {'train_loss': '2.28037'}; time used = 0.975379228591919s
epoch 45: {'train_loss': '2.24325'}; time used = 0.948432445526123s
epoch 50: {'train_loss': '2.21782'}; time used = 0.9550130367279053s
epoch 55: {'train_loss': '2.19843'}; time used = 1.13920259475708s
epoch 60: {'train_loss': '2.15783'}; time used = 1.177109718322754s
epoch 65: {'train_loss': '2.13337'}; time used = 1.291139841079712s
epoch 70: {'train_loss': '2.15147'}; time used = 0.9991374015808105s
epoch 75: {'train_loss': '2.11353'}; time used = 1.0152392387390137s
epoch 80: {'train_loss': '2.12686'}; time used = 1.0030269622802734s
epoch 85: {'train_loss': '2.13324'}; time used = 0.9750843048095703s
epoch 90: {'train_loss': '2.09320'}; time used = 1.0108520984649658s
epoch 95: {'train_loss': '2.05682'}; time used = 0.9770956039428711s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.613933086395264.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78010'}; time used = 4.450679302215576s
epoch 10: {'train_loss': '2.78323'}; time used = 4.303211212158203s
epoch 15: {'train_loss': '2.77394'}; time used = 4.332314729690552s
epoch 20: {'train_loss': '2.77327'}; time used = 4.336636543273926s
epoch 25: {'train_loss': '2.77554'}; time used = 4.331892490386963s
epoch 30: {'train_loss': '2.77456'}; time used = 4.404229640960693s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.48833107948303.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78143'}; time used = 1.1047353744506836s
epoch 10: {'train_loss': '2.77906'}; time used = 0.9974298477172852s
epoch 15: {'train_loss': '2.77826'}; time used = 0.9480166435241699s
epoch 20: {'train_loss': '2.77389'}; time used = 0.9554266929626465s
epoch 25: {'train_loss': '2.77074'}; time used = 0.9289810657501221s
epoch 30: {'train_loss': '2.77002'}; time used = 0.9313857555389404s
epoch 35: {'train_loss': '2.76870'}; time used = 0.967116117477417s
epoch 40: {'train_loss': '2.76652'}; time used = 1.0290029048919678s
epoch 45: {'train_loss': '2.76548'}; time used = 1.056821346282959s
epoch 50: {'train_loss': '2.76210'}; time used = 0.9464297294616699s
epoch 55: {'train_loss': '2.76120'}; time used = 0.9516909122467041s
epoch 60: {'train_loss': '2.76214'}; time used = 0.9326066970825195s
epoch 65: {'train_loss': '2.76351'}; time used = 0.9249520301818848s
epoch 70: {'train_loss': '2.75725'}; time used = 1.0017437934875488s
epoch 75: {'train_loss': '2.75871'}; time used = 0.9479794502258301s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.030023336410522.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.22637'}; time used = 1.9635045528411865s
epoch 10: {'train_loss': '3.08833'}; time used = 2.0412042140960693s
epoch 15: {'train_loss': '2.94099'}; time used = 2.0826220512390137s
epoch 20: {'train_loss': '2.82474'}; time used = 1.9983015060424805s
epoch 25: {'train_loss': '2.74037'}; time used = 2.157134771347046s
epoch 30: {'train_loss': '2.66644'}; time used = 2.048792600631714s
epoch 35: {'train_loss': '2.62783'}; time used = 2.1971275806427s
epoch 40: {'train_loss': '2.56746'}; time used = 1.877046823501587s
epoch 45: {'train_loss': '2.52945'}; time used = 1.8348500728607178s
epoch 50: {'train_loss': '2.49657'}; time used = 1.8279893398284912s
epoch 55: {'train_loss': '2.49386'}; time used = 1.852480173110962s
epoch 60: {'train_loss': '2.48905'}; time used = 1.8141207695007324s
epoch 65: {'train_loss': '2.47682'}; time used = 1.798583984375s
epoch 70: {'train_loss': '2.46593'}; time used = 1.8121116161346436s
epoch 75: {'train_loss': '2.46951'}; time used = 1.8173506259918213s
epoch 80: {'train_loss': '2.43968'}; time used = 1.9406805038452148s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.0201621055603.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05462'}; time used = 2.1269569396972656s
epoch 10: {'train_loss': '2.77691'}; time used = 2.050732374191284s
epoch 15: {'train_loss': '2.80957'}; time used = 2.101043701171875s
epoch 20: {'train_loss': '2.81197'}; time used = 2.1290018558502197s
epoch 25: {'train_loss': '2.77440'}; time used = 2.111233949661255s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.937676191329956.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 8.040604591369629s
epoch 10: {'train_loss': '1.38629'}; time used = 6.04203724861145s
epoch 15: {'train_loss': '1.38629'}; time used = 6.020060062408447s
epoch 20: {'train_loss': '1.38629'}; time used = 5.9371888637542725s
epoch 25: {'train_loss': '1.38629'}; time used = 5.59324312210083s
epoch 30: {'train_loss': '1.38629'}; time used = 5.541903257369995s
epoch 35: {'train_loss': '1.38629'}; time used = 5.734926462173462s
epoch 40: {'train_loss': '1.38629'}; time used = 6.057530879974365s
epoch 45: {'train_loss': '1.38629'}; time used = 6.370834827423096s
epoch 50: {'train_loss': '1.38629'}; time used = 9.302975177764893s
epoch 55: {'train_loss': '1.38629'}; time used = 8.852386474609375s
epoch 60: {'train_loss': '1.38629'}; time used = 6.471232891082764s
epoch 65: {'train_loss': '1.38629'}; time used = 5.942993879318237s
epoch 70: {'train_loss': '1.38629'}; time used = 5.983078241348267s
epoch 75: {'train_loss': '1.38629'}; time used = 7.226955890655518s
epoch 80: {'train_loss': '1.38629'}; time used = 5.942557096481323s
epoch 85: {'train_loss': '1.38629'}; time used = 5.929719686508179s
epoch 90: {'train_loss': '1.38629'}; time used = 6.2508556842803955s
epoch 95: {'train_loss': '1.38629'}; time used = 7.8312036991119385s
epoch 100: {'train_loss': '1.38629'}; time used = 7.510060548782349s
epoch 105: {'train_loss': '1.38629'}; time used = 5.738337755203247s
epoch 110: {'train_loss': '1.38629'}; time used = 5.761585235595703s
epoch 115: {'train_loss': '1.38629'}; time used = 5.846425294876099s
epoch 120: {'train_loss': '1.38629'}; time used = 5.938272714614868s
epoch 125: {'train_loss': '1.38629'}; time used = 5.894757509231567s
epoch 130: {'train_loss': '1.38629'}; time used = 5.974838018417358s
epoch 135: {'train_loss': '1.38629'}; time used = 5.741698265075684s
epoch 140: {'train_loss': '1.38629'}; time used = 5.650761842727661s
epoch 145: {'train_loss': '1.38629'}; time used = 7.075703382492065s
epoch 150: {'train_loss': '1.38629'}; time used = 7.905055999755859s
epoch 155: {'train_loss': '1.38629'}; time used = 5.610296964645386s
epoch 160: {'train_loss': '1.38629'}; time used = 5.602246284484863s
epoch 165: {'train_loss': '1.38629'}; time used = 5.6803388595581055s
epoch 170: {'train_loss': '1.38629'}; time used = 5.7963292598724365s
epoch 175: {'train_loss': '1.38629'}; time used = 5.890249252319336s
epoch 180: {'train_loss': '1.38629'}; time used = 5.753535270690918s
epoch 185: {'train_loss': '1.38629'}; time used = 5.817785978317261s
epoch 190: {'train_loss': '1.38629'}; time used = 5.740146160125732s
epoch 195: {'train_loss': '1.38629'}; time used = 6.285753488540649s
epoch 200: {'train_loss': '1.38629'}; time used = 5.9833083152771s
epoch 205: {'train_loss': '1.38629'}; time used = 8.953408241271973s
epoch 210: {'train_loss': '1.38629'}; time used = 6.8741912841796875s
epoch 215: {'train_loss': '1.38629'}; time used = 6.12646746635437s
epoch 220: {'train_loss': '1.38629'}; time used = 5.918733835220337s
epoch 225: {'train_loss': '1.38629'}; time used = 6.435734987258911s
epoch 230: {'train_loss': '1.38629'}; time used = 6.406470775604248s
epoch 235: {'train_loss': '1.38629'}; time used = 6.116671085357666s
epoch 240: {'train_loss': '1.38629'}; time used = 6.103847503662109s
epoch 245: {'train_loss': '1.38629'}; time used = 5.8066325187683105s
epoch 250: {'train_loss': '1.38629'}; time used = 5.902161598205566s
epoch 255: {'train_loss': '1.38629'}; time used = 6.974817991256714s
epoch 260: {'train_loss': '1.38629'}; time used = 5.765233516693115s
epoch 265: {'train_loss': '1.38629'}; time used = 5.592793226242065s
epoch 270: {'train_loss': '1.38629'}; time used = 5.658421516418457s
epoch 275: {'train_loss': '1.38629'}; time used = 5.9778382778167725s
epoch 280: {'train_loss': '1.38629'}; time used = 5.758575439453125s
epoch 285: {'train_loss': '1.38629'}; time used = 8.827089548110962s
epoch 290: {'train_loss': '1.38629'}; time used = 6.293622970581055s
epoch 295: {'train_loss': '1.38629'}; time used = 5.778772592544556s
epoch 300: {'train_loss': '1.38629'}; time used = 5.824313163757324s
epoch 305: {'train_loss': '1.38629'}; time used = 5.7220423221588135s
epoch 310: {'train_loss': '1.38629'}; time used = 5.858632802963257s
epoch 315: {'train_loss': '1.38629'}; time used = 6.967504262924194s
epoch 320: {'train_loss': '1.38629'}; time used = 5.665290117263794s
epoch 325: {'train_loss': '1.38629'}; time used = 5.698786020278931s
epoch 330: {'train_loss': '1.38629'}; time used = 5.753742933273315s
epoch 335: {'train_loss': '1.38629'}; time used = 5.754576683044434s
epoch 340: {'train_loss': '1.38629'}; time used = 5.715955495834351s
epoch 345: {'train_loss': '1.38629'}; time used = 5.829240322113037s
epoch 350: {'train_loss': '1.38629'}; time used = 6.947608709335327s
epoch 355: {'train_loss': '1.38629'}; time used = 5.696385383605957s
epoch 360: {'train_loss': '1.38629'}; time used = 5.741152763366699s
epoch 365: {'train_loss': '1.38629'}; time used = 5.720305442810059s
epoch 370: {'train_loss': '1.38629'}; time used = 5.838374614715576s
epoch 375: {'train_loss': '1.38629'}; time used = 5.929003000259399s
epoch 380: {'train_loss': '1.38629'}; time used = 5.777577638626099s
epoch 385: {'train_loss': '1.38629'}; time used = 5.685054779052734s
epoch 390: {'train_loss': '1.38629'}; time used = 7.537898778915405s
epoch 395: {'train_loss': '1.38629'}; time used = 7.300219535827637s
epoch 400: {'train_loss': '1.38629'}; time used = 9.743483304977417s
epoch 405: {'train_loss': '1.38629'}; time used = 6.1653053760528564s
epoch 410: {'train_loss': '1.38629'}; time used = 5.9198691844940186s
epoch 415: {'train_loss': '1.38629'}; time used = 5.810621023178101s
epoch 420: {'train_loss': '1.38629'}; time used = 5.723359107971191s
epoch 425: {'train_loss': '1.38629'}; time used = 5.663440942764282s
epoch 430: {'train_loss': '1.38629'}; time used = 7.786972761154175s
epoch 435: {'train_loss': '1.38629'}; time used = 7.242008209228516s
epoch 440: {'train_loss': '1.38629'}; time used = 8.13551950454712s
epoch 445: {'train_loss': '1.38629'}; time used = 7.572699546813965s
epoch 450: {'train_loss': '1.38629'}; time used = 5.528310060501099s
epoch 455: {'train_loss': '1.38629'}; time used = 6.31537389755249s
epoch 460: {'train_loss': '1.38629'}; time used = 5.846128702163696s
epoch 465: {'train_loss': '1.38629'}; time used = 5.861201047897339s
epoch 470: {'train_loss': '1.38629'}; time used = 5.852660417556763s
epoch 475: {'train_loss': '1.38629'}; time used = 5.901838064193726s
epoch 480: {'train_loss': '1.38629'}; time used = 7.623523712158203s
epoch 485: {'train_loss': '1.38629'}; time used = 5.869288444519043s
epoch 490: {'train_loss': '1.38629'}; time used = 5.892535209655762s
epoch 495: {'train_loss': '1.38629'}; time used = 6.06118631362915s
epoch 500: {'train_loss': '1.38629'}; time used = 6.047299385070801s
Finished training. Time used = 641.8408961296082.
Training classifier using 80.00% nodes...
{'micro': 0.41999999999999993, 'macro': 0.3393353394833341, 'samples': 0.42, 'weighted': 0.3291552792988341, 'accuracy': 0.42}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86749'}; time used = 2.9618847370147705s
epoch 10: {'train_loss': '2.80523'}; time used = 1.1997287273406982s
epoch 15: {'train_loss': '2.77686'}; time used = 1.210770845413208s
epoch 20: {'train_loss': '2.77433'}; time used = 1.0504035949707031s
epoch 25: {'train_loss': '2.77947'}; time used = 1.0114405155181885s
epoch 30: {'train_loss': '2.77672'}; time used = 2.204908847808838s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.780736446380615.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86132'}; time used = 2.5189738273620605s
epoch 10: {'train_loss': '2.78841'}; time used = 2.4390382766723633s
epoch 15: {'train_loss': '2.77030'}; time used = 2.421555519104004s
epoch 20: {'train_loss': '2.77156'}; time used = 2.398928642272949s
epoch 25: {'train_loss': '2.76938'}; time used = 2.417090892791748s
epoch 30: {'train_loss': '2.75475'}; time used = 2.506303071975708s
epoch 35: {'train_loss': '2.73159'}; time used = 2.3093059062957764s
epoch 40: {'train_loss': '2.71429'}; time used = 2.406447649002075s
epoch 45: {'train_loss': '2.67678'}; time used = 2.4535415172576904s
epoch 50: {'train_loss': '2.65175'}; time used = 2.3198294639587402s
epoch 55: {'train_loss': '2.67833'}; time used = 2.4150023460388184s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.949686765670776.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39066'}; time used = 1.9703624248504639s
epoch 10: {'train_loss': '1.30751'}; time used = 2.0678060054779053s
epoch 15: {'train_loss': '1.18148'}; time used = 2.131622791290283s
epoch 20: {'train_loss': '1.21256'}; time used = 1.9744513034820557s
epoch 25: {'train_loss': '1.09643'}; time used = 2.081597328186035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.79958987236023.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38736'}; time used = 1.1006393432617188s
epoch 10: {'train_loss': '1.39736'}; time used = 1.008336067199707s
epoch 15: {'train_loss': '1.27388'}; time used = 2.4347832202911377s
epoch 20: {'train_loss': '1.44021'}; time used = 2.5314035415649414s
epoch 25: {'train_loss': '0.87064'}; time used = 2.32383131980896s
epoch 30: {'train_loss': '1.25864'}; time used = 2.174827814102173s
epoch 35: {'train_loss': '1.37683'}; time used = 1.3584389686584473s
epoch 40: {'train_loss': '1.02265'}; time used = 0.9416816234588623s
epoch 45: {'train_loss': '0.89749'}; time used = 1.0439081192016602s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.66307544708252.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38700'}; time used = 1.113473892211914s
epoch 10: {'train_loss': '1.39653'}; time used = 0.997161865234375s
epoch 15: {'train_loss': '1.27109'}; time used = 0.994002103805542s
epoch 20: {'train_loss': '1.32650'}; time used = 1.0082893371582031s
epoch 25: {'train_loss': '1.17288'}; time used = 1.002589225769043s
epoch 30: {'train_loss': '1.25951'}; time used = 0.978459358215332s
epoch 35: {'train_loss': '1.26976'}; time used = 0.9761776924133301s
epoch 40: {'train_loss': '1.20992'}; time used = 0.9835655689239502s
epoch 45: {'train_loss': '1.01995'}; time used = 0.9925897121429443s
epoch 50: {'train_loss': '1.11673'}; time used = 0.9670672416687012s
epoch 55: {'train_loss': '1.10382'}; time used = 0.9946286678314209s
epoch 60: {'train_loss': '1.15426'}; time used = 0.9743537902832031s
epoch 65: {'train_loss': '0.92887'}; time used = 0.9881877899169922s
epoch 70: {'train_loss': '1.33701'}; time used = 0.9838829040527344s
epoch 75: {'train_loss': '1.31823'}; time used = 0.9855155944824219s
epoch 80: {'train_loss': '1.02394'}; time used = 0.9789636135101318s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.660006046295166.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.64 GiB already allocated; 202.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77175'}; time used = 1.0610311031341553s
epoch 10: {'train_loss': '2.49498'}; time used = 0.9019904136657715s
epoch 15: {'train_loss': '1.91010'}; time used = 0.9051554203033447s
epoch 20: {'train_loss': '1.72848'}; time used = 0.898674488067627s
epoch 25: {'train_loss': '1.67940'}; time used = 1.0111594200134277s
epoch 30: {'train_loss': '1.58832'}; time used = 0.8973464965820312s
epoch 35: {'train_loss': '1.45982'}; time used = 0.9568502902984619s
epoch 40: {'train_loss': '1.44617'}; time used = 0.9204151630401611s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.032296657562256.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 7.51 GiB already allocated; 1.39 GiB free; 44.18 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.37954'}; time used = 1.2965328693389893s
epoch 10: {'train_loss': '0.27704'}; time used = 1.0467424392700195s
epoch 15: {'train_loss': '0.29931'}; time used = 0.9861574172973633s
epoch 20: {'train_loss': '0.28281'}; time used = 0.9901120662689209s
epoch 25: {'train_loss': '0.32889'}; time used = 0.9754645824432373s
epoch 30: {'train_loss': '0.25797'}; time used = 0.9415607452392578s
epoch 35: {'train_loss': '0.29062'}; time used = 0.9671163558959961s
epoch 40: {'train_loss': '0.24326'}; time used = 0.9556272029876709s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.978501319885254.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39472'}; time used = 1.1500256061553955s
epoch 10: {'train_loss': '1.39949'}; time used = 1.0292677879333496s
epoch 15: {'train_loss': '1.28379'}; time used = 1.0788938999176025s
epoch 20: {'train_loss': '1.02435'}; time used = 1.0996437072753906s
epoch 25: {'train_loss': '0.81245'}; time used = 1.1016507148742676s
epoch 30: {'train_loss': '0.69615'}; time used = 1.0271406173706055s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.62604022026062.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.14634'}; time used = 2.184980630874634s
epoch 10: {'train_loss': '2.82447'}; time used = 1.7480568885803223s
epoch 15: {'train_loss': '2.76266'}; time used = 2.382615566253662s
epoch 20: {'train_loss': '2.72956'}; time used = 3.1013472080230713s
epoch 25: {'train_loss': '2.68474'}; time used = 3.117966890335083s
epoch 30: {'train_loss': '2.64421'}; time used = 2.8148348331451416s
epoch 35: {'train_loss': '2.60083'}; time used = 1.7078423500061035s
epoch 40: {'train_loss': '2.57094'}; time used = 1.773104190826416s
epoch 45: {'train_loss': '2.52721'}; time used = 1.7223775386810303s
epoch 50: {'train_loss': '2.46802'}; time used = 2.025529384613037s
epoch 55: {'train_loss': '2.42442'}; time used = 2.0268588066101074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.041883945465088.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79352'}; time used = 1.8567917346954346s
epoch 10: {'train_loss': '2.78026'}; time used = 1.888387680053711s
epoch 15: {'train_loss': '2.78139'}; time used = 1.8504548072814941s
epoch 20: {'train_loss': '2.77595'}; time used = 1.9753549098968506s
epoch 25: {'train_loss': '2.77174'}; time used = 2.104792594909668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.051693439483643.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4891114982578397, 'samples': 0.5072463768115942, 'weighted': 0.49608645154774533, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.10460'}; time used = 2.239725112915039s
epoch 10: {'train_loss': '2.95735'}; time used = 2.0349087715148926s
epoch 15: {'train_loss': '2.87077'}; time used = 2.0594804286956787s
epoch 20: {'train_loss': '2.85139'}; time used = 1.9822332859039307s
epoch 25: {'train_loss': '2.82154'}; time used = 2.1703124046325684s
epoch 30: {'train_loss': '2.81079'}; time used = 2.1916592121124268s
epoch 35: {'train_loss': '2.80167'}; time used = 3.2040960788726807s
epoch 40: {'train_loss': '2.79473'}; time used = 3.4953207969665527s
epoch 45: {'train_loss': '2.79424'}; time used = 2.5125269889831543s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.551801919937134.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77183'}; time used = 1.8520455360412598s
epoch 10: {'train_loss': '2.65710'}; time used = 1.7428572177886963s
epoch 15: {'train_loss': '2.63921'}; time used = 1.6827969551086426s
epoch 20: {'train_loss': '2.61901'}; time used = 1.684441089630127s
epoch 25: {'train_loss': '2.59203'}; time used = 1.88338041305542s
epoch 30: {'train_loss': '2.56402'}; time used = 1.8593382835388184s
epoch 35: {'train_loss': '2.53371'}; time used = 1.7023670673370361s
epoch 40: {'train_loss': '2.50340'}; time used = 1.9095580577850342s
epoch 45: {'train_loss': '2.46987'}; time used = 3.2069363594055176s
epoch 50: {'train_loss': '2.39211'}; time used = 3.807234048843384s
epoch 55: {'train_loss': '2.40998'}; time used = 2.0349273681640625s
epoch 60: {'train_loss': '2.38585'}; time used = 1.8597521781921387s
epoch 65: {'train_loss': '2.34720'}; time used = 2.530029058456421s
epoch 70: {'train_loss': '2.29869'}; time used = 3.155731678009033s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.12469029426575.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4828042328042328, 'samples': 0.5072463768115942, 'weighted': 0.4909516141400199, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90433'}; time used = 1.9181230068206787s
epoch 10: {'train_loss': '2.79846'}; time used = 1.7841064929962158s
epoch 15: {'train_loss': '2.77469'}; time used = 2.5616602897644043s
epoch 20: {'train_loss': '2.77335'}; time used = 1.7386054992675781s
epoch 25: {'train_loss': '2.77581'}; time used = 1.868706226348877s
epoch 30: {'train_loss': '2.76899'}; time used = 1.7545251846313477s
epoch 35: {'train_loss': '2.76965'}; time used = 1.7635905742645264s
epoch 40: {'train_loss': '2.76865'}; time used = 1.6946992874145508s
epoch 45: {'train_loss': '2.76599'}; time used = 1.93827223777771s
epoch 50: {'train_loss': '2.76372'}; time used = 1.7883427143096924s
epoch 55: {'train_loss': '2.76315'}; time used = 1.7232046127319336s
epoch 60: {'train_loss': '2.75979'}; time used = 1.7384896278381348s
epoch 65: {'train_loss': '2.75801'}; time used = 1.7306098937988281s
epoch 70: {'train_loss': '2.75632'}; time used = 1.710007667541504s
epoch 75: {'train_loss': '2.75212'}; time used = 1.7785899639129639s
epoch 80: {'train_loss': '2.75316'}; time used = 1.8926739692687988s
epoch 85: {'train_loss': '2.75242'}; time used = 3.946194648742676s
epoch 90: {'train_loss': '2.74626'}; time used = 5.562448263168335s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.97833728790283.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.25011'}; time used = 1.1133170127868652s
epoch 10: {'train_loss': '0.11527'}; time used = 0.9281041622161865s
epoch 15: {'train_loss': '0.06738'}; time used = 0.9252545833587646s
epoch 20: {'train_loss': '0.06190'}; time used = 0.9462072849273682s
epoch 25: {'train_loss': '0.06168'}; time used = 0.9399838447570801s
epoch 30: {'train_loss': '0.07575'}; time used = 0.9538917541503906s
epoch 35: {'train_loss': '0.06864'}; time used = 0.9289023876190186s
epoch 40: {'train_loss': '0.05074'}; time used = 0.9474523067474365s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.919992208480835.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.98509'}; time used = 1.3662467002868652s
epoch 10: {'train_loss': '2.82632'}; time used = 1.044264554977417s
epoch 15: {'train_loss': '2.80938'}; time used = 1.0158390998840332s
epoch 20: {'train_loss': '2.78889'}; time used = 1.0078370571136475s
epoch 25: {'train_loss': '2.77705'}; time used = 1.0034348964691162s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.043668508529663.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35317'}; time used = 1.7479639053344727s
epoch 10: {'train_loss': '0.88597'}; time used = 1.866161823272705s
epoch 15: {'train_loss': '0.75574'}; time used = 1.7124793529510498s
epoch 20: {'train_loss': '0.52487'}; time used = 1.8600244522094727s
epoch 25: {'train_loss': '0.37474'}; time used = 1.8254895210266113s
epoch 30: {'train_loss': '0.07809'}; time used = 1.7931127548217773s
epoch 35: {'train_loss': '0.03080'}; time used = 1.730717420578003s
epoch 40: {'train_loss': '0.10695'}; time used = 1.8927466869354248s
epoch 45: {'train_loss': '0.11418'}; time used = 1.8190059661865234s
epoch 50: {'train_loss': '0.21407'}; time used = 1.8609678745269775s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.69098734855652.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.19936'}; time used = 1.121394157409668s
epoch 10: {'train_loss': '0.86097'}; time used = 1.0095582008361816s
epoch 15: {'train_loss': '0.69403'}; time used = 1.0470421314239502s
epoch 20: {'train_loss': '0.59825'}; time used = 1.002762794494629s
epoch 25: {'train_loss': '0.56724'}; time used = 1.0588409900665283s
epoch 30: {'train_loss': '0.57150'}; time used = 1.0007023811340332s
epoch 35: {'train_loss': '0.46929'}; time used = 1.0502731800079346s
epoch 40: {'train_loss': '0.37660'}; time used = 1.0235764980316162s
epoch 45: {'train_loss': '0.31118'}; time used = 1.0363175868988037s
epoch 50: {'train_loss': '0.27177'}; time used = 1.0171091556549072s
epoch 55: {'train_loss': '0.27991'}; time used = 1.0693464279174805s
epoch 60: {'train_loss': '0.21765'}; time used = 1.1339645385742188s
epoch 65: {'train_loss': '0.20883'}; time used = 1.0647172927856445s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.80928945541382.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.64 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.69020'}; time used = 1.3696396350860596s
epoch 10: {'train_loss': '2.61344'}; time used = 1.0233855247497559s
epoch 15: {'train_loss': '2.51119'}; time used = 1.204887866973877s
epoch 20: {'train_loss': '2.43466'}; time used = 1.5082271099090576s
epoch 25: {'train_loss': '2.38152'}; time used = 1.8899812698364258s
epoch 30: {'train_loss': '2.26930'}; time used = 1.8703339099884033s
epoch 35: {'train_loss': '2.23126'}; time used = 1.973254919052124s
epoch 40: {'train_loss': '2.19487'}; time used = 1.7216129302978516s
epoch 45: {'train_loss': '2.20360'}; time used = 1.2109730243682861s
epoch 50: {'train_loss': '2.20826'}; time used = 1.0450496673583984s
epoch 55: {'train_loss': '2.11692'}; time used = 1.136747121810913s
epoch 60: {'train_loss': '2.08618'}; time used = 1.095390796661377s
epoch 65: {'train_loss': '2.03209'}; time used = 1.0114197731018066s
epoch 70: {'train_loss': '2.06617'}; time used = 1.1009390354156494s
epoch 75: {'train_loss': '2.01953'}; time used = 1.173124074935913s
epoch 80: {'train_loss': '2.02615'}; time used = 1.2032709121704102s
epoch 85: {'train_loss': '2.02610'}; time used = 1.1911365985870361s
epoch 90: {'train_loss': '2.11248'}; time used = 1.2031233310699463s
epoch 95: {'train_loss': '2.11450'}; time used = 1.2077651023864746s
epoch 100: {'train_loss': '2.13164'}; time used = 1.2037937641143799s
epoch 105: {'train_loss': '2.06363'}; time used = 1.2565524578094482s
epoch 110: {'train_loss': '2.01514'}; time used = 1.023383378982544s
epoch 115: {'train_loss': '2.03641'}; time used = 0.9913046360015869s
epoch 120: {'train_loss': '1.97096'}; time used = 0.9966206550598145s
epoch 125: {'train_loss': '2.02031'}; time used = 1.0206270217895508s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.817819595336914.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89313'}; time used = 2.5000717639923096s
epoch 10: {'train_loss': '2.85247'}; time used = 2.55902361869812s
epoch 15: {'train_loss': '2.84162'}; time used = 2.73079776763916s
epoch 20: {'train_loss': '2.81188'}; time used = 2.4933183193206787s
epoch 25: {'train_loss': '2.79587'}; time used = 2.515659809112549s
epoch 30: {'train_loss': '2.79542'}; time used = 2.4414751529693604s
epoch 35: {'train_loss': '2.80286'}; time used = 2.448141574859619s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.680946826934814.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77406'}; time used = 2.443014621734619s
epoch 10: {'train_loss': '2.79770'}; time used = 2.0079257488250732s
epoch 15: {'train_loss': '2.71735'}; time used = 0.9998924732208252s
epoch 20: {'train_loss': '2.40685'}; time used = 0.9550299644470215s
epoch 25: {'train_loss': '1.81759'}; time used = 0.9385740756988525s
epoch 30: {'train_loss': '1.76502'}; time used = 0.9298059940338135s
epoch 35: {'train_loss': '1.58440'}; time used = 0.915215015411377s
epoch 40: {'train_loss': '1.52487'}; time used = 0.9535982608795166s
epoch 45: {'train_loss': '1.57780'}; time used = 1.0125999450683594s
epoch 50: {'train_loss': '1.71965'}; time used = 0.9404118061065674s
epoch 55: {'train_loss': '1.55945'}; time used = 1.0269079208374023s
epoch 60: {'train_loss': '1.56900'}; time used = 1.2190742492675781s
epoch 65: {'train_loss': '1.45615'}; time used = 1.0774657726287842s
epoch 70: {'train_loss': '1.43507'}; time used = 1.0503695011138916s
epoch 75: {'train_loss': '1.36481'}; time used = 1.0437748432159424s
epoch 80: {'train_loss': '1.38760'}; time used = 1.0118157863616943s
epoch 85: {'train_loss': '1.40762'}; time used = 1.0485925674438477s
epoch 90: {'train_loss': '1.37799'}; time used = 1.028656244277954s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.20617413520813.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.25057'}; time used = 1.7883412837982178s
epoch 10: {'train_loss': '1.23176'}; time used = 1.9784533977508545s
epoch 15: {'train_loss': '1.11649'}; time used = 1.958634376525879s
epoch 20: {'train_loss': '0.99803'}; time used = 1.8796303272247314s
epoch 25: {'train_loss': '0.77369'}; time used = 1.8735618591308594s
epoch 30: {'train_loss': '0.48315'}; time used = 1.7205677032470703s
epoch 35: {'train_loss': '0.36671'}; time used = 1.7983994483947754s
epoch 40: {'train_loss': '0.18619'}; time used = 1.715895175933838s
epoch 45: {'train_loss': '0.21678'}; time used = 1.6441679000854492s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.263738870620728.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83280'}; time used = 5.652530193328857s
epoch 10: {'train_loss': '2.80204'}; time used = 5.8482348918914795s
epoch 15: {'train_loss': '2.78791'}; time used = 5.712631464004517s
epoch 20: {'train_loss': '2.77982'}; time used = 6.990558624267578s
epoch 25: {'train_loss': '2.77455'}; time used = 4.711704730987549s
epoch 30: {'train_loss': '2.77194'}; time used = 5.368987560272217s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.88586068153381.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7048155096935584, 'samples': 0.705, 'weighted': 0.7046679174484052, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36328'}; time used = 5.037808895111084s
epoch 10: {'train_loss': '1.38882'}; time used = 7.38238525390625s
epoch 15: {'train_loss': '1.37029'}; time used = 5.977074384689331s
epoch 20: {'train_loss': '1.35785'}; time used = 6.0505194664001465s
epoch 25: {'train_loss': '1.36405'}; time used = 7.237681150436401s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.114018201828.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.7199159915991601, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33063'}; time used = 2.1849026679992676s
epoch 10: {'train_loss': '1.20836'}; time used = 2.1233766078948975s
epoch 15: {'train_loss': '1.16185'}; time used = 2.599839210510254s
epoch 20: {'train_loss': '1.16358'}; time used = 2.706282615661621s
epoch 25: {'train_loss': '1.10681'}; time used = 2.2489964962005615s
epoch 30: {'train_loss': '0.97429'}; time used = 2.097554922103882s
epoch 35: {'train_loss': '0.94885'}; time used = 2.0968503952026367s
epoch 40: {'train_loss': '0.90713'}; time used = 2.1802713871002197s
epoch 45: {'train_loss': '0.87540'}; time used = 2.1856513023376465s
epoch 50: {'train_loss': '0.75571'}; time used = 2.205430507659912s
epoch 55: {'train_loss': '0.67242'}; time used = 2.3044636249542236s
epoch 60: {'train_loss': '0.73403'}; time used = 2.138641357421875s
epoch 65: {'train_loss': '0.75023'}; time used = 2.2339024543762207s
epoch 70: {'train_loss': '0.77395'}; time used = 2.4512765407562256s
epoch 75: {'train_loss': '0.80422'}; time used = 2.4035227298736572s
epoch 80: {'train_loss': '0.65437'}; time used = 2.066901683807373s
epoch 85: {'train_loss': '0.56897'}; time used = 2.044968843460083s
epoch 90: {'train_loss': '0.63334'}; time used = 2.1926002502441406s
epoch 95: {'train_loss': '0.38572'}; time used = 2.1118016242980957s
epoch 100: {'train_loss': '0.50028'}; time used = 2.1318728923797607s
epoch 105: {'train_loss': '0.45354'}; time used = 2.0485520362854004s
epoch 110: {'train_loss': '0.31252'}; time used = 2.0384020805358887s
epoch 115: {'train_loss': '0.21396'}; time used = 2.0519516468048096s
epoch 120: {'train_loss': '0.29497'}; time used = 2.0448529720306396s
epoch 125: {'train_loss': '0.22044'}; time used = 2.2414379119873047s
epoch 130: {'train_loss': '0.15918'}; time used = 2.058851480484009s
epoch 135: {'train_loss': '0.09609'}; time used = 2.08088755607605s
epoch 140: {'train_loss': '0.31168'}; time used = 2.0329082012176514s
epoch 145: {'train_loss': '0.15039'}; time used = 2.1305811405181885s
epoch 150: {'train_loss': '0.28467'}; time used = 2.3517558574676514s
epoch 155: {'train_loss': '0.09091'}; time used = 4.0365517139434814s
epoch 160: {'train_loss': '0.12675'}; time used = 3.9981586933135986s
epoch 165: {'train_loss': '0.17353'}; time used = 2.791776418685913s
epoch 170: {'train_loss': '0.25817'}; time used = 2.0650455951690674s
epoch 175: {'train_loss': '0.08252'}; time used = 2.080479145050049s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 86.82171964645386.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6360926393029123, 'samples': 0.6666666666666666, 'weighted': 0.6437361461438508, 'accuracy': 0.6666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03335'}; time used = 1.823302984237671s
epoch 10: {'train_loss': '0.98283'}; time used = 1.8701040744781494s
epoch 15: {'train_loss': '0.92309'}; time used = 1.5910727977752686s
epoch 20: {'train_loss': '0.40303'}; time used = 1.5540344715118408s
epoch 25: {'train_loss': '0.38354'}; time used = 1.6556072235107422s
epoch 30: {'train_loss': '0.20702'}; time used = 1.5829987525939941s
epoch 35: {'train_loss': '0.25427'}; time used = 2.391724109649658s
epoch 40: {'train_loss': '0.73163'}; time used = 3.9236695766448975s
epoch 45: {'train_loss': '0.28824'}; time used = 2.8205769062042236s
epoch 50: {'train_loss': '0.22824'}; time used = 1.537065029144287s
epoch 55: {'train_loss': '0.72912'}; time used = 1.5789084434509277s
epoch 60: {'train_loss': '0.28007'}; time used = 1.541285753250122s
epoch 65: {'train_loss': '0.26481'}; time used = 1.5200986862182617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.746368646621704.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.43159'}; time used = 1.322798252105713s
epoch 10: {'train_loss': '0.23979'}; time used = 1.1681795120239258s
epoch 15: {'train_loss': '0.15571'}; time used = 1.1237847805023193s
epoch 20: {'train_loss': '0.01661'}; time used = 1.1119608879089355s
epoch 25: {'train_loss': '0.03961'}; time used = 1.3080291748046875s
epoch 30: {'train_loss': '0.33113'}; time used = 1.314143180847168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.353944063186646.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38898'}; time used = 1.0886647701263428s
epoch 10: {'train_loss': '1.35012'}; time used = 1.0083138942718506s
epoch 15: {'train_loss': '1.27881'}; time used = 0.9125454425811768s
epoch 20: {'train_loss': '1.28217'}; time used = 0.9616196155548096s
epoch 25: {'train_loss': '1.16896'}; time used = 1.0755152702331543s
epoch 30: {'train_loss': '1.03601'}; time used = 1.0501327514648438s
epoch 35: {'train_loss': '0.94742'}; time used = 1.0277526378631592s
epoch 40: {'train_loss': '0.87038'}; time used = 0.9782838821411133s
epoch 45: {'train_loss': '0.69521'}; time used = 1.047532320022583s
epoch 50: {'train_loss': '0.83471'}; time used = 0.9581727981567383s
epoch 55: {'train_loss': '0.72847'}; time used = 0.9621491432189941s
epoch 60: {'train_loss': '0.73148'}; time used = 1.0447418689727783s
epoch 65: {'train_loss': '0.61672'}; time used = 0.9548561573028564s
epoch 70: {'train_loss': '0.71089'}; time used = 0.9844300746917725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.059587955474854.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.17530'}; time used = 2.7999138832092285s
epoch 10: {'train_loss': '2.89208'}; time used = 2.5208141803741455s
epoch 15: {'train_loss': '2.78637'}; time used = 2.234962224960327s
epoch 20: {'train_loss': '2.78214'}; time used = 1.7564115524291992s
epoch 25: {'train_loss': '2.78763'}; time used = 1.039827823638916s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.68394637107849.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13745'}; time used = 1.6834666728973389s
epoch 10: {'train_loss': '0.86063'}; time used = 1.890300989151001s
epoch 15: {'train_loss': '0.34716'}; time used = 1.8703746795654297s
epoch 20: {'train_loss': '0.43251'}; time used = 1.8489267826080322s
epoch 25: {'train_loss': '0.43372'}; time used = 2.0175211429595947s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.118924617767334.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37090'}; time used = 1.3124589920043945s
epoch 10: {'train_loss': '1.29348'}; time used = 0.9902462959289551s
epoch 15: {'train_loss': '1.21037'}; time used = 1.7254393100738525s
epoch 20: {'train_loss': '1.20340'}; time used = 1.786949634552002s
epoch 25: {'train_loss': '1.06763'}; time used = 0.9932961463928223s
epoch 30: {'train_loss': '1.00070'}; time used = 0.9297847747802734s
epoch 35: {'train_loss': '0.91901'}; time used = 1.06636643409729s
epoch 40: {'train_loss': '0.87317'}; time used = 0.937518835067749s
epoch 45: {'train_loss': '0.67570'}; time used = 1.1539630889892578s
epoch 50: {'train_loss': '0.81708'}; time used = 1.0486719608306885s
epoch 55: {'train_loss': '0.72732'}; time used = 0.9684755802154541s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.263773441314697.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79900'}; time used = 1.7312593460083008s
epoch 10: {'train_loss': '2.69532'}; time used = 1.5872223377227783s
epoch 15: {'train_loss': '2.67727'}; time used = 1.6528005599975586s
epoch 20: {'train_loss': '2.62629'}; time used = 1.8122050762176514s
epoch 25: {'train_loss': '2.60609'}; time used = 1.743018388748169s
epoch 30: {'train_loss': '2.57027'}; time used = 1.6804413795471191s
epoch 35: {'train_loss': '2.54168'}; time used = 1.6518266201019287s
epoch 40: {'train_loss': '2.50668'}; time used = 1.6469426155090332s
epoch 45: {'train_loss': '2.48082'}; time used = 1.984288215637207s
epoch 50: {'train_loss': '2.42168'}; time used = 1.8056368827819824s
epoch 55: {'train_loss': '2.51380'}; time used = 1.884310245513916s
epoch 60: {'train_loss': '2.45921'}; time used = 1.900212049484253s
epoch 65: {'train_loss': '2.41981'}; time used = 2.117870330810547s
epoch 70: {'train_loss': '2.35255'}; time used = 3.304835319519043s
epoch 75: {'train_loss': '2.29053'}; time used = 1.759411334991455s
epoch 80: {'train_loss': '2.29748'}; time used = 1.8093929290771484s
epoch 85: {'train_loss': '2.26417'}; time used = 1.7877624034881592s
epoch 90: {'train_loss': '2.33775'}; time used = 1.7821316719055176s
epoch 95: {'train_loss': '2.27256'}; time used = 1.880394697189331s
epoch 100: {'train_loss': '2.19757'}; time used = 2.2445931434631348s
epoch 105: {'train_loss': '2.18386'}; time used = 3.485830068588257s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.16145730018616.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84822'}; time used = 4.610142946243286s
epoch 10: {'train_loss': '2.77743'}; time used = 4.65288519859314s
epoch 15: {'train_loss': '2.78147'}; time used = 4.791875839233398s
epoch 20: {'train_loss': '2.77765'}; time used = 5.769838094711304s
epoch 25: {'train_loss': '2.77368'}; time used = 4.255311965942383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.034937620162964.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7298919567827131, 'samples': 0.73, 'weighted': 0.7297839135654262, 'accuracy': 0.73}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84376'}; time used = 1.067777156829834s
epoch 10: {'train_loss': '2.78779'}; time used = 0.96563720703125s
epoch 15: {'train_loss': '2.77516'}; time used = 0.9540190696716309s
epoch 20: {'train_loss': '2.77292'}; time used = 0.983405351638794s
epoch 25: {'train_loss': '2.77483'}; time used = 0.9587874412536621s
epoch 30: {'train_loss': '2.77426'}; time used = 0.9935634136199951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.982503890991211.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38750'}; time used = 1.3379924297332764s
epoch 10: {'train_loss': '1.41398'}; time used = 1.334409475326538s
epoch 15: {'train_loss': '1.34485'}; time used = 1.3489692211151123s
epoch 20: {'train_loss': '1.38726'}; time used = 1.409013032913208s
epoch 25: {'train_loss': '1.32376'}; time used = 2.3772261142730713s
epoch 30: {'train_loss': '1.37300'}; time used = 2.3443751335144043s
epoch 35: {'train_loss': '1.41807'}; time used = 2.4196808338165283s
epoch 40: {'train_loss': '1.32277'}; time used = 2.0192878246307373s
epoch 45: {'train_loss': '1.27515'}; time used = 1.02850341796875s
epoch 50: {'train_loss': '1.31480'}; time used = 1.1252977848052979s
epoch 55: {'train_loss': '1.27297'}; time used = 1.0611038208007812s
epoch 60: {'train_loss': '1.19537'}; time used = 1.063239574432373s
epoch 65: {'train_loss': '1.13361'}; time used = 1.1076817512512207s
epoch 70: {'train_loss': '1.07668'}; time used = 1.0332119464874268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.609440565109253.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35756'}; time used = 1.8335280418395996s
epoch 10: {'train_loss': '1.14054'}; time used = 1.9281845092773438s
epoch 15: {'train_loss': '0.93979'}; time used = 1.6920130252838135s
epoch 20: {'train_loss': '0.81238'}; time used = 1.717167854309082s
epoch 25: {'train_loss': '0.66637'}; time used = 1.7734880447387695s
epoch 30: {'train_loss': '0.41509'}; time used = 1.721935749053955s
epoch 35: {'train_loss': '0.64681'}; time used = 1.7048594951629639s
epoch 40: {'train_loss': '0.29738'}; time used = 1.7087764739990234s
epoch 45: {'train_loss': '0.57581'}; time used = 2.0004780292510986s
epoch 50: {'train_loss': '0.04214'}; time used = 1.7542667388916016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.794355869293213.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4923270969098172, 'samples': 0.4927536231884058, 'weighted': 0.49339341260628894, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89313'}; time used = 2.8309903144836426s
epoch 10: {'train_loss': '2.85247'}; time used = 4.192914009094238s
epoch 15: {'train_loss': '2.84162'}; time used = 4.239182472229004s
epoch 20: {'train_loss': '2.81188'}; time used = 3.0755674839019775s
epoch 25: {'train_loss': '2.79587'}; time used = 2.5515925884246826s
epoch 30: {'train_loss': '2.79542'}; time used = 2.4771854877471924s
epoch 35: {'train_loss': '2.80286'}; time used = 2.429395914077759s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.393425703048706.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37527'}; time used = 1.0640077590942383s
epoch 10: {'train_loss': '1.31943'}; time used = 0.9602646827697754s
epoch 15: {'train_loss': '1.19888'}; time used = 1.027946949005127s
epoch 20: {'train_loss': '1.17722'}; time used = 1.0071544647216797s
epoch 25: {'train_loss': '0.98226'}; time used = 0.9709649085998535s
epoch 30: {'train_loss': '0.88744'}; time used = 0.9709935188293457s
epoch 35: {'train_loss': '0.80879'}; time used = 0.9593472480773926s
epoch 40: {'train_loss': '0.78523'}; time used = 0.973609447479248s
epoch 45: {'train_loss': '0.64944'}; time used = 0.9695718288421631s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.458298206329346.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30715'}; time used = 2.004202365875244s
epoch 10: {'train_loss': '1.22915'}; time used = 2.446378469467163s
epoch 15: {'train_loss': '1.19738'}; time used = 1.8455567359924316s
epoch 20: {'train_loss': '1.32404'}; time used = 1.9784929752349854s
epoch 25: {'train_loss': '1.28353'}; time used = 2.16348934173584s
epoch 30: {'train_loss': '1.23218'}; time used = 1.9670546054840088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.891511917114258.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6778438030560272, 'samples': 0.6811594202898551, 'weighted': 0.68021210108019, 'accuracy': 0.6811594202898551}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.84522'}; time used = 1.0013837814331055s
epoch 10: {'train_loss': '0.57955'}; time used = 1.0114357471466064s
epoch 15: {'train_loss': '0.36531'}; time used = 1.0398614406585693s
epoch 20: {'train_loss': '0.27277'}; time used = 1.0727880001068115s
epoch 25: {'train_loss': '0.25718'}; time used = 1.137660026550293s
epoch 30: {'train_loss': '0.20049'}; time used = 3.048457145690918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.351992130279541.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.11455'}; time used = 1.7052638530731201s
epoch 10: {'train_loss': '1.00920'}; time used = 2.1425058841705322s
epoch 15: {'train_loss': '0.86030'}; time used = 2.042773723602295s
epoch 20: {'train_loss': '0.57960'}; time used = 1.7207136154174805s
epoch 25: {'train_loss': '0.27600'}; time used = 1.818030595779419s
epoch 30: {'train_loss': '0.13117'}; time used = 1.653888463973999s
epoch 35: {'train_loss': '0.08214'}; time used = 1.9048926830291748s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.091439485549927.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.596679915828852, 'samples': 0.6376811594202898, 'weighted': 0.6059983802814516, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11480'}; time used = 1.5373101234436035s
epoch 10: {'train_loss': '2.77624'}; time used = 1.4248132705688477s
epoch 15: {'train_loss': '2.78143'}; time used = 1.4382219314575195s
epoch 20: {'train_loss': '2.79471'}; time used = 1.427389144897461s
epoch 25: {'train_loss': '2.79812'}; time used = 1.3787896633148193s
epoch 30: {'train_loss': '2.79336'}; time used = 1.4165313243865967s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.796319484710693.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39021'}; time used = 1.2000422477722168s
epoch 10: {'train_loss': '1.36489'}; time used = 1.2161357402801514s
epoch 15: {'train_loss': '1.28931'}; time used = 1.08976411819458s
epoch 20: {'train_loss': '1.27973'}; time used = 1.0273170471191406s
epoch 25: {'train_loss': '1.16847'}; time used = 1.0302395820617676s
epoch 30: {'train_loss': '1.21232'}; time used = 1.6387791633605957s
epoch 35: {'train_loss': '1.27352'}; time used = 1.5705866813659668s
epoch 40: {'train_loss': '1.17365'}; time used = 1.010467290878296s
epoch 45: {'train_loss': '1.01424'}; time used = 1.010042428970337s
epoch 50: {'train_loss': '1.12781'}; time used = 1.0704421997070312s
epoch 55: {'train_loss': '1.15078'}; time used = 1.138429880142212s
epoch 60: {'train_loss': '1.16095'}; time used = 1.0067996978759766s
epoch 65: {'train_loss': '0.88295'}; time used = 1.0474131107330322s
epoch 70: {'train_loss': '1.27561'}; time used = 1.0153000354766846s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.402260065078735.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.74521'}; time used = 2.1113345623016357s
epoch 10: {'train_loss': '2.70454'}; time used = 2.1038100719451904s
epoch 15: {'train_loss': '2.69060'}; time used = 2.0186827182769775s
epoch 20: {'train_loss': '2.67094'}; time used = 2.0382819175720215s
epoch 25: {'train_loss': '2.65471'}; time used = 2.1226327419281006s
epoch 30: {'train_loss': '2.64559'}; time used = 2.1019246578216553s
epoch 35: {'train_loss': '2.64396'}; time used = 2.0412790775299072s
epoch 40: {'train_loss': '2.64375'}; time used = 1.8348972797393799s
epoch 45: {'train_loss': '2.64155'}; time used = 1.7872958183288574s
epoch 50: {'train_loss': '2.63009'}; time used = 1.6498537063598633s
epoch 55: {'train_loss': '2.63109'}; time used = 1.8585216999053955s
epoch 60: {'train_loss': '2.63574'}; time used = 1.695948839187622s
epoch 65: {'train_loss': '2.61995'}; time used = 1.6538541316986084s
epoch 70: {'train_loss': '2.60998'}; time used = 1.6352274417877197s
epoch 75: {'train_loss': '2.59960'}; time used = 1.8758835792541504s
epoch 80: {'train_loss': '2.59483'}; time used = 1.7763314247131348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.35067319869995.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35885'}; time used = 2.3183791637420654s
epoch 10: {'train_loss': '1.29221'}; time used = 2.0608150959014893s
epoch 15: {'train_loss': '1.30796'}; time used = 1.8305892944335938s
epoch 20: {'train_loss': '1.40529'}; time used = 2.043492317199707s
epoch 25: {'train_loss': '1.35095'}; time used = 1.9935147762298584s
epoch 30: {'train_loss': '1.31801'}; time used = 2.1047842502593994s
epoch 35: {'train_loss': '1.30219'}; time used = 2.148148775100708s
epoch 40: {'train_loss': '1.27229'}; time used = 3.6238811016082764s
epoch 45: {'train_loss': '1.35604'}; time used = 3.6323328018188477s
epoch 50: {'train_loss': '1.21462'}; time used = 2.554927110671997s
epoch 55: {'train_loss': '1.23795'}; time used = 1.884467363357544s
epoch 60: {'train_loss': '1.27194'}; time used = 2.071977376937866s
epoch 65: {'train_loss': '1.32857'}; time used = 1.7772102355957031s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.774250984191895.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.49818181818181817, 'samples': 0.5362318840579711, 'weighted': 0.5081949934123847, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82570'}; time used = 2.5616793632507324s
epoch 10: {'train_loss': '2.78273'}; time used = 2.4871621131896973s
epoch 15: {'train_loss': '2.77329'}; time used = 2.7294483184814453s
epoch 20: {'train_loss': '2.77776'}; time used = 2.587761878967285s
epoch 25: {'train_loss': '2.77458'}; time used = 2.7699499130249023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.182422876358032.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38848'}; time used = 1.1793677806854248s
epoch 10: {'train_loss': '1.40755'}; time used = 1.048360824584961s
epoch 15: {'train_loss': '1.26046'}; time used = 1.1095211505889893s
epoch 20: {'train_loss': '1.22712'}; time used = 1.0379478931427002s
epoch 25: {'train_loss': '0.78612'}; time used = 1.1819593906402588s
epoch 30: {'train_loss': '0.77912'}; time used = 1.2771832942962646s
epoch 35: {'train_loss': '0.91096'}; time used = 1.8827252388000488s
epoch 40: {'train_loss': '0.92610'}; time used = 1.3291492462158203s
epoch 45: {'train_loss': '0.75962'}; time used = 0.9923489093780518s
epoch 50: {'train_loss': '0.77200'}; time used = 0.9976184368133545s
epoch 55: {'train_loss': '0.52696'}; time used = 0.9982635974884033s
epoch 60: {'train_loss': '0.50343'}; time used = 1.0001869201660156s
epoch 65: {'train_loss': '0.31539'}; time used = 1.1785860061645508s
epoch 70: {'train_loss': '0.63847'}; time used = 0.9914031028747559s
epoch 75: {'train_loss': '0.23744'}; time used = 0.998382568359375s
epoch 80: {'train_loss': '0.87832'}; time used = 1.0273778438568115s
epoch 85: {'train_loss': '0.25318'}; time used = 1.0624008178710938s
epoch 90: {'train_loss': '0.37939'}; time used = 1.0557892322540283s
epoch 95: {'train_loss': '0.15846'}; time used = 2.523096799850464s
epoch 100: {'train_loss': '0.27266'}; time used = 1.0725810527801514s
epoch 105: {'train_loss': '0.18679'}; time used = 0.9631450176239014s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.709939002990723.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6607142857142858, 'samples': 0.6842105263157895, 'weighted': 0.6748120300751881, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12764'}; time used = 1.731126308441162s
epoch 10: {'train_loss': '0.90596'}; time used = 1.7144348621368408s
epoch 15: {'train_loss': '0.62179'}; time used = 1.7316813468933105s
epoch 20: {'train_loss': '0.31773'}; time used = 1.6919670104980469s
epoch 25: {'train_loss': '0.21748'}; time used = 1.8055830001831055s
epoch 30: {'train_loss': '0.17307'}; time used = 1.6306419372558594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.750795841217041.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.47550675675675674, 'samples': 0.4782608695652174, 'weighted': 0.4782608695652174, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.22909'}; time used = 1.152181625366211s
epoch 10: {'train_loss': '3.01154'}; time used = 1.0299928188323975s
epoch 15: {'train_loss': '2.89038'}; time used = 1.0157954692840576s
epoch 20: {'train_loss': '2.79573'}; time used = 1.0398156642913818s
epoch 25: {'train_loss': '2.66391'}; time used = 1.0766196250915527s
epoch 30: {'train_loss': '2.55488'}; time used = 1.0342357158660889s
epoch 35: {'train_loss': '2.44227'}; time used = 1.0342528820037842s
epoch 40: {'train_loss': '2.34257'}; time used = 1.0265791416168213s
epoch 45: {'train_loss': '2.31452'}; time used = 1.0374159812927246s
epoch 50: {'train_loss': '2.30848'}; time used = 1.0358178615570068s
epoch 55: {'train_loss': '2.25327'}; time used = 1.0297448635101318s
epoch 60: {'train_loss': '2.21803'}; time used = 1.1154496669769287s
epoch 65: {'train_loss': '2.20922'}; time used = 1.0562124252319336s
epoch 70: {'train_loss': '2.21013'}; time used = 1.0317399501800537s
epoch 75: {'train_loss': '2.13423'}; time used = 1.0319633483886719s
epoch 80: {'train_loss': '2.11624'}; time used = 1.120983600616455s
epoch 85: {'train_loss': '2.13605'}; time used = 1.0401251316070557s
epoch 90: {'train_loss': '2.10845'}; time used = 1.1082513332366943s
epoch 95: {'train_loss': '2.15137'}; time used = 1.0459003448486328s
epoch 100: {'train_loss': '2.11018'}; time used = 1.0363686084747314s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.8620662689209.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83754'}; time used = 1.3755173683166504s
epoch 10: {'train_loss': '2.80317'}; time used = 1.2339649200439453s
epoch 15: {'train_loss': '2.79028'}; time used = 1.1988389492034912s
epoch 20: {'train_loss': '2.78258'}; time used = 1.2966158390045166s
epoch 25: {'train_loss': '2.77610'}; time used = 1.2728049755096436s
epoch 30: {'train_loss': '2.77097'}; time used = 1.15781831741333s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.812596082687378.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72829'}; time used = 1.5816712379455566s
epoch 10: {'train_loss': '2.68594'}; time used = 1.925992488861084s
epoch 15: {'train_loss': '2.41637'}; time used = 1.2458703517913818s
epoch 20: {'train_loss': '2.42279'}; time used = 1.2318639755249023s
epoch 25: {'train_loss': '2.12547'}; time used = 1.2242145538330078s
epoch 30: {'train_loss': '2.16364'}; time used = 1.4856040477752686s
epoch 35: {'train_loss': '1.99186'}; time used = 1.4231321811676025s
epoch 40: {'train_loss': '1.98199'}; time used = 1.4149959087371826s
epoch 45: {'train_loss': '1.95572'}; time used = 1.4506468772888184s
epoch 50: {'train_loss': '1.94207'}; time used = 1.4802660942077637s
epoch 55: {'train_loss': '1.85506'}; time used = 1.5031075477600098s
epoch 60: {'train_loss': '2.27295'}; time used = 1.5900232791900635s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.50746250152588.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.84946'}; time used = 1.7568440437316895s
epoch 10: {'train_loss': '2.78129'}; time used = 1.6566743850708008s
epoch 15: {'train_loss': '2.75771'}; time used = 1.6938011646270752s
epoch 20: {'train_loss': '2.72970'}; time used = 1.7662150859832764s
epoch 25: {'train_loss': '2.70227'}; time used = 1.7787055969238281s
epoch 30: {'train_loss': '2.68178'}; time used = 1.9282238483428955s
epoch 35: {'train_loss': '2.66206'}; time used = 1.9694147109985352s
epoch 40: {'train_loss': '2.64047'}; time used = 1.8979060649871826s
epoch 45: {'train_loss': '2.61025'}; time used = 1.8662021160125732s
epoch 50: {'train_loss': '2.58040'}; time used = 1.8541488647460938s
epoch 55: {'train_loss': '2.58311'}; time used = 1.9325129985809326s
epoch 60: {'train_loss': '2.56349'}; time used = 1.8220922946929932s
epoch 65: {'train_loss': '2.54872'}; time used = 1.5776965618133545s
epoch 70: {'train_loss': '2.51847'}; time used = 1.578852891921997s
epoch 75: {'train_loss': '2.50637'}; time used = 1.5406677722930908s
epoch 80: {'train_loss': '2.47841'}; time used = 1.6342706680297852s
epoch 85: {'train_loss': '2.48278'}; time used = 1.5394279956817627s
epoch 90: {'train_loss': '2.45379'}; time used = 1.7207236289978027s
epoch 95: {'train_loss': '2.46509'}; time used = 1.5939927101135254s
epoch 100: {'train_loss': '2.43924'}; time used = 1.539198637008667s
epoch 105: {'train_loss': '2.44387'}; time used = 1.6219232082366943s
epoch 110: {'train_loss': '2.43407'}; time used = 1.5513396263122559s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.67329120635986.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.64258'}; time used = 1.2637660503387451s
epoch 10: {'train_loss': '2.52905'}; time used = 1.1036114692687988s
epoch 15: {'train_loss': '2.46733'}; time used = 1.1489152908325195s
epoch 20: {'train_loss': '2.37819'}; time used = 1.1178054809570312s
epoch 25: {'train_loss': '2.33950'}; time used = 1.1329851150512695s
epoch 30: {'train_loss': '2.28693'}; time used = 1.1078166961669922s
epoch 35: {'train_loss': '2.25416'}; time used = 1.1010518074035645s
epoch 40: {'train_loss': '2.20756'}; time used = 1.1191306114196777s
epoch 45: {'train_loss': '2.17514'}; time used = 1.1071436405181885s
epoch 50: {'train_loss': '2.16648'}; time used = 1.0990612506866455s
epoch 55: {'train_loss': '2.14001'}; time used = 1.1153888702392578s
epoch 60: {'train_loss': '2.11834'}; time used = 1.2523293495178223s
epoch 65: {'train_loss': '2.12035'}; time used = 1.1634621620178223s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.860971450805664.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83360'}; time used = 5.034794092178345s
epoch 10: {'train_loss': '2.80314'}; time used = 7.686506748199463s
epoch 15: {'train_loss': '2.78897'}; time used = 4.743961572647095s
epoch 20: {'train_loss': '2.77956'}; time used = 4.676764249801636s
epoch 25: {'train_loss': '2.77405'}; time used = 6.358738422393799s
epoch 30: {'train_loss': '2.77181'}; time used = 5.367603778839111s
epoch 35: {'train_loss': '2.77119'}; time used = 4.80405855178833s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 71.12013626098633.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.72997299729973, 'samples': 0.73, 'weighted': 0.72991899189919, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79900'}; time used = 1.7014086246490479s
epoch 10: {'train_loss': '2.69532'}; time used = 1.6842844486236572s
epoch 15: {'train_loss': '2.67727'}; time used = 1.6298449039459229s
epoch 20: {'train_loss': '2.62629'}; time used = 1.629201889038086s
epoch 25: {'train_loss': '2.60609'}; time used = 1.7521207332611084s
epoch 30: {'train_loss': '2.57027'}; time used = 1.6421890258789062s
epoch 35: {'train_loss': '2.54168'}; time used = 1.6916453838348389s
epoch 40: {'train_loss': '2.50668'}; time used = 1.6821839809417725s
epoch 45: {'train_loss': '2.48082'}; time used = 1.833745002746582s
epoch 50: {'train_loss': '2.42168'}; time used = 1.7790069580078125s
epoch 55: {'train_loss': '2.51380'}; time used = 1.7610759735107422s
epoch 60: {'train_loss': '2.45921'}; time used = 1.6802194118499756s
epoch 65: {'train_loss': '2.41981'}; time used = 2.8547723293304443s
epoch 70: {'train_loss': '2.35255'}; time used = 1.661151647567749s
epoch 75: {'train_loss': '2.29053'}; time used = 1.6870794296264648s
epoch 80: {'train_loss': '2.29748'}; time used = 1.9386088848114014s
epoch 85: {'train_loss': '2.26417'}; time used = 1.7006230354309082s
epoch 90: {'train_loss': '2.33775'}; time used = 1.6973700523376465s
epoch 95: {'train_loss': '2.27256'}; time used = 1.6881065368652344s
epoch 100: {'train_loss': '2.19757'}; time used = 1.6879148483276367s
epoch 105: {'train_loss': '2.18386'}; time used = 1.7352921962738037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.75731706619263.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37758'}; time used = 1.57301926612854s
epoch 10: {'train_loss': '1.34552'}; time used = 1.3731658458709717s
epoch 15: {'train_loss': '1.27922'}; time used = 1.4349350929260254s
epoch 20: {'train_loss': '1.27377'}; time used = 2.5093891620635986s
epoch 25: {'train_loss': '1.16515'}; time used = 2.626903533935547s
epoch 30: {'train_loss': '1.09699'}; time used = 2.572939395904541s
epoch 35: {'train_loss': '1.04345'}; time used = 2.415808916091919s
epoch 40: {'train_loss': '1.02374'}; time used = 1.9901492595672607s
epoch 45: {'train_loss': '0.72243'}; time used = 1.3325631618499756s
epoch 50: {'train_loss': '1.41757'}; time used = 1.3526976108551025s
epoch 55: {'train_loss': '1.37321'}; time used = 1.3071200847625732s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.977955102920532.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7913725490196077, 'samples': 0.8157894736842105, 'weighted': 0.8026418988648091, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79947'}; time used = 1.9946234226226807s
epoch 10: {'train_loss': '2.77243'}; time used = 1.844515323638916s
epoch 15: {'train_loss': '2.75450'}; time used = 2.078526258468628s
epoch 20: {'train_loss': '2.75006'}; time used = 2.035109519958496s
epoch 25: {'train_loss': '2.74002'}; time used = 2.1915745735168457s
epoch 30: {'train_loss': '2.72541'}; time used = 1.7659032344818115s
epoch 35: {'train_loss': '2.71099'}; time used = 1.8165929317474365s
epoch 40: {'train_loss': '2.67997'}; time used = 1.7300007343292236s
epoch 45: {'train_loss': '2.63793'}; time used = 1.7401642799377441s
epoch 50: {'train_loss': '2.58077'}; time used = 1.718686580657959s
epoch 55: {'train_loss': '2.51879'}; time used = 1.8825156688690186s
epoch 60: {'train_loss': '2.50561'}; time used = 2.0127503871917725s
epoch 65: {'train_loss': '2.45689'}; time used = 1.9999711513519287s
epoch 70: {'train_loss': '2.44774'}; time used = 1.9248714447021484s
epoch 75: {'train_loss': '2.43902'}; time used = 1.7292239665985107s
epoch 80: {'train_loss': '2.41459'}; time used = 1.986412763595581s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.439799070358276.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38328'}; time used = 3.6865713596343994s
epoch 10: {'train_loss': '1.35535'}; time used = 4.158612489700317s
epoch 15: {'train_loss': '1.38333'}; time used = 2.551346778869629s
epoch 20: {'train_loss': '1.44637'}; time used = 2.319275379180908s
epoch 25: {'train_loss': '1.41364'}; time used = 2.4877946376800537s
epoch 30: {'train_loss': '1.36690'}; time used = 2.2599406242370605s
epoch 35: {'train_loss': '1.28694'}; time used = 2.46372389793396s
epoch 40: {'train_loss': '1.12915'}; time used = 2.927530288696289s
epoch 45: {'train_loss': '1.01269'}; time used = 4.149785041809082s
epoch 50: {'train_loss': '0.70083'}; time used = 4.204726696014404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.93721389770508.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87262'}; time used = 1.8528382778167725s
epoch 10: {'train_loss': '2.82200'}; time used = 2.0246176719665527s
epoch 15: {'train_loss': '2.78814'}; time used = 2.2634754180908203s
epoch 20: {'train_loss': '2.77074'}; time used = 2.032212972640991s
epoch 25: {'train_loss': '2.77031'}; time used = 2.0193915367126465s
epoch 30: {'train_loss': '2.76924'}; time used = 1.8496296405792236s
epoch 35: {'train_loss': '2.76511'}; time used = 1.920863389968872s
epoch 40: {'train_loss': '2.76486'}; time used = 1.9342091083526611s
epoch 45: {'train_loss': '2.76368'}; time used = 1.808476448059082s
epoch 50: {'train_loss': '2.76081'}; time used = 2.1629199981689453s
epoch 55: {'train_loss': '2.75997'}; time used = 2.0952775478363037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.624618530273438.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.47550675675675674, 'samples': 0.4782608695652174, 'weighted': 0.4782608695652174, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29328'}; time used = 2.142888069152832s
epoch 10: {'train_loss': '1.19164'}; time used = 2.1004486083984375s
epoch 15: {'train_loss': '1.02558'}; time used = 2.323883056640625s
epoch 20: {'train_loss': '0.69132'}; time used = 2.1817338466644287s
epoch 25: {'train_loss': '0.65252'}; time used = 2.241706371307373s
epoch 30: {'train_loss': '0.33506'}; time used = 2.152822971343994s
epoch 35: {'train_loss': '0.28902'}; time used = 2.210785150527954s
epoch 40: {'train_loss': '0.06831'}; time used = 2.1768407821655273s
epoch 45: {'train_loss': '0.09289'}; time used = 2.0246434211730957s
epoch 50: {'train_loss': '0.03978'}; time used = 2.3067421913146973s
epoch 55: {'train_loss': '0.02387'}; time used = 3.3984384536743164s
epoch 60: {'train_loss': '0.02264'}; time used = 3.288456439971924s
epoch 65: {'train_loss': '0.01579'}; time used = 2.730630397796631s
epoch 70: {'train_loss': '0.01555'}; time used = 2.0769450664520264s
epoch 75: {'train_loss': '0.01028'}; time used = 1.9705290794372559s
epoch 80: {'train_loss': '0.07829'}; time used = 2.1012256145477295s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.37099647521973.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5740740740740741, 'samples': 0.5942028985507246, 'weighted': 0.5807836822329576, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90970'}; time used = 1.6654767990112305s
epoch 10: {'train_loss': '2.78845'}; time used = 1.6060702800750732s
epoch 15: {'train_loss': '2.75968'}; time used = 1.6300947666168213s
epoch 20: {'train_loss': '2.75066'}; time used = 1.6245906352996826s
epoch 25: {'train_loss': '2.75043'}; time used = 1.7174761295318604s
epoch 30: {'train_loss': '2.74069'}; time used = 1.623793601989746s
epoch 35: {'train_loss': '2.73466'}; time used = 1.6140034198760986s
epoch 40: {'train_loss': '2.73046'}; time used = 1.7145237922668457s
epoch 45: {'train_loss': '2.72147'}; time used = 1.6519584655761719s
epoch 50: {'train_loss': '2.71490'}; time used = 1.675844430923462s
epoch 55: {'train_loss': '2.71171'}; time used = 1.6205947399139404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.00550866127014.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79608'}; time used = 1.42173433303833s
epoch 10: {'train_loss': '2.74794'}; time used = 1.434654951095581s
epoch 15: {'train_loss': '2.75057'}; time used = 1.3380889892578125s
epoch 20: {'train_loss': '2.66941'}; time used = 1.366891622543335s
epoch 25: {'train_loss': '2.59107'}; time used = 1.4320428371429443s
epoch 30: {'train_loss': '2.44521'}; time used = 1.4217698574066162s
epoch 35: {'train_loss': '2.25162'}; time used = 1.2990000247955322s
epoch 40: {'train_loss': '2.14822'}; time used = 1.3615748882293701s
epoch 45: {'train_loss': '2.10668'}; time used = 1.3334450721740723s
epoch 50: {'train_loss': '2.09758'}; time used = 1.2485342025756836s
epoch 55: {'train_loss': '2.05220'}; time used = 1.2765684127807617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.771353006362915.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.42267'}; time used = 1.9708690643310547s
epoch 10: {'train_loss': '2.90726'}; time used = 2.0231754779815674s
epoch 15: {'train_loss': '2.88139'}; time used = 2.2027790546417236s
epoch 20: {'train_loss': '2.84371'}; time used = 2.1025662422180176s
epoch 25: {'train_loss': '2.79713'}; time used = 2.1366219520568848s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.72942304611206.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5174825174825175, 'samples': 0.6086956521739131, 'weighted': 0.53268470659775, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.27717'}; time used = 1.993049144744873s
epoch 10: {'train_loss': '1.18337'}; time used = 1.9412105083465576s
epoch 15: {'train_loss': '0.98781'}; time used = 2.090059995651245s
epoch 20: {'train_loss': '0.84072'}; time used = 2.0447444915771484s
epoch 25: {'train_loss': '0.77284'}; time used = 2.1336636543273926s
epoch 30: {'train_loss': '0.72078'}; time used = 2.5395288467407227s
epoch 35: {'train_loss': '0.78832'}; time used = 3.2268142700195312s
epoch 40: {'train_loss': '0.63504'}; time used = 3.42824125289917s
epoch 45: {'train_loss': '0.64450'}; time used = 2.0348386764526367s
epoch 50: {'train_loss': '0.60668'}; time used = 1.8954441547393799s
epoch 55: {'train_loss': '0.64694'}; time used = 1.8401172161102295s
epoch 60: {'train_loss': '0.57898'}; time used = 1.7940497398376465s
epoch 65: {'train_loss': '0.55716'}; time used = 1.756077527999878s
epoch 70: {'train_loss': '0.49127'}; time used = 1.7895560264587402s
epoch 75: {'train_loss': '0.54842'}; time used = 1.8248324394226074s
epoch 80: {'train_loss': '0.49371'}; time used = 1.9482970237731934s
epoch 85: {'train_loss': '0.46192'}; time used = 1.7532315254211426s
epoch 90: {'train_loss': '0.55016'}; time used = 1.7121262550354004s
epoch 95: {'train_loss': '0.58105'}; time used = 1.7377657890319824s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.70747375488281.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77252'}; time used = 1.2403461933135986s
epoch 10: {'train_loss': '2.78421'}; time used = 1.3476450443267822s
epoch 15: {'train_loss': '2.78172'}; time used = 1.1564445495605469s
epoch 20: {'train_loss': '2.77309'}; time used = 1.2181026935577393s
epoch 25: {'train_loss': '2.77593'}; time used = 1.15293550491333s
epoch 30: {'train_loss': '2.77341'}; time used = 1.1639719009399414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.750547885894775.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.592857142857143, 'samples': 0.6842105263157895, 'weighted': 0.6233082706766918, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38848'}; time used = 1.145880937576294s
epoch 10: {'train_loss': '1.40755'}; time used = 1.1133530139923096s
epoch 15: {'train_loss': '1.26046'}; time used = 1.0620522499084473s
epoch 20: {'train_loss': '1.22712'}; time used = 1.104705810546875s
epoch 25: {'train_loss': '0.78612'}; time used = 0.9880445003509521s
epoch 30: {'train_loss': '0.77912'}; time used = 0.9773406982421875s
epoch 35: {'train_loss': '0.91096'}; time used = 1.2086610794067383s
epoch 40: {'train_loss': '0.92610'}; time used = 1.2839293479919434s
epoch 45: {'train_loss': '0.75962'}; time used = 1.2516024112701416s
epoch 50: {'train_loss': '0.77200'}; time used = 1.245591640472412s
epoch 55: {'train_loss': '0.52696'}; time used = 1.2729675769805908s
epoch 60: {'train_loss': '0.50343'}; time used = 1.2180233001708984s
epoch 65: {'train_loss': '0.31539'}; time used = 1.2351012229919434s
epoch 70: {'train_loss': '0.63847'}; time used = 1.209418773651123s
epoch 75: {'train_loss': '0.23744'}; time used = 1.2546453475952148s
epoch 80: {'train_loss': '0.87832'}; time used = 0.9922585487365723s
epoch 85: {'train_loss': '0.25318'}; time used = 0.9686946868896484s
epoch 90: {'train_loss': '0.37939'}; time used = 0.9835391044616699s
epoch 95: {'train_loss': '0.15846'}; time used = 0.9818334579467773s
epoch 100: {'train_loss': '0.27266'}; time used = 0.9447147846221924s
epoch 105: {'train_loss': '0.18679'}; time used = 0.9788007736206055s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.009222984313965.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6607142857142858, 'samples': 0.6842105263157895, 'weighted': 0.6748120300751881, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16538'}; time used = 1.6048107147216797s
epoch 10: {'train_loss': '0.80631'}; time used = 1.2052414417266846s
epoch 15: {'train_loss': '0.63736'}; time used = 1.1782066822052002s
epoch 20: {'train_loss': '0.59167'}; time used = 1.1867148876190186s
epoch 25: {'train_loss': '0.50487'}; time used = 1.0491390228271484s
epoch 30: {'train_loss': '0.42211'}; time used = 1.2689759731292725s
epoch 35: {'train_loss': '0.37194'}; time used = 1.3656198978424072s
epoch 40: {'train_loss': '0.34072'}; time used = 2.0512282848358154s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.279439210891724.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.79721'}; time used = 1.1259346008300781s
epoch 10: {'train_loss': '0.53180'}; time used = 0.9462575912475586s
epoch 15: {'train_loss': '0.20311'}; time used = 0.9590117931365967s
epoch 20: {'train_loss': '0.40612'}; time used = 0.9472980499267578s
epoch 25: {'train_loss': '0.26432'}; time used = 0.9833455085754395s
epoch 30: {'train_loss': '0.17012'}; time used = 0.9952425956726074s
epoch 35: {'train_loss': '0.14694'}; time used = 1.008246898651123s
epoch 40: {'train_loss': '0.13860'}; time used = 0.9752743244171143s
epoch 45: {'train_loss': '0.11282'}; time used = 1.0797317028045654s
epoch 50: {'train_loss': '0.10487'}; time used = 0.9685723781585693s
epoch 55: {'train_loss': '0.08957'}; time used = 0.9623696804046631s
epoch 60: {'train_loss': '0.06163'}; time used = 1.0704636573791504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.286451816558838.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.41416'}; time used = 2.6847050189971924s
epoch 10: {'train_loss': '1.40068'}; time used = 2.344486713409424s
epoch 15: {'train_loss': '1.38468'}; time used = 2.5556416511535645s
epoch 20: {'train_loss': '1.39197'}; time used = 2.5844004154205322s
epoch 25: {'train_loss': '1.37672'}; time used = 2.4085500240325928s
epoch 30: {'train_loss': '1.38074'}; time used = 2.51165771484375s
epoch 35: {'train_loss': '1.41484'}; time used = 2.3184151649475098s
epoch 40: {'train_loss': '1.37316'}; time used = 1.3603286743164062s
epoch 45: {'train_loss': '1.35845'}; time used = 1.3670711517333984s
epoch 50: {'train_loss': '1.39424'}; time used = 1.2066388130187988s
epoch 55: {'train_loss': '1.36754'}; time used = 1.1633968353271484s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.654101848602295.
Training classifier using 80.00% nodes...
{'micro': 0.5263157894736842, 'macro': 0.4519230769230769, 'samples': 0.5263157894736842, 'weighted': 0.4838056680161944, 'accuracy': 0.5263157894736842}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82502'}; time used = 1.8284289836883545s
epoch 10: {'train_loss': '2.78188'}; time used = 3.2122373580932617s
epoch 15: {'train_loss': '2.76554'}; time used = 4.20832896232605s
epoch 20: {'train_loss': '2.76225'}; time used = 1.6931769847869873s
epoch 25: {'train_loss': '2.75238'}; time used = 1.6906049251556396s
epoch 30: {'train_loss': '2.74459'}; time used = 1.610389232635498s
epoch 35: {'train_loss': '2.73912'}; time used = 1.6360368728637695s
epoch 40: {'train_loss': '2.73133'}; time used = 1.6451866626739502s
epoch 45: {'train_loss': '2.72193'}; time used = 1.6175181865692139s
epoch 50: {'train_loss': '2.71528'}; time used = 1.6681034564971924s
epoch 55: {'train_loss': '2.71056'}; time used = 1.636488676071167s
epoch 60: {'train_loss': '2.69985'}; time used = 1.6384739875793457s
epoch 65: {'train_loss': '2.69696'}; time used = 1.6551666259765625s
epoch 70: {'train_loss': '2.70328'}; time used = 1.8304121494293213s
epoch 75: {'train_loss': '2.68964'}; time used = 1.6755847930908203s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.78942918777466.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.16912'}; time used = 1.858975887298584s
epoch 10: {'train_loss': '2.89063'}; time used = 1.897979974746704s
epoch 15: {'train_loss': '2.80269'}; time used = 1.9598777294158936s
epoch 20: {'train_loss': '2.77412'}; time used = 2.033700466156006s
epoch 25: {'train_loss': '2.78510'}; time used = 1.9131784439086914s
epoch 30: {'train_loss': '2.77404'}; time used = 1.8206257820129395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.297010898590088.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31251'}; time used = 1.274012565612793s
epoch 10: {'train_loss': '1.38854'}; time used = 1.1352458000183105s
epoch 15: {'train_loss': '1.38769'}; time used = 1.2138268947601318s
epoch 20: {'train_loss': '1.38730'}; time used = 1.1105599403381348s
epoch 25: {'train_loss': '1.38946'}; time used = 1.008784532546997s
epoch 30: {'train_loss': '1.38317'}; time used = 1.3529443740844727s
epoch 35: {'train_loss': '1.38619'}; time used = 1.174942970275879s
epoch 40: {'train_loss': '1.37177'}; time used = 1.217010498046875s
epoch 45: {'train_loss': '1.33104'}; time used = 1.4005975723266602s
epoch 50: {'train_loss': '1.37015'}; time used = 2.1507978439331055s
epoch 55: {'train_loss': '1.25482'}; time used = 2.2743217945098877s
epoch 60: {'train_loss': '1.36663'}; time used = 2.3340158462524414s
epoch 65: {'train_loss': '0.79326'}; time used = 2.294387102127075s
epoch 70: {'train_loss': '1.97307'}; time used = 1.9474780559539795s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.29967999458313.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39503'}; time used = 1.1257505416870117s
epoch 10: {'train_loss': '1.40859'}; time used = 1.0035600662231445s
epoch 15: {'train_loss': '1.37390'}; time used = 1.0545077323913574s
epoch 20: {'train_loss': '1.37298'}; time used = 1.1299021244049072s
epoch 25: {'train_loss': '1.31044'}; time used = 1.080369472503662s
epoch 30: {'train_loss': '1.26766'}; time used = 1.1235299110412598s
epoch 35: {'train_loss': '1.35387'}; time used = 0.9867680072784424s
epoch 40: {'train_loss': '1.31193'}; time used = 1.0181186199188232s
epoch 45: {'train_loss': '1.14860'}; time used = 1.9121918678283691s
epoch 50: {'train_loss': '1.23558'}; time used = 1.1511855125427246s
epoch 55: {'train_loss': '1.22039'}; time used = 0.9749531745910645s
epoch 60: {'train_loss': '1.25786'}; time used = 0.9461812973022461s
epoch 65: {'train_loss': '1.02455'}; time used = 0.9730916023254395s
epoch 70: {'train_loss': '1.24392'}; time used = 1.0168235301971436s
epoch 75: {'train_loss': '1.32010'}; time used = 0.927635908126831s
epoch 80: {'train_loss': '1.12827'}; time used = 0.9455232620239258s
epoch 85: {'train_loss': '1.22543'}; time used = 1.315143346786499s
epoch 90: {'train_loss': '1.06919'}; time used = 1.1770081520080566s
epoch 95: {'train_loss': '1.17619'}; time used = 1.1991770267486572s
epoch 100: {'train_loss': '1.14890'}; time used = 1.1511292457580566s
epoch 105: {'train_loss': '1.08823'}; time used = 0.9475762844085693s
epoch 110: {'train_loss': '1.20788'}; time used = 0.9700782299041748s
epoch 115: {'train_loss': '1.37560'}; time used = 1.1084814071655273s
epoch 120: {'train_loss': '1.29055'}; time used = 1.0481805801391602s
epoch 125: {'train_loss': '1.01007'}; time used = 1.021892786026001s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.42999005317688.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31246'}; time used = 1.1729018688201904s
epoch 10: {'train_loss': '1.31919'}; time used = 1.0912020206451416s
epoch 15: {'train_loss': '1.06267'}; time used = 1.0281379222869873s
epoch 20: {'train_loss': '1.18838'}; time used = 1.2157621383666992s
epoch 25: {'train_loss': '0.53300'}; time used = 1.1623404026031494s
epoch 30: {'train_loss': '0.46508'}; time used = 1.1031043529510498s
epoch 35: {'train_loss': '0.79758'}; time used = 1.1181364059448242s
epoch 40: {'train_loss': '0.70304'}; time used = 0.9994266033172607s
epoch 45: {'train_loss': '0.59081'}; time used = 0.9853863716125488s
epoch 50: {'train_loss': '0.47339'}; time used = 1.0029559135437012s
epoch 55: {'train_loss': '0.27423'}; time used = 1.009089469909668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.822195291519165.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38294'}; time used = 1.8333230018615723s
epoch 10: {'train_loss': '1.19155'}; time used = 1.9845874309539795s
epoch 15: {'train_loss': '0.90465'}; time used = 1.9723305702209473s
epoch 20: {'train_loss': '0.95324'}; time used = 1.947601079940796s
epoch 25: {'train_loss': '0.59466'}; time used = 1.955240249633789s
epoch 30: {'train_loss': '0.40423'}; time used = 1.9876623153686523s
epoch 35: {'train_loss': '0.65533'}; time used = 1.9744458198547363s
epoch 40: {'train_loss': '0.49168'}; time used = 1.8173415660858154s
epoch 45: {'train_loss': '0.13300'}; time used = 1.9879481792449951s
epoch 50: {'train_loss': '0.06316'}; time used = 2.193966865539551s
epoch 55: {'train_loss': '0.00189'}; time used = 1.8425264358520508s
epoch 60: {'train_loss': '0.00095'}; time used = 1.7906622886657715s
epoch 65: {'train_loss': '0.00084'}; time used = 1.7639248371124268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.515003442764282.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77483'}; time used = 1.544142723083496s
epoch 10: {'train_loss': '2.77444'}; time used = 1.542478322982788s
epoch 15: {'train_loss': '2.78077'}; time used = 1.3371312618255615s
epoch 20: {'train_loss': '2.77432'}; time used = 1.3166658878326416s
epoch 25: {'train_loss': '2.77300'}; time used = 1.2914435863494873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.328083276748657.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78656'}; time used = 2.035132646560669s
epoch 10: {'train_loss': '2.77481'}; time used = 1.70810866355896s
epoch 15: {'train_loss': '2.77679'}; time used = 2.0882372856140137s
epoch 20: {'train_loss': '2.77283'}; time used = 1.735266923904419s
epoch 25: {'train_loss': '2.76844'}; time used = 1.823085069656372s
epoch 30: {'train_loss': '2.76223'}; time used = 1.7583935260772705s
epoch 35: {'train_loss': '2.75985'}; time used = 1.7643487453460693s
epoch 40: {'train_loss': '2.75658'}; time used = 1.8732619285583496s
epoch 45: {'train_loss': '2.75558'}; time used = 1.7184982299804688s
epoch 50: {'train_loss': '2.75321'}; time used = 1.9472384452819824s
epoch 55: {'train_loss': '2.75750'}; time used = 1.949782133102417s
epoch 60: {'train_loss': '2.75046'}; time used = 1.8370556831359863s
epoch 65: {'train_loss': '2.73482'}; time used = 1.9108531475067139s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.794811964035034.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4189473684210526, 'samples': 0.5362318840579711, 'weighted': 0.4378642257818459, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03586'}; time used = 1.7027428150177002s
epoch 10: {'train_loss': '0.04404'}; time used = 1.698211431503296s
epoch 15: {'train_loss': '0.05937'}; time used = 1.79197359085083s
epoch 20: {'train_loss': '0.00098'}; time used = 1.6152820587158203s
epoch 25: {'train_loss': '0.02823'}; time used = 1.6847915649414062s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.454188585281372.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78311'}; time used = 1.8420703411102295s
epoch 10: {'train_loss': '2.76510'}; time used = 1.7677562236785889s
epoch 15: {'train_loss': '2.75637'}; time used = 1.5834355354309082s
epoch 20: {'train_loss': '2.73715'}; time used = 1.6242899894714355s
epoch 25: {'train_loss': '2.69785'}; time used = 1.7401556968688965s
epoch 30: {'train_loss': '2.66609'}; time used = 1.6157035827636719s
epoch 35: {'train_loss': '2.62386'}; time used = 2.5729482173919678s
epoch 40: {'train_loss': '2.54524'}; time used = 2.5305750370025635s
epoch 45: {'train_loss': '2.50179'}; time used = 1.6201171875s
epoch 50: {'train_loss': '2.42941'}; time used = 1.7286577224731445s
epoch 55: {'train_loss': '2.45753'}; time used = 1.6289219856262207s
epoch 60: {'train_loss': '2.42356'}; time used = 1.5558362007141113s
epoch 65: {'train_loss': '2.35887'}; time used = 1.7651052474975586s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.0382661819458.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.96246'}; time used = 1.9851291179656982s
epoch 10: {'train_loss': '2.85744'}; time used = 2.21761417388916s
epoch 15: {'train_loss': '2.77341'}; time used = 2.047010660171509s
epoch 20: {'train_loss': '2.76951'}; time used = 1.7431018352508545s
epoch 25: {'train_loss': '2.75747'}; time used = 1.9833340644836426s
epoch 30: {'train_loss': '2.74761'}; time used = 1.7314789295196533s
epoch 35: {'train_loss': '2.74271'}; time used = 1.7235991954803467s
epoch 40: {'train_loss': '2.72870'}; time used = 3.5953528881073s
epoch 45: {'train_loss': '2.71829'}; time used = 2.280184268951416s
epoch 50: {'train_loss': '2.70040'}; time used = 1.9008033275604248s
epoch 55: {'train_loss': '2.70087'}; time used = 1.9615638256072998s
epoch 60: {'train_loss': '2.68482'}; time used = 1.7844021320343018s
epoch 65: {'train_loss': '2.68175'}; time used = 1.723306655883789s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.989983797073364.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6133620689655173, 'samples': 0.6231884057971014, 'weighted': 0.6178285857071465, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.01652'}; time used = 1.9089159965515137s
epoch 10: {'train_loss': '2.83757'}; time used = 2.431664228439331s
epoch 15: {'train_loss': '2.78078'}; time used = 2.186966896057129s
epoch 20: {'train_loss': '2.77394'}; time used = 1.824286699295044s
epoch 25: {'train_loss': '2.77795'}; time used = 1.9871408939361572s
epoch 30: {'train_loss': '2.77080'}; time used = 1.8984920978546143s
epoch 35: {'train_loss': '2.77156'}; time used = 1.9062504768371582s
epoch 40: {'train_loss': '2.77179'}; time used = 1.8084492683410645s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.61669898033142.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04733'}; time used = 8.003031730651855s
epoch 10: {'train_loss': '2.77759'}; time used = 7.660901308059692s
epoch 15: {'train_loss': '2.81078'}; time used = 7.816246747970581s
epoch 20: {'train_loss': '2.79149'}; time used = 7.751372575759888s
epoch 25: {'train_loss': '2.77398'}; time used = 8.118852615356445s
epoch 30: {'train_loss': '2.77806'}; time used = 7.360782861709595s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.51576018333435.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.43783014101327455, 'samples': 0.5033333333333333, 'weighted': 0.4282545588167746, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89030'}; time used = 1.2043614387512207s
epoch 10: {'train_loss': '2.80199'}; time used = 1.104203462600708s
epoch 15: {'train_loss': '2.75900'}; time used = 1.1080296039581299s
epoch 20: {'train_loss': '2.72428'}; time used = 1.1148455142974854s
epoch 25: {'train_loss': '2.66586'}; time used = 1.0773134231567383s
epoch 30: {'train_loss': '2.51503'}; time used = 1.0833485126495361s
epoch 35: {'train_loss': '2.32517'}; time used = 1.0922377109527588s
epoch 40: {'train_loss': '2.34274'}; time used = 1.0863709449768066s
epoch 45: {'train_loss': '2.27146'}; time used = 1.0931978225708008s
epoch 50: {'train_loss': '2.27907'}; time used = 1.0937325954437256s
epoch 55: {'train_loss': '2.22829'}; time used = 1.1582117080688477s
epoch 60: {'train_loss': '2.19237'}; time used = 1.2476074695587158s
epoch 65: {'train_loss': '2.15818'}; time used = 1.1358397006988525s
epoch 70: {'train_loss': '2.17425'}; time used = 1.1109123229980469s
epoch 75: {'train_loss': '2.12082'}; time used = 1.1306507587432861s
epoch 80: {'train_loss': '2.10087'}; time used = 1.1365554332733154s
epoch 85: {'train_loss': '2.11900'}; time used = 1.1228818893432617s
epoch 90: {'train_loss': '2.09845'}; time used = 1.1103579998016357s
epoch 95: {'train_loss': '2.14619'}; time used = 1.1248867511749268s
epoch 100: {'train_loss': '2.14934'}; time used = 1.111703634262085s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.432602167129517.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39771'}; time used = 1.6981308460235596s
epoch 10: {'train_loss': '1.39384'}; time used = 1.4027087688446045s
epoch 15: {'train_loss': '1.38984'}; time used = 1.379845380783081s
epoch 20: {'train_loss': '1.38078'}; time used = 1.3845946788787842s
epoch 25: {'train_loss': '1.38439'}; time used = 1.425854206085205s
epoch 30: {'train_loss': '1.37395'}; time used = 1.7522432804107666s
epoch 35: {'train_loss': '1.33251'}; time used = 1.6330170631408691s
epoch 40: {'train_loss': '1.23351'}; time used = 1.7499885559082031s
epoch 45: {'train_loss': '1.08844'}; time used = 1.551293134689331s
epoch 50: {'train_loss': '0.91956'}; time used = 1.4820306301116943s
epoch 55: {'train_loss': '0.90855'}; time used = 1.6232099533081055s
epoch 60: {'train_loss': '0.91450'}; time used = 1.3771476745605469s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.09779715538025.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36008'}; time used = 1.1997911930084229s
epoch 10: {'train_loss': '1.39274'}; time used = 1.0863959789276123s
epoch 15: {'train_loss': '1.38434'}; time used = 1.136481523513794s
epoch 20: {'train_loss': '1.38662'}; time used = 1.2398476600646973s
epoch 25: {'train_loss': '1.38239'}; time used = 1.0918443202972412s
epoch 30: {'train_loss': '1.37403'}; time used = 1.20035982131958s
epoch 35: {'train_loss': '1.37820'}; time used = 1.1346633434295654s
epoch 40: {'train_loss': '1.32280'}; time used = 1.1100749969482422s
epoch 45: {'train_loss': '1.20744'}; time used = 1.1007981300354004s
epoch 50: {'train_loss': '1.26263'}; time used = 1.0978474617004395s
epoch 55: {'train_loss': '1.21836'}; time used = 1.0931177139282227s
epoch 60: {'train_loss': '1.33641'}; time used = 1.2234065532684326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.76423406600952.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7301136363636364, 'samples': 0.7368421052631579, 'weighted': 0.7368421052631579, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86515'}; time used = 1.1183059215545654s
epoch 10: {'train_loss': '2.77536'}; time used = 1.0204660892486572s
epoch 15: {'train_loss': '2.80412'}; time used = 1.014814853668213s
epoch 20: {'train_loss': '2.77917'}; time used = 1.0149309635162354s
epoch 25: {'train_loss': '2.77743'}; time used = 1.209672212600708s
epoch 30: {'train_loss': '2.77560'}; time used = 1.3319423198699951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.999783754348755.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.37059'}; time used = 1.0635783672332764s
epoch 10: {'train_loss': '1.49165'}; time used = 0.9647722244262695s
epoch 15: {'train_loss': '1.16142'}; time used = 1.0890750885009766s
epoch 20: {'train_loss': '1.23903'}; time used = 0.9617211818695068s
epoch 25: {'train_loss': '0.83761'}; time used = 1.081366777420044s
epoch 30: {'train_loss': '0.94551'}; time used = 0.9755058288574219s
epoch 35: {'train_loss': '0.86698'}; time used = 1.1040384769439697s
epoch 40: {'train_loss': '0.81250'}; time used = 0.9850168228149414s
epoch 45: {'train_loss': '0.54695'}; time used = 0.9317388534545898s
epoch 50: {'train_loss': '0.44530'}; time used = 1.007451057434082s
epoch 55: {'train_loss': '0.36628'}; time used = 1.0249946117401123s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.040955066680908.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83388'}; time used = 4.922210454940796s
epoch 10: {'train_loss': '2.80319'}; time used = 4.727163314819336s
epoch 15: {'train_loss': '2.78918'}; time used = 4.882763385772705s
epoch 20: {'train_loss': '2.78005'}; time used = 4.8398027420043945s
epoch 25: {'train_loss': '2.77487'}; time used = 4.80709981918335s
epoch 30: {'train_loss': '2.77287'}; time used = 4.606348037719727s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.29491209983826.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.30816'}; time used = 2.5139153003692627s
epoch 10: {'train_loss': '2.81393'}; time used = 2.4711525440216064s
epoch 15: {'train_loss': '2.77647'}; time used = 2.4366772174835205s
epoch 20: {'train_loss': '2.79667'}; time used = 2.4384422302246094s
epoch 25: {'train_loss': '2.77061'}; time used = 2.4783132076263428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.789238691329956.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.45238095238095244, 'samples': 0.5362318840579711, 'weighted': 0.46790890269151136, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86519'}; time used = 1.9222347736358643s
epoch 10: {'train_loss': '2.77937'}; time used = 1.8659124374389648s
epoch 15: {'train_loss': '2.74082'}; time used = 2.4383797645568848s
epoch 20: {'train_loss': '2.72254'}; time used = 1.6749799251556396s
epoch 25: {'train_loss': '2.69430'}; time used = 1.761016607284546s
epoch 30: {'train_loss': '2.67126'}; time used = 1.6603457927703857s
epoch 35: {'train_loss': '2.64400'}; time used = 1.8113820552825928s
epoch 40: {'train_loss': '2.59905'}; time used = 1.748319149017334s
epoch 45: {'train_loss': '2.58936'}; time used = 1.930262565612793s
epoch 50: {'train_loss': '2.56761'}; time used = 1.7160847187042236s
epoch 55: {'train_loss': '2.55491'}; time used = 1.9244678020477295s
epoch 60: {'train_loss': '2.53705'}; time used = 1.617884874343872s
epoch 65: {'train_loss': '2.50770'}; time used = 1.7323298454284668s
epoch 70: {'train_loss': '2.48219'}; time used = 3.2043774127960205s
epoch 75: {'train_loss': '2.45807'}; time used = 2.012338638305664s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.243826150894165.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.06592'}; time used = 1.8374347686767578s
epoch 10: {'train_loss': '0.59144'}; time used = 1.7121248245239258s
epoch 15: {'train_loss': '0.49598'}; time used = 1.844958782196045s
epoch 20: {'train_loss': '0.46348'}; time used = 1.7274541854858398s
epoch 25: {'train_loss': '0.51989'}; time used = 1.7916998863220215s
epoch 30: {'train_loss': '0.52461'}; time used = 1.750629186630249s
epoch 35: {'train_loss': '0.46421'}; time used = 1.8083586692810059s
epoch 40: {'train_loss': '0.51688'}; time used = 1.7331395149230957s
epoch 45: {'train_loss': '0.43264'}; time used = 1.9252715110778809s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.512874603271484.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6431034482758622, 'samples': 0.6521739130434783, 'weighted': 0.6472263868065968, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.75309'}; time used = 1.8147251605987549s
epoch 10: {'train_loss': '2.70498'}; time used = 1.7583959102630615s
epoch 15: {'train_loss': '2.68493'}; time used = 1.6222336292266846s
epoch 20: {'train_loss': '2.67567'}; time used = 1.6287477016448975s
epoch 25: {'train_loss': '2.66505'}; time used = 1.7111740112304688s
epoch 30: {'train_loss': '2.65623'}; time used = 1.7322628498077393s
epoch 35: {'train_loss': '2.65201'}; time used = 1.7771995067596436s
epoch 40: {'train_loss': '2.64643'}; time used = 1.811988115310669s
epoch 45: {'train_loss': '2.63679'}; time used = 1.9802849292755127s
epoch 50: {'train_loss': '2.61889'}; time used = 1.7734935283660889s
epoch 55: {'train_loss': '2.61318'}; time used = 1.9590630531311035s
epoch 60: {'train_loss': '2.61258'}; time used = 1.8545167446136475s
epoch 65: {'train_loss': '2.59518'}; time used = 1.8912427425384521s
epoch 70: {'train_loss': '2.58228'}; time used = 1.783947467803955s
epoch 75: {'train_loss': '2.57308'}; time used = 1.7268602848052979s
epoch 80: {'train_loss': '2.57022'}; time used = 1.827526569366455s
epoch 85: {'train_loss': '2.57221'}; time used = 1.7285664081573486s
epoch 90: {'train_loss': '2.57375'}; time used = 1.7668297290802002s
epoch 95: {'train_loss': '2.57092'}; time used = 1.8089511394500732s
epoch 100: {'train_loss': '2.56065'}; time used = 1.8110640048980713s
epoch 105: {'train_loss': '2.56250'}; time used = 1.8348476886749268s
epoch 110: {'train_loss': '2.55980'}; time used = 1.7645010948181152s
epoch 115: {'train_loss': '2.55710'}; time used = 1.775172472000122s
epoch 120: {'train_loss': '2.55960'}; time used = 1.8093295097351074s
epoch 125: {'train_loss': '2.55637'}; time used = 1.6581125259399414s
epoch 130: {'train_loss': '2.55960'}; time used = 2.033536434173584s
epoch 135: {'train_loss': '2.56188'}; time used = 2.0623831748962402s
epoch 140: {'train_loss': '2.55732'}; time used = 2.5008411407470703s
epoch 145: {'train_loss': '2.55025'}; time used = 1.622006893157959s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.676758766174316.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4987179487179487, 'samples': 0.5072463768115942, 'weighted': 0.5034559643255295, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.29648'}; time used = 8.238588809967041s
epoch 10: {'train_loss': '1.32545'}; time used = 9.218947887420654s
epoch 15: {'train_loss': '1.26097'}; time used = 7.739758729934692s
epoch 20: {'train_loss': '1.20575'}; time used = 7.558141469955444s
epoch 25: {'train_loss': '1.13392'}; time used = 12.085278749465942s
epoch 30: {'train_loss': '1.18674'}; time used = 7.972376346588135s
epoch 35: {'train_loss': '0.90045'}; time used = 7.5503623485565186s
epoch 40: {'train_loss': '1.15998'}; time used = 7.440963268280029s
epoch 45: {'train_loss': '1.09855'}; time used = 7.5698559284210205s
epoch 50: {'train_loss': '1.09578'}; time used = 8.974684715270996s
epoch 55: {'train_loss': '1.21930'}; time used = 10.154295682907104s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 118.83611464500427.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.47511814545547865, 'samples': 0.5166666666666667, 'weighted': 0.467581019002262, 'accuracy': 0.5166666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.64250'}; time used = 1.2629334926605225s
epoch 10: {'train_loss': '2.53954'}; time used = 1.0451388359069824s
epoch 15: {'train_loss': '2.41155'}; time used = 1.008042573928833s
epoch 20: {'train_loss': '2.33511'}; time used = 1.0066590309143066s
epoch 25: {'train_loss': '2.26618'}; time used = 1.006850242614746s
epoch 30: {'train_loss': '2.19837'}; time used = 1.106212854385376s
epoch 35: {'train_loss': '2.07141'}; time used = 1.1423461437225342s
epoch 40: {'train_loss': '1.91234'}; time used = 1.169257402420044s
epoch 45: {'train_loss': '2.19064'}; time used = 1.050093173980713s
epoch 50: {'train_loss': '2.24673'}; time used = 1.0171124935150146s
epoch 55: {'train_loss': '2.09891'}; time used = 1.1670689582824707s
epoch 60: {'train_loss': '2.07191'}; time used = 1.0546979904174805s
epoch 65: {'train_loss': '1.88851'}; time used = 0.984886646270752s
epoch 70: {'train_loss': '1.81986'}; time used = 1.1297385692596436s
epoch 75: {'train_loss': '1.66300'}; time used = 1.1690852642059326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.116450309753418.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.65811'}; time used = 1.183565378189087s
epoch 10: {'train_loss': '2.58695'}; time used = 0.9910986423492432s
epoch 15: {'train_loss': '2.25646'}; time used = 0.9071552753448486s
epoch 20: {'train_loss': '2.13339'}; time used = 0.8968193531036377s
epoch 25: {'train_loss': '2.07305'}; time used = 0.9864647388458252s
epoch 30: {'train_loss': '1.99645'}; time used = 1.0695512294769287s
epoch 35: {'train_loss': '1.92759'}; time used = 1.0633606910705566s
epoch 40: {'train_loss': '1.89970'}; time used = 1.0401206016540527s
epoch 45: {'train_loss': '1.88881'}; time used = 1.0317494869232178s
epoch 50: {'train_loss': '1.87751'}; time used = 1.0293796062469482s
epoch 55: {'train_loss': '1.87424'}; time used = 0.9346342086791992s
epoch 60: {'train_loss': '1.96930'}; time used = 0.9584081172943115s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.193284273147583.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78143'}; time used = 1.208406686782837s
epoch 10: {'train_loss': '2.77906'}; time used = 1.2068195343017578s
epoch 15: {'train_loss': '2.77826'}; time used = 1.188744068145752s
epoch 20: {'train_loss': '2.77389'}; time used = 1.059537649154663s
epoch 25: {'train_loss': '2.77074'}; time used = 1.0140681266784668s
epoch 30: {'train_loss': '2.77002'}; time used = 1.0962903499603271s
epoch 35: {'train_loss': '2.76870'}; time used = 1.115180253982544s
epoch 40: {'train_loss': '2.76652'}; time used = 1.0524656772613525s
epoch 45: {'train_loss': '2.76548'}; time used = 1.062720775604248s
epoch 50: {'train_loss': '2.76210'}; time used = 1.0687298774719238s
epoch 55: {'train_loss': '2.76120'}; time used = 1.2705399990081787s
epoch 60: {'train_loss': '2.76214'}; time used = 1.994065761566162s
epoch 65: {'train_loss': '2.76351'}; time used = 1.0200772285461426s
epoch 70: {'train_loss': '2.75725'}; time used = 0.9999313354492188s
epoch 75: {'train_loss': '2.75871'}; time used = 1.0171964168548584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.87462091445923.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89985'}; time used = 1.9299161434173584s
epoch 10: {'train_loss': '2.79227'}; time used = 1.9110829830169678s
epoch 15: {'train_loss': '2.78223'}; time used = 1.8106434345245361s
epoch 20: {'train_loss': '2.77880'}; time used = 1.9955339431762695s
epoch 25: {'train_loss': '2.77572'}; time used = 2.0333025455474854s
epoch 30: {'train_loss': '2.77258'}; time used = 1.9934816360473633s
epoch 35: {'train_loss': '2.76789'}; time used = 1.855992317199707s
epoch 40: {'train_loss': '2.76506'}; time used = 3.2290830612182617s
epoch 45: {'train_loss': '2.75922'}; time used = 3.5369598865509033s
epoch 50: {'train_loss': '2.75263'}; time used = 3.851362943649292s
epoch 55: {'train_loss': '2.73020'}; time used = 2.2104690074920654s
epoch 60: {'train_loss': '2.67237'}; time used = 1.9673986434936523s
epoch 65: {'train_loss': '2.64517'}; time used = 1.872817039489746s
epoch 70: {'train_loss': '2.61194'}; time used = 1.9434404373168945s
epoch 75: {'train_loss': '2.52772'}; time used = 1.8826217651367188s
epoch 80: {'train_loss': '2.50406'}; time used = 1.983492374420166s
epoch 85: {'train_loss': '2.51574'}; time used = 1.8245387077331543s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.263383626937866.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.518095238095238, 'samples': 0.5217391304347826, 'weighted': 0.5211318150448585, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.88932'}; time used = 1.0744454860687256s
epoch 10: {'train_loss': '2.78692'}; time used = 1.0724031925201416s
epoch 15: {'train_loss': '2.77250'}; time used = 0.9727146625518799s
epoch 20: {'train_loss': '2.77797'}; time used = 0.9595756530761719s
epoch 25: {'train_loss': '2.77668'}; time used = 0.9361748695373535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.21404480934143.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.30653'}; time used = 1.9427778720855713s
epoch 10: {'train_loss': '1.23310'}; time used = 1.864914894104004s
epoch 15: {'train_loss': '1.21731'}; time used = 1.8806076049804688s
epoch 20: {'train_loss': '1.31929'}; time used = 1.9048852920532227s
epoch 25: {'train_loss': '1.28410'}; time used = 1.9722461700439453s
epoch 30: {'train_loss': '1.20863'}; time used = 1.850928783416748s
epoch 35: {'train_loss': '1.23904'}; time used = 1.9342269897460938s
epoch 40: {'train_loss': '1.19874'}; time used = 4.167474746704102s
epoch 45: {'train_loss': '1.27081'}; time used = 1.9704365730285645s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.809590101242065.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75752'}; time used = 1.1005463600158691s
epoch 10: {'train_loss': '2.56929'}; time used = 1.0087244510650635s
epoch 15: {'train_loss': '2.41551'}; time used = 0.991175651550293s
epoch 20: {'train_loss': '2.33082'}; time used = 0.9886748790740967s
epoch 25: {'train_loss': '2.21407'}; time used = 1.0516021251678467s
epoch 30: {'train_loss': '2.01489'}; time used = 1.0836284160614014s
epoch 35: {'train_loss': '1.78391'}; time used = 1.0124642848968506s
epoch 40: {'train_loss': '1.96970'}; time used = 1.024731159210205s
epoch 45: {'train_loss': '1.74596'}; time used = 1.0263433456420898s
epoch 50: {'train_loss': '1.78368'}; time used = 1.1264729499816895s
epoch 55: {'train_loss': '1.67518'}; time used = 1.0367765426635742s
epoch 60: {'train_loss': '1.62689'}; time used = 1.2316744327545166s
epoch 65: {'train_loss': '1.57324'}; time used = 1.1353554725646973s
epoch 70: {'train_loss': '1.53790'}; time used = 0.9926083087921143s
epoch 75: {'train_loss': '1.45414'}; time used = 1.009037733078003s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.53768229484558.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.35576'}; time used = 1.143517255783081s
epoch 10: {'train_loss': '1.34995'}; time used = 1.180771827697754s
epoch 15: {'train_loss': '0.63964'}; time used = 1.051830530166626s
epoch 20: {'train_loss': '0.67049'}; time used = 1.0540189743041992s
epoch 25: {'train_loss': '0.17568'}; time used = 1.005575180053711s
epoch 30: {'train_loss': '0.24515'}; time used = 0.9734649658203125s
epoch 35: {'train_loss': '0.16505'}; time used = 0.9740340709686279s
epoch 40: {'train_loss': '0.21751'}; time used = 0.9610469341278076s
epoch 45: {'train_loss': '0.05346'}; time used = 0.9589483737945557s
epoch 50: {'train_loss': '0.04718'}; time used = 0.9446685314178467s
epoch 55: {'train_loss': '0.00805'}; time used = 0.9714536666870117s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.211516380310059.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86171'}; time used = 1.8628735542297363s
epoch 10: {'train_loss': '2.79330'}; time used = 1.6814165115356445s
epoch 15: {'train_loss': '2.77702'}; time used = 1.7041988372802734s
epoch 20: {'train_loss': '2.77244'}; time used = 1.7333927154541016s
epoch 25: {'train_loss': '2.77502'}; time used = 2.0247819423675537s
epoch 30: {'train_loss': '2.77445'}; time used = 1.717419147491455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.701649188995361.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90505'}; time used = 1.449753999710083s
epoch 10: {'train_loss': '2.79868'}; time used = 1.2236323356628418s
epoch 15: {'train_loss': '2.77298'}; time used = 1.4382472038269043s
epoch 20: {'train_loss': '2.78064'}; time used = 1.2061736583709717s
epoch 25: {'train_loss': '2.77820'}; time used = 1.1599540710449219s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.28610348701477.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.4317048853439681, 'samples': 0.6052631578947368, 'weighted': 0.48129296321561627, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83886'}; time used = 2.8918850421905518s
epoch 10: {'train_loss': '2.72187'}; time used = 2.7433555126190186s
epoch 15: {'train_loss': '2.70216'}; time used = 2.4662961959838867s
epoch 20: {'train_loss': '2.68259'}; time used = 1.6303107738494873s
epoch 25: {'train_loss': '2.65924'}; time used = 1.769521713256836s
epoch 30: {'train_loss': '2.64130'}; time used = 1.7869348526000977s
epoch 35: {'train_loss': '2.63267'}; time used = 1.6812644004821777s
epoch 40: {'train_loss': '2.61979'}; time used = 1.7161669731140137s
epoch 45: {'train_loss': '2.60730'}; time used = 1.638920783996582s
epoch 50: {'train_loss': '2.58314'}; time used = 1.7781627178192139s
epoch 55: {'train_loss': '2.59144'}; time used = 3.0137927532196045s
epoch 60: {'train_loss': '2.59856'}; time used = 3.1328072547912598s
epoch 65: {'train_loss': '2.58477'}; time used = 2.8321611881256104s
epoch 70: {'train_loss': '2.57313'}; time used = 1.9949285984039307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.37581539154053.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94453'}; time used = 1.0561871528625488s
epoch 10: {'train_loss': '2.82469'}; time used = 1.1187124252319336s
epoch 15: {'train_loss': '2.79906'}; time used = 0.9398603439331055s
epoch 20: {'train_loss': '2.78504'}; time used = 0.9311389923095703s
epoch 25: {'train_loss': '2.77826'}; time used = 1.0287396907806396s
epoch 30: {'train_loss': '2.77349'}; time used = 1.9881665706634521s
epoch 35: {'train_loss': '2.77233'}; time used = 2.4277822971343994s
epoch 40: {'train_loss': '2.77245'}; time used = 2.4473788738250732s
epoch 45: {'train_loss': '2.77292'}; time used = 2.3994088172912598s
epoch 50: {'train_loss': '2.77239'}; time used = 2.344501495361328s
epoch 55: {'train_loss': '2.77234'}; time used = 1.6709811687469482s
epoch 60: {'train_loss': '2.77180'}; time used = 1.036147117614746s
epoch 65: {'train_loss': '2.77206'}; time used = 1.1069865226745605s
epoch 70: {'train_loss': '2.77237'}; time used = 1.0312037467956543s
epoch 75: {'train_loss': '2.77215'}; time used = 1.1068284511566162s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.674887895584106.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92382'}; time used = 2.3287205696105957s
epoch 10: {'train_loss': '2.86475'}; time used = 2.2230944633483887s
epoch 15: {'train_loss': '2.84683'}; time used = 1.9037141799926758s
epoch 20: {'train_loss': '2.81633'}; time used = 1.9740374088287354s
epoch 25: {'train_loss': '2.79725'}; time used = 1.8907487392425537s
epoch 30: {'train_loss': '2.78654'}; time used = 3.893080234527588s
epoch 35: {'train_loss': '2.78016'}; time used = 3.578983783721924s
epoch 40: {'train_loss': '2.77629'}; time used = 3.4176361560821533s
epoch 45: {'train_loss': '2.77375'}; time used = 2.0135316848754883s
epoch 50: {'train_loss': '2.77235'}; time used = 1.9790611267089844s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.262959003448486.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39783'}; time used = 1.3824732303619385s
epoch 10: {'train_loss': '1.39661'}; time used = 1.3789191246032715s
epoch 15: {'train_loss': '1.37751'}; time used = 1.2733337879180908s
epoch 20: {'train_loss': '1.37267'}; time used = 1.3049440383911133s
epoch 25: {'train_loss': '1.28813'}; time used = 1.2610142230987549s
epoch 30: {'train_loss': '1.22342'}; time used = 1.237241268157959s
epoch 35: {'train_loss': '1.05523'}; time used = 1.2838833332061768s
epoch 40: {'train_loss': '0.98914'}; time used = 1.3880507946014404s
epoch 45: {'train_loss': '0.87724'}; time used = 1.2092649936676025s
epoch 50: {'train_loss': '0.77741'}; time used = 1.214937448501587s
epoch 55: {'train_loss': '0.70496'}; time used = 1.1484522819519043s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.66305136680603.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37217'}; time used = 1.8189022541046143s
epoch 10: {'train_loss': '1.26303'}; time used = 2.10139799118042s
epoch 15: {'train_loss': '1.11766'}; time used = 3.344378709793091s
epoch 20: {'train_loss': '0.91244'}; time used = 3.281038999557495s
epoch 25: {'train_loss': '0.73701'}; time used = 2.77494215965271s
epoch 30: {'train_loss': '0.47067'}; time used = 1.929168701171875s
epoch 35: {'train_loss': '0.70663'}; time used = 1.8086905479431152s
epoch 40: {'train_loss': '0.64586'}; time used = 1.7152321338653564s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.410510063171387.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37547'}; time used = 1.7862324714660645s
epoch 10: {'train_loss': '1.30036'}; time used = 1.8717231750488281s
epoch 15: {'train_loss': '1.26664'}; time used = 1.7614846229553223s
epoch 20: {'train_loss': '1.34806'}; time used = 1.687680721282959s
epoch 25: {'train_loss': '1.21496'}; time used = 1.7962002754211426s
epoch 30: {'train_loss': '1.07154'}; time used = 1.6982409954071045s
epoch 35: {'train_loss': '1.24740'}; time used = 1.7802984714508057s
epoch 40: {'train_loss': '1.15138'}; time used = 1.69545578956604s
epoch 45: {'train_loss': '1.24312'}; time used = 1.8538672924041748s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.47666311264038.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5988372093023256, 'samples': 0.6231884057971014, 'weighted': 0.6059993259184361, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.15663'}; time used = 1.9443528652191162s
epoch 10: {'train_loss': '0.13600'}; time used = 1.8053970336914062s
epoch 15: {'train_loss': '0.11868'}; time used = 1.830803394317627s
epoch 20: {'train_loss': '0.01069'}; time used = 1.7808499336242676s
epoch 25: {'train_loss': '0.03482'}; time used = 2.0955288410186768s
epoch 30: {'train_loss': '0.02647'}; time used = 1.864957571029663s
epoch 35: {'train_loss': '0.10356'}; time used = 1.8186523914337158s
epoch 40: {'train_loss': '0.00549'}; time used = 1.7368102073669434s
epoch 45: {'train_loss': '0.00410'}; time used = 1.8693830966949463s
epoch 50: {'train_loss': '0.03864'}; time used = 1.7677552700042725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.07884168624878.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.50982'}; time used = 1.535651683807373s
epoch 10: {'train_loss': '0.24960'}; time used = 1.407357931137085s
epoch 15: {'train_loss': '0.24738'}; time used = 1.4579691886901855s
epoch 20: {'train_loss': '0.17206'}; time used = 1.2515778541564941s
epoch 25: {'train_loss': '0.16510'}; time used = 1.2589056491851807s
epoch 30: {'train_loss': '0.13510'}; time used = 1.247631549835205s
epoch 35: {'train_loss': '0.13298'}; time used = 1.402503490447998s
epoch 40: {'train_loss': '0.10331'}; time used = 1.294064998626709s
epoch 45: {'train_loss': '0.17868'}; time used = 1.2986807823181152s
epoch 50: {'train_loss': '0.17697'}; time used = 1.2993929386138916s
epoch 55: {'train_loss': '0.10591'}; time used = 1.3005788326263428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.384285926818848.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84705'}; time used = 5.6008288860321045s
epoch 10: {'train_loss': '2.77653'}; time used = 5.318404674530029s
epoch 15: {'train_loss': '2.77996'}; time used = 4.856123924255371s
epoch 20: {'train_loss': '2.77662'}; time used = 4.811024188995361s
epoch 25: {'train_loss': '2.77132'}; time used = 4.9908223152160645s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.036495208740234.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16538'}; time used = 1.4407660961151123s
epoch 10: {'train_loss': '0.80631'}; time used = 1.0484459400177002s
epoch 15: {'train_loss': '0.63736'}; time used = 1.071258306503296s
epoch 20: {'train_loss': '0.59167'}; time used = 1.0796279907226562s
epoch 25: {'train_loss': '0.50487'}; time used = 1.3942477703094482s
epoch 30: {'train_loss': '0.42211'}; time used = 1.3235464096069336s
epoch 35: {'train_loss': '0.37194'}; time used = 1.073972463607788s
epoch 40: {'train_loss': '0.34072'}; time used = 1.0707087516784668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.371249198913574.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.24044'}; time used = 1.2196414470672607s
epoch 10: {'train_loss': '0.10364'}; time used = 1.096729040145874s
epoch 15: {'train_loss': '0.08149'}; time used = 1.1434955596923828s
epoch 20: {'train_loss': '0.03630'}; time used = 1.0228230953216553s
epoch 25: {'train_loss': '0.03894'}; time used = 1.1413142681121826s
epoch 30: {'train_loss': '0.02390'}; time used = 0.93072509765625s
epoch 35: {'train_loss': '0.02690'}; time used = 0.959824800491333s
epoch 40: {'train_loss': '0.02188'}; time used = 0.9219911098480225s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.929675817489624.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79659'}; time used = 1.8274405002593994s
epoch 10: {'train_loss': '2.76599'}; time used = 1.7919621467590332s
epoch 15: {'train_loss': '2.77023'}; time used = 1.8674700260162354s
epoch 20: {'train_loss': '2.75727'}; time used = 1.8366138935089111s
epoch 25: {'train_loss': '2.73014'}; time used = 2.131080150604248s
epoch 30: {'train_loss': '2.70989'}; time used = 1.7885065078735352s
epoch 35: {'train_loss': '2.69716'}; time used = 2.0031135082244873s
epoch 40: {'train_loss': '2.69590'}; time used = 2.162692070007324s
epoch 45: {'train_loss': '2.69172'}; time used = 2.0626320838928223s
epoch 50: {'train_loss': '2.68692'}; time used = 2.094675064086914s
epoch 55: {'train_loss': '2.69341'}; time used = 2.121424436569214s
epoch 60: {'train_loss': '2.67591'}; time used = 1.9298057556152344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.03483510017395.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.45238095238095244, 'samples': 0.5362318840579711, 'weighted': 0.46790890269151136, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98455'}; time used = 2.26188325881958s
epoch 10: {'train_loss': '2.82624'}; time used = 1.9932820796966553s
epoch 15: {'train_loss': '2.78558'}; time used = 2.017733097076416s
epoch 20: {'train_loss': '2.77511'}; time used = 2.1336097717285156s
epoch 25: {'train_loss': '2.78005'}; time used = 3.426042079925537s
epoch 30: {'train_loss': '2.77668'}; time used = 2.4696507453918457s
epoch 35: {'train_loss': '2.77349'}; time used = 2.024257183074951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.804282188415527.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.92334'}; time used = 1.7216217517852783s
epoch 10: {'train_loss': '2.76998'}; time used = 1.8465948104858398s
epoch 15: {'train_loss': '2.76364'}; time used = 1.6875979900360107s
epoch 20: {'train_loss': '2.75545'}; time used = 1.6905837059020996s
epoch 25: {'train_loss': '2.73716'}; time used = 2.086867094039917s
epoch 30: {'train_loss': '2.71490'}; time used = 2.1200368404388428s
epoch 35: {'train_loss': '2.67756'}; time used = 1.8032200336456299s
epoch 40: {'train_loss': '2.60332'}; time used = 2.084681749343872s
epoch 45: {'train_loss': '2.50883'}; time used = 1.9538421630859375s
epoch 50: {'train_loss': '2.47238'}; time used = 1.9082868099212646s
epoch 55: {'train_loss': '2.45007'}; time used = 1.84071683883667s
epoch 60: {'train_loss': '2.43912'}; time used = 2.2330822944641113s
epoch 65: {'train_loss': '2.44425'}; time used = 1.883051872253418s
epoch 70: {'train_loss': '2.39077'}; time used = 1.9581594467163086s
epoch 75: {'train_loss': '2.38083'}; time used = 1.6552486419677734s
epoch 80: {'train_loss': '2.36379'}; time used = 1.8292253017425537s
epoch 85: {'train_loss': '2.44955'}; time used = 1.7065048217773438s
epoch 90: {'train_loss': '2.42865'}; time used = 2.689155101776123s
epoch 95: {'train_loss': '2.40752'}; time used = 3.1299054622650146s
epoch 100: {'train_loss': '2.38145'}; time used = 2.9130125045776367s
epoch 105: {'train_loss': '2.35814'}; time used = 2.393213987350464s
epoch 110: {'train_loss': '2.35666'}; time used = 1.6972639560699463s
epoch 115: {'train_loss': '2.36584'}; time used = 1.6182610988616943s
epoch 120: {'train_loss': '2.34197'}; time used = 1.8650777339935303s
epoch 125: {'train_loss': '2.34069'}; time used = 1.6964778900146484s
epoch 130: {'train_loss': '2.33722'}; time used = 1.8557605743408203s
epoch 135: {'train_loss': '2.35166'}; time used = 1.689042091369629s
epoch 140: {'train_loss': '2.34160'}; time used = 1.8030810356140137s
epoch 145: {'train_loss': '2.33866'}; time used = 1.6575989723205566s
epoch 150: {'train_loss': '2.32427'}; time used = 1.7143850326538086s
epoch 155: {'train_loss': '2.31631'}; time used = 1.6094014644622803s
epoch 160: {'train_loss': '2.32742'}; time used = 1.8061444759368896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 67.19481992721558.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5871794871794872, 'samples': 0.5942028985507246, 'weighted': 0.5910813823857303, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02877'}; time used = 2.736088514328003s
epoch 10: {'train_loss': '0.87091'}; time used = 1.7918784618377686s
epoch 15: {'train_loss': '1.36903'}; time used = 1.8259680271148682s
epoch 20: {'train_loss': '1.03208'}; time used = 2.989942789077759s
epoch 25: {'train_loss': '0.87903'}; time used = 3.1895647048950195s
epoch 30: {'train_loss': '0.83471'}; time used = 2.558230400085449s
epoch 35: {'train_loss': '0.34677'}; time used = 1.8238153457641602s
epoch 40: {'train_loss': '0.26179'}; time used = 1.6933958530426025s
epoch 45: {'train_loss': '0.37380'}; time used = 1.6988964080810547s
epoch 50: {'train_loss': '0.21030'}; time used = 1.6994099617004395s
epoch 55: {'train_loss': '0.28068'}; time used = 1.7071058750152588s
epoch 60: {'train_loss': '0.23794'}; time used = 1.6618611812591553s
epoch 65: {'train_loss': '0.27047'}; time used = 1.6994972229003906s
epoch 70: {'train_loss': '0.27469'}; time used = 1.5915074348449707s
epoch 75: {'train_loss': '0.29557'}; time used = 1.676605463027954s
epoch 80: {'train_loss': '0.17451'}; time used = 1.8757891654968262s
epoch 85: {'train_loss': '0.15998'}; time used = 1.7680542469024658s
epoch 90: {'train_loss': '0.38114'}; time used = 1.6833577156066895s
epoch 95: {'train_loss': '0.15611'}; time used = 1.6420011520385742s
epoch 100: {'train_loss': '0.14454'}; time used = 1.838099718093872s
epoch 105: {'train_loss': '0.22969'}; time used = 2.304847478866577s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.36800765991211.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4130434782608695, 'samples': 0.4782608695652174, 'weighted': 0.4272211720226843, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03586'}; time used = 1.6827702522277832s
epoch 10: {'train_loss': '0.04404'}; time used = 1.7704100608825684s
epoch 15: {'train_loss': '0.05937'}; time used = 1.6630909442901611s
epoch 20: {'train_loss': '0.00098'}; time used = 1.9152777194976807s
epoch 25: {'train_loss': '0.02823'}; time used = 3.155768394470215s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.459418058395386.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.01532'}; time used = 1.821742057800293s
epoch 10: {'train_loss': '2.83681'}; time used = 2.54058837890625s
epoch 15: {'train_loss': '2.78189'}; time used = 1.8262503147125244s
epoch 20: {'train_loss': '2.77256'}; time used = 1.884568691253662s
epoch 25: {'train_loss': '2.77641'}; time used = 2.0699987411499023s
epoch 30: {'train_loss': '2.76975'}; time used = 1.8101141452789307s
epoch 35: {'train_loss': '2.76796'}; time used = 2.0712506771087646s
epoch 40: {'train_loss': '2.76896'}; time used = 1.898287057876587s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.657738208770752.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4943965517241379, 'samples': 0.5072463768115942, 'weighted': 0.5002373813093453, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35725'}; time used = 7.719265699386597s
epoch 10: {'train_loss': '1.37777'}; time used = 7.409858226776123s
epoch 15: {'train_loss': '1.31525'}; time used = 7.158068418502808s
epoch 20: {'train_loss': '1.25462'}; time used = 8.335386991500854s
epoch 25: {'train_loss': '1.16974'}; time used = 9.64739990234375s
epoch 30: {'train_loss': '1.28651'}; time used = 10.496380090713501s
epoch 35: {'train_loss': '1.13915'}; time used = 7.059257507324219s
epoch 40: {'train_loss': '1.15673'}; time used = 6.864858627319336s
epoch 45: {'train_loss': '1.12409'}; time used = 6.848337650299072s
epoch 50: {'train_loss': '1.09297'}; time used = 6.773224830627441s
epoch 55: {'train_loss': '1.28650'}; time used = 6.746464014053345s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 106.87493562698364.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.48326715373031975, 'samples': 0.5066666666666667, 'weighted': 0.4775108609727149, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37217'}; time used = 1.838327169418335s
epoch 10: {'train_loss': '1.26303'}; time used = 1.7780473232269287s
epoch 15: {'train_loss': '1.11766'}; time used = 1.7658050060272217s
epoch 20: {'train_loss': '0.91244'}; time used = 1.9359726905822754s
epoch 25: {'train_loss': '0.73701'}; time used = 1.9988844394683838s
epoch 30: {'train_loss': '0.47067'}; time used = 1.8818581104278564s
epoch 35: {'train_loss': '0.70663'}; time used = 1.8236727714538574s
epoch 40: {'train_loss': '0.64586'}; time used = 1.760801076889038s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.167112112045288.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.32470'}; time used = 2.0512502193450928s
epoch 10: {'train_loss': '1.23144'}; time used = 2.326090097427368s
epoch 15: {'train_loss': '1.21774'}; time used = 2.138498544692993s
epoch 20: {'train_loss': '1.24377'}; time used = 2.191211700439453s
epoch 25: {'train_loss': '0.88411'}; time used = 2.1625471115112305s
epoch 30: {'train_loss': '0.96320'}; time used = 1.8375065326690674s
epoch 35: {'train_loss': '1.06848'}; time used = 1.814211130142212s
epoch 40: {'train_loss': '1.15836'}; time used = 1.9916605949401855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.760725736618042.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.11220'}; time used = 1.1263079643249512s
epoch 10: {'train_loss': '2.80466'}; time used = 0.9823622703552246s
epoch 15: {'train_loss': '2.79712'}; time used = 0.936349630355835s
epoch 20: {'train_loss': '2.80456'}; time used = 0.9622011184692383s
epoch 25: {'train_loss': '2.77228'}; time used = 0.9590659141540527s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.956802606582642.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39591'}; time used = 1.0652387142181396s
epoch 10: {'train_loss': '1.36817'}; time used = 0.9371287822723389s
epoch 15: {'train_loss': '1.26616'}; time used = 0.959683895111084s
epoch 20: {'train_loss': '1.26285'}; time used = 0.9387445449829102s
epoch 25: {'train_loss': '1.06481'}; time used = 0.9396312236785889s
epoch 30: {'train_loss': '1.16276'}; time used = 0.9315299987792969s
epoch 35: {'train_loss': '1.15639'}; time used = 0.9560010433197021s
epoch 40: {'train_loss': '1.07687'}; time used = 0.9431228637695312s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.873553037643433.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.25092'}; time used = 1.6621983051300049s
epoch 10: {'train_loss': '1.13343'}; time used = 1.583014726638794s
epoch 15: {'train_loss': '1.07350'}; time used = 1.587843418121338s
epoch 20: {'train_loss': '0.98287'}; time used = 1.6079330444335938s
epoch 25: {'train_loss': '0.85130'}; time used = 1.7821948528289795s
epoch 30: {'train_loss': '0.70541'}; time used = 1.6200215816497803s
epoch 35: {'train_loss': '0.42553'}; time used = 1.5726306438446045s
epoch 40: {'train_loss': '0.23226'}; time used = 1.5606765747070312s
epoch 45: {'train_loss': '0.16946'}; time used = 1.5904295444488525s
epoch 50: {'train_loss': '0.09561'}; time used = 1.5725631713867188s
epoch 55: {'train_loss': '0.12281'}; time used = 1.625849962234497s
epoch 60: {'train_loss': '0.08862'}; time used = 1.5628159046173096s
epoch 65: {'train_loss': '0.06826'}; time used = 1.5887937545776367s
epoch 70: {'train_loss': '0.08598'}; time used = 1.5749235153198242s
epoch 75: {'train_loss': '0.05891'}; time used = 1.5873899459838867s
epoch 80: {'train_loss': '0.11089'}; time used = 1.6059510707855225s
epoch 85: {'train_loss': '0.01545'}; time used = 1.625333547592163s
epoch 90: {'train_loss': '0.01426'}; time used = 1.594886064529419s
epoch 95: {'train_loss': '0.04279'}; time used = 1.5839407444000244s
epoch 100: {'train_loss': '0.04283'}; time used = 1.57985258102417s
epoch 105: {'train_loss': '0.04806'}; time used = 1.7244763374328613s
epoch 110: {'train_loss': '0.00881'}; time used = 1.5852797031402588s
epoch 115: {'train_loss': '0.00461'}; time used = 1.5650858879089355s
epoch 120: {'train_loss': '0.01198'}; time used = 1.5402655601501465s
epoch 125: {'train_loss': '0.00647'}; time used = 1.5418107509613037s
epoch 130: {'train_loss': '0.00382'}; time used = 1.7172479629516602s
epoch 135: {'train_loss': '0.00853'}; time used = 1.631974458694458s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.567540645599365.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38683'}; time used = 1.4513092041015625s
epoch 10: {'train_loss': '1.43138'}; time used = 1.269200086593628s
epoch 15: {'train_loss': '1.39949'}; time used = 1.2752833366394043s
epoch 20: {'train_loss': '1.35106'}; time used = 1.3771841526031494s
epoch 25: {'train_loss': '1.38615'}; time used = 1.3274683952331543s
epoch 30: {'train_loss': '1.36777'}; time used = 1.303373098373413s
epoch 35: {'train_loss': '1.38722'}; time used = 1.272470474243164s
epoch 40: {'train_loss': '1.36744'}; time used = 1.2843830585479736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.447407484054565.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36651'}; time used = 1.1209795475006104s
epoch 10: {'train_loss': '1.32640'}; time used = 1.0435869693756104s
epoch 15: {'train_loss': '1.23521'}; time used = 1.0059256553649902s
epoch 20: {'train_loss': '1.20006'}; time used = 1.0714874267578125s
epoch 25: {'train_loss': '0.96273'}; time used = 0.9771080017089844s
epoch 30: {'train_loss': '0.88622'}; time used = 1.0139522552490234s
epoch 35: {'train_loss': '0.76291'}; time used = 0.9883301258087158s
epoch 40: {'train_loss': '0.93591'}; time used = 1.0213313102722168s
epoch 45: {'train_loss': '0.74931'}; time used = 0.994525671005249s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.919053316116333.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85268'}; time used = 1.0691659450531006s
epoch 10: {'train_loss': '2.80887'}; time used = 0.9710910320281982s
epoch 15: {'train_loss': '2.78665'}; time used = 1.0294108390808105s
epoch 20: {'train_loss': '2.77310'}; time used = 0.9296815395355225s
epoch 25: {'train_loss': '2.77263'}; time used = 0.926598072052002s
epoch 30: {'train_loss': '2.77329'}; time used = 0.9245288372039795s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.945640325546265.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77175'}; time used = 1.1880221366882324s
epoch 10: {'train_loss': '2.49498'}; time used = 0.9387631416320801s
epoch 15: {'train_loss': '1.91010'}; time used = 1.0514426231384277s
epoch 20: {'train_loss': '1.72848'}; time used = 0.9639554023742676s
epoch 25: {'train_loss': '1.67940'}; time used = 0.9492902755737305s
epoch 30: {'train_loss': '1.58832'}; time used = 0.9389989376068115s
epoch 35: {'train_loss': '1.45982'}; time used = 0.925757884979248s
epoch 40: {'train_loss': '1.44617'}; time used = 0.9443964958190918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.16568374633789.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.11220'}; time used = 1.1380462646484375s
epoch 10: {'train_loss': '2.80466'}; time used = 1.14683198928833s
epoch 15: {'train_loss': '2.79712'}; time used = 1.1912670135498047s
epoch 20: {'train_loss': '2.80456'}; time used = 1.0325145721435547s
epoch 25: {'train_loss': '2.77228'}; time used = 1.0438666343688965s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.793123245239258.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39274'}; time used = 1.1624886989593506s
epoch 10: {'train_loss': '1.37996'}; time used = 1.009312629699707s
epoch 15: {'train_loss': '1.34288'}; time used = 1.0404300689697266s
epoch 20: {'train_loss': '1.31355'}; time used = 1.0449495315551758s
epoch 25: {'train_loss': '1.24586'}; time used = 1.0336024761199951s
epoch 30: {'train_loss': '1.13049'}; time used = 1.0430142879486084s
epoch 35: {'train_loss': '0.91282'}; time used = 1.0398125648498535s
epoch 40: {'train_loss': '0.87024'}; time used = 1.012324571609497s
epoch 45: {'train_loss': '0.78156'}; time used = 1.0197551250457764s
epoch 50: {'train_loss': '0.71338'}; time used = 1.0113189220428467s
epoch 55: {'train_loss': '0.58696'}; time used = 1.0156311988830566s
epoch 60: {'train_loss': '0.71545'}; time used = 1.013028621673584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.796931505203247.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79675'}; time used = 1.0346717834472656s
epoch 10: {'train_loss': '2.81502'}; time used = 0.9402332305908203s
epoch 15: {'train_loss': '2.78053'}; time used = 0.9433741569519043s
epoch 20: {'train_loss': '2.77388'}; time used = 0.9688584804534912s
epoch 25: {'train_loss': '2.78190'}; time used = 0.9377820491790771s
epoch 30: {'train_loss': '2.77777'}; time used = 0.9395875930786133s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.026483535766602.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.58803'}; time used = 1.0767765045166016s
epoch 10: {'train_loss': '1.96249'}; time used = 0.9298758506774902s
epoch 15: {'train_loss': '1.80942'}; time used = 0.9289388656616211s
epoch 20: {'train_loss': '1.54739'}; time used = 0.9128518104553223s
epoch 25: {'train_loss': '1.55807'}; time used = 0.9166138172149658s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.707010507583618.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7913725490196077, 'samples': 0.8157894736842105, 'weighted': 0.8026418988648091, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.26340'}; time used = 2.5900909900665283s
epoch 10: {'train_loss': '1.18190'}; time used = 2.501772165298462s
epoch 15: {'train_loss': '1.12383'}; time used = 2.503333806991577s
epoch 20: {'train_loss': '1.03138'}; time used = 2.48500657081604s
epoch 25: {'train_loss': '0.81402'}; time used = 2.563303232192993s
epoch 30: {'train_loss': '0.58427'}; time used = 2.495271682739258s
epoch 35: {'train_loss': '0.32831'}; time used = 2.5425586700439453s
epoch 40: {'train_loss': '0.16146'}; time used = 2.510178327560425s
epoch 45: {'train_loss': '0.11171'}; time used = 2.553290605545044s
epoch 50: {'train_loss': '0.10329'}; time used = 2.481821298599243s
epoch 55: {'train_loss': '0.11212'}; time used = 2.507906436920166s
epoch 60: {'train_loss': '0.04495'}; time used = 2.507769823074341s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.23609972000122.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.4559139784946237, 'samples': 0.5217391304347826, 'weighted': 0.46962755181549015, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79337'}; time used = 1.7924480438232422s
epoch 10: {'train_loss': '2.73387'}; time used = 1.5327448844909668s
epoch 15: {'train_loss': '2.70456'}; time used = 1.5125703811645508s
epoch 20: {'train_loss': '2.69159'}; time used = 1.5111188888549805s
epoch 25: {'train_loss': '2.66297'}; time used = 1.570892095565796s
epoch 30: {'train_loss': '2.64691'}; time used = 1.505725622177124s
epoch 35: {'train_loss': '2.64093'}; time used = 1.4965126514434814s
epoch 40: {'train_loss': '2.64094'}; time used = 1.5072507858276367s
epoch 45: {'train_loss': '2.63649'}; time used = 1.5029985904693604s
epoch 50: {'train_loss': '2.62501'}; time used = 1.531320333480835s
epoch 55: {'train_loss': '2.62540'}; time used = 1.6029398441314697s
epoch 60: {'train_loss': '2.63288'}; time used = 1.5355808734893799s
epoch 65: {'train_loss': '2.62569'}; time used = 1.525998830795288s
epoch 70: {'train_loss': '2.61508'}; time used = 1.5345890522003174s
epoch 75: {'train_loss': '2.60728'}; time used = 1.5326893329620361s
epoch 80: {'train_loss': '2.60556'}; time used = 1.5797967910766602s
epoch 85: {'train_loss': '2.60207'}; time used = 1.5517566204071045s
epoch 90: {'train_loss': '2.60719'}; time used = 1.6633093357086182s
epoch 95: {'train_loss': '2.60039'}; time used = 1.5433878898620605s
epoch 100: {'train_loss': '2.58023'}; time used = 1.5178794860839844s
epoch 105: {'train_loss': '2.57818'}; time used = 1.582963466644287s
epoch 110: {'train_loss': '2.56835'}; time used = 1.5265426635742188s
epoch 115: {'train_loss': '2.56859'}; time used = 1.5464823246002197s
epoch 120: {'train_loss': '2.56901'}; time used = 1.5482864379882812s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.35042881965637.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74189'}; time used = 1.0245158672332764s
epoch 10: {'train_loss': '2.68455'}; time used = 0.9334609508514404s
epoch 15: {'train_loss': '2.57938'}; time used = 0.9235081672668457s
epoch 20: {'train_loss': '2.44570'}; time used = 0.9549648761749268s
epoch 25: {'train_loss': '2.22272'}; time used = 1.0010347366333008s
epoch 30: {'train_loss': '2.36017'}; time used = 0.949603796005249s
epoch 35: {'train_loss': '2.16890'}; time used = 0.9329104423522949s
epoch 40: {'train_loss': '2.07597'}; time used = 0.9387829303741455s
epoch 45: {'train_loss': '1.95954'}; time used = 0.9332540035247803s
epoch 50: {'train_loss': '1.92748'}; time used = 0.944730281829834s
epoch 55: {'train_loss': '1.85427'}; time used = 0.9565587043762207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.82395601272583.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.61781'}; time used = 1.2950224876403809s
epoch 10: {'train_loss': '2.44129'}; time used = 1.1511716842651367s
epoch 15: {'train_loss': '2.32789'}; time used = 0.9570121765136719s
epoch 20: {'train_loss': '2.22533'}; time used = 0.9758398532867432s
epoch 25: {'train_loss': '2.17048'}; time used = 0.9742646217346191s
epoch 30: {'train_loss': '2.11830'}; time used = 0.9592094421386719s
epoch 35: {'train_loss': '2.11061'}; time used = 1.039675235748291s
epoch 40: {'train_loss': '2.12154'}; time used = 0.9497814178466797s
epoch 45: {'train_loss': '2.11607'}; time used = 0.928508996963501s
epoch 50: {'train_loss': '2.13388'}; time used = 0.9074687957763672s
epoch 55: {'train_loss': '2.11428'}; time used = 0.9227299690246582s
epoch 60: {'train_loss': '2.09740'}; time used = 1.1525013446807861s
epoch 65: {'train_loss': '2.10756'}; time used = 1.128922939300537s
epoch 70: {'train_loss': '2.11283'}; time used = 1.052293062210083s
epoch 75: {'train_loss': '2.08592'}; time used = 1.0863335132598877s
epoch 80: {'train_loss': '2.09988'}; time used = 1.1941394805908203s
epoch 85: {'train_loss': '2.11179'}; time used = 1.084758996963501s
epoch 90: {'train_loss': '2.11656'}; time used = 1.092740535736084s
epoch 95: {'train_loss': '2.11759'}; time used = 1.0549421310424805s
epoch 100: {'train_loss': '2.14728'}; time used = 0.8879506587982178s
epoch 105: {'train_loss': '2.10989'}; time used = 0.9779021739959717s
epoch 110: {'train_loss': '2.08587'}; time used = 0.8995263576507568s
epoch 115: {'train_loss': '2.07981'}; time used = 0.9047074317932129s
epoch 120: {'train_loss': '2.07415'}; time used = 0.9196083545684814s
epoch 125: {'train_loss': '2.09627'}; time used = 0.9032511711120605s
epoch 130: {'train_loss': '2.08235'}; time used = 0.9276828765869141s
epoch 135: {'train_loss': '2.06108'}; time used = 0.9045331478118896s
epoch 140: {'train_loss': '2.09358'}; time used = 0.9061532020568848s
epoch 145: {'train_loss': '2.08853'}; time used = 0.9187440872192383s
epoch 150: {'train_loss': '2.07108'}; time used = 0.9000027179718018s
epoch 155: {'train_loss': '2.10606'}; time used = 0.9075696468353271s
epoch 160: {'train_loss': '2.09174'}; time used = 0.9139893054962158s
epoch 165: {'train_loss': '2.11243'}; time used = 0.9080185890197754s
epoch 170: {'train_loss': '2.11790'}; time used = 0.9195680618286133s
epoch 175: {'train_loss': '2.06126'}; time used = 0.8985357284545898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.98524188995361.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.19582'}; time used = 1.9146580696105957s
epoch 10: {'train_loss': '1.03213'}; time used = 1.7331933975219727s
epoch 15: {'train_loss': '0.93469'}; time used = 1.8545527458190918s
epoch 20: {'train_loss': '0.77093'}; time used = 2.708352565765381s
epoch 25: {'train_loss': '0.47799'}; time used = 4.282964706420898s
epoch 30: {'train_loss': '0.33788'}; time used = 5.661023139953613s
epoch 35: {'train_loss': '0.18348'}; time used = 4.8886473178863525s
epoch 40: {'train_loss': '0.14824'}; time used = 4.437082290649414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.36855340003967.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86520'}; time used = 1.2407591342926025s
epoch 10: {'train_loss': '2.81772'}; time used = 1.044879674911499s
epoch 15: {'train_loss': '2.78975'}; time used = 1.1217238903045654s
epoch 20: {'train_loss': '2.77337'}; time used = 1.2786870002746582s
epoch 25: {'train_loss': '2.77400'}; time used = 1.1976213455200195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.323153734207153.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85855'}; time used = 1.1474168300628662s
epoch 10: {'train_loss': '2.77647'}; time used = 2.395047903060913s
epoch 15: {'train_loss': '2.80594'}; time used = 2.458470106124878s
epoch 20: {'train_loss': '2.77712'}; time used = 2.2786593437194824s
epoch 25: {'train_loss': '2.77814'}; time used = 2.1241097450256348s
epoch 30: {'train_loss': '2.77434'}; time used = 2.160667657852173s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.129383325576782.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.69020'}; time used = 1.23618745803833s
epoch 10: {'train_loss': '2.61344'}; time used = 1.1726667881011963s
epoch 15: {'train_loss': '2.51119'}; time used = 1.1656708717346191s
epoch 20: {'train_loss': '2.43466'}; time used = 1.0735740661621094s
epoch 25: {'train_loss': '2.38152'}; time used = 1.0613713264465332s
epoch 30: {'train_loss': '2.26930'}; time used = 1.2132620811462402s
epoch 35: {'train_loss': '2.23126'}; time used = 1.2473886013031006s
epoch 40: {'train_loss': '2.19487'}; time used = 1.0765507221221924s
epoch 45: {'train_loss': '2.20360'}; time used = 1.0334908962249756s
epoch 50: {'train_loss': '2.20826'}; time used = 1.0226259231567383s
epoch 55: {'train_loss': '2.11692'}; time used = 1.0474505424499512s
epoch 60: {'train_loss': '2.08618'}; time used = 1.1268749237060547s
epoch 65: {'train_loss': '2.03209'}; time used = 1.0271131992340088s
epoch 70: {'train_loss': '2.06617'}; time used = 1.0561790466308594s
epoch 75: {'train_loss': '2.01953'}; time used = 1.0629677772521973s
epoch 80: {'train_loss': '2.02615'}; time used = 1.0477824211120605s
epoch 85: {'train_loss': '2.02610'}; time used = 1.10660719871521s
epoch 90: {'train_loss': '2.11248'}; time used = 0.9909651279449463s
epoch 95: {'train_loss': '2.11450'}; time used = 1.0085806846618652s
epoch 100: {'train_loss': '2.13164'}; time used = 1.0269732475280762s
epoch 105: {'train_loss': '2.06363'}; time used = 1.3683891296386719s
epoch 110: {'train_loss': '2.01514'}; time used = 1.6325201988220215s
epoch 115: {'train_loss': '2.03641'}; time used = 1.058753490447998s
epoch 120: {'train_loss': '1.97096'}; time used = 1.2354190349578857s
epoch 125: {'train_loss': '2.02031'}; time used = 1.222426176071167s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.06679344177246.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38242'}; time used = 1.9528543949127197s
epoch 10: {'train_loss': '1.32953'}; time used = 1.8547484874725342s
epoch 15: {'train_loss': '1.31482'}; time used = 1.8509972095489502s
epoch 20: {'train_loss': '1.41776'}; time used = 1.9274349212646484s
epoch 25: {'train_loss': '1.29556'}; time used = 1.828723669052124s
epoch 30: {'train_loss': '1.10529'}; time used = 3.059178352355957s
epoch 35: {'train_loss': '1.24654'}; time used = 3.3405301570892334s
epoch 40: {'train_loss': '1.15609'}; time used = 3.353165626525879s
epoch 45: {'train_loss': '1.31793'}; time used = 2.616858720779419s
epoch 50: {'train_loss': '1.08770'}; time used = 1.8304917812347412s
epoch 55: {'train_loss': '1.04631'}; time used = 1.7970349788665771s
epoch 60: {'train_loss': '1.22784'}; time used = 1.666513442993164s
epoch 65: {'train_loss': '1.24786'}; time used = 1.642801284790039s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.57766938209534.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.33399'}; time used = 1.7165424823760986s
epoch 10: {'train_loss': '1.23131'}; time used = 1.7163333892822266s
epoch 15: {'train_loss': '1.18835'}; time used = 1.7579915523529053s
epoch 20: {'train_loss': '1.31426'}; time used = 1.6558828353881836s
epoch 25: {'train_loss': '1.25735'}; time used = 1.7706246376037598s
epoch 30: {'train_loss': '1.21243'}; time used = 1.5992939472198486s
epoch 35: {'train_loss': '1.25752'}; time used = 1.6151576042175293s
epoch 40: {'train_loss': '1.17740'}; time used = 1.7103137969970703s
epoch 45: {'train_loss': '1.22737'}; time used = 1.6735482215881348s
epoch 50: {'train_loss': '1.10052'}; time used = 1.8510181903839111s
epoch 55: {'train_loss': '1.07567'}; time used = 1.7260692119598389s
epoch 60: {'train_loss': '1.13940'}; time used = 1.6746387481689453s
epoch 65: {'train_loss': '1.23101'}; time used = 1.8295695781707764s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.490713834762573.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.45 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.99186'}; time used = 1.031712532043457s
epoch 10: {'train_loss': '0.59542'}; time used = 1.0572011470794678s
epoch 15: {'train_loss': '0.36097'}; time used = 1.1923670768737793s
epoch 20: {'train_loss': '0.19137'}; time used = 1.0577483177185059s
epoch 25: {'train_loss': '0.12181'}; time used = 1.0564851760864258s
epoch 30: {'train_loss': '0.06730'}; time used = 1.0250563621520996s
epoch 35: {'train_loss': '0.05954'}; time used = 0.9055497646331787s
epoch 40: {'train_loss': '0.03863'}; time used = 0.9084475040435791s
epoch 45: {'train_loss': '0.04773'}; time used = 0.9849927425384521s
epoch 50: {'train_loss': '0.03547'}; time used = 0.8998496532440186s
epoch 55: {'train_loss': '0.01915'}; time used = 0.8955116271972656s
epoch 60: {'train_loss': '0.01529'}; time used = 0.9567995071411133s
epoch 65: {'train_loss': '0.02144'}; time used = 0.9176530838012695s
epoch 70: {'train_loss': '0.01594'}; time used = 0.8850712776184082s
epoch 75: {'train_loss': '0.01024'}; time used = 0.8526294231414795s
epoch 80: {'train_loss': '0.01558'}; time used = 0.8597338199615479s
epoch 85: {'train_loss': '0.01721'}; time used = 0.868659496307373s
epoch 90: {'train_loss': '0.02047'}; time used = 0.8659839630126953s
epoch 95: {'train_loss': '0.02506'}; time used = 0.855262279510498s
epoch 100: {'train_loss': '0.02972'}; time used = 0.8627047538757324s
epoch 105: {'train_loss': '0.03857'}; time used = 0.9594466686248779s
epoch 110: {'train_loss': '0.04154'}; time used = 0.9628026485443115s
epoch 115: {'train_loss': '0.03890'}; time used = 0.8982899188995361s
epoch 120: {'train_loss': '0.03917'}; time used = 0.907172441482544s
epoch 125: {'train_loss': '0.02300'}; time used = 0.8994011878967285s
epoch 130: {'train_loss': '0.02378'}; time used = 0.9022495746612549s
epoch 135: {'train_loss': '0.02922'}; time used = 0.8892076015472412s
epoch 140: {'train_loss': '0.03347'}; time used = 0.8971877098083496s
epoch 145: {'train_loss': '0.01571'}; time used = 0.8950493335723877s
epoch 150: {'train_loss': '0.01757'}; time used = 0.9487144947052002s
epoch 155: {'train_loss': '0.02291'}; time used = 1.0078816413879395s
epoch 160: {'train_loss': '0.01530'}; time used = 0.9097726345062256s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.71146821975708.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.22213'}; time used = 1.2529115676879883s
epoch 10: {'train_loss': '0.03842'}; time used = 1.051393985748291s
epoch 15: {'train_loss': '0.00113'}; time used = 0.8959710597991943s
epoch 20: {'train_loss': '0.01744'}; time used = 0.9001619815826416s
epoch 25: {'train_loss': '0.00524'}; time used = 1.0248377323150635s
epoch 30: {'train_loss': '0.00068'}; time used = 1.0831727981567383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.401020765304565.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 252, in main
    res = task.evaluate(model, res, graph)  # evaluate
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 21, in evaluate
    return self._classify(dataset, res, 0)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 34, in _classify
    return clf.train_and_evaluate(dataset, self.train_kwargs()['clf_ratio'], seed=seed)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 80, in train_and_evaluate
    self.train(X_train, Y_train, graph.labels()[1])
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 50, in train
    self.clf.fit(X_train, Y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 216, in fit
    for i, column in enumerate(columns))
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 921, in __call__
    if self.dispatch_one_batch(iterator):
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 182, in apply_async
    result = ImmediateResult(func)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 549, in __init__
    self.results = batch()
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 80, in _fit_binary
    estimator.fit(X, y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py", line 2004, in fit
    accept_large_sparse=solver != 'liblinear')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 719, in check_X_y
    estimator=estimator)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 542, in check_array
    allow_nan=force_all_finite == 'allow-nan')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 56, in _assert_all_finite
    raise ValueError(msg_err.format(type_err, X.dtype))
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.36509'}; time used = 1.8232126235961914s
epoch 10: {'train_loss': '1.22982'}; time used = 1.8083863258361816s
epoch 15: {'train_loss': '1.12925'}; time used = 1.790064811706543s
epoch 20: {'train_loss': '1.13433'}; time used = 1.7835710048675537s
epoch 25: {'train_loss': '1.01162'}; time used = 1.9437475204467773s
epoch 30: {'train_loss': '0.55686'}; time used = 1.839702844619751s
epoch 35: {'train_loss': '0.67361'}; time used = 3.0419251918792725s
epoch 40: {'train_loss': '0.69172'}; time used = 3.6105892658233643s
epoch 45: {'train_loss': '0.78424'}; time used = 3.5755650997161865s
epoch 50: {'train_loss': '0.61252'}; time used = 2.366096258163452s
epoch 55: {'train_loss': '0.53233'}; time used = 1.9419467449188232s
epoch 60: {'train_loss': '0.56625'}; time used = 1.8902153968811035s
epoch 65: {'train_loss': '0.55060'}; time used = 1.742713451385498s
epoch 70: {'train_loss': '0.61120'}; time used = 1.8431830406188965s
epoch 75: {'train_loss': '1.37482'}; time used = 1.8933587074279785s
epoch 80: {'train_loss': '1.27228'}; time used = 1.6484251022338867s
epoch 85: {'train_loss': 'nan'}; time used = 1.6720318794250488s
epoch 90: {'train_loss': 'nan'}; time used = 1.9354887008666992s
epoch 95: {'train_loss': 'nan'}; time used = 1.7087924480438232s
epoch 100: {'train_loss': 'nan'}; time used = 1.7596914768218994s
epoch 105: {'train_loss': 'nan'}; time used = 1.6724052429199219s
epoch 110: {'train_loss': 'nan'}; time used = 1.6944808959960938s
epoch 115: {'train_loss': 'nan'}; time used = 1.6644771099090576s
epoch 120: {'train_loss': 'nan'}; time used = 1.676337718963623s
epoch 125: {'train_loss': 'nan'}; time used = 1.6687052249908447s
epoch 130: {'train_loss': 'nan'}; time used = 1.756160020828247s
epoch 135: {'train_loss': 'nan'}; time used = 1.6586108207702637s
epoch 140: {'train_loss': 'nan'}; time used = 1.6790428161621094s
epoch 145: {'train_loss': 'nan'}; time used = 1.7167401313781738s
epoch 150: {'train_loss': 'nan'}; time used = 1.7146451473236084s
epoch 155: {'train_loss': 'nan'}; time used = 1.8001337051391602s
epoch 160: {'train_loss': 'nan'}; time used = 1.6949937343597412s
epoch 165: {'train_loss': 'nan'}; time used = 1.6992979049682617s
epoch 170: {'train_loss': 'nan'}; time used = 1.6519207954406738s
epoch 175: {'train_loss': 'nan'}; time used = 1.6751773357391357s
epoch 180: {'train_loss': 'nan'}; time used = 1.702371597290039s
epoch 185: {'train_loss': 'nan'}; time used = 1.6635098457336426s
epoch 190: {'train_loss': 'nan'}; time used = 1.662092924118042s
epoch 195: {'train_loss': 'nan'}; time used = 1.6576032638549805s
epoch 200: {'train_loss': 'nan'}; time used = 1.6728284358978271s
epoch 205: {'train_loss': 'nan'}; time used = 1.7272908687591553s
epoch 210: {'train_loss': 'nan'}; time used = 1.695173978805542s
epoch 215: {'train_loss': 'nan'}; time used = 2.177856922149658s
epoch 220: {'train_loss': 'nan'}; time used = 4.280492067337036s
epoch 225: {'train_loss': 'nan'}; time used = 4.475625991821289s
epoch 230: {'train_loss': 'nan'}; time used = 1.8785943984985352s
epoch 235: {'train_loss': 'nan'}; time used = 1.7642743587493896s
epoch 240: {'train_loss': 'nan'}; time used = 1.7182011604309082s
epoch 245: {'train_loss': 'nan'}; time used = 1.6757004261016846s
epoch 250: {'train_loss': 'nan'}; time used = 1.736255168914795s
epoch 255: {'train_loss': 'nan'}; time used = 1.6838021278381348s
epoch 260: {'train_loss': 'nan'}; time used = 1.7176895141601562s
epoch 265: {'train_loss': 'nan'}; time used = 1.6905100345611572s
epoch 270: {'train_loss': 'nan'}; time used = 1.691178560256958s
epoch 275: {'train_loss': 'nan'}; time used = 1.7512922286987305s
epoch 280: {'train_loss': 'nan'}; time used = 1.702821969985962s
epoch 285: {'train_loss': 'nan'}; time used = 1.8038265705108643s
epoch 290: {'train_loss': 'nan'}; time used = 1.9928333759307861s
epoch 295: {'train_loss': 'nan'}; time used = 2.386122465133667s
epoch 300: {'train_loss': 'nan'}; time used = 1.7035911083221436s
epoch 305: {'train_loss': 'nan'}; time used = 1.6738483905792236s
epoch 310: {'train_loss': 'nan'}; time used = 1.8204083442687988s
epoch 315: {'train_loss': 'nan'}; time used = 1.7847490310668945s
epoch 320: {'train_loss': 'nan'}; time used = 1.7157633304595947s
epoch 325: {'train_loss': 'nan'}; time used = 1.7235133647918701s
epoch 330: {'train_loss': 'nan'}; time used = 1.7992405891418457s
epoch 335: {'train_loss': 'nan'}; time used = 1.7233641147613525s
epoch 340: {'train_loss': 'nan'}; time used = 1.7554948329925537s
epoch 345: {'train_loss': 'nan'}; time used = 1.6565191745758057s
epoch 350: {'train_loss': 'nan'}; time used = 1.7554330825805664s
epoch 355: {'train_loss': 'nan'}; time used = 1.700549840927124s
epoch 360: {'train_loss': 'nan'}; time used = 1.8974332809448242s
epoch 365: {'train_loss': 'nan'}; time used = 1.7088468074798584s
epoch 370: {'train_loss': 'nan'}; time used = 1.9433341026306152s
epoch 375: {'train_loss': 'nan'}; time used = 3.3101484775543213s
epoch 380: {'train_loss': 'nan'}; time used = 3.8168673515319824s
epoch 385: {'train_loss': 'nan'}; time used = 4.229445219039917s
epoch 390: {'train_loss': 'nan'}; time used = 3.4712932109832764s
epoch 395: {'train_loss': 'nan'}; time used = 1.7877709865570068s
epoch 400: {'train_loss': 'nan'}; time used = 1.7504384517669678s
epoch 405: {'train_loss': 'nan'}; time used = 1.7989201545715332s
epoch 410: {'train_loss': 'nan'}; time used = 1.673175573348999s
epoch 415: {'train_loss': 'nan'}; time used = 1.850475549697876s
epoch 420: {'train_loss': 'nan'}; time used = 1.6996161937713623s
epoch 425: {'train_loss': 'nan'}; time used = 2.3434836864471436s
epoch 430: {'train_loss': 'nan'}; time used = 3.6812829971313477s
epoch 435: {'train_loss': 'nan'}; time used = 3.286621332168579s
epoch 440: {'train_loss': 'nan'}; time used = 3.3721938133239746s
epoch 445: {'train_loss': 'nan'}; time used = 1.9279778003692627s
epoch 450: {'train_loss': 'nan'}; time used = 2.8247883319854736s
epoch 455: {'train_loss': 'nan'}; time used = 1.6652123928070068s
epoch 460: {'train_loss': 'nan'}; time used = 1.6606590747833252s
epoch 465: {'train_loss': 'nan'}; time used = 1.6449334621429443s
epoch 470: {'train_loss': 'nan'}; time used = 1.6950523853302002s
epoch 475: {'train_loss': 'nan'}; time used = 1.6575331687927246s
epoch 480: {'train_loss': 'nan'}; time used = 1.6729941368103027s
epoch 485: {'train_loss': 'nan'}; time used = 1.9835331439971924s
epoch 490: {'train_loss': 'nan'}; time used = 1.6657583713531494s
epoch 495: {'train_loss': 'nan'}; time used = 1.7063579559326172s
epoch 500: {'train_loss': 'nan'}; time used = 1.625065565109253s
Finished training. Time used = 205.64323592185974.
Training classifier using 80.00% nodes...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.15224'}; time used = 1.08388090133667s
epoch 10: {'train_loss': '2.80111'}; time used = 0.9956338405609131s
epoch 15: {'train_loss': '2.82097'}; time used = 1.0003063678741455s
epoch 20: {'train_loss': '2.81323'}; time used = 1.6874637603759766s
epoch 25: {'train_loss': '2.79821'}; time used = 2.655158281326294s
epoch 30: {'train_loss': '2.78960'}; time used = 1.5948457717895508s
epoch 35: {'train_loss': '2.78359'}; time used = 0.9908552169799805s
epoch 40: {'train_loss': '2.78102'}; time used = 1.0517733097076416s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.281094789505005.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37511'}; time used = 1.0556244850158691s
epoch 10: {'train_loss': '1.41316'}; time used = 0.9273746013641357s
epoch 15: {'train_loss': '1.37138'}; time used = 1.0281307697296143s
epoch 20: {'train_loss': '1.38808'}; time used = 1.0562095642089844s
epoch 25: {'train_loss': '1.35555'}; time used = 1.1312670707702637s
epoch 30: {'train_loss': '1.34333'}; time used = 0.9701700210571289s
epoch 35: {'train_loss': '1.33826'}; time used = 1.0688328742980957s
epoch 40: {'train_loss': '1.34416'}; time used = 0.9994843006134033s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.957348585128784.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.6027874564459931, 'samples': 0.6052631578947368, 'weighted': 0.6077388593434807, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.65933'}; time used = 1.560995101928711s
epoch 10: {'train_loss': '0.20226'}; time used = 1.2860355377197266s
epoch 15: {'train_loss': '0.07433'}; time used = 1.302046775817871s
epoch 20: {'train_loss': '0.07288'}; time used = 1.2995667457580566s
epoch 25: {'train_loss': '0.02034'}; time used = 1.2665703296661377s
epoch 30: {'train_loss': '0.01753'}; time used = 1.275406837463379s
epoch 35: {'train_loss': '0.01609'}; time used = 1.281862735748291s
epoch 40: {'train_loss': '0.00063'}; time used = 1.3442096710205078s
epoch 45: {'train_loss': '0.00025'}; time used = 1.353531837463379s
epoch 50: {'train_loss': '0.00220'}; time used = 1.3452866077423096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.324744939804077.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85129'}; time used = 6.424789667129517s
epoch 10: {'train_loss': '2.77797'}; time used = 7.358097076416016s
epoch 15: {'train_loss': '2.77956'}; time used = 7.195709943771362s
epoch 20: {'train_loss': '2.78609'}; time used = 6.932705879211426s
epoch 25: {'train_loss': '2.77362'}; time used = 6.729849338531494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.03709053993225.
Training classifier using 80.00% nodes...
{'micro': 0.49666666666666665, 'macro': 0.4290110410113157, 'samples': 0.49666666666666665, 'weighted': 0.41921763285789937, 'accuracy': 0.49666666666666665}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03517'}; time used = 2.05735445022583s
epoch 10: {'train_loss': '0.94469'}; time used = 2.4429519176483154s
epoch 15: {'train_loss': '0.64979'}; time used = 3.1498892307281494s
epoch 20: {'train_loss': '0.64326'}; time used = 2.9516983032226562s
epoch 25: {'train_loss': '0.42835'}; time used = 2.9080018997192383s
epoch 30: {'train_loss': '0.30581'}; time used = 1.7636725902557373s
epoch 35: {'train_loss': '0.38521'}; time used = 1.7634801864624023s
epoch 40: {'train_loss': '0.32406'}; time used = 1.7345051765441895s
epoch 45: {'train_loss': '0.27743'}; time used = 1.63370680809021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.078070163726807.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.29284'}; time used = 5.842221736907959s
epoch 10: {'train_loss': '1.18724'}; time used = 5.729063987731934s
epoch 15: {'train_loss': '1.01298'}; time used = 5.530107259750366s
epoch 20: {'train_loss': '0.75280'}; time used = 5.6286327838897705s
epoch 25: {'train_loss': '0.75878'}; time used = 5.156897306442261s
epoch 30: {'train_loss': '0.40761'}; time used = 5.148741960525513s
epoch 35: {'train_loss': '0.10112'}; time used = 4.948265075683594s
epoch 40: {'train_loss': '0.16626'}; time used = 5.133285045623779s
epoch 45: {'train_loss': '0.03322'}; time used = 5.10965895652771s
epoch 50: {'train_loss': '1.52513'}; time used = 5.19454288482666s
epoch 55: {'train_loss': '0.53580'}; time used = 5.081405401229858s
epoch 60: {'train_loss': '0.08492'}; time used = 5.132936716079712s
epoch 65: {'train_loss': '0.00794'}; time used = 4.993247032165527s
epoch 70: {'train_loss': '0.01653'}; time used = 5.399099111557007s
epoch 75: {'train_loss': '0.00673'}; time used = 9.791878700256348s
epoch 80: {'train_loss': '0.11193'}; time used = 5.2021167278289795s
epoch 85: {'train_loss': '0.00039'}; time used = 5.37746524810791s
epoch 90: {'train_loss': '0.06786'}; time used = 5.474046230316162s
epoch 95: {'train_loss': '0.01492'}; time used = 5.052502393722534s
epoch 100: {'train_loss': '0.26916'}; time used = 4.917487859725952s
epoch 105: {'train_loss': '0.05810'}; time used = 4.995510816574097s
epoch 110: {'train_loss': '0.00905'}; time used = 5.041513442993164s
epoch 115: {'train_loss': '1.98503'}; time used = 5.909329652786255s
epoch 120: {'train_loss': '0.00035'}; time used = 5.240354061126709s
epoch 125: {'train_loss': '0.09219'}; time used = 5.148832559585571s
epoch 130: {'train_loss': '0.79909'}; time used = 5.336725473403931s
epoch 135: {'train_loss': '0.00015'}; time used = 5.341857194900513s
epoch 140: {'train_loss': '0.00574'}; time used = 5.210798263549805s
epoch 145: {'train_loss': '0.00217'}; time used = 5.17310094833374s
epoch 150: {'train_loss': '0.47194'}; time used = 6.646842002868652s
epoch 155: {'train_loss': '0.11958'}; time used = 5.9257001876831055s
epoch 160: {'train_loss': '0.00002'}; time used = 5.115337610244751s
epoch 165: {'train_loss': '0.01254'}; time used = 5.039365768432617s
epoch 170: {'train_loss': '0.00431'}; time used = 5.274566888809204s
epoch 175: {'train_loss': '0.21516'}; time used = 4.99316668510437s
epoch 180: {'train_loss': '0.01813'}; time used = 5.015538215637207s
epoch 185: {'train_loss': '0.01460'}; time used = 5.093047380447388s
epoch 190: {'train_loss': '0.00071'}; time used = 5.657661437988281s
epoch 195: {'train_loss': '0.00381'}; time used = 8.139194011688232s
epoch 200: {'train_loss': '0.00269'}; time used = 5.116716384887695s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 240.19828534126282.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.96942'}; time used = 2.3590216636657715s
epoch 10: {'train_loss': '2.84475'}; time used = 2.54410719871521s
epoch 15: {'train_loss': '2.80572'}; time used = 2.256385087966919s
epoch 20: {'train_loss': '2.77845'}; time used = 1.302964687347412s
epoch 25: {'train_loss': '2.77285'}; time used = 0.9951992034912109s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.94658136367798.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.45589'}; time used = 5.256343603134155s
epoch 10: {'train_loss': '2.84591'}; time used = 4.4904255867004395s
epoch 15: {'train_loss': '2.83529'}; time used = 4.3563103675842285s
epoch 20: {'train_loss': '2.84115'}; time used = 4.330094814300537s
epoch 25: {'train_loss': '2.82535'}; time used = 4.389452219009399s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.040576457977295.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82485'}; time used = 1.0906426906585693s
epoch 10: {'train_loss': '2.77690'}; time used = 1.12906813621521s
epoch 15: {'train_loss': '2.77674'}; time used = 0.9924745559692383s
epoch 20: {'train_loss': '2.78083'}; time used = 1.0076572895050049s
epoch 25: {'train_loss': '2.77362'}; time used = 1.0060453414916992s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.651309728622437.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.49042145593869735, 'samples': 0.631578947368421, 'weighted': 0.5327687033676145, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87431'}; time used = 3.5363762378692627s
epoch 10: {'train_loss': '2.79271'}; time used = 2.234300136566162s
epoch 15: {'train_loss': '2.78810'}; time used = 2.023409366607666s
epoch 20: {'train_loss': '2.77761'}; time used = 1.9813332557678223s
epoch 25: {'train_loss': '2.77210'}; time used = 1.7280504703521729s
epoch 30: {'train_loss': '2.77173'}; time used = 1.6542620658874512s
epoch 35: {'train_loss': '2.77060'}; time used = 1.5931634902954102s
epoch 40: {'train_loss': '2.76982'}; time used = 1.60103178024292s
epoch 45: {'train_loss': '2.76867'}; time used = 1.6274335384368896s
epoch 50: {'train_loss': '2.76816'}; time used = 1.8521885871887207s
epoch 55: {'train_loss': '2.76721'}; time used = 1.6091465950012207s
epoch 60: {'train_loss': '2.76533'}; time used = 1.734851360321045s
epoch 65: {'train_loss': '2.75994'}; time used = 1.6375839710235596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.82370972633362.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.90986'}; time used = 1.8692951202392578s
epoch 10: {'train_loss': '2.80482'}; time used = 2.0170891284942627s
epoch 15: {'train_loss': '2.78170'}; time used = 2.142906904220581s
epoch 20: {'train_loss': '2.76375'}; time used = 3.6363584995269775s
epoch 25: {'train_loss': '2.75225'}; time used = 2.2970385551452637s
epoch 30: {'train_loss': '2.74195'}; time used = 1.7129974365234375s
epoch 35: {'train_loss': '2.73283'}; time used = 1.9305329322814941s
epoch 40: {'train_loss': '2.72230'}; time used = 2.245689868927002s
epoch 45: {'train_loss': '2.69942'}; time used = 1.6889493465423584s
epoch 50: {'train_loss': '2.68553'}; time used = 1.7473812103271484s
epoch 55: {'train_loss': '2.67534'}; time used = 1.6829307079315186s
epoch 60: {'train_loss': '2.63098'}; time used = 1.6733593940734863s
epoch 65: {'train_loss': '2.60142'}; time used = 1.7044873237609863s
epoch 70: {'train_loss': '2.59101'}; time used = 1.694122076034546s
epoch 75: {'train_loss': '2.53364'}; time used = 1.762347936630249s
epoch 80: {'train_loss': '2.53203'}; time used = 1.7038543224334717s
epoch 85: {'train_loss': '2.54426'}; time used = 1.6891093254089355s
epoch 90: {'train_loss': '2.49084'}; time used = 1.7331361770629883s
epoch 95: {'train_loss': '2.49938'}; time used = 1.679137945175171s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.47240853309631.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36921'}; time used = 1.779245138168335s
epoch 10: {'train_loss': '1.27734'}; time used = 2.0201382637023926s
epoch 15: {'train_loss': '1.20228'}; time used = 2.1092779636383057s
epoch 20: {'train_loss': '1.27646'}; time used = 2.068674087524414s
epoch 25: {'train_loss': '1.21266'}; time used = 2.140141487121582s
epoch 30: {'train_loss': '1.28965'}; time used = 2.067978858947754s
epoch 35: {'train_loss': '1.21463'}; time used = 2.0811426639556885s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.47429633140564.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6794763513513513, 'samples': 0.6811594202898551, 'weighted': 0.6811594202898551, 'accuracy': 0.6811594202898551}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.90202'}; time used = 1.980222225189209s
epoch 10: {'train_loss': '2.79912'}; time used = 1.8961968421936035s
epoch 15: {'train_loss': '2.78539'}; time used = 1.8872158527374268s
epoch 20: {'train_loss': '2.78118'}; time used = 1.8369579315185547s
epoch 25: {'train_loss': '2.77795'}; time used = 1.9163837432861328s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.210095167160034.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79304'}; time used = 1.3728485107421875s
epoch 10: {'train_loss': '2.75068'}; time used = 1.4162704944610596s
epoch 15: {'train_loss': '2.75598'}; time used = 1.354645013809204s
epoch 20: {'train_loss': '2.67619'}; time used = 1.4152724742889404s
epoch 25: {'train_loss': '2.59397'}; time used = 1.2924079895019531s
epoch 30: {'train_loss': '2.42593'}; time used = 1.398118019104004s
epoch 35: {'train_loss': '2.23404'}; time used = 1.3336403369903564s
epoch 40: {'train_loss': '2.14843'}; time used = 1.3762245178222656s
epoch 45: {'train_loss': '2.09830'}; time used = 1.269599199295044s
epoch 50: {'train_loss': '2.10948'}; time used = 1.3526482582092285s
epoch 55: {'train_loss': '2.05336'}; time used = 1.2732274532318115s
epoch 60: {'train_loss': '2.00469'}; time used = 1.3341684341430664s
epoch 65: {'train_loss': '1.98151'}; time used = 1.8920865058898926s
epoch 70: {'train_loss': '1.96824'}; time used = 2.049384117126465s
epoch 75: {'train_loss': '1.87812'}; time used = 2.083061456680298s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.226789474487305.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4406926406926407, 'samples': 0.5526315789473685, 'weighted': 0.4802005012531328, 'accuracy': 0.5526315789473685}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.12054'}; time used = 1.09212064743042s
epoch 10: {'train_loss': '0.96836'}; time used = 0.9902987480163574s
epoch 15: {'train_loss': '0.27984'}; time used = 1.7107856273651123s
epoch 20: {'train_loss': '0.13064'}; time used = 1.2482085227966309s
epoch 25: {'train_loss': '0.01692'}; time used = 0.9777975082397461s
epoch 30: {'train_loss': '0.33073'}; time used = 0.9356217384338379s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.28158187866211.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.19615'}; time used = 1.0989503860473633s
epoch 10: {'train_loss': '2.76744'}; time used = 0.9623990058898926s
epoch 15: {'train_loss': '2.76323'}; time used = 0.9901587963104248s
epoch 20: {'train_loss': '2.75841'}; time used = 1.0082921981811523s
epoch 25: {'train_loss': '2.73891'}; time used = 0.9985878467559814s
epoch 30: {'train_loss': '2.62287'}; time used = 0.9613802433013916s
epoch 35: {'train_loss': '1.80920'}; time used = 0.9938631057739258s
epoch 40: {'train_loss': '2.24691'}; time used = 0.9687232971191406s
epoch 45: {'train_loss': '1.63511'}; time used = 0.9645147323608398s
epoch 50: {'train_loss': '1.51049'}; time used = 0.9667503833770752s
epoch 55: {'train_loss': '1.28943'}; time used = 0.9941904544830322s
epoch 60: {'train_loss': '1.20618'}; time used = 1.0592093467712402s
epoch 65: {'train_loss': '1.17787'}; time used = 1.0026640892028809s
epoch 70: {'train_loss': '1.10702'}; time used = 0.9877004623413086s
epoch 75: {'train_loss': '1.01387'}; time used = 0.9795901775360107s
epoch 80: {'train_loss': '1.11480'}; time used = 0.986565113067627s
epoch 85: {'train_loss': '1.11500'}; time used = 1.006216287612915s
epoch 90: {'train_loss': '1.00396'}; time used = 0.9769504070281982s
epoch 95: {'train_loss': '0.99832'}; time used = 0.9956929683685303s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.598551750183105.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35756'}; time used = 1.6556439399719238s
epoch 10: {'train_loss': '1.14054'}; time used = 1.576902151107788s
epoch 15: {'train_loss': '0.93979'}; time used = 1.7136380672454834s
epoch 20: {'train_loss': '0.81238'}; time used = 1.6398489475250244s
epoch 25: {'train_loss': '0.66637'}; time used = 1.6501600742340088s
epoch 30: {'train_loss': '0.41509'}; time used = 2.521984815597534s
epoch 35: {'train_loss': '0.64681'}; time used = 1.65781569480896s
epoch 40: {'train_loss': '0.29738'}; time used = 1.6217024326324463s
epoch 45: {'train_loss': '0.57581'}; time used = 1.714784860610962s
epoch 50: {'train_loss': '0.04214'}; time used = 1.76871657371521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.102355003356934.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4923270969098172, 'samples': 0.4927536231884058, 'weighted': 0.49339341260628894, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.00161'}; time used = 1.6866743564605713s
epoch 10: {'train_loss': '2.92272'}; time used = 1.6734917163848877s
epoch 15: {'train_loss': '2.79479'}; time used = 1.6661512851715088s
epoch 20: {'train_loss': '2.75444'}; time used = 1.697115182876587s
epoch 25: {'train_loss': '2.73024'}; time used = 1.7713158130645752s
epoch 30: {'train_loss': '2.70484'}; time used = 1.781484603881836s
epoch 35: {'train_loss': '2.68399'}; time used = 1.6662092208862305s
epoch 40: {'train_loss': '2.65292'}; time used = 1.6771652698516846s
epoch 45: {'train_loss': '2.62053'}; time used = 1.68243408203125s
epoch 50: {'train_loss': '2.58028'}; time used = 1.6766250133514404s
epoch 55: {'train_loss': '2.57271'}; time used = 1.7269015312194824s
epoch 60: {'train_loss': '2.55574'}; time used = 1.6576974391937256s
epoch 65: {'train_loss': '2.51729'}; time used = 1.678830623626709s
epoch 70: {'train_loss': '2.47525'}; time used = 1.645749807357788s
epoch 75: {'train_loss': '2.46896'}; time used = 1.6852145195007324s
epoch 80: {'train_loss': '2.42648'}; time used = 1.8170709609985352s
epoch 85: {'train_loss': '2.43030'}; time used = 1.6930303573608398s
epoch 90: {'train_loss': '2.43214'}; time used = 1.6589422225952148s
epoch 95: {'train_loss': '2.41314'}; time used = 1.6979670524597168s
epoch 100: {'train_loss': '2.39206'}; time used = 1.739450454711914s
epoch 105: {'train_loss': '2.40156'}; time used = 1.7175772190093994s
epoch 110: {'train_loss': '2.36959'}; time used = 1.6518464088439941s
epoch 115: {'train_loss': '2.37911'}; time used = 1.6748433113098145s
epoch 120: {'train_loss': '2.35983'}; time used = 1.6696889400482178s
epoch 125: {'train_loss': '2.33497'}; time used = 1.6670117378234863s
epoch 130: {'train_loss': '2.35132'}; time used = 1.6466681957244873s
epoch 135: {'train_loss': '2.33486'}; time used = 1.7439167499542236s
epoch 140: {'train_loss': '2.33663'}; time used = 1.6623153686523438s
epoch 145: {'train_loss': '2.31590'}; time used = 1.7019662857055664s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.090561628341675.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.80124'}; time used = 1.684325933456421s
epoch 10: {'train_loss': '2.77207'}; time used = 1.730041742324829s
epoch 15: {'train_loss': '2.75430'}; time used = 1.6539268493652344s
epoch 20: {'train_loss': '2.74911'}; time used = 1.6219618320465088s
epoch 25: {'train_loss': '2.73869'}; time used = 1.8172307014465332s
epoch 30: {'train_loss': '2.72134'}; time used = 1.6828703880310059s
epoch 35: {'train_loss': '2.70737'}; time used = 1.7836670875549316s
epoch 40: {'train_loss': '2.67494'}; time used = 1.682755708694458s
epoch 45: {'train_loss': '2.63144'}; time used = 1.8195552825927734s
epoch 50: {'train_loss': '2.57410'}; time used = 1.6830358505249023s
epoch 55: {'train_loss': '2.52997'}; time used = 1.7160046100616455s
epoch 60: {'train_loss': '2.50880'}; time used = 2.855198383331299s
epoch 65: {'train_loss': '2.46655'}; time used = 2.9136977195739746s
epoch 70: {'train_loss': '2.45224'}; time used = 2.797172784805298s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.825218677520752.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.76817'}; time used = 1.046574354171753s
epoch 10: {'train_loss': '2.40174'}; time used = 0.8247895240783691s
epoch 15: {'train_loss': '2.27525'}; time used = 0.8374440670013428s
epoch 20: {'train_loss': '2.15543'}; time used = 0.9069054126739502s
epoch 25: {'train_loss': '2.10852'}; time used = 0.8404755592346191s
epoch 30: {'train_loss': '2.05726'}; time used = 0.8643877506256104s
epoch 35: {'train_loss': '2.00031'}; time used = 0.8167750835418701s
epoch 40: {'train_loss': '1.96373'}; time used = 0.8742513656616211s
epoch 45: {'train_loss': '1.96110'}; time used = 0.8347451686859131s
epoch 50: {'train_loss': '1.91435'}; time used = 0.8513250350952148s
epoch 55: {'train_loss': '1.88538'}; time used = 0.8684036731719971s
epoch 60: {'train_loss': '1.86024'}; time used = 0.9505214691162109s
epoch 65: {'train_loss': '1.80914'}; time used = 0.8657872676849365s
epoch 70: {'train_loss': '1.81951'}; time used = 1.0035204887390137s
epoch 75: {'train_loss': '1.77572'}; time used = 1.0707118511199951s
epoch 80: {'train_loss': '1.78021'}; time used = 1.0537679195404053s
epoch 85: {'train_loss': '1.81324'}; time used = 1.2427608966827393s
epoch 90: {'train_loss': '1.78622'}; time used = 0.9206600189208984s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.059056758880615.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.26516'}; time used = 2.4935991764068604s
epoch 10: {'train_loss': '1.19452'}; time used = 2.419877052307129s
epoch 15: {'train_loss': '1.13887'}; time used = 2.3433594703674316s
epoch 20: {'train_loss': '1.04810'}; time used = 2.4401638507843018s
epoch 25: {'train_loss': '0.83066'}; time used = 2.5023367404937744s
epoch 30: {'train_loss': '0.59386'}; time used = 2.411609649658203s
epoch 35: {'train_loss': '0.45596'}; time used = 2.3483943939208984s
epoch 40: {'train_loss': '0.24230'}; time used = 2.371495485305786s
epoch 45: {'train_loss': '0.17591'}; time used = 2.3250362873077393s
epoch 50: {'train_loss': '0.10677'}; time used = 2.3250908851623535s
epoch 55: {'train_loss': '0.12488'}; time used = 2.816375494003296s
epoch 60: {'train_loss': '0.06333'}; time used = 3.213188886642456s
epoch 65: {'train_loss': '0.04349'}; time used = 2.3255832195281982s
epoch 70: {'train_loss': '0.05841'}; time used = 2.752239942550659s
epoch 75: {'train_loss': '0.01746'}; time used = 2.377631425857544s
epoch 80: {'train_loss': '0.05139'}; time used = 2.3723161220550537s
epoch 85: {'train_loss': '0.02430'}; time used = 2.320521593093872s
epoch 90: {'train_loss': '0.03105'}; time used = 2.33841609954834s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.97854399681091.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12015'}; time used = 2.060357093811035s
epoch 10: {'train_loss': '0.17893'}; time used = 1.9447309970855713s
epoch 15: {'train_loss': '0.00016'}; time used = 1.973233699798584s
epoch 20: {'train_loss': '0.00001'}; time used = 2.0506112575531006s
epoch 25: {'train_loss': '0.00000'}; time used = 1.989823341369629s
epoch 30: {'train_loss': '0.00000'}; time used = 2.0000224113464355s
epoch 35: {'train_loss': '0.00278'}; time used = 1.9112286567687988s
epoch 40: {'train_loss': '0.00000'}; time used = 1.9347898960113525s
epoch 45: {'train_loss': '0.00000'}; time used = 1.925182819366455s
epoch 50: {'train_loss': '0.00000'}; time used = 1.96317720413208s
epoch 55: {'train_loss': '0.00013'}; time used = 1.9672255516052246s
epoch 60: {'train_loss': '0.00000'}; time used = 1.9048161506652832s
epoch 65: {'train_loss': '0.00000'}; time used = 1.9080860614776611s
epoch 70: {'train_loss': '0.00000'}; time used = 1.9054551124572754s
epoch 75: {'train_loss': '0.00000'}; time used = 1.9060251712799072s
epoch 80: {'train_loss': '0.00000'}; time used = 1.9624037742614746s
epoch 85: {'train_loss': '0.00000'}; time used = 1.8958525657653809s
epoch 90: {'train_loss': '0.00000'}; time used = 1.900923252105713s
epoch 95: {'train_loss': '0.00000'}; time used = 1.8970835208892822s
epoch 100: {'train_loss': '0.00000'}; time used = 1.894801378250122s
epoch 105: {'train_loss': '0.00000'}; time used = 1.9484302997589111s
epoch 110: {'train_loss': '0.00000'}; time used = 1.8879139423370361s
epoch 115: {'train_loss': '0.00000'}; time used = 1.9029560089111328s
epoch 120: {'train_loss': '0.00000'}; time used = 1.8917427062988281s
epoch 125: {'train_loss': '0.00000'}; time used = 2.1283187866210938s
epoch 130: {'train_loss': '0.00000'}; time used = 1.9198646545410156s
epoch 135: {'train_loss': '0.00000'}; time used = 2.067704916000366s
epoch 140: {'train_loss': '0.00000'}; time used = 1.8948988914489746s
epoch 145: {'train_loss': '0.00000'}; time used = 1.934931993484497s
epoch 150: {'train_loss': '0.00000'}; time used = 1.900496482849121s
epoch 155: {'train_loss': '0.00000'}; time used = 1.9895515441894531s
epoch 160: {'train_loss': '0.00000'}; time used = 1.9518189430236816s
epoch 165: {'train_loss': '0.00000'}; time used = 1.873504877090454s
epoch 170: {'train_loss': '0.00000'}; time used = 1.9079616069793701s
epoch 175: {'train_loss': '0.00000'}; time used = 1.9513492584228516s
epoch 180: {'train_loss': '0.00000'}; time used = 2.057386875152588s
epoch 185: {'train_loss': '0.00000'}; time used = 1.9408068656921387s
epoch 190: {'train_loss': '0.00000'}; time used = 2.0045902729034424s
epoch 195: {'train_loss': '0.00000'}; time used = 1.8764073848724365s
epoch 200: {'train_loss': '0.00000'}; time used = 2.491115093231201s
epoch 205: {'train_loss': '0.00000'}; time used = 3.2525603771209717s
epoch 210: {'train_loss': '0.00000'}; time used = 3.2072641849517822s
epoch 215: {'train_loss': '0.00000'}; time used = 2.5273854732513428s
epoch 220: {'train_loss': '0.00000'}; time used = 1.9527080059051514s
epoch 225: {'train_loss': '0.00000'}; time used = 2.0531890392303467s
epoch 230: {'train_loss': '0.00000'}; time used = 1.905810832977295s
epoch 235: {'train_loss': '0.00000'}; time used = 1.9850640296936035s
epoch 240: {'train_loss': '0.00000'}; time used = 2.0865719318389893s
epoch 245: {'train_loss': '0.00000'}; time used = 1.932307243347168s
epoch 250: {'train_loss': '0.00000'}; time used = 1.986417531967163s
epoch 255: {'train_loss': '0.00000'}; time used = 1.9022164344787598s
epoch 260: {'train_loss': '0.00000'}; time used = 2.023261547088623s
epoch 265: {'train_loss': '0.00000'}; time used = 1.8869693279266357s
epoch 270: {'train_loss': '0.00000'}; time used = 1.8901231288909912s
epoch 275: {'train_loss': '0.00000'}; time used = 1.8663115501403809s
epoch 280: {'train_loss': '0.00000'}; time used = 1.9068856239318848s
epoch 285: {'train_loss': '0.00000'}; time used = 1.860851526260376s
epoch 290: {'train_loss': '0.00000'}; time used = 1.8746373653411865s
epoch 295: {'train_loss': '0.00000'}; time used = 1.9071955680847168s
epoch 300: {'train_loss': '0.00000'}; time used = 1.8713278770446777s
epoch 305: {'train_loss': '0.00000'}; time used = 1.8665211200714111s
epoch 310: {'train_loss': '0.00000'}; time used = 1.8777005672454834s
epoch 315: {'train_loss': '0.00000'}; time used = 1.8813939094543457s
epoch 320: {'train_loss': '0.00000'}; time used = 1.927861213684082s
epoch 325: {'train_loss': '0.00000'}; time used = 1.8839950561523438s
epoch 330: {'train_loss': '0.00000'}; time used = 1.9698500633239746s
epoch 335: {'train_loss': '0.00000'}; time used = 1.9556448459625244s
epoch 340: {'train_loss': '0.00000'}; time used = 1.8419256210327148s
epoch 345: {'train_loss': '0.00000'}; time used = 1.8487365245819092s
epoch 350: {'train_loss': '0.00000'}; time used = 1.8873860836029053s
epoch 355: {'train_loss': '0.00005'}; time used = 1.8542625904083252s
epoch 360: {'train_loss': '0.00000'}; time used = 1.8472919464111328s
epoch 365: {'train_loss': '0.00000'}; time used = 1.889859676361084s
epoch 370: {'train_loss': '0.00000'}; time used = 1.8628356456756592s
epoch 375: {'train_loss': '0.00000'}; time used = 1.9012908935546875s
epoch 380: {'train_loss': '0.00000'}; time used = 1.8529834747314453s
epoch 385: {'train_loss': '0.00000'}; time used = 1.8552641868591309s
epoch 390: {'train_loss': '0.00000'}; time used = 2.026554822921753s
epoch 395: {'train_loss': '0.00000'}; time used = 1.9173238277435303s
epoch 400: {'train_loss': '0.00000'}; time used = 1.8854279518127441s
epoch 405: {'train_loss': '0.00000'}; time used = 1.948793888092041s
epoch 410: {'train_loss': '0.00000'}; time used = 2.0110702514648438s
epoch 415: {'train_loss': '0.00000'}; time used = 1.8966901302337646s
epoch 420: {'train_loss': '0.00000'}; time used = 1.8882925510406494s
epoch 425: {'train_loss': '0.00000'}; time used = 1.9375746250152588s
epoch 430: {'train_loss': '0.00000'}; time used = 2.0255792140960693s
epoch 435: {'train_loss': '0.00000'}; time used = 1.8930368423461914s
epoch 440: {'train_loss': '0.00000'}; time used = 1.9984967708587646s
epoch 445: {'train_loss': '0.00000'}; time used = 1.9137349128723145s
epoch 450: {'train_loss': '0.00000'}; time used = 2.2522037029266357s
epoch 455: {'train_loss': '0.00001'}; time used = 3.076005697250366s
epoch 460: {'train_loss': '0.00018'}; time used = 3.253723621368408s
epoch 465: {'train_loss': '0.00000'}; time used = 2.87644624710083s
epoch 470: {'train_loss': '0.00006'}; time used = 2.091804027557373s
epoch 475: {'train_loss': '0.99074'}; time used = 2.018659830093384s
epoch 480: {'train_loss': '0.25285'}; time used = 2.3590774536132812s
epoch 485: {'train_loss': '0.00035'}; time used = 2.322545051574707s
epoch 490: {'train_loss': '0.00002'}; time used = 1.8885726928710938s
epoch 495: {'train_loss': '0.00000'}; time used = 1.8697824478149414s
epoch 500: {'train_loss': '0.00003'}; time used = 1.8733439445495605s
Finished training. Time used = 205.3755943775177.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.645498752593994s
epoch 10: {'train_loss': '1.38629'}; time used = 6.578529596328735s
epoch 15: {'train_loss': '1.38629'}; time used = 6.484633207321167s
epoch 20: {'train_loss': '1.38629'}; time used = 6.564879655838013s
epoch 25: {'train_loss': '1.38629'}; time used = 6.699909687042236s
epoch 30: {'train_loss': '1.38629'}; time used = 6.427103757858276s
epoch 35: {'train_loss': '1.38629'}; time used = 6.343918323516846s
epoch 40: {'train_loss': '1.38629'}; time used = 7.586086750030518s
epoch 45: {'train_loss': '1.38629'}; time used = 8.31927490234375s
epoch 50: {'train_loss': '1.38629'}; time used = 6.570813417434692s
epoch 55: {'train_loss': '1.38629'}; time used = 6.5865795612335205s
epoch 60: {'train_loss': '1.38629'}; time used = 6.487838506698608s
epoch 65: {'train_loss': '1.38629'}; time used = 6.50814962387085s
epoch 70: {'train_loss': '1.38629'}; time used = 6.751648664474487s
epoch 75: {'train_loss': '1.38629'}; time used = 7.280009508132935s
epoch 80: {'train_loss': '1.38629'}; time used = 7.918840646743774s
epoch 85: {'train_loss': '1.38629'}; time used = 7.235448360443115s
epoch 90: {'train_loss': '1.38629'}; time used = 6.66217827796936s
epoch 95: {'train_loss': '1.38629'}; time used = 6.520079612731934s
epoch 100: {'train_loss': '1.38629'}; time used = 7.097830772399902s
epoch 105: {'train_loss': '1.38629'}; time used = 7.080114126205444s
epoch 110: {'train_loss': '1.38629'}; time used = 7.38082218170166s
epoch 115: {'train_loss': '1.38629'}; time used = 6.559948921203613s
epoch 120: {'train_loss': '1.38629'}; time used = 7.699523687362671s
epoch 125: {'train_loss': '1.38629'}; time used = 6.586624622344971s
epoch 130: {'train_loss': '1.38629'}; time used = 6.476904392242432s
epoch 135: {'train_loss': '1.38629'}; time used = 7.053465127944946s
epoch 140: {'train_loss': '1.38629'}; time used = 11.463477849960327s
epoch 145: {'train_loss': '1.38629'}; time used = 7.141313552856445s
epoch 150: {'train_loss': '1.38629'}; time used = 6.785155534744263s
epoch 155: {'train_loss': '1.38629'}; time used = 6.681921720504761s
epoch 160: {'train_loss': '1.38629'}; time used = 6.649376392364502s
epoch 165: {'train_loss': '1.38629'}; time used = 6.61616325378418s
epoch 170: {'train_loss': '1.38629'}; time used = 6.700445890426636s
epoch 175: {'train_loss': '1.38629'}; time used = 6.511719226837158s
epoch 180: {'train_loss': '1.38629'}; time used = 6.479410648345947s
epoch 185: {'train_loss': '1.38629'}; time used = 8.427395105361938s
epoch 190: {'train_loss': '1.38629'}; time used = 7.706258773803711s
epoch 195: {'train_loss': '1.38629'}; time used = 7.5658979415893555s
epoch 200: {'train_loss': '1.38629'}; time used = 8.854065895080566s
epoch 205: {'train_loss': '1.38629'}; time used = 6.569650888442993s
epoch 210: {'train_loss': '1.38629'}; time used = 6.560259819030762s
epoch 215: {'train_loss': '1.38629'}; time used = 7.28877854347229s
epoch 220: {'train_loss': '1.38629'}; time used = 6.601312875747681s
epoch 225: {'train_loss': '1.38629'}; time used = 6.663573265075684s
epoch 230: {'train_loss': '1.38629'}; time used = 6.592083930969238s
epoch 235: {'train_loss': '1.38629'}; time used = 7.223636627197266s
epoch 240: {'train_loss': '1.38629'}; time used = 7.298708915710449s
epoch 245: {'train_loss': '1.38629'}; time used = 6.727391481399536s
epoch 250: {'train_loss': '1.38629'}; time used = 8.989918947219849s
epoch 255: {'train_loss': '1.38629'}; time used = 9.783916473388672s
epoch 260: {'train_loss': '1.38629'}; time used = 8.259732723236084s
epoch 265: {'train_loss': '1.38629'}; time used = 10.373641729354858s
epoch 270: {'train_loss': '1.38629'}; time used = 6.714656352996826s
epoch 275: {'train_loss': '1.38629'}; time used = 6.681586503982544s
epoch 280: {'train_loss': '1.38629'}; time used = 8.243939876556396s
epoch 285: {'train_loss': '1.38629'}; time used = 7.254218339920044s
epoch 290: {'train_loss': '1.38629'}; time used = 9.64876651763916s
epoch 295: {'train_loss': '1.38629'}; time used = 6.868935823440552s
epoch 300: {'train_loss': '1.38629'}; time used = 6.905290365219116s
epoch 305: {'train_loss': '1.38629'}; time used = 6.931370496749878s
epoch 310: {'train_loss': '1.38629'}; time used = 6.637189149856567s
epoch 315: {'train_loss': '1.38629'}; time used = 6.711181879043579s
epoch 320: {'train_loss': '1.38629'}; time used = 6.667410135269165s
epoch 325: {'train_loss': '1.38629'}; time used = 10.323790073394775s
epoch 330: {'train_loss': '1.38629'}; time used = 6.941558599472046s
epoch 335: {'train_loss': '1.38629'}; time used = 6.602165937423706s
epoch 340: {'train_loss': '1.38629'}; time used = 6.670457124710083s
epoch 345: {'train_loss': '1.38629'}; time used = 6.814277648925781s
epoch 350: {'train_loss': '1.38629'}; time used = 6.962182521820068s
epoch 355: {'train_loss': '1.38629'}; time used = 6.979182958602905s
epoch 360: {'train_loss': '1.38629'}; time used = 6.672538995742798s
epoch 365: {'train_loss': '1.38629'}; time used = 6.700236558914185s
epoch 370: {'train_loss': '1.38629'}; time used = 6.747715711593628s
epoch 375: {'train_loss': '1.38629'}; time used = 6.731874227523804s
epoch 380: {'train_loss': '1.38629'}; time used = 6.795245409011841s
epoch 385: {'train_loss': '1.38629'}; time used = 6.894477128982544s
epoch 390: {'train_loss': '1.38629'}; time used = 7.253595590591431s
epoch 395: {'train_loss': '1.38629'}; time used = 6.770374059677124s
epoch 400: {'train_loss': '1.38629'}; time used = 6.729975938796997s
epoch 405: {'train_loss': '1.38629'}; time used = 6.901713609695435s
epoch 410: {'train_loss': '1.38629'}; time used = 6.843120574951172s
epoch 415: {'train_loss': '1.38629'}; time used = 7.1461145877838135s
epoch 420: {'train_loss': '1.38629'}; time used = 6.835931062698364s
epoch 425: {'train_loss': '1.38629'}; time used = 6.948460578918457s
epoch 430: {'train_loss': '1.38629'}; time used = 6.943093538284302s
epoch 435: {'train_loss': '1.38629'}; time used = 6.869963884353638s
epoch 440: {'train_loss': '1.38629'}; time used = 10.525094985961914s
epoch 445: {'train_loss': '1.38629'}; time used = 7.52773380279541s
epoch 450: {'train_loss': '1.38629'}; time used = 7.1768107414245605s
epoch 455: {'train_loss': '1.38629'}; time used = 9.35561203956604s
epoch 460: {'train_loss': '1.38629'}; time used = 8.779553890228271s
epoch 465: {'train_loss': '1.38629'}; time used = 7.1922101974487305s
epoch 470: {'train_loss': '1.38629'}; time used = 7.129232406616211s
epoch 475: {'train_loss': '1.38629'}; time used = 7.227322340011597s
epoch 480: {'train_loss': '1.38629'}; time used = 7.4870359897613525s
epoch 485: {'train_loss': '1.38629'}; time used = 7.564050912857056s
epoch 490: {'train_loss': '1.38629'}; time used = 10.671940565109253s
epoch 495: {'train_loss': '1.38629'}; time used = 8.190594911575317s
epoch 500: {'train_loss': '1.38629'}; time used = 7.651910305023193s
Finished training. Time used = 738.995046377182.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.97405'}; time used = 2.422848701477051s
epoch 10: {'train_loss': '2.82362'}; time used = 2.381294012069702s
epoch 15: {'train_loss': '2.77436'}; time used = 2.603212594985962s
epoch 20: {'train_loss': '2.75933'}; time used = 2.3909010887145996s
epoch 25: {'train_loss': '2.76029'}; time used = 2.4572818279266357s
epoch 30: {'train_loss': '2.74888'}; time used = 2.291731119155884s
epoch 35: {'train_loss': '2.74053'}; time used = 2.4314534664154053s
epoch 40: {'train_loss': '2.72639'}; time used = 2.218862771987915s
epoch 45: {'train_loss': '2.71198'}; time used = 2.6269876956939697s
epoch 50: {'train_loss': '2.70247'}; time used = 2.3480114936828613s
epoch 55: {'train_loss': '2.70448'}; time used = 2.6277682781219482s
epoch 60: {'train_loss': '2.68644'}; time used = 2.546449899673462s
epoch 65: {'train_loss': '2.68881'}; time used = 2.640091896057129s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.41191625595093.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.34750'}; time used = 1.2107622623443604s
epoch 10: {'train_loss': '0.21238'}; time used = 1.0159966945648193s
epoch 15: {'train_loss': '0.14200'}; time used = 1.050581693649292s
epoch 20: {'train_loss': '0.15263'}; time used = 1.0834429264068604s
epoch 25: {'train_loss': '0.17061'}; time used = 0.9959042072296143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.345877885818481.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6492307692307693, 'samples': 0.6842105263157895, 'weighted': 0.6667206477732792, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85764'}; time used = 1.5790257453918457s
epoch 10: {'train_loss': '2.77432'}; time used = 1.3642349243164062s
epoch 15: {'train_loss': '2.77286'}; time used = 3.5648653507232666s
epoch 20: {'train_loss': '2.77203'}; time used = 2.0531349182128906s
epoch 25: {'train_loss': '2.77302'}; time used = 1.6669552326202393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.236570358276367.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36409'}; time used = 2.2472455501556396s
epoch 10: {'train_loss': '1.29635'}; time used = 2.3050954341888428s
epoch 15: {'train_loss': '1.23216'}; time used = 2.2121667861938477s
epoch 20: {'train_loss': '1.30168'}; time used = 2.148737668991089s
epoch 25: {'train_loss': '1.02189'}; time used = 2.312370538711548s
epoch 30: {'train_loss': '0.94610'}; time used = 2.1925880908966064s
epoch 35: {'train_loss': '0.79437'}; time used = 2.4733216762542725s
epoch 40: {'train_loss': '0.71195'}; time used = 2.2068662643432617s
epoch 45: {'train_loss': '0.71085'}; time used = 3.208286762237549s
epoch 50: {'train_loss': '0.65028'}; time used = 2.518507480621338s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.684781789779663.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5410856039476507, 'samples': 0.5507246376811594, 'weighted': 0.545905120814405, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.85519'}; time used = 2.0591824054718018s
epoch 10: {'train_loss': '2.87981'}; time used = 2.9259040355682373s
epoch 15: {'train_loss': '2.80441'}; time used = 1.7562646865844727s
epoch 20: {'train_loss': '2.77507'}; time used = 1.0658414363861084s
epoch 25: {'train_loss': '2.77676'}; time used = 1.143198013305664s
epoch 30: {'train_loss': '2.77247'}; time used = 1.2502570152282715s
epoch 35: {'train_loss': '2.77170'}; time used = 1.0594537258148193s
epoch 40: {'train_loss': '2.77304'}; time used = 1.0671672821044922s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.553399562835693.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76798'}; time used = 2.7454967498779297s
epoch 10: {'train_loss': '2.74352'}; time used = 3.2245607376098633s
epoch 15: {'train_loss': '2.72358'}; time used = 2.356353282928467s
epoch 20: {'train_loss': '2.70463'}; time used = 1.7924799919128418s
epoch 25: {'train_loss': '2.67950'}; time used = 1.8873395919799805s
epoch 30: {'train_loss': '2.65594'}; time used = 1.9407520294189453s
epoch 35: {'train_loss': '2.64243'}; time used = 1.88344144821167s
epoch 40: {'train_loss': '2.62605'}; time used = 1.7266483306884766s
epoch 45: {'train_loss': '2.59891'}; time used = 1.7827081680297852s
epoch 50: {'train_loss': '2.56859'}; time used = 1.7815518379211426s
epoch 55: {'train_loss': '2.55141'}; time used = 1.9531915187835693s
epoch 60: {'train_loss': '2.52933'}; time used = 1.794567584991455s
epoch 65: {'train_loss': '2.48896'}; time used = 1.818042278289795s
epoch 70: {'train_loss': '2.44349'}; time used = 1.8108229637145996s
epoch 75: {'train_loss': '2.41670'}; time used = 1.7598209381103516s
epoch 80: {'train_loss': '2.40519'}; time used = 1.7963223457336426s
epoch 85: {'train_loss': '2.41029'}; time used = 1.7759430408477783s
epoch 90: {'train_loss': '2.40819'}; time used = 1.729417085647583s
epoch 95: {'train_loss': '2.40720'}; time used = 1.684004783630371s
epoch 100: {'train_loss': '2.38248'}; time used = 1.7046756744384766s
epoch 105: {'train_loss': '2.38719'}; time used = 1.8026165962219238s
epoch 110: {'train_loss': '2.37019'}; time used = 1.760282278060913s
epoch 115: {'train_loss': '2.37295'}; time used = 1.6746392250061035s
epoch 120: {'train_loss': '2.36601'}; time used = 1.8689539432525635s
epoch 125: {'train_loss': '2.35467'}; time used = 1.9266183376312256s
epoch 130: {'train_loss': '2.37341'}; time used = 1.9191501140594482s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.31261968612671.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.19598'}; time used = 1.9991581439971924s
epoch 10: {'train_loss': '1.14093'}; time used = 2.0796053409576416s
epoch 15: {'train_loss': '0.78726'}; time used = 2.6599600315093994s
epoch 20: {'train_loss': '0.63998'}; time used = 1.882993459701538s
epoch 25: {'train_loss': '0.58707'}; time used = 2.029101610183716s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.431914567947388.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.18768'}; time used = 1.4554059505462646s
epoch 10: {'train_loss': '3.00816'}; time used = 1.1761233806610107s
epoch 15: {'train_loss': '2.87823'}; time used = 1.154907464981079s
epoch 20: {'train_loss': '2.79853'}; time used = 1.471036434173584s
epoch 25: {'train_loss': '2.68152'}; time used = 1.2722423076629639s
epoch 30: {'train_loss': '2.57839'}; time used = 1.3069512844085693s
epoch 35: {'train_loss': '2.46301'}; time used = 1.4119720458984375s
epoch 40: {'train_loss': '2.35977'}; time used = 1.291977882385254s
epoch 45: {'train_loss': '2.32555'}; time used = 1.2431209087371826s
epoch 50: {'train_loss': '2.33418'}; time used = 1.2957265377044678s
epoch 55: {'train_loss': '2.23923'}; time used = 1.2495150566101074s
epoch 60: {'train_loss': '2.21781'}; time used = 1.446516752243042s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.866432666778564.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.80067'}; time used = 1.1522393226623535s
epoch 10: {'train_loss': '0.90435'}; time used = 1.1184732913970947s
epoch 15: {'train_loss': '0.35958'}; time used = 1.0569608211517334s
epoch 20: {'train_loss': '0.23567'}; time used = 1.064100742340088s
epoch 25: {'train_loss': '0.21475'}; time used = 1.260232925415039s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.565851926803589.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.17 GiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '3.07855'}; time used = 4.398345232009888s
epoch 10: {'train_loss': '3.00532'}; time used = 5.169999599456787s
epoch 15: {'train_loss': '2.94614'}; time used = 5.48980975151062s
epoch 20: {'train_loss': '2.88640'}; time used = 3.967216968536377s
epoch 25: {'train_loss': '2.82304'}; time used = 3.3755548000335693s
epoch 30: {'train_loss': '2.76701'}; time used = 2.1834328174591064s
epoch 35: {'train_loss': '2.73199'}; time used = 1.9928386211395264s
epoch 40: {'train_loss': '2.68099'}; time used = 1.960601806640625s
epoch 45: {'train_loss': '2.64409'}; time used = 1.845313310623169s
epoch 50: {'train_loss': '2.60292'}; time used = 1.916623830795288s
epoch 55: {'train_loss': '2.58424'}; time used = 1.945812702178955s
epoch 60: {'train_loss': '2.56843'}; time used = 1.9367601871490479s
epoch 65: {'train_loss': '2.54092'}; time used = 2.1728522777557373s
epoch 70: {'train_loss': '2.52703'}; time used = 1.9520595073699951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.5922212600708.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33787'}; time used = 2.3119213581085205s
epoch 10: {'train_loss': '1.23930'}; time used = 2.077685832977295s
epoch 15: {'train_loss': '1.21687'}; time used = 2.1015193462371826s
epoch 20: {'train_loss': '1.29424'}; time used = 2.174999952316284s
epoch 25: {'train_loss': '1.24467'}; time used = 2.539806365966797s
epoch 30: {'train_loss': '1.21680'}; time used = 2.309882879257202s
epoch 35: {'train_loss': '1.24978'}; time used = 2.135800838470459s
epoch 40: {'train_loss': '1.18063'}; time used = 2.216292381286621s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.653295755386353.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5353535353535354, 'samples': 0.5362318840579711, 'weighted': 0.5368174498609282, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75571'}; time used = 2.1292858123779297s
epoch 10: {'train_loss': '2.74266'}; time used = 2.3079254627227783s
epoch 15: {'train_loss': '2.70106'}; time used = 1.3697619438171387s
epoch 20: {'train_loss': '2.62702'}; time used = 1.3724884986877441s
epoch 25: {'train_loss': '2.50522'}; time used = 1.3940589427947998s
epoch 30: {'train_loss': '2.36089'}; time used = 1.2780330181121826s
epoch 35: {'train_loss': '2.31346'}; time used = 1.337817668914795s
epoch 40: {'train_loss': '2.23857'}; time used = 1.2297818660736084s
epoch 45: {'train_loss': '2.19777'}; time used = 2.7536914348602295s
epoch 50: {'train_loss': '2.18622'}; time used = 2.5780909061431885s
epoch 55: {'train_loss': '2.13804'}; time used = 2.016608715057373s
epoch 60: {'train_loss': '2.22415'}; time used = 1.324108600616455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.873905658721924.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79564'}; time used = 1.2226948738098145s
epoch 10: {'train_loss': '2.62943'}; time used = 1.0942652225494385s
epoch 15: {'train_loss': '2.15464'}; time used = 1.0798377990722656s
epoch 20: {'train_loss': '1.84618'}; time used = 1.0965986251831055s
epoch 25: {'train_loss': '1.74065'}; time used = 1.193091869354248s
epoch 30: {'train_loss': '1.68821'}; time used = 1.0837781429290771s
epoch 35: {'train_loss': '2.19384'}; time used = 1.064452886581421s
epoch 40: {'train_loss': '2.02257'}; time used = 1.1559951305389404s
epoch 45: {'train_loss': '1.90970'}; time used = 1.124194622039795s
epoch 50: {'train_loss': '1.75469'}; time used = 1.059041976928711s
epoch 55: {'train_loss': '1.64922'}; time used = 1.0820538997650146s
epoch 60: {'train_loss': '1.62057'}; time used = 1.1304903030395508s
epoch 65: {'train_loss': '1.53269'}; time used = 1.8826048374176025s
epoch 70: {'train_loss': '1.72820'}; time used = 1.3575506210327148s
epoch 75: {'train_loss': '1.59948'}; time used = 1.095780372619629s
epoch 80: {'train_loss': '1.56981'}; time used = 1.087693214416504s
epoch 85: {'train_loss': '1.55739'}; time used = 1.1916029453277588s
epoch 90: {'train_loss': '1.51464'}; time used = 1.06504487991333s
epoch 95: {'train_loss': '1.48682'}; time used = 1.117253303527832s
epoch 100: {'train_loss': '1.45724'}; time used = 1.2246530055999756s
epoch 105: {'train_loss': '1.37538'}; time used = 1.331451416015625s
epoch 110: {'train_loss': '1.33376'}; time used = 1.0269665718078613s
epoch 115: {'train_loss': '1.34072'}; time used = 1.0546202659606934s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.221450805664062.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9163609684519443, 'samples': 0.9210526315789473, 'weighted': 0.9194887438699463, 'accuracy': 0.9210526315789473}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.04862'}; time used = 2.462348222732544s
epoch 10: {'train_loss': '0.58843'}; time used = 1.6857995986938477s
epoch 15: {'train_loss': '0.48643'}; time used = 1.7869274616241455s
epoch 20: {'train_loss': '0.46660'}; time used = 1.6634600162506104s
epoch 25: {'train_loss': '0.51087'}; time used = 1.8695247173309326s
epoch 30: {'train_loss': '0.53643'}; time used = 1.737574577331543s
epoch 35: {'train_loss': '0.47172'}; time used = 2.3599398136138916s
epoch 40: {'train_loss': '0.54196'}; time used = 2.666177988052368s
epoch 45: {'train_loss': '0.43088'}; time used = 1.757298469543457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.751808404922485.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.18480'}; time used = 1.3315694332122803s
epoch 10: {'train_loss': '2.77633'}; time used = 1.1230871677398682s
epoch 15: {'train_loss': '2.62467'}; time used = 1.30037260055542s
epoch 20: {'train_loss': '2.49339'}; time used = 1.2599589824676514s
epoch 25: {'train_loss': '2.40229'}; time used = 1.3829004764556885s
epoch 30: {'train_loss': '2.33781'}; time used = 1.2051753997802734s
epoch 35: {'train_loss': '2.28785'}; time used = 1.9345417022705078s
epoch 40: {'train_loss': '2.24698'}; time used = 2.047748565673828s
epoch 45: {'train_loss': '2.19859'}; time used = 1.9951426982879639s
epoch 50: {'train_loss': '2.19199'}; time used = 1.7680325508117676s
epoch 55: {'train_loss': '2.12088'}; time used = 1.848863124847412s
epoch 60: {'train_loss': '2.01833'}; time used = 1.9999001026153564s
epoch 65: {'train_loss': '2.30139'}; time used = 1.260451316833496s
epoch 70: {'train_loss': '1.90247'}; time used = 1.128650426864624s
epoch 75: {'train_loss': '1.61577'}; time used = 1.101050615310669s
epoch 80: {'train_loss': '1.61341'}; time used = 1.026258945465088s
epoch 85: {'train_loss': '1.71444'}; time used = 1.0189650058746338s
epoch 90: {'train_loss': '1.69716'}; time used = 1.0697157382965088s
epoch 95: {'train_loss': '1.61917'}; time used = 1.1512317657470703s
epoch 100: {'train_loss': '1.61318'}; time used = 1.8622286319732666s
epoch 105: {'train_loss': '1.66615'}; time used = 1.045344352722168s
epoch 110: {'train_loss': '1.50713'}; time used = 1.0729146003723145s
epoch 115: {'train_loss': '1.76998'}; time used = 0.9270913600921631s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.88861584663391.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.482980012893677s
epoch 10: {'train_loss': '1.38629'}; time used = 7.380065679550171s
epoch 15: {'train_loss': '1.38629'}; time used = 10.527040958404541s
epoch 20: {'train_loss': '1.38629'}; time used = 7.842035293579102s
epoch 25: {'train_loss': '1.38629'}; time used = 7.151005744934082s
epoch 30: {'train_loss': '1.38629'}; time used = 7.152456521987915s
epoch 35: {'train_loss': '1.38629'}; time used = 7.227574586868286s
epoch 40: {'train_loss': '1.38629'}; time used = 7.2522947788238525s
epoch 45: {'train_loss': '1.38629'}; time used = 9.880486011505127s
epoch 50: {'train_loss': '1.38629'}; time used = 7.332854509353638s
epoch 55: {'train_loss': '1.38629'}; time used = 10.612810850143433s
epoch 60: {'train_loss': '1.38629'}; time used = 7.596408367156982s
epoch 65: {'train_loss': '1.38629'}; time used = 10.569252014160156s
epoch 70: {'train_loss': '1.38629'}; time used = 6.9402711391448975s
epoch 75: {'train_loss': '1.38629'}; time used = 6.824558258056641s
epoch 80: {'train_loss': '1.38629'}; time used = 7.130827903747559s
epoch 85: {'train_loss': '1.38629'}; time used = 6.98543119430542s
epoch 90: {'train_loss': '1.38629'}; time used = 10.727208852767944s
epoch 95: {'train_loss': '1.38629'}; time used = 7.327268838882446s
epoch 100: {'train_loss': '1.38629'}; time used = 6.997774362564087s
epoch 105: {'train_loss': '1.38629'}; time used = 7.219431638717651s
epoch 110: {'train_loss': '1.38629'}; time used = 9.645588874816895s
epoch 115: {'train_loss': '1.38629'}; time used = 13.049395561218262s
epoch 120: {'train_loss': '1.38629'}; time used = 12.217652559280396s
epoch 125: {'train_loss': '1.38629'}; time used = 7.095176935195923s
epoch 130: {'train_loss': '1.38629'}; time used = 7.163547515869141s
epoch 135: {'train_loss': '1.38629'}; time used = 7.199953556060791s
epoch 140: {'train_loss': '1.38629'}; time used = 7.3740174770355225s
epoch 145: {'train_loss': '1.38629'}; time used = 7.135995149612427s
epoch 150: {'train_loss': '1.38629'}; time used = 7.101110458374023s
epoch 155: {'train_loss': '1.38629'}; time used = 8.87497067451477s
epoch 160: {'train_loss': '1.38629'}; time used = 9.59017038345337s
epoch 165: {'train_loss': '1.38629'}; time used = 11.557136535644531s
epoch 170: {'train_loss': '1.38629'}; time used = 7.696819305419922s
epoch 175: {'train_loss': '1.38629'}; time used = 7.169296503067017s
epoch 180: {'train_loss': '1.38629'}; time used = 7.69172215461731s
epoch 185: {'train_loss': '1.38629'}; time used = 11.307192325592041s
epoch 190: {'train_loss': '1.38629'}; time used = 9.853639602661133s
epoch 195: {'train_loss': '1.38629'}; time used = 6.949270486831665s
epoch 200: {'train_loss': '1.38629'}; time used = 10.258306503295898s
epoch 205: {'train_loss': '1.38629'}; time used = 8.764219760894775s
epoch 210: {'train_loss': '1.38629'}; time used = 7.110973596572876s
epoch 215: {'train_loss': '1.38629'}; time used = 6.999061584472656s
epoch 220: {'train_loss': '1.38629'}; time used = 7.033087491989136s
epoch 225: {'train_loss': '1.38629'}; time used = 6.7962486743927s
epoch 230: {'train_loss': '1.38629'}; time used = 7.527572870254517s
epoch 235: {'train_loss': '1.38629'}; time used = 10.379381656646729s
epoch 240: {'train_loss': '1.38629'}; time used = 7.834126710891724s
epoch 245: {'train_loss': '1.38629'}; time used = 6.956268548965454s
epoch 250: {'train_loss': '1.38629'}; time used = 7.196566104888916s
epoch 255: {'train_loss': '1.38629'}; time used = 7.113502025604248s
epoch 260: {'train_loss': '1.38629'}; time used = 6.954608678817749s
epoch 265: {'train_loss': '1.38629'}; time used = 6.9783935546875s
epoch 270: {'train_loss': '1.38629'}; time used = 6.957530975341797s
epoch 275: {'train_loss': '1.38629'}; time used = 6.966899871826172s
epoch 280: {'train_loss': '1.38629'}; time used = 6.861438035964966s
epoch 285: {'train_loss': '1.38629'}; time used = 6.881864786148071s
epoch 290: {'train_loss': '1.38629'}; time used = 7.04205584526062s
epoch 295: {'train_loss': '1.38629'}; time used = 7.119659423828125s
epoch 300: {'train_loss': '1.38629'}; time used = 7.065178632736206s
epoch 305: {'train_loss': '1.38629'}; time used = 7.132932901382446s
epoch 310: {'train_loss': '1.38629'}; time used = 7.016323804855347s
epoch 315: {'train_loss': '1.38629'}; time used = 6.957797288894653s
epoch 320: {'train_loss': '1.38629'}; time used = 7.577214479446411s
epoch 325: {'train_loss': '1.38629'}; time used = 11.780847549438477s
epoch 330: {'train_loss': '1.38629'}; time used = 7.73676872253418s
epoch 335: {'train_loss': '1.38629'}; time used = 6.958488464355469s
epoch 340: {'train_loss': '1.38629'}; time used = 10.415977954864502s
epoch 345: {'train_loss': '1.38629'}; time used = 7.767336845397949s
epoch 350: {'train_loss': '1.38629'}; time used = 6.852934837341309s
epoch 355: {'train_loss': '1.38629'}; time used = 6.911825180053711s
epoch 360: {'train_loss': '1.38629'}; time used = 6.831862926483154s
epoch 365: {'train_loss': '1.38629'}; time used = 7.588796138763428s
epoch 370: {'train_loss': '1.38629'}; time used = 7.042637586593628s
epoch 375: {'train_loss': '1.38629'}; time used = 7.114490270614624s
epoch 380: {'train_loss': '1.38629'}; time used = 7.313055992126465s
epoch 385: {'train_loss': '1.38629'}; time used = 7.057204484939575s
epoch 390: {'train_loss': '1.38629'}; time used = 9.822192668914795s
epoch 395: {'train_loss': '1.38629'}; time used = 12.6748046875s
epoch 400: {'train_loss': '1.38629'}; time used = 8.414266347885132s
epoch 405: {'train_loss': '1.38629'}; time used = 8.212789058685303s
epoch 410: {'train_loss': '1.38629'}; time used = 9.603810548782349s
epoch 415: {'train_loss': '1.38629'}; time used = 6.996911525726318s
epoch 420: {'train_loss': '1.38629'}; time used = 8.25319790840149s
epoch 425: {'train_loss': '1.38629'}; time used = 6.918936252593994s
epoch 430: {'train_loss': '1.38629'}; time used = 10.922584533691406s
epoch 435: {'train_loss': '1.38629'}; time used = 6.947515487670898s
epoch 440: {'train_loss': '1.38629'}; time used = 6.930847406387329s
epoch 445: {'train_loss': '1.38629'}; time used = 6.89872932434082s
epoch 450: {'train_loss': '1.38629'}; time used = 6.800333261489868s
epoch 455: {'train_loss': '1.38629'}; time used = 6.8777453899383545s
epoch 460: {'train_loss': '1.38629'}; time used = 6.912303924560547s
epoch 465: {'train_loss': '1.38629'}; time used = 10.28976559638977s
epoch 470: {'train_loss': '1.38629'}; time used = 6.940340995788574s
epoch 475: {'train_loss': '1.38629'}; time used = 7.022627592086792s
epoch 480: {'train_loss': '1.38629'}; time used = 6.9979939460754395s
epoch 485: {'train_loss': '1.38629'}; time used = 6.914547681808472s
epoch 490: {'train_loss': '1.38629'}; time used = 7.100040912628174s
epoch 495: {'train_loss': '1.38629'}; time used = 6.948859691619873s
epoch 500: {'train_loss': '1.38629'}; time used = 6.884657144546509s
Finished training. Time used = 804.3757445812225.
Training classifier using 80.00% nodes...
{'micro': 0.4533333333333333, 'macro': 0.36773416489300265, 'samples': 0.4533333333333333, 'weighted': 0.35670213994621264, 'accuracy': 0.4533333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.73222'}; time used = 3.3733599185943604s
epoch 10: {'train_loss': '2.59380'}; time used = 2.1910221576690674s
epoch 15: {'train_loss': '2.42854'}; time used = 1.6986298561096191s
epoch 20: {'train_loss': '2.34628'}; time used = 0.977747917175293s
epoch 25: {'train_loss': '2.21499'}; time used = 1.037172794342041s
epoch 30: {'train_loss': '2.17172'}; time used = 1.425915002822876s
epoch 35: {'train_loss': '1.96411'}; time used = 1.814180612564087s
epoch 40: {'train_loss': '1.88226'}; time used = 0.9718353748321533s
epoch 45: {'train_loss': '1.67874'}; time used = 0.8729300498962402s
epoch 50: {'train_loss': '1.62555'}; time used = 0.9592273235321045s
epoch 55: {'train_loss': '1.55504'}; time used = 0.9441087245941162s
epoch 60: {'train_loss': '1.50808'}; time used = 1.3480732440948486s
epoch 65: {'train_loss': '1.49343'}; time used = 1.2618587017059326s
epoch 70: {'train_loss': '1.47159'}; time used = 1.2440836429595947s
epoch 75: {'train_loss': '1.37789'}; time used = 1.0739264488220215s
epoch 80: {'train_loss': '1.45393'}; time used = 0.9876816272735596s
epoch 85: {'train_loss': '1.45598'}; time used = 1.0965712070465088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.3428738117218.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88549'}; time used = 1.4868340492248535s
epoch 10: {'train_loss': '2.81638'}; time used = 1.4620862007141113s
epoch 15: {'train_loss': '2.80135'}; time used = 1.2244741916656494s
epoch 20: {'train_loss': '2.78896'}; time used = 1.0707669258117676s
epoch 25: {'train_loss': '2.78512'}; time used = 1.0064938068389893s
epoch 30: {'train_loss': '2.77841'}; time used = 1.0196423530578613s
epoch 35: {'train_loss': '2.78039'}; time used = 1.0324597358703613s
epoch 40: {'train_loss': '2.77270'}; time used = 2.260084390640259s
epoch 45: {'train_loss': '2.77107'}; time used = 2.8403096199035645s
epoch 50: {'train_loss': '2.76323'}; time used = 1.1633198261260986s
epoch 55: {'train_loss': '2.75691'}; time used = 0.9848692417144775s
epoch 60: {'train_loss': '2.75700'}; time used = 1.1934723854064941s
epoch 65: {'train_loss': '2.75514'}; time used = 1.1084001064300537s
epoch 70: {'train_loss': '2.73478'}; time used = 1.4163434505462646s
epoch 75: {'train_loss': '2.73959'}; time used = 1.1477782726287842s
epoch 80: {'train_loss': '2.72086'}; time used = 1.2438642978668213s
epoch 85: {'train_loss': '2.72018'}; time used = 1.8087007999420166s
epoch 90: {'train_loss': '2.71692'}; time used = 1.6240897178649902s
epoch 95: {'train_loss': '2.70959'}; time used = 1.2240042686462402s
epoch 100: {'train_loss': '2.69112'}; time used = 1.0747666358947754s
epoch 105: {'train_loss': '2.70234'}; time used = 1.09255051612854s
epoch 110: {'train_loss': '2.68805'}; time used = 1.237558364868164s
epoch 115: {'train_loss': '2.69081'}; time used = 1.2277235984802246s
epoch 120: {'train_loss': '2.69222'}; time used = 1.301882266998291s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.078511476516724.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8246153846153846, 'samples': 0.8421052631578947, 'weighted': 0.8333603238866396, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.05 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37667'}; time used = 1.9276134967803955s
epoch 10: {'train_loss': '1.25019'}; time used = 3.0268771648406982s
epoch 15: {'train_loss': '1.21500'}; time used = 3.7084431648254395s
epoch 20: {'train_loss': '1.15651'}; time used = 4.881564617156982s
epoch 25: {'train_loss': '1.14388'}; time used = 4.897616386413574s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.486952781677246.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84257'}; time used = 2.86299991607666s
epoch 10: {'train_loss': '2.76918'}; time used = 2.591193914413452s
epoch 15: {'train_loss': '2.78108'}; time used = 2.8240396976470947s
epoch 20: {'train_loss': '2.77534'}; time used = 2.901014566421509s
epoch 25: {'train_loss': '2.75773'}; time used = 4.524981737136841s
epoch 30: {'train_loss': '2.74691'}; time used = 3.241107940673828s
epoch 35: {'train_loss': '2.73023'}; time used = 2.485201358795166s
epoch 40: {'train_loss': '2.71945'}; time used = 2.64080810546875s
epoch 45: {'train_loss': '2.71564'}; time used = 2.6063363552093506s
epoch 50: {'train_loss': '2.70235'}; time used = 2.6659140586853027s
epoch 55: {'train_loss': '2.70240'}; time used = 2.577820301055908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.33597421646118.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37710'}; time used = 2.1949524879455566s
epoch 10: {'train_loss': '1.27384'}; time used = 3.74591064453125s
epoch 15: {'train_loss': '1.20750'}; time used = 4.361284971237183s
epoch 20: {'train_loss': '1.28374'}; time used = 3.727044105529785s
epoch 25: {'train_loss': '1.18489'}; time used = 3.9193408489227295s
epoch 30: {'train_loss': '0.75963'}; time used = 2.9553260803222656s
epoch 35: {'train_loss': '0.80812'}; time used = 2.047808885574341s
epoch 40: {'train_loss': '0.83028'}; time used = 2.0235040187835693s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.436169385910034.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.63529'}; time used = 1.9216923713684082s
epoch 10: {'train_loss': '0.04889'}; time used = 1.7820427417755127s
epoch 15: {'train_loss': '0.14184'}; time used = 1.8944637775421143s
epoch 20: {'train_loss': '0.02548'}; time used = 1.8108625411987305s
epoch 25: {'train_loss': '0.04612'}; time used = 1.8976902961730957s
epoch 30: {'train_loss': '0.02275'}; time used = 2.209242582321167s
epoch 35: {'train_loss': '0.02525'}; time used = 5.106236934661865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.110087156295776.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5436507936507937, 'samples': 0.5652173913043478, 'weighted': 0.5508396595353117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81941'}; time used = 3.6753082275390625s
epoch 10: {'train_loss': '2.67200'}; time used = 3.509418249130249s
epoch 15: {'train_loss': '2.58870'}; time used = 3.3503475189208984s
epoch 20: {'train_loss': '2.49256'}; time used = 3.6432244777679443s
epoch 25: {'train_loss': '2.35110'}; time used = 2.4396071434020996s
epoch 30: {'train_loss': '2.19357'}; time used = 1.6882097721099854s
epoch 35: {'train_loss': '2.05813'}; time used = 1.2931487560272217s
epoch 40: {'train_loss': '1.99052'}; time used = 1.1276984214782715s
epoch 45: {'train_loss': '1.86344'}; time used = 1.2593331336975098s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.048985719680786.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79352'}; time used = 2.6160945892333984s
epoch 10: {'train_loss': '2.78026'}; time used = 2.1587769985198975s
epoch 15: {'train_loss': '2.78139'}; time used = 2.161200523376465s
epoch 20: {'train_loss': '2.77595'}; time used = 2.1890501976013184s
epoch 25: {'train_loss': '2.77174'}; time used = 2.124101400375366s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.57460904121399.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4891114982578397, 'samples': 0.5072463768115942, 'weighted': 0.49608645154774533, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.31793'}; time used = 10.045517444610596s
epoch 10: {'train_loss': '1.29275'}; time used = 8.804068803787231s
epoch 15: {'train_loss': '1.18101'}; time used = 7.8129353523254395s
epoch 20: {'train_loss': '0.95610'}; time used = 8.386119604110718s
epoch 25: {'train_loss': '0.78763'}; time used = 8.07473087310791s
epoch 30: {'train_loss': '0.70174'}; time used = 7.8521058559417725s
epoch 35: {'train_loss': '0.45836'}; time used = 9.555931806564331s
epoch 40: {'train_loss': '0.50374'}; time used = 7.929375886917114s
epoch 45: {'train_loss': '0.47167'}; time used = 8.056487798690796s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 100.93406891822815.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.4772828503916032, 'samples': 0.5166666666666667, 'weighted': 0.4701285439843326, 'accuracy': 0.5166666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.95457'}; time used = 1.7673587799072266s
epoch 10: {'train_loss': '2.84329'}; time used = 1.5573463439941406s
epoch 15: {'train_loss': '2.81912'}; time used = 1.525130033493042s
epoch 20: {'train_loss': '2.79155'}; time used = 1.5774438381195068s
epoch 25: {'train_loss': '2.79733'}; time used = 1.5792672634124756s
epoch 30: {'train_loss': '2.78843'}; time used = 1.7226662635803223s
epoch 35: {'train_loss': '2.78765'}; time used = 1.410731554031372s
epoch 40: {'train_loss': '2.78727'}; time used = 2.764202117919922s
epoch 45: {'train_loss': '2.79055'}; time used = 3.3832316398620605s
epoch 50: {'train_loss': '2.78653'}; time used = 2.772942066192627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.125948667526245.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.22727'}; time used = 2.1831772327423096s
epoch 10: {'train_loss': '0.90598'}; time used = 2.138982057571411s
epoch 15: {'train_loss': '0.69784'}; time used = 2.400495767593384s
epoch 20: {'train_loss': '0.43864'}; time used = 2.17061710357666s
epoch 25: {'train_loss': '0.48716'}; time used = 2.156428813934326s
epoch 30: {'train_loss': '0.37383'}; time used = 2.058589220046997s
epoch 35: {'train_loss': '0.42744'}; time used = 2.1575112342834473s
epoch 40: {'train_loss': '0.33719'}; time used = 2.2561514377593994s
epoch 45: {'train_loss': '0.32263'}; time used = 2.1426122188568115s
epoch 50: {'train_loss': '0.35837'}; time used = 2.361531972885132s
epoch 55: {'train_loss': '0.05273'}; time used = 1.996455192565918s
epoch 60: {'train_loss': '0.07263'}; time used = 2.0226101875305176s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.797375440597534.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39286'}; time used = 1.4897210597991943s
epoch 10: {'train_loss': '1.41455'}; time used = 2.0845296382904053s
epoch 15: {'train_loss': '1.39239'}; time used = 2.509059190750122s
epoch 20: {'train_loss': '1.37962'}; time used = 2.701267957687378s
epoch 25: {'train_loss': '1.42587'}; time used = 2.349332332611084s
epoch 30: {'train_loss': '1.37226'}; time used = 2.59953236579895s
epoch 35: {'train_loss': '1.38055'}; time used = 1.9962282180786133s
epoch 40: {'train_loss': '1.36430'}; time used = 1.2770164012908936s
epoch 45: {'train_loss': '1.35853'}; time used = 1.2822799682617188s
epoch 50: {'train_loss': '1.41150'}; time used = 1.3133397102355957s
epoch 55: {'train_loss': '1.38413'}; time used = 1.5159025192260742s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.896268606185913.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39783'}; time used = 1.6114234924316406s
epoch 10: {'train_loss': '1.39661'}; time used = 2.4123308658599854s
epoch 15: {'train_loss': '1.37751'}; time used = 2.649029493331909s
epoch 20: {'train_loss': '1.37267'}; time used = 2.6982674598693848s
epoch 25: {'train_loss': '1.28813'}; time used = 2.4657986164093018s
epoch 30: {'train_loss': '1.22342'}; time used = 2.1253113746643066s
epoch 35: {'train_loss': '1.05523'}; time used = 1.2720816135406494s
epoch 40: {'train_loss': '0.98914'}; time used = 1.6650888919830322s
epoch 45: {'train_loss': '0.87724'}; time used = 1.5180366039276123s
epoch 50: {'train_loss': '0.77741'}; time used = 1.5294034481048584s
epoch 55: {'train_loss': '0.70496'}; time used = 1.4431049823760986s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.35086941719055.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.95482'}; time used = 1.319453239440918s
epoch 10: {'train_loss': '2.85247'}; time used = 1.2855780124664307s
epoch 15: {'train_loss': '2.82747'}; time used = 1.1424205303192139s
epoch 20: {'train_loss': '2.80076'}; time used = 1.0668120384216309s
epoch 25: {'train_loss': '2.78415'}; time used = 1.2825355529785156s
epoch 30: {'train_loss': '2.77703'}; time used = 1.0493202209472656s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.394506216049194.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90476'}; time used = 2.058084011077881s
epoch 10: {'train_loss': '2.80534'}; time used = 3.452878475189209s
epoch 15: {'train_loss': '2.77154'}; time used = 3.704909324645996s
epoch 20: {'train_loss': '2.76349'}; time used = 4.05752968788147s
epoch 25: {'train_loss': '2.76564'}; time used = 3.7007648944854736s
epoch 30: {'train_loss': '2.75762'}; time used = 2.179847478866577s
epoch 35: {'train_loss': '2.75390'}; time used = 2.6369788646698s
epoch 40: {'train_loss': '2.75231'}; time used = 2.4259891510009766s
epoch 45: {'train_loss': '2.75027'}; time used = 3.0521962642669678s
epoch 50: {'train_loss': '2.74647'}; time used = 2.2152748107910156s
epoch 55: {'train_loss': '2.74807'}; time used = 1.9843449592590332s
epoch 60: {'train_loss': '2.73946'}; time used = 2.1208670139312744s
epoch 65: {'train_loss': '2.74079'}; time used = 2.266646146774292s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.524720907211304.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35711'}; time used = 1.3105614185333252s
epoch 10: {'train_loss': '1.24259'}; time used = 1.2961788177490234s
epoch 15: {'train_loss': '0.91691'}; time used = 1.1837987899780273s
epoch 20: {'train_loss': '0.48174'}; time used = 1.1418030261993408s
epoch 25: {'train_loss': '0.11753'}; time used = 1.2633297443389893s
epoch 30: {'train_loss': '0.09409'}; time used = 1.4045608043670654s
epoch 35: {'train_loss': '0.05107'}; time used = 1.2448782920837402s
epoch 40: {'train_loss': '0.12925'}; time used = 1.2992374897003174s
epoch 45: {'train_loss': '0.00897'}; time used = 1.3446907997131348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.38129711151123.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.05 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.65672'}; time used = 2.082998514175415s
epoch 10: {'train_loss': '0.46598'}; time used = 1.9706969261169434s
epoch 15: {'train_loss': '0.37160'}; time used = 1.349473476409912s
epoch 20: {'train_loss': '0.26078'}; time used = 1.1600322723388672s
epoch 25: {'train_loss': '0.09226'}; time used = 1.1767008304595947s
epoch 30: {'train_loss': '0.05083'}; time used = 1.0913875102996826s
epoch 35: {'train_loss': '0.05566'}; time used = 1.1250429153442383s
epoch 40: {'train_loss': '0.06130'}; time used = 1.1136794090270996s
epoch 45: {'train_loss': '0.06182'}; time used = 1.3707928657531738s
epoch 50: {'train_loss': '0.05372'}; time used = 1.8209269046783447s
epoch 55: {'train_loss': '0.05670'}; time used = 1.1460316181182861s
epoch 60: {'train_loss': '0.07880'}; time used = 1.1550040245056152s
epoch 65: {'train_loss': '0.10650'}; time used = 1.5192441940307617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.96733045578003.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36078'}; time used = 1.6375985145568848s
epoch 10: {'train_loss': '1.27797'}; time used = 1.410954475402832s
epoch 15: {'train_loss': '1.16872'}; time used = 1.548766851425171s
epoch 20: {'train_loss': '1.37162'}; time used = 1.442331075668335s
epoch 25: {'train_loss': '1.38780'}; time used = 2.5437071323394775s
epoch 30: {'train_loss': '1.37454'}; time used = 2.7775535583496094s
epoch 35: {'train_loss': '1.36606'}; time used = 1.5010490417480469s
epoch 40: {'train_loss': '1.29304'}; time used = 1.5543510913848877s
epoch 45: {'train_loss': '1.13781'}; time used = 1.4936292171478271s
epoch 50: {'train_loss': '1.03393'}; time used = 1.5338551998138428s
epoch 55: {'train_loss': '1.03499'}; time used = 1.4733314514160156s
epoch 60: {'train_loss': '0.98586'}; time used = 1.6293458938598633s
epoch 65: {'train_loss': '0.67361'}; time used = 1.6135523319244385s
epoch 70: {'train_loss': '0.79861'}; time used = 1.3677399158477783s
epoch 75: {'train_loss': '0.68790'}; time used = 1.5241403579711914s
epoch 80: {'train_loss': '0.66695'}; time used = 1.608142375946045s
epoch 85: {'train_loss': '0.51780'}; time used = 1.4949424266815186s
epoch 90: {'train_loss': '0.71856'}; time used = 1.3977649211883545s
epoch 95: {'train_loss': '0.83693'}; time used = 1.5007953643798828s
epoch 100: {'train_loss': '0.72668'}; time used = 1.4315176010131836s
epoch 105: {'train_loss': '0.52317'}; time used = 1.5219502449035645s
epoch 110: {'train_loss': '0.63886'}; time used = 1.5580809116363525s
epoch 115: {'train_loss': '0.69756'}; time used = 1.3372609615325928s
epoch 120: {'train_loss': '0.77765'}; time used = 1.4197824001312256s
epoch 125: {'train_loss': '0.51522'}; time used = 1.514683485031128s
epoch 130: {'train_loss': '0.52005'}; time used = 1.5111455917358398s
epoch 135: {'train_loss': '0.35611'}; time used = 1.403693675994873s
epoch 140: {'train_loss': '0.58653'}; time used = 1.5247015953063965s
epoch 145: {'train_loss': '0.67999'}; time used = 1.5030224323272705s
epoch 150: {'train_loss': '0.53785'}; time used = 1.7397840023040771s
epoch 155: {'train_loss': '0.44447'}; time used = 1.725679636001587s
epoch 160: {'train_loss': '0.49799'}; time used = 1.4597387313842773s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.633947134017944.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.90779'}; time used = 3.03474497795105s
epoch 10: {'train_loss': '2.76722'}; time used = 3.0810091495513916s
epoch 15: {'train_loss': '2.73792'}; time used = 2.8922293186187744s
epoch 20: {'train_loss': '2.67860'}; time used = 2.9216620922088623s
epoch 25: {'train_loss': '2.61874'}; time used = 2.1393935680389404s
epoch 30: {'train_loss': '2.57402'}; time used = 1.85213041305542s
epoch 35: {'train_loss': '2.50986'}; time used = 1.7648699283599854s
epoch 40: {'train_loss': '2.41516'}; time used = 2.0472443103790283s
epoch 45: {'train_loss': '2.45275'}; time used = 1.8505563735961914s
epoch 50: {'train_loss': '2.31755'}; time used = 1.891432762145996s
epoch 55: {'train_loss': '2.28450'}; time used = 1.6890437602996826s
epoch 60: {'train_loss': '2.23592'}; time used = 1.6578116416931152s
epoch 65: {'train_loss': '2.08507'}; time used = 1.7684216499328613s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.60344195365906.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.93194'}; time used = 3.150289535522461s
epoch 10: {'train_loss': '2.81369'}; time used = 1.963571548461914s
epoch 15: {'train_loss': '2.78278'}; time used = 1.934692144393921s
epoch 20: {'train_loss': '2.77148'}; time used = 1.9852116107940674s
epoch 25: {'train_loss': '2.77563'}; time used = 2.125025510787964s
epoch 30: {'train_loss': '2.77509'}; time used = 2.0768673419952393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.712035655975342.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.78494'}; time used = 1.9283220767974854s
epoch 10: {'train_loss': '2.76571'}; time used = 2.003368377685547s
epoch 15: {'train_loss': '2.67318'}; time used = 1.7110228538513184s
epoch 20: {'train_loss': '2.63335'}; time used = 1.972269058227539s
epoch 25: {'train_loss': '2.61245'}; time used = 1.9620287418365479s
epoch 30: {'train_loss': '2.59145'}; time used = 1.846329689025879s
epoch 35: {'train_loss': '2.55913'}; time used = 1.8451666831970215s
epoch 40: {'train_loss': '2.51861'}; time used = 1.9185352325439453s
epoch 45: {'train_loss': '2.48563'}; time used = 2.035066843032837s
epoch 50: {'train_loss': '2.40973'}; time used = 2.0071182250976562s
epoch 55: {'train_loss': '2.39740'}; time used = 1.9380240440368652s
epoch 60: {'train_loss': '2.50563'}; time used = 1.95223069190979s
epoch 65: {'train_loss': '2.38772'}; time used = 1.812119722366333s
epoch 70: {'train_loss': '2.32497'}; time used = 1.767296314239502s
epoch 75: {'train_loss': '2.28148'}; time used = 1.9605622291564941s
epoch 80: {'train_loss': '2.27755'}; time used = 1.7524473667144775s
epoch 85: {'train_loss': '2.23566'}; time used = 2.19689679145813s
epoch 90: {'train_loss': '2.22568'}; time used = 2.1092114448547363s
epoch 95: {'train_loss': '2.18117'}; time used = 2.129373073577881s
epoch 100: {'train_loss': '2.40031'}; time used = 2.268221139907837s
epoch 105: {'train_loss': '2.51791'}; time used = 2.352159261703491s
epoch 110: {'train_loss': '2.44046'}; time used = 1.9042301177978516s
epoch 115: {'train_loss': '2.37938'}; time used = 1.745013952255249s
epoch 120: {'train_loss': '2.34670'}; time used = 1.978384256362915s
epoch 125: {'train_loss': '2.26532'}; time used = 2.0664639472961426s
epoch 130: {'train_loss': '2.25348'}; time used = 1.972538709640503s
epoch 135: {'train_loss': '2.22719'}; time used = 1.7979955673217773s
epoch 140: {'train_loss': '2.16818'}; time used = 1.804403305053711s
epoch 145: {'train_loss': '2.14521'}; time used = 1.759559154510498s
epoch 150: {'train_loss': '2.15599'}; time used = 1.7219417095184326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.77561664581299.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92349'}; time used = 1.9481160640716553s
epoch 10: {'train_loss': '2.80127'}; time used = 1.8595595359802246s
epoch 15: {'train_loss': '2.76721'}; time used = 1.8363242149353027s
epoch 20: {'train_loss': '2.74317'}; time used = 1.8557839393615723s
epoch 25: {'train_loss': '2.72155'}; time used = 1.9187140464782715s
epoch 30: {'train_loss': '2.70044'}; time used = 2.270174026489258s
epoch 35: {'train_loss': '2.67557'}; time used = 3.1298861503601074s
epoch 40: {'train_loss': '2.62550'}; time used = 1.7823350429534912s
epoch 45: {'train_loss': '2.59021'}; time used = 1.846724510192871s
epoch 50: {'train_loss': '2.54735'}; time used = 4.219622850418091s
epoch 55: {'train_loss': '2.53316'}; time used = 5.047948837280273s
epoch 60: {'train_loss': '2.51693'}; time used = 4.550815105438232s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.24147939682007.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6086956521739131, 'samples': 0.6086956521739131, 'weighted': 0.6086956521739131, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.90978'}; time used = 1.8411884307861328s
epoch 10: {'train_loss': '2.81058'}; time used = 1.752701997756958s
epoch 15: {'train_loss': '2.78819'}; time used = 2.0911617279052734s
epoch 20: {'train_loss': '2.77523'}; time used = 1.7361359596252441s
epoch 25: {'train_loss': '2.76946'}; time used = 1.976201057434082s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.745867490768433.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.08485'}; time used = 2.5306878089904785s
epoch 10: {'train_loss': '0.28920'}; time used = 2.5479369163513184s
epoch 15: {'train_loss': '0.13994'}; time used = 2.499356746673584s
epoch 20: {'train_loss': '0.12146'}; time used = 2.6330976486206055s
epoch 25: {'train_loss': '0.09695'}; time used = 2.4860146045684814s
epoch 30: {'train_loss': '0.18920'}; time used = 2.590489149093628s
epoch 35: {'train_loss': '0.06102'}; time used = 2.429497480392456s
epoch 40: {'train_loss': '0.06223'}; time used = 2.6125402450561523s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.702108144760132.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81358'}; time used = 2.8038110733032227s
epoch 10: {'train_loss': '2.76675'}; time used = 2.701504945755005s
epoch 15: {'train_loss': '2.75564'}; time used = 2.7452192306518555s
epoch 20: {'train_loss': '2.73463'}; time used = 2.6824021339416504s
epoch 25: {'train_loss': '2.71587'}; time used = 2.830826759338379s
epoch 30: {'train_loss': '2.69758'}; time used = 2.6711654663085938s
epoch 35: {'train_loss': '2.69150'}; time used = 2.7023661136627197s
epoch 40: {'train_loss': '2.69148'}; time used = 3.3825175762176514s
epoch 45: {'train_loss': '2.68983'}; time used = 2.832042932510376s
epoch 50: {'train_loss': '2.68146'}; time used = 3.5184333324432373s
epoch 55: {'train_loss': '2.68986'}; time used = 2.6067450046539307s
epoch 60: {'train_loss': '2.67447'}; time used = 2.746985912322998s
epoch 65: {'train_loss': '2.68049'}; time used = 2.52416729927063s
epoch 70: {'train_loss': '2.68687'}; time used = 2.5484392642974854s
epoch 75: {'train_loss': '2.66486'}; time used = 2.8800485134124756s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.360753297805786.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.25048'}; time used = 2.0106449127197266s
epoch 10: {'train_loss': '2.80899'}; time used = 2.0353312492370605s
epoch 15: {'train_loss': '2.78500'}; time used = 2.1049740314483643s
epoch 20: {'train_loss': '2.79362'}; time used = 2.1213419437408447s
epoch 25: {'train_loss': '2.77278'}; time used = 2.364436388015747s
epoch 30: {'train_loss': '2.77182'}; time used = 2.3787877559661865s
epoch 35: {'train_loss': '2.77149'}; time used = 2.842179775238037s
epoch 40: {'train_loss': '2.76948'}; time used = 2.7169106006622314s
epoch 45: {'train_loss': '2.76961'}; time used = 1.7418029308319092s
epoch 50: {'train_loss': '2.76653'}; time used = 1.9772732257843018s
epoch 55: {'train_loss': '2.76921'}; time used = 1.7800569534301758s
epoch 60: {'train_loss': '2.76572'}; time used = 2.0331709384918213s
epoch 65: {'train_loss': '2.76186'}; time used = 1.9330272674560547s
epoch 70: {'train_loss': '2.76115'}; time used = 1.830404281616211s
epoch 75: {'train_loss': '2.75694'}; time used = 1.9649345874786377s
epoch 80: {'train_loss': '2.75809'}; time used = 2.0983188152313232s
epoch 85: {'train_loss': '2.75705'}; time used = 1.86757230758667s
epoch 90: {'train_loss': '2.75294'}; time used = 1.8789360523223877s
epoch 95: {'train_loss': '2.75363'}; time used = 2.0284712314605713s
epoch 100: {'train_loss': '2.75623'}; time used = 2.047072649002075s
epoch 105: {'train_loss': '2.75144'}; time used = 2.304727077484131s
epoch 110: {'train_loss': '2.75086'}; time used = 1.862046241760254s
epoch 115: {'train_loss': '2.74366'}; time used = 2.994668483734131s
epoch 120: {'train_loss': '2.74517'}; time used = 1.8046724796295166s
epoch 125: {'train_loss': '2.74180'}; time used = 2.058988332748413s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 58.031017541885376.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5179175118323192, 'samples': 0.5507246376811594, 'weighted': 0.5270306023458858, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.97405'}; time used = 2.421008586883545s
epoch 10: {'train_loss': '2.82362'}; time used = 2.3804352283477783s
epoch 15: {'train_loss': '2.77436'}; time used = 2.3052806854248047s
epoch 20: {'train_loss': '2.75933'}; time used = 4.023153305053711s
epoch 25: {'train_loss': '2.76029'}; time used = 3.8396265506744385s
epoch 30: {'train_loss': '2.74888'}; time used = 4.091528415679932s
epoch 35: {'train_loss': '2.74053'}; time used = 2.675999879837036s
epoch 40: {'train_loss': '2.72639'}; time used = 2.2522664070129395s
epoch 45: {'train_loss': '2.71198'}; time used = 2.211130380630493s
epoch 50: {'train_loss': '2.70247'}; time used = 2.3387293815612793s
epoch 55: {'train_loss': '2.70448'}; time used = 2.2832584381103516s
epoch 60: {'train_loss': '2.68644'}; time used = 2.375955104827881s
epoch 65: {'train_loss': '2.68881'}; time used = 2.2635011672973633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.391658782958984.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38043'}; time used = 2.1505415439605713s
epoch 10: {'train_loss': '1.25693'}; time used = 2.541517972946167s
epoch 15: {'train_loss': '1.14522'}; time used = 2.2769217491149902s
epoch 20: {'train_loss': '1.35858'}; time used = 1.885789155960083s
epoch 25: {'train_loss': '1.24208'}; time used = 2.89064359664917s
epoch 30: {'train_loss': '1.11767'}; time used = 3.6840505599975586s
epoch 35: {'train_loss': '1.19521'}; time used = 3.9840662479400635s
epoch 40: {'train_loss': '1.15173'}; time used = 2.741741418838501s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.1505913734436.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23305'}; time used = 1.1502408981323242s
epoch 10: {'train_loss': '2.89471'}; time used = 1.1646230220794678s
epoch 15: {'train_loss': '2.77973'}; time used = 1.1553046703338623s
epoch 20: {'train_loss': '2.78881'}; time used = 1.4067096710205078s
epoch 25: {'train_loss': '2.78590'}; time used = 1.2250607013702393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.362016201019287.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89030'}; time used = 1.346782922744751s
epoch 10: {'train_loss': '2.80199'}; time used = 1.1459128856658936s
epoch 15: {'train_loss': '2.75900'}; time used = 1.1675844192504883s
epoch 20: {'train_loss': '2.72428'}; time used = 1.0945191383361816s
epoch 25: {'train_loss': '2.66586'}; time used = 1.149768590927124s
epoch 30: {'train_loss': '2.51503'}; time used = 1.1945643424987793s
epoch 35: {'train_loss': '2.32517'}; time used = 1.0785176753997803s
epoch 40: {'train_loss': '2.34274'}; time used = 1.2513961791992188s
epoch 45: {'train_loss': '2.27146'}; time used = 1.2228384017944336s
epoch 50: {'train_loss': '2.27907'}; time used = 1.1243667602539062s
epoch 55: {'train_loss': '2.22829'}; time used = 1.18257474899292s
epoch 60: {'train_loss': '2.19237'}; time used = 1.315023422241211s
epoch 65: {'train_loss': '2.15818'}; time used = 1.1214661598205566s
epoch 70: {'train_loss': '2.17425'}; time used = 1.1100728511810303s
epoch 75: {'train_loss': '2.12082'}; time used = 1.4470975399017334s
epoch 80: {'train_loss': '2.10087'}; time used = 2.6477527618408203s
epoch 85: {'train_loss': '2.11900'}; time used = 2.6733734607696533s
epoch 90: {'train_loss': '2.09845'}; time used = 2.6468825340270996s
epoch 95: {'train_loss': '2.14619'}; time used = 2.5173213481903076s
epoch 100: {'train_loss': '2.14934'}; time used = 2.442183494567871s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.782565116882324.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03275'}; time used = 2.7720186710357666s
epoch 10: {'train_loss': '2.90455'}; time used = 2.8498969078063965s
epoch 15: {'train_loss': '2.85705'}; time used = 2.87861704826355s
epoch 20: {'train_loss': '2.82895'}; time used = 3.0528299808502197s
epoch 25: {'train_loss': '2.80675'}; time used = 6.1545562744140625s
epoch 30: {'train_loss': '2.79805'}; time used = 5.6980202198028564s
epoch 35: {'train_loss': '2.80471'}; time used = 3.7121448516845703s
epoch 40: {'train_loss': '2.79777'}; time used = 2.745598316192627s
epoch 45: {'train_loss': '2.79612'}; time used = 2.774954319000244s
epoch 50: {'train_loss': '2.79168'}; time used = 2.534193515777588s
epoch 55: {'train_loss': '2.78973'}; time used = 2.4961469173431396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.53236746788025.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.24104'}; time used = 1.7412974834442139s
epoch 10: {'train_loss': '2.81796'}; time used = 2.044250249862671s
epoch 15: {'train_loss': '2.76538'}; time used = 1.8202385902404785s
epoch 20: {'train_loss': '2.76921'}; time used = 1.8757350444793701s
epoch 25: {'train_loss': '2.75719'}; time used = 1.876772403717041s
epoch 30: {'train_loss': '2.74782'}; time used = 1.9443933963775635s
epoch 35: {'train_loss': '2.74346'}; time used = 2.140005350112915s
epoch 40: {'train_loss': '2.73601'}; time used = 1.8082001209259033s
epoch 45: {'train_loss': '2.72198'}; time used = 1.8815405368804932s
epoch 50: {'train_loss': '2.71186'}; time used = 1.8505558967590332s
epoch 55: {'train_loss': '2.70944'}; time used = 1.8564250469207764s
epoch 60: {'train_loss': '2.69009'}; time used = 1.8808813095092773s
epoch 65: {'train_loss': '2.68089'}; time used = 2.421410083770752s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.182645320892334.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.25057'}; time used = 2.0172226428985596s
epoch 10: {'train_loss': '1.23176'}; time used = 1.957749366760254s
epoch 15: {'train_loss': '1.11649'}; time used = 1.728179693222046s
epoch 20: {'train_loss': '0.99803'}; time used = 2.222090244293213s
epoch 25: {'train_loss': '0.77369'}; time used = 2.056091547012329s
epoch 30: {'train_loss': '0.48315'}; time used = 1.628896713256836s
epoch 35: {'train_loss': '0.36671'}; time used = 1.7860875129699707s
epoch 40: {'train_loss': '0.18619'}; time used = 1.8058154582977295s
epoch 45: {'train_loss': '0.21678'}; time used = 1.6863329410552979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.512295484542847.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.64415'}; time used = 1.1942548751831055s
epoch 10: {'train_loss': '2.53139'}; time used = 1.0787827968597412s
epoch 15: {'train_loss': '2.47509'}; time used = 1.0074732303619385s
epoch 20: {'train_loss': '2.38731'}; time used = 1.1816833019256592s
epoch 25: {'train_loss': '2.34327'}; time used = 1.1842522621154785s
epoch 30: {'train_loss': '2.28567'}; time used = 1.0264687538146973s
epoch 35: {'train_loss': '2.25319'}; time used = 1.0426807403564453s
epoch 40: {'train_loss': '2.20492'}; time used = 1.008120059967041s
epoch 45: {'train_loss': '2.17376'}; time used = 0.9939653873443604s
epoch 50: {'train_loss': '2.16284'}; time used = 0.9977409839630127s
epoch 55: {'train_loss': '2.13628'}; time used = 0.9377751350402832s
epoch 60: {'train_loss': '2.11083'}; time used = 1.0408635139465332s
epoch 65: {'train_loss': '2.11282'}; time used = 1.0921599864959717s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.9103786945343.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.22727'}; time used = 2.0849714279174805s
epoch 10: {'train_loss': '0.90598'}; time used = 1.8129582405090332s
epoch 15: {'train_loss': '0.69784'}; time used = 1.9935555458068848s
epoch 20: {'train_loss': '0.43864'}; time used = 1.9673645496368408s
epoch 25: {'train_loss': '0.48716'}; time used = 2.2183282375335693s
epoch 30: {'train_loss': '0.37383'}; time used = 1.7750663757324219s
epoch 35: {'train_loss': '0.42744'}; time used = 2.1378722190856934s
epoch 40: {'train_loss': '0.33719'}; time used = 1.9271678924560547s
epoch 45: {'train_loss': '0.32263'}; time used = 2.1020660400390625s
epoch 50: {'train_loss': '0.35837'}; time used = 2.212045907974243s
epoch 55: {'train_loss': '0.05273'}; time used = 2.0926012992858887s
epoch 60: {'train_loss': '0.07263'}; time used = 2.559314727783203s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.69554376602173.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.32752'}; time used = 1.268125057220459s
epoch 10: {'train_loss': '0.17111'}; time used = 1.3961732387542725s
epoch 15: {'train_loss': '0.11421'}; time used = 1.2004168033599854s
epoch 20: {'train_loss': '0.12392'}; time used = 1.0584437847137451s
epoch 25: {'train_loss': '0.21250'}; time used = 1.2595295906066895s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.22471570968628.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.80502'}; time used = 1.4618301391601562s
epoch 10: {'train_loss': '2.70076'}; time used = 1.033876657485962s
epoch 15: {'train_loss': '2.62915'}; time used = 0.971074104309082s
epoch 20: {'train_loss': '2.53432'}; time used = 1.0797643661499023s
epoch 25: {'train_loss': '2.42489'}; time used = 1.4735467433929443s
epoch 30: {'train_loss': '2.28964'}; time used = 1.0260720252990723s
epoch 35: {'train_loss': '2.13895'}; time used = 1.1631529331207275s
epoch 40: {'train_loss': '2.02806'}; time used = 1.8232500553131104s
epoch 45: {'train_loss': '2.02019'}; time used = 1.857452630996704s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.605576038360596.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39626'}; time used = 1.9994680881500244s
epoch 10: {'train_loss': '1.22629'}; time used = 2.0919697284698486s
epoch 15: {'train_loss': '0.94528'}; time used = 1.865574598312378s
epoch 20: {'train_loss': '0.93581'}; time used = 2.4248647689819336s
epoch 25: {'train_loss': '0.62867'}; time used = 2.037675619125366s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.056274890899658.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.99291'}; time used = 1.8238141536712646s
epoch 10: {'train_loss': '2.96680'}; time used = 1.801053762435913s
epoch 15: {'train_loss': '2.83629'}; time used = 1.8478038311004639s
epoch 20: {'train_loss': '2.78668'}; time used = 1.8164210319519043s
epoch 25: {'train_loss': '2.75378'}; time used = 1.993605375289917s
epoch 30: {'train_loss': '2.72964'}; time used = 1.8803150653839111s
epoch 35: {'train_loss': '2.70505'}; time used = 1.6644020080566406s
epoch 40: {'train_loss': '2.67457'}; time used = 1.892749547958374s
epoch 45: {'train_loss': '2.65663'}; time used = 1.7206087112426758s
epoch 50: {'train_loss': '2.61982'}; time used = 1.722034215927124s
epoch 55: {'train_loss': '2.60364'}; time used = 1.984384536743164s
epoch 60: {'train_loss': '2.58550'}; time used = 1.8694102764129639s
epoch 65: {'train_loss': '2.53948'}; time used = 2.376211643218994s
epoch 70: {'train_loss': '2.51711'}; time used = 3.06803035736084s
epoch 75: {'train_loss': '2.47413'}; time used = 2.992393970489502s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.301244258880615.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 12.03891134262085s
epoch 10: {'train_loss': '1.38629'}; time used = 8.762494564056396s
epoch 15: {'train_loss': '1.38629'}; time used = 7.347503662109375s
epoch 20: {'train_loss': '1.38629'}; time used = 7.365009307861328s
epoch 25: {'train_loss': '1.38629'}; time used = 9.01770305633545s
epoch 30: {'train_loss': '1.38629'}; time used = 9.476900339126587s
epoch 35: {'train_loss': '1.38629'}; time used = 7.268985748291016s
epoch 40: {'train_loss': '1.38629'}; time used = 7.110898017883301s
epoch 45: {'train_loss': '1.38629'}; time used = 7.217536926269531s
epoch 50: {'train_loss': '1.38629'}; time used = 7.0169103145599365s
epoch 55: {'train_loss': '1.38629'}; time used = 6.985876798629761s
epoch 60: {'train_loss': '1.38629'}; time used = 6.736142873764038s
epoch 65: {'train_loss': '1.38629'}; time used = 7.189076900482178s
epoch 70: {'train_loss': '1.38629'}; time used = 6.832441806793213s
epoch 75: {'train_loss': '1.38629'}; time used = 7.150357484817505s
epoch 80: {'train_loss': '1.38629'}; time used = 7.186371326446533s
epoch 85: {'train_loss': '1.38629'}; time used = 7.124897480010986s
epoch 90: {'train_loss': '1.38629'}; time used = 7.057865619659424s
epoch 95: {'train_loss': '1.38629'}; time used = 7.1689369678497314s
epoch 100: {'train_loss': '1.38629'}; time used = 6.915399789810181s
epoch 105: {'train_loss': '1.38629'}; time used = 7.407600402832031s
epoch 110: {'train_loss': '1.38629'}; time used = 10.118582248687744s
epoch 115: {'train_loss': '1.38629'}; time used = 8.795782804489136s
epoch 120: {'train_loss': '1.38629'}; time used = 7.044897794723511s
epoch 125: {'train_loss': '1.38629'}; time used = 7.5749664306640625s
epoch 130: {'train_loss': '1.38629'}; time used = 7.703780651092529s
epoch 135: {'train_loss': '1.38629'}; time used = 11.046469688415527s
epoch 140: {'train_loss': '1.38629'}; time used = 7.311086177825928s
epoch 145: {'train_loss': '1.38629'}; time used = 7.88573956489563s
epoch 150: {'train_loss': '1.38629'}; time used = 9.580138921737671s
epoch 155: {'train_loss': '1.38629'}; time used = 7.063258171081543s
epoch 160: {'train_loss': '1.38629'}; time used = 6.824090480804443s
epoch 165: {'train_loss': '1.38629'}; time used = 7.130077362060547s
epoch 170: {'train_loss': '1.38629'}; time used = 6.979036331176758s
epoch 175: {'train_loss': '1.38629'}; time used = 8.843737602233887s
epoch 180: {'train_loss': '1.38629'}; time used = 9.647966384887695s
epoch 185: {'train_loss': '1.38629'}; time used = 7.092186450958252s
epoch 190: {'train_loss': '1.38629'}; time used = 8.245986938476562s
epoch 195: {'train_loss': '1.38629'}; time used = 9.521746397018433s
epoch 200: {'train_loss': '1.38629'}; time used = 7.044288396835327s
epoch 205: {'train_loss': '1.38629'}; time used = 7.3462817668914795s
epoch 210: {'train_loss': '1.38629'}; time used = 6.635944843292236s
epoch 215: {'train_loss': '1.38629'}; time used = 6.958245515823364s
epoch 220: {'train_loss': '1.38629'}; time used = 6.81566596031189s
epoch 225: {'train_loss': '1.38629'}; time used = 7.17237401008606s
epoch 230: {'train_loss': '1.38629'}; time used = 6.949241876602173s
epoch 235: {'train_loss': '1.38629'}; time used = 6.881020784378052s
epoch 240: {'train_loss': '1.38629'}; time used = 6.94355320930481s
epoch 245: {'train_loss': '1.38629'}; time used = 6.86006760597229s
epoch 250: {'train_loss': '1.38629'}; time used = 7.225693941116333s
epoch 255: {'train_loss': '1.38629'}; time used = 7.108231544494629s
epoch 260: {'train_loss': '1.38629'}; time used = 6.886338233947754s
epoch 265: {'train_loss': '1.38629'}; time used = 6.895373582839966s
epoch 270: {'train_loss': '1.38629'}; time used = 6.818629503250122s
epoch 275: {'train_loss': '1.38629'}; time used = 6.938495874404907s
epoch 280: {'train_loss': '1.38629'}; time used = 6.906895875930786s
epoch 285: {'train_loss': '1.38629'}; time used = 6.802969455718994s
epoch 290: {'train_loss': '1.38629'}; time used = 7.431478023529053s
epoch 295: {'train_loss': '1.38629'}; time used = 7.004103660583496s
epoch 300: {'train_loss': '1.38629'}; time used = 8.313406944274902s
epoch 305: {'train_loss': '1.38629'}; time used = 6.903050899505615s
epoch 310: {'train_loss': '1.38629'}; time used = 6.779756546020508s
epoch 315: {'train_loss': '1.38629'}; time used = 6.892806529998779s
epoch 320: {'train_loss': '1.38629'}; time used = 6.88289999961853s
epoch 325: {'train_loss': '1.38629'}; time used = 6.803868293762207s
epoch 330: {'train_loss': '1.38629'}; time used = 6.918288946151733s
epoch 335: {'train_loss': '1.38629'}; time used = 7.051260471343994s
epoch 340: {'train_loss': '1.38629'}; time used = 6.679298639297485s
epoch 345: {'train_loss': '1.38629'}; time used = 6.913957834243774s
epoch 350: {'train_loss': '1.38629'}; time used = 6.877291202545166s
epoch 355: {'train_loss': '1.38629'}; time used = 7.865886449813843s
epoch 360: {'train_loss': '1.38629'}; time used = 7.057471513748169s
epoch 365: {'train_loss': '1.38629'}; time used = 7.030679941177368s
epoch 370: {'train_loss': '1.38629'}; time used = 6.8354315757751465s
epoch 375: {'train_loss': '1.38629'}; time used = 6.780427932739258s
epoch 380: {'train_loss': '1.38629'}; time used = 6.9693615436553955s
epoch 385: {'train_loss': '1.38629'}; time used = 6.793899297714233s
epoch 390: {'train_loss': '1.38629'}; time used = 6.8695433139801025s
epoch 395: {'train_loss': '1.38629'}; time used = 6.658131122589111s
epoch 400: {'train_loss': '1.38629'}; time used = 6.802200078964233s
epoch 405: {'train_loss': '1.38629'}; time used = 7.319720268249512s
epoch 410: {'train_loss': '1.38629'}; time used = 9.37352728843689s
epoch 415: {'train_loss': '1.38629'}; time used = 9.237270593643188s
epoch 420: {'train_loss': '1.38629'}; time used = 7.0399699211120605s
epoch 425: {'train_loss': '1.38629'}; time used = 6.708937644958496s
epoch 430: {'train_loss': '1.38629'}; time used = 6.736084938049316s
epoch 435: {'train_loss': '1.38629'}; time used = 6.697156190872192s
epoch 440: {'train_loss': '1.38629'}; time used = 6.988186597824097s
epoch 445: {'train_loss': '1.38629'}; time used = 6.728400230407715s
epoch 450: {'train_loss': '1.38629'}; time used = 6.972086668014526s
epoch 455: {'train_loss': '1.38629'}; time used = 6.800127267837524s
epoch 460: {'train_loss': '1.38629'}; time used = 6.969636917114258s
epoch 465: {'train_loss': '1.38629'}; time used = 7.049749374389648s
epoch 470: {'train_loss': '1.38629'}; time used = 6.870139837265015s
epoch 475: {'train_loss': '1.38629'}; time used = 6.978077173233032s
epoch 480: {'train_loss': '1.38629'}; time used = 7.966296434402466s
epoch 485: {'train_loss': '1.38629'}; time used = 7.4936041831970215s
epoch 490: {'train_loss': '1.38629'}; time used = 10.971186399459839s
epoch 495: {'train_loss': '1.38629'}; time used = 7.93890643119812s
epoch 500: {'train_loss': '1.38629'}; time used = 10.505459308624268s
Finished training. Time used = 758.5319380760193.
Training classifier using 80.00% nodes...
{'micro': 0.41, 'macro': 0.33154377842354993, 'samples': 0.41, 'weighted': 0.3215974650708434, 'accuracy': 0.41}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85589'}; time used = 1.5690340995788574s
epoch 10: {'train_loss': '2.79138'}; time used = 1.3708245754241943s
epoch 15: {'train_loss': '2.68002'}; time used = 1.414921522140503s
epoch 20: {'train_loss': '2.50189'}; time used = 1.5076699256896973s
epoch 25: {'train_loss': '2.30736'}; time used = 1.3005943298339844s
epoch 30: {'train_loss': '2.17472'}; time used = 1.3954229354858398s
epoch 35: {'train_loss': '2.08560'}; time used = 1.4548544883728027s
epoch 40: {'train_loss': '2.06959'}; time used = 1.2891395092010498s
epoch 45: {'train_loss': '2.05204'}; time used = 1.4270539283752441s
epoch 50: {'train_loss': '2.12214'}; time used = 1.338362455368042s
epoch 55: {'train_loss': '2.00792'}; time used = 1.386979103088379s
epoch 60: {'train_loss': '2.02373'}; time used = 1.4088943004608154s
epoch 65: {'train_loss': '2.01020'}; time used = 1.2878003120422363s
epoch 70: {'train_loss': '1.96432'}; time used = 1.4016499519348145s
epoch 75: {'train_loss': '1.89417'}; time used = 1.474775791168213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.72899627685547.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.15931'}; time used = 1.9923648834228516s
epoch 10: {'train_loss': '0.96798'}; time used = 1.6294844150543213s
epoch 15: {'train_loss': '0.82937'}; time used = 1.022014856338501s
epoch 20: {'train_loss': '0.69579'}; time used = 1.299276351928711s
epoch 25: {'train_loss': '0.47111'}; time used = 0.9835155010223389s
epoch 30: {'train_loss': '0.23558'}; time used = 1.0347440242767334s
epoch 35: {'train_loss': '0.27392'}; time used = 1.137711524963379s
epoch 40: {'train_loss': '0.13537'}; time used = 0.9954051971435547s
epoch 45: {'train_loss': '0.12871'}; time used = 1.1163430213928223s
epoch 50: {'train_loss': '0.10649'}; time used = 0.9994668960571289s
epoch 55: {'train_loss': '0.08365'}; time used = 0.9757883548736572s
epoch 60: {'train_loss': '0.07078'}; time used = 1.0839929580688477s
epoch 65: {'train_loss': '0.06462'}; time used = 1.1928157806396484s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.607704162597656.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.34058'}; time used = 1.2997684478759766s
epoch 10: {'train_loss': '0.21998'}; time used = 1.3700599670410156s
epoch 15: {'train_loss': '0.19155'}; time used = 1.1701078414916992s
epoch 20: {'train_loss': '0.12689'}; time used = 2.2351627349853516s
epoch 25: {'train_loss': '0.11810'}; time used = 2.4463441371917725s
epoch 30: {'train_loss': '0.12205'}; time used = 1.9584174156188965s
epoch 35: {'train_loss': '0.10515'}; time used = 0.989124059677124s
epoch 40: {'train_loss': '0.08648'}; time used = 0.948847770690918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.0644633769989.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.16901'}; time used = 1.8853895664215088s
epoch 10: {'train_loss': '0.70441'}; time used = 1.9111573696136475s
epoch 15: {'train_loss': '0.46350'}; time used = 1.7504031658172607s
epoch 20: {'train_loss': '0.33113'}; time used = 1.7418880462646484s
epoch 25: {'train_loss': '0.17753'}; time used = 1.8300938606262207s
epoch 30: {'train_loss': '0.13471'}; time used = 1.81070876121521s
epoch 35: {'train_loss': '0.10987'}; time used = 1.758709192276001s
epoch 40: {'train_loss': '0.11030'}; time used = 1.7647788524627686s
epoch 45: {'train_loss': '0.08843'}; time used = 1.867701530456543s
epoch 50: {'train_loss': '0.10086'}; time used = 1.7714838981628418s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.44448232650757.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6778438030560272, 'samples': 0.6811594202898551, 'weighted': 0.68021210108019, 'accuracy': 0.6811594202898551}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.35259'}; time used = 2.3853108882904053s
epoch 10: {'train_loss': '1.29899'}; time used = 2.1099870204925537s
epoch 15: {'train_loss': '1.32151'}; time used = 2.149029493331909s
epoch 20: {'train_loss': '1.40306'}; time used = 2.3175086975097656s
epoch 25: {'train_loss': '1.35590'}; time used = 2.559743881225586s
epoch 30: {'train_loss': '1.29929'}; time used = 2.5513527393341064s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.33651328086853.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02257'}; time used = 1.7762432098388672s
epoch 10: {'train_loss': '0.50533'}; time used = 2.10455060005188s
epoch 15: {'train_loss': '0.00019'}; time used = 3.119272232055664s
epoch 20: {'train_loss': '0.00009'}; time used = 3.3917055130004883s
epoch 25: {'train_loss': '0.00006'}; time used = 3.273026704788208s
epoch 30: {'train_loss': '0.02103'}; time used = 2.996267557144165s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.332348585128784.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.84869'}; time used = 1.4009175300598145s
epoch 10: {'train_loss': '2.50198'}; time used = 1.2471673488616943s
epoch 15: {'train_loss': '2.52389'}; time used = 1.287163496017456s
epoch 20: {'train_loss': '2.45636'}; time used = 1.1498615741729736s
epoch 25: {'train_loss': '2.41027'}; time used = 1.070610523223877s
epoch 30: {'train_loss': '2.32605'}; time used = 1.046238899230957s
epoch 35: {'train_loss': '2.26342'}; time used = 1.0531530380249023s
epoch 40: {'train_loss': '2.22529'}; time used = 1.2021498680114746s
epoch 45: {'train_loss': '2.19640'}; time used = 1.1673669815063477s
epoch 50: {'train_loss': '2.18958'}; time used = 1.2661044597625732s
epoch 55: {'train_loss': '2.16163'}; time used = 1.0081555843353271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.98036503791809.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.77757'}; time used = 7.661752462387085s
epoch 10: {'train_loss': '2.77894'}; time used = 7.821892499923706s
epoch 15: {'train_loss': '2.76824'}; time used = 7.84341287612915s
epoch 20: {'train_loss': '2.76615'}; time used = 9.362401247024536s
epoch 25: {'train_loss': '2.76326'}; time used = 8.352296829223633s
epoch 30: {'train_loss': '2.75321'}; time used = 8.868982315063477s
epoch 35: {'train_loss': '2.73465'}; time used = 8.829123735427856s
epoch 40: {'train_loss': '2.72272'}; time used = 7.700396537780762s
epoch 45: {'train_loss': '2.71849'}; time used = 12.984777212142944s
epoch 50: {'train_loss': '2.71915'}; time used = 8.378308057785034s
epoch 55: {'train_loss': '2.71688'}; time used = 7.75855016708374s
epoch 60: {'train_loss': '2.71935'}; time used = 8.812559127807617s
epoch 65: {'train_loss': '2.71480'}; time used = 14.202766180038452s
epoch 70: {'train_loss': '2.71750'}; time used = 14.296799421310425s
epoch 75: {'train_loss': '2.71411'}; time used = 8.839207410812378s
epoch 80: {'train_loss': '2.71843'}; time used = 7.751836538314819s
epoch 85: {'train_loss': '2.71436'}; time used = 12.146740436553955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 181.67472958564758.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4213642213642214, 'samples': 0.5033333333333333, 'weighted': 0.4103449163449163, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.84869'}; time used = 1.1118786334991455s
epoch 10: {'train_loss': '2.50198'}; time used = 0.9688234329223633s
epoch 15: {'train_loss': '2.52389'}; time used = 1.103757619857788s
epoch 20: {'train_loss': '2.45636'}; time used = 0.9063665866851807s
epoch 25: {'train_loss': '2.41027'}; time used = 0.8863785266876221s
epoch 30: {'train_loss': '2.32605'}; time used = 0.9899883270263672s
epoch 35: {'train_loss': '2.26342'}; time used = 1.0163888931274414s
epoch 40: {'train_loss': '2.22529'}; time used = 1.255204677581787s
epoch 45: {'train_loss': '2.19640'}; time used = 1.3255529403686523s
epoch 50: {'train_loss': '2.18958'}; time used = 1.216620922088623s
epoch 55: {'train_loss': '2.16163'}; time used = 1.1678829193115234s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.962093353271484.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85662'}; time used = 2.8767035007476807s
epoch 10: {'train_loss': '2.95262'}; time used = 3.0402324199676514s
epoch 15: {'train_loss': '2.81467'}; time used = 3.731579065322876s
epoch 20: {'train_loss': '2.76649'}; time used = 3.6699182987213135s
epoch 25: {'train_loss': '2.73732'}; time used = 4.529035568237305s
epoch 30: {'train_loss': '2.71198'}; time used = 4.187766075134277s
epoch 35: {'train_loss': '2.68932'}; time used = 2.629159688949585s
epoch 40: {'train_loss': '2.65807'}; time used = 1.9456005096435547s
epoch 45: {'train_loss': '2.63979'}; time used = 1.9714455604553223s
epoch 50: {'train_loss': '2.60073'}; time used = 1.8983237743377686s
epoch 55: {'train_loss': '2.58082'}; time used = 1.928312063217163s
epoch 60: {'train_loss': '2.55301'}; time used = 1.6822149753570557s
epoch 65: {'train_loss': '2.51286'}; time used = 2.540311574935913s
epoch 70: {'train_loss': '2.49758'}; time used = 2.978976249694824s
epoch 75: {'train_loss': '2.46912'}; time used = 3.02866530418396s
epoch 80: {'train_loss': '2.47959'}; time used = 3.05118989944458s
epoch 85: {'train_loss': '2.46634'}; time used = 2.566556692123413s
epoch 90: {'train_loss': '2.45633'}; time used = 1.7927324771881104s
epoch 95: {'train_loss': '2.44050'}; time used = 1.7664437294006348s
epoch 100: {'train_loss': '2.40138'}; time used = 1.878735065460205s
epoch 105: {'train_loss': '2.42828'}; time used = 1.911179542541504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.013219594955444.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.19733'}; time used = 1.4873793125152588s
epoch 10: {'train_loss': '0.95631'}; time used = 1.1301133632659912s
epoch 15: {'train_loss': '0.64542'}; time used = 1.2283124923706055s
epoch 20: {'train_loss': '0.43131'}; time used = 0.9645950794219971s
epoch 25: {'train_loss': '0.34611'}; time used = 1.2185683250427246s
epoch 30: {'train_loss': '0.23448'}; time used = 1.2297205924987793s
epoch 35: {'train_loss': '0.20022'}; time used = 1.0994040966033936s
epoch 40: {'train_loss': '0.15515'}; time used = 1.1345186233520508s
epoch 45: {'train_loss': '0.13009'}; time used = 1.247997522354126s
epoch 50: {'train_loss': '0.18770'}; time used = 1.1027207374572754s
epoch 55: {'train_loss': '0.10384'}; time used = 1.2187941074371338s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.785483837127686.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.68 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85764'}; time used = 1.6293582916259766s
epoch 10: {'train_loss': '2.77432'}; time used = 1.5517933368682861s
epoch 15: {'train_loss': '2.77286'}; time used = 1.6010634899139404s
epoch 20: {'train_loss': '2.77203'}; time used = 1.821831226348877s
epoch 25: {'train_loss': '2.77302'}; time used = 3.253755569458008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.803163051605225.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37894'}; time used = 2.132967233657837s
epoch 10: {'train_loss': '1.30891'}; time used = 1.958360195159912s
epoch 15: {'train_loss': '1.29121'}; time used = 3.8669590950012207s
epoch 20: {'train_loss': '1.13476'}; time used = 3.9779675006866455s
epoch 25: {'train_loss': '0.86050'}; time used = 4.030530691146851s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.739583492279053.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39710'}; time used = 1.3904235363006592s
epoch 10: {'train_loss': '1.38891'}; time used = 1.1227030754089355s
epoch 15: {'train_loss': '1.33753'}; time used = 1.2207343578338623s
epoch 20: {'train_loss': '1.28712'}; time used = 1.2799279689788818s
epoch 25: {'train_loss': '1.13888'}; time used = 1.385195016860962s
epoch 30: {'train_loss': '1.12803'}; time used = 1.4068317413330078s
epoch 35: {'train_loss': '1.14407'}; time used = 1.1738858222961426s
epoch 40: {'train_loss': '1.14963'}; time used = 1.4067573547363281s
epoch 45: {'train_loss': '0.92170'}; time used = 1.2448742389678955s
epoch 50: {'train_loss': '0.96276'}; time used = 1.3112189769744873s
epoch 55: {'train_loss': '1.09443'}; time used = 1.1996192932128906s
epoch 60: {'train_loss': '1.14216'}; time used = 1.2371900081634521s
epoch 65: {'train_loss': '0.85313'}; time used = 1.1791651248931885s
epoch 70: {'train_loss': '0.98953'}; time used = 1.153834342956543s
epoch 75: {'train_loss': '0.88338'}; time used = 2.282283306121826s
epoch 80: {'train_loss': '0.69549'}; time used = 2.794959545135498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.896084785461426.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6607142857142858, 'samples': 0.6842105263157895, 'weighted': 0.6748120300751881, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74569'}; time used = 1.269381046295166s
epoch 10: {'train_loss': '2.64887'}; time used = 1.2934889793395996s
epoch 15: {'train_loss': '2.46980'}; time used = 1.376810073852539s
epoch 20: {'train_loss': '2.38941'}; time used = 2.204070806503296s
epoch 25: {'train_loss': '2.29601'}; time used = 1.6893212795257568s
epoch 30: {'train_loss': '2.15432'}; time used = 1.1306967735290527s
epoch 35: {'train_loss': '1.85865'}; time used = 1.1480402946472168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.592163324356079.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01880'}; time used = 1.1907038688659668s
epoch 10: {'train_loss': '0.51527'}; time used = 2.025156021118164s
epoch 15: {'train_loss': '0.35322'}; time used = 1.197173833847046s
epoch 20: {'train_loss': '0.24692'}; time used = 1.1253747940063477s
epoch 25: {'train_loss': '0.18056'}; time used = 1.1282074451446533s
epoch 30: {'train_loss': '0.10972'}; time used = 1.1689631938934326s
epoch 35: {'train_loss': '0.08257'}; time used = 1.2680811882019043s
epoch 40: {'train_loss': '0.05007'}; time used = 1.115382194519043s
epoch 45: {'train_loss': '0.04393'}; time used = 1.083601474761963s
epoch 50: {'train_loss': '0.02516'}; time used = 1.0592310428619385s
epoch 55: {'train_loss': '0.01631'}; time used = 1.0731639862060547s
epoch 60: {'train_loss': '0.01409'}; time used = 1.1198010444641113s
epoch 65: {'train_loss': '0.01777'}; time used = 1.331618309020996s
epoch 70: {'train_loss': '0.01004'}; time used = 1.4281237125396729s
epoch 75: {'train_loss': '0.00859'}; time used = 2.1852293014526367s
epoch 80: {'train_loss': '0.00903'}; time used = 2.0387589931488037s
epoch 85: {'train_loss': '0.00717'}; time used = 1.4852888584136963s
epoch 90: {'train_loss': '0.00652'}; time used = 1.1519577503204346s
epoch 95: {'train_loss': '0.00990'}; time used = 1.1735475063323975s
epoch 100: {'train_loss': '0.45568'}; time used = 1.1023550033569336s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.703765392303467.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92306'}; time used = 2.0711562633514404s
epoch 10: {'train_loss': '2.80505'}; time used = 1.8698554039001465s
epoch 15: {'train_loss': '2.79137'}; time used = 1.8873975276947021s
epoch 20: {'train_loss': '2.78773'}; time used = 2.021831512451172s
epoch 25: {'train_loss': '2.78057'}; time used = 2.058035373687744s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.441759586334229.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.34225'}; time used = 1.4441266059875488s
epoch 10: {'train_loss': '0.22058'}; time used = 1.2390992641448975s
epoch 15: {'train_loss': '0.18609'}; time used = 1.1578409671783447s
epoch 20: {'train_loss': '0.12009'}; time used = 1.0751512050628662s
epoch 25: {'train_loss': '0.11671'}; time used = 0.979914665222168s
epoch 30: {'train_loss': '0.12084'}; time used = 1.0346331596374512s
epoch 35: {'train_loss': '0.10569'}; time used = 0.9141461849212646s
epoch 40: {'train_loss': '0.08616'}; time used = 1.331256628036499s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.88258957862854.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39771'}; time used = 1.6309256553649902s
epoch 10: {'train_loss': '1.39384'}; time used = 1.5833461284637451s
epoch 15: {'train_loss': '1.38984'}; time used = 1.6106517314910889s
epoch 20: {'train_loss': '1.38078'}; time used = 1.376887321472168s
epoch 25: {'train_loss': '1.38439'}; time used = 1.4818840026855469s
epoch 30: {'train_loss': '1.37395'}; time used = 1.460096836090088s
epoch 35: {'train_loss': '1.33251'}; time used = 1.3790357112884521s
epoch 40: {'train_loss': '1.23351'}; time used = 1.3781402111053467s
epoch 45: {'train_loss': '1.08844'}; time used = 1.3657681941986084s
epoch 50: {'train_loss': '0.91956'}; time used = 1.3909523487091064s
epoch 55: {'train_loss': '0.90855'}; time used = 1.3568658828735352s
epoch 60: {'train_loss': '0.91450'}; time used = 1.4957773685455322s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.178083419799805.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.22603'}; time used = 1.323669195175171s
epoch 10: {'train_loss': '1.73035'}; time used = 1.291916847229004s
epoch 15: {'train_loss': '1.36854'}; time used = 1.3317208290100098s
epoch 20: {'train_loss': '1.56382'}; time used = 1.3992352485656738s
epoch 25: {'train_loss': '1.15426'}; time used = 1.4008641242980957s
epoch 30: {'train_loss': '1.49923'}; time used = 1.421992540359497s
epoch 35: {'train_loss': '1.62213'}; time used = 1.69862961769104s
epoch 40: {'train_loss': '1.45478'}; time used = 1.4012844562530518s
epoch 45: {'train_loss': '1.29166'}; time used = 1.4345989227294922s
epoch 50: {'train_loss': '1.20723'}; time used = 1.2395668029785156s
epoch 55: {'train_loss': '0.96069'}; time used = 1.3453121185302734s
epoch 60: {'train_loss': '0.92218'}; time used = 1.375732421875s
epoch 65: {'train_loss': '1.23855'}; time used = 1.251507043838501s
epoch 70: {'train_loss': '1.13391'}; time used = 1.2434167861938477s
epoch 75: {'train_loss': '1.29165'}; time used = 1.3794231414794922s
epoch 80: {'train_loss': '1.17564'}; time used = 1.317079782485962s
epoch 85: {'train_loss': '1.42793'}; time used = 1.3231322765350342s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.8802752494812.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.84974'}; time used = 8.145241498947144s
epoch 10: {'train_loss': '2.77725'}; time used = 6.138210296630859s
epoch 15: {'train_loss': '2.77803'}; time used = 5.950041770935059s
epoch 20: {'train_loss': '2.78451'}; time used = 5.575113534927368s
epoch 25: {'train_loss': '2.77240'}; time used = 5.7193169593811035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.83224081993103.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.00439'}; time used = 1.0640125274658203s
epoch 10: {'train_loss': '0.70272'}; time used = 1.225050687789917s
epoch 15: {'train_loss': '0.57685'}; time used = 1.1648337841033936s
epoch 20: {'train_loss': '0.46185'}; time used = 1.1225008964538574s
epoch 25: {'train_loss': '0.44195'}; time used = 1.2205307483673096s
epoch 30: {'train_loss': '0.34037'}; time used = 1.1676080226898193s
epoch 35: {'train_loss': '0.34824'}; time used = 1.3001806735992432s
epoch 40: {'train_loss': '0.30622'}; time used = 1.16109037399292s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.845927953720093.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.235352993011475s
epoch 10: {'train_loss': '1.38629'}; time used = 7.061307191848755s
epoch 15: {'train_loss': '1.38629'}; time used = 6.708037614822388s
epoch 20: {'train_loss': '1.38629'}; time used = 6.810727834701538s
epoch 25: {'train_loss': '1.38629'}; time used = 6.82342791557312s
epoch 30: {'train_loss': '1.38629'}; time used = 6.680457353591919s
epoch 35: {'train_loss': '1.38629'}; time used = 6.435868263244629s
epoch 40: {'train_loss': '1.38629'}; time used = 6.676422834396362s
epoch 45: {'train_loss': '1.38629'}; time used = 6.844008922576904s
epoch 50: {'train_loss': '1.38629'}; time used = 6.598665714263916s
epoch 55: {'train_loss': '1.38629'}; time used = 6.629740238189697s
epoch 60: {'train_loss': '1.38629'}; time used = 7.01416015625s
epoch 65: {'train_loss': '1.38629'}; time used = 6.855197191238403s
epoch 70: {'train_loss': '1.38629'}; time used = 6.601217746734619s
epoch 75: {'train_loss': '1.38629'}; time used = 10.941765785217285s
epoch 80: {'train_loss': '1.38629'}; time used = 10.624471187591553s
epoch 85: {'train_loss': '1.38629'}; time used = 7.758193731307983s
epoch 90: {'train_loss': '1.38629'}; time used = 6.989389657974243s
epoch 95: {'train_loss': '1.38629'}; time used = 7.391272306442261s
epoch 100: {'train_loss': '1.38629'}; time used = 9.671873092651367s
epoch 105: {'train_loss': '1.38629'}; time used = 8.846415281295776s
epoch 110: {'train_loss': '1.38629'}; time used = 6.647169351577759s
epoch 115: {'train_loss': '1.38629'}; time used = 9.7648184299469s
epoch 120: {'train_loss': '1.38629'}; time used = 9.453372478485107s
epoch 125: {'train_loss': '1.38629'}; time used = 10.100371837615967s
epoch 130: {'train_loss': '1.38629'}; time used = 9.61692762374878s
epoch 135: {'train_loss': '1.38629'}; time used = 7.653924942016602s
epoch 140: {'train_loss': '1.38629'}; time used = 6.526310682296753s
epoch 145: {'train_loss': '1.38629'}; time used = 6.707634687423706s
epoch 150: {'train_loss': '1.38629'}; time used = 6.600748300552368s
epoch 155: {'train_loss': '1.38629'}; time used = 7.7072060108184814s
epoch 160: {'train_loss': '1.38629'}; time used = 6.853975296020508s
epoch 165: {'train_loss': '1.38629'}; time used = 6.829680442810059s
epoch 170: {'train_loss': '1.38629'}; time used = 6.66052770614624s
epoch 175: {'train_loss': '1.38629'}; time used = 6.675224781036377s
epoch 180: {'train_loss': '1.38629'}; time used = 6.687292814254761s
epoch 185: {'train_loss': '1.38629'}; time used = 8.222223281860352s
epoch 190: {'train_loss': '1.38629'}; time used = 6.759542465209961s
epoch 195: {'train_loss': '1.38629'}; time used = 10.119207620620728s
epoch 200: {'train_loss': '1.38629'}; time used = 7.3742148876190186s
epoch 205: {'train_loss': '1.38629'}; time used = 6.972768068313599s
epoch 210: {'train_loss': '1.38629'}; time used = 7.892070055007935s
epoch 215: {'train_loss': '1.38629'}; time used = 7.4239678382873535s
epoch 220: {'train_loss': '1.38629'}; time used = 6.62269926071167s
epoch 225: {'train_loss': '1.38629'}; time used = 7.331246852874756s
epoch 230: {'train_loss': '1.38629'}; time used = 8.321669816970825s
epoch 235: {'train_loss': '1.38629'}; time used = 12.17310118675232s
epoch 240: {'train_loss': '1.38629'}; time used = 7.125911235809326s
epoch 245: {'train_loss': '1.38629'}; time used = 6.385383605957031s
epoch 250: {'train_loss': '1.38629'}; time used = 6.712921619415283s
epoch 255: {'train_loss': '1.38629'}; time used = 6.440771818161011s
epoch 260: {'train_loss': '1.38629'}; time used = 6.771608352661133s
epoch 265: {'train_loss': '1.38629'}; time used = 6.791454792022705s
epoch 270: {'train_loss': '1.38629'}; time used = 6.666921138763428s
epoch 275: {'train_loss': '1.38629'}; time used = 6.737657070159912s
epoch 280: {'train_loss': '1.38629'}; time used = 7.991876840591431s
epoch 285: {'train_loss': '1.38629'}; time used = 7.3960349559783936s
epoch 290: {'train_loss': '1.38629'}; time used = 11.053751468658447s
epoch 295: {'train_loss': '1.38629'}; time used = 7.938308238983154s
epoch 300: {'train_loss': '1.38629'}; time used = 9.793352365493774s
epoch 305: {'train_loss': '1.38629'}; time used = 6.841799259185791s
epoch 310: {'train_loss': '1.38629'}; time used = 6.652958154678345s
epoch 315: {'train_loss': '1.38629'}; time used = 7.7835657596588135s
epoch 320: {'train_loss': '1.38629'}; time used = 6.964962005615234s
epoch 325: {'train_loss': '1.38629'}; time used = 9.749484300613403s
epoch 330: {'train_loss': '1.38629'}; time used = 9.47185468673706s
epoch 335: {'train_loss': '1.38629'}; time used = 6.377302646636963s
epoch 340: {'train_loss': '1.38629'}; time used = 6.459776401519775s
epoch 345: {'train_loss': '1.38629'}; time used = 7.0098185539245605s
epoch 350: {'train_loss': '1.38629'}; time used = 6.633987665176392s
epoch 355: {'train_loss': '1.38629'}; time used = 6.638026237487793s
epoch 360: {'train_loss': '1.38629'}; time used = 6.4742021560668945s
epoch 365: {'train_loss': '1.38629'}; time used = 7.77953577041626s
epoch 370: {'train_loss': '1.38629'}; time used = 7.5423736572265625s
epoch 375: {'train_loss': '1.38629'}; time used = 7.396506309509277s
epoch 380: {'train_loss': '1.38629'}; time used = 6.684003829956055s
epoch 385: {'train_loss': '1.38629'}; time used = 7.764277935028076s
epoch 390: {'train_loss': '1.38629'}; time used = 7.28397274017334s
epoch 395: {'train_loss': '1.38629'}; time used = 7.083449363708496s
epoch 400: {'train_loss': '1.38629'}; time used = 7.016268014907837s
epoch 405: {'train_loss': '1.38629'}; time used = 6.71154260635376s
epoch 410: {'train_loss': '1.38629'}; time used = 6.943897247314453s
epoch 415: {'train_loss': '1.38629'}; time used = 7.23652195930481s
epoch 420: {'train_loss': '1.38629'}; time used = 6.605472803115845s
epoch 425: {'train_loss': '1.38629'}; time used = 6.508253574371338s
epoch 430: {'train_loss': '1.38629'}; time used = 6.586106300354004s
epoch 435: {'train_loss': '1.38629'}; time used = 6.4065563678741455s
epoch 440: {'train_loss': '1.38629'}; time used = 6.65460205078125s
epoch 445: {'train_loss': '1.38629'}; time used = 10.962883710861206s
epoch 450: {'train_loss': '1.38629'}; time used = 11.131792306900024s
epoch 455: {'train_loss': '1.38629'}; time used = 7.7197160720825195s
epoch 460: {'train_loss': '1.38629'}; time used = 7.261383295059204s
epoch 465: {'train_loss': '1.38629'}; time used = 6.399662971496582s
epoch 470: {'train_loss': '1.38629'}; time used = 6.40083909034729s
epoch 475: {'train_loss': '1.38629'}; time used = 6.357601642608643s
epoch 480: {'train_loss': '1.38629'}; time used = 6.323004484176636s
epoch 485: {'train_loss': '1.38629'}; time used = 15.723806381225586s
epoch 490: {'train_loss': '1.38629'}; time used = 6.370315074920654s
epoch 495: {'train_loss': '1.38629'}; time used = 9.432856321334839s
epoch 500: {'train_loss': '1.38629'}; time used = 6.524837493896484s
Finished training. Time used = 766.580516576767.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.77923'}; time used = 5.656803369522095s
epoch 10: {'train_loss': '2.78222'}; time used = 6.803781270980835s
epoch 15: {'train_loss': '2.77251'}; time used = 6.724939823150635s
epoch 20: {'train_loss': '2.77219'}; time used = 6.584740161895752s
epoch 25: {'train_loss': '2.77374'}; time used = 5.382338285446167s
epoch 30: {'train_loss': '2.77206'}; time used = 5.5389063358306885s
epoch 35: {'train_loss': '2.76981'}; time used = 5.525054454803467s
epoch 40: {'train_loss': '2.76862'}; time used = 5.773701906204224s
epoch 45: {'train_loss': '2.76729'}; time used = 6.582355976104736s
epoch 50: {'train_loss': '2.76514'}; time used = 5.675727605819702s
epoch 55: {'train_loss': '2.76195'}; time used = 5.648312568664551s
epoch 60: {'train_loss': '2.75685'}; time used = 6.6148521900177s
epoch 65: {'train_loss': '2.74877'}; time used = 5.682859420776367s
epoch 70: {'train_loss': '2.74308'}; time used = 5.240779638290405s
epoch 75: {'train_loss': '2.74326'}; time used = 5.570293426513672s
epoch 80: {'train_loss': '2.74396'}; time used = 6.607382535934448s
epoch 85: {'train_loss': '2.74200'}; time used = 6.659782648086548s
epoch 90: {'train_loss': '2.74247'}; time used = 5.952762603759766s
epoch 95: {'train_loss': '2.74710'}; time used = 6.185445785522461s
epoch 100: {'train_loss': '2.74282'}; time used = 5.697983264923096s
epoch 105: {'train_loss': '2.73895'}; time used = 4.923677444458008s
epoch 110: {'train_loss': '2.74009'}; time used = 5.015944957733154s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 148.99537777900696.
Training classifier using 80.00% nodes...
{'micro': 0.715, 'macro': 0.7149928748218706, 'samples': 0.715, 'weighted': 0.7150213755343884, 'accuracy': 0.715}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.24605'}; time used = 2.7901079654693604s
epoch 10: {'train_loss': '0.29931'}; time used = 2.0994760990142822s
epoch 15: {'train_loss': '0.23419'}; time used = 2.1722333431243896s
epoch 20: {'train_loss': '0.00619'}; time used = 2.082529306411743s
epoch 25: {'train_loss': '0.00009'}; time used = 2.1285736560821533s
epoch 30: {'train_loss': '0.00055'}; time used = 1.9856328964233398s
epoch 35: {'train_loss': '0.00002'}; time used = 1.9716346263885498s
epoch 40: {'train_loss': '0.00002'}; time used = 2.0382790565490723s
epoch 45: {'train_loss': '0.00000'}; time used = 2.211681604385376s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.263964414596558.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.34072'}; time used = 2.1247057914733887s
epoch 10: {'train_loss': '1.10729'}; time used = 3.5097146034240723s
epoch 15: {'train_loss': '0.88148'}; time used = 3.448540210723877s
epoch 20: {'train_loss': '0.74760'}; time used = 2.9068527221679688s
epoch 25: {'train_loss': '0.57400'}; time used = 2.253018856048584s
epoch 30: {'train_loss': '0.06545'}; time used = 1.9975159168243408s
epoch 35: {'train_loss': '0.16783'}; time used = 5.38543438911438s
epoch 40: {'train_loss': '0.02555'}; time used = 2.5271174907684326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.980223417282104.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.91822'}; time used = 2.5707550048828125s
epoch 10: {'train_loss': '2.77436'}; time used = 2.5017406940460205s
epoch 15: {'train_loss': '2.77274'}; time used = 2.617138385772705s
epoch 20: {'train_loss': '2.77467'}; time used = 2.5373129844665527s
epoch 25: {'train_loss': '2.77818'}; time used = 2.584745407104492s
epoch 30: {'train_loss': '2.77891'}; time used = 2.911417007446289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.871530771255493.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.75309'}; time used = 1.683643102645874s
epoch 10: {'train_loss': '2.70498'}; time used = 1.65098237991333s
epoch 15: {'train_loss': '2.68493'}; time used = 1.6587119102478027s
epoch 20: {'train_loss': '2.67567'}; time used = 1.6565086841583252s
epoch 25: {'train_loss': '2.66505'}; time used = 1.837580919265747s
epoch 30: {'train_loss': '2.65623'}; time used = 1.780144214630127s
epoch 35: {'train_loss': '2.65201'}; time used = 1.7539677619934082s
epoch 40: {'train_loss': '2.64643'}; time used = 1.7264728546142578s
epoch 45: {'train_loss': '2.63679'}; time used = 1.8259756565093994s
epoch 50: {'train_loss': '2.61889'}; time used = 1.6964237689971924s
epoch 55: {'train_loss': '2.61318'}; time used = 2.0913033485412598s
epoch 60: {'train_loss': '2.61258'}; time used = 2.9408023357391357s
epoch 65: {'train_loss': '2.59518'}; time used = 3.1979010105133057s
epoch 70: {'train_loss': '2.58228'}; time used = 2.778560161590576s
epoch 75: {'train_loss': '2.57308'}; time used = 1.6579174995422363s
epoch 80: {'train_loss': '2.57022'}; time used = 1.7458434104919434s
epoch 85: {'train_loss': '2.57221'}; time used = 1.6813182830810547s
epoch 90: {'train_loss': '2.57375'}; time used = 1.6254682540893555s
epoch 95: {'train_loss': '2.57092'}; time used = 1.757612943649292s
epoch 100: {'train_loss': '2.56065'}; time used = 1.667412519454956s
epoch 105: {'train_loss': '2.56250'}; time used = 1.695810079574585s
epoch 110: {'train_loss': '2.55980'}; time used = 1.7148520946502686s
epoch 115: {'train_loss': '2.55710'}; time used = 1.629749059677124s
epoch 120: {'train_loss': '2.55960'}; time used = 1.6791355609893799s
epoch 125: {'train_loss': '2.55637'}; time used = 1.611156940460205s
epoch 130: {'train_loss': '2.55960'}; time used = 3.1897706985473633s
epoch 135: {'train_loss': '2.56188'}; time used = 2.326777458190918s
epoch 140: {'train_loss': '2.55732'}; time used = 1.8859989643096924s
epoch 145: {'train_loss': '2.55025'}; time used = 2.1451575756073s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.97114396095276.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4987179487179487, 'samples': 0.5072463768115942, 'weighted': 0.5034559643255295, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.34433'}; time used = 1.1211662292480469s
epoch 10: {'train_loss': '1.33999'}; time used = 0.9983491897583008s
epoch 15: {'train_loss': '1.25260'}; time used = 0.9634993076324463s
epoch 20: {'train_loss': '1.31688'}; time used = 0.9915664196014404s
epoch 25: {'train_loss': '1.18768'}; time used = 0.9945876598358154s
epoch 30: {'train_loss': '1.19451'}; time used = 1.0363130569458008s
epoch 35: {'train_loss': '1.25134'}; time used = 0.9584481716156006s
epoch 40: {'train_loss': '1.19214'}; time used = 1.0058505535125732s
epoch 45: {'train_loss': '1.00178'}; time used = 0.9510738849639893s
epoch 50: {'train_loss': '1.11879'}; time used = 1.0266814231872559s
epoch 55: {'train_loss': '1.14003'}; time used = 1.0053126811981201s
epoch 60: {'train_loss': '1.19738'}; time used = 0.9847366809844971s
epoch 65: {'train_loss': '0.93674'}; time used = 0.9759385585784912s
epoch 70: {'train_loss': '1.21454'}; time used = 0.9780149459838867s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.554439544677734.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6375641966250918, 'samples': 0.6578947368421053, 'weighted': 0.6511178901031008, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92566'}; time used = 2.137753963470459s
epoch 10: {'train_loss': '2.81263'}; time used = 2.107222080230713s
epoch 15: {'train_loss': '2.79482'}; time used = 2.1044600009918213s
epoch 20: {'train_loss': '2.78944'}; time used = 2.1948130130767822s
epoch 25: {'train_loss': '2.78263'}; time used = 2.2120511531829834s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.412787437438965.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5760869565217391, 'samples': 0.6231884057971014, 'weighted': 0.5863264020163832, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.08485'}; time used = 2.459521770477295s
epoch 10: {'train_loss': '0.28920'}; time used = 2.9455318450927734s
epoch 15: {'train_loss': '0.13994'}; time used = 3.366537094116211s
epoch 20: {'train_loss': '0.12146'}; time used = 2.438563346862793s
epoch 25: {'train_loss': '0.09695'}; time used = 2.6354784965515137s
epoch 30: {'train_loss': '0.18920'}; time used = 2.6509623527526855s
epoch 35: {'train_loss': '0.06102'}; time used = 2.519430637359619s
epoch 40: {'train_loss': '0.06223'}; time used = 2.5648038387298584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.539799690246582.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01993'}; time used = 2.6679933071136475s
epoch 10: {'train_loss': '0.60238'}; time used = 3.1842753887176514s
epoch 15: {'train_loss': '0.30277'}; time used = 2.634291887283325s
epoch 20: {'train_loss': '0.07583'}; time used = 2.4701290130615234s
epoch 25: {'train_loss': '0.00088'}; time used = 2.738502025604248s
epoch 30: {'train_loss': '0.06293'}; time used = 2.7629168033599854s
epoch 35: {'train_loss': '0.00929'}; time used = 3.667621612548828s
epoch 40: {'train_loss': '0.03483'}; time used = 3.750962734222412s
epoch 45: {'train_loss': '1.01819'}; time used = 3.198169231414795s
epoch 50: {'train_loss': '0.19948'}; time used = 2.586024045944214s
epoch 55: {'train_loss': '0.07705'}; time used = 2.6066555976867676s
epoch 60: {'train_loss': '0.05738'}; time used = 2.537707567214966s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.79263377189636.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37285'}; time used = 1.9290759563446045s
epoch 10: {'train_loss': '1.41366'}; time used = 1.210339069366455s
epoch 15: {'train_loss': '1.35692'}; time used = 1.3634705543518066s
epoch 20: {'train_loss': '1.38593'}; time used = 1.0594308376312256s
epoch 25: {'train_loss': '1.34566'}; time used = 1.0199096202850342s
epoch 30: {'train_loss': '1.36180'}; time used = 0.9854800701141357s
epoch 35: {'train_loss': '1.38171'}; time used = 1.0483622550964355s
epoch 40: {'train_loss': '1.34152'}; time used = 1.0334208011627197s
epoch 45: {'train_loss': '1.24927'}; time used = 1.0483982563018799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.408752918243408.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.74521'}; time used = 2.050536632537842s
epoch 10: {'train_loss': '2.70454'}; time used = 1.914052963256836s
epoch 15: {'train_loss': '2.69060'}; time used = 1.6291627883911133s
epoch 20: {'train_loss': '2.67094'}; time used = 1.649367094039917s
epoch 25: {'train_loss': '2.65471'}; time used = 1.7168118953704834s
epoch 30: {'train_loss': '2.64559'}; time used = 1.633784294128418s
epoch 35: {'train_loss': '2.64396'}; time used = 1.6162703037261963s
epoch 40: {'train_loss': '2.64375'}; time used = 1.812793254852295s
epoch 45: {'train_loss': '2.64155'}; time used = 1.6320271492004395s
epoch 50: {'train_loss': '2.63009'}; time used = 1.634758710861206s
epoch 55: {'train_loss': '2.63109'}; time used = 1.7208077907562256s
epoch 60: {'train_loss': '2.63574'}; time used = 1.6509935855865479s
epoch 65: {'train_loss': '2.61995'}; time used = 1.6306192874908447s
epoch 70: {'train_loss': '2.60998'}; time used = 1.5921239852905273s
epoch 75: {'train_loss': '2.59960'}; time used = 1.605137825012207s
epoch 80: {'train_loss': '2.59483'}; time used = 1.6780812740325928s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.48238229751587.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05402'}; time used = 8.73014211654663s
epoch 10: {'train_loss': '2.78257'}; time used = 9.180389165878296s
epoch 15: {'train_loss': '2.80728'}; time used = 9.145562410354614s
epoch 20: {'train_loss': '2.79384'}; time used = 9.241594076156616s
epoch 25: {'train_loss': '2.77301'}; time used = 8.37777328491211s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 94.56981301307678.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.45661375661375664, 'samples': 0.4633333333333333, 'weighted': 0.45258201058201064, 'accuracy': 0.4633333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18620'}; time used = 1.1708307266235352s
epoch 10: {'train_loss': '0.43249'}; time used = 1.0935688018798828s
epoch 15: {'train_loss': '0.05659'}; time used = 0.9415981769561768s
epoch 20: {'train_loss': '0.02376'}; time used = 0.9424591064453125s
epoch 25: {'train_loss': '0.03093'}; time used = 0.9279472827911377s
epoch 30: {'train_loss': '0.00783'}; time used = 0.9496750831604004s
epoch 35: {'train_loss': '0.01089'}; time used = 1.0531566143035889s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.003351211547852.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82769'}; time used = 1.7748124599456787s
epoch 10: {'train_loss': '2.80081'}; time used = 1.88144850730896s
epoch 15: {'train_loss': '2.78886'}; time used = 2.090860605239868s
epoch 20: {'train_loss': '2.77615'}; time used = 1.714357852935791s
epoch 25: {'train_loss': '2.76911'}; time used = 1.8465807437896729s
epoch 30: {'train_loss': '2.76131'}; time used = 1.721627950668335s
epoch 35: {'train_loss': '2.75700'}; time used = 1.7387940883636475s
epoch 40: {'train_loss': '2.75166'}; time used = 1.705702304840088s
epoch 45: {'train_loss': '2.74087'}; time used = 1.7053179740905762s
epoch 50: {'train_loss': '2.73913'}; time used = 1.7550227642059326s
epoch 55: {'train_loss': '2.72980'}; time used = 1.7220618724822998s
epoch 60: {'train_loss': '2.70229'}; time used = 1.7103064060211182s
epoch 65: {'train_loss': '2.67838'}; time used = 1.6876883506774902s
epoch 70: {'train_loss': '2.68821'}; time used = 1.6876075267791748s
epoch 75: {'train_loss': '2.64095'}; time used = 1.981705665588379s
epoch 80: {'train_loss': '2.65331'}; time used = 1.8623862266540527s
epoch 85: {'train_loss': '2.65172'}; time used = 1.8983230590820312s
epoch 90: {'train_loss': '2.63297'}; time used = 1.7122204303741455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.14802432060242.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5021222410865874, 'samples': 0.5072463768115942, 'weighted': 0.5057823380330209, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.08023'}; time used = 1.7335116863250732s
epoch 10: {'train_loss': '0.92203'}; time used = 1.7771496772766113s
epoch 15: {'train_loss': '0.83016'}; time used = 1.7619409561157227s
epoch 20: {'train_loss': '1.02935'}; time used = 1.6836750507354736s
epoch 25: {'train_loss': '1.01120'}; time used = 1.7522172927856445s
epoch 30: {'train_loss': '0.89069'}; time used = 1.6847805976867676s
epoch 35: {'train_loss': '0.57365'}; time used = 1.770413875579834s
epoch 40: {'train_loss': '0.51417'}; time used = 1.7672455310821533s
epoch 45: {'train_loss': '0.31985'}; time used = 1.7829487323760986s
epoch 50: {'train_loss': '0.15262'}; time used = 1.7323505878448486s
epoch 55: {'train_loss': '0.05873'}; time used = 1.9504773616790771s
epoch 60: {'train_loss': '0.60623'}; time used = 1.7858753204345703s
epoch 65: {'train_loss': '0.38570'}; time used = 1.7252135276794434s
epoch 70: {'train_loss': '0.51640'}; time used = 1.730747938156128s
epoch 75: {'train_loss': '0.14028'}; time used = 1.717484712600708s
epoch 80: {'train_loss': '0.28798'}; time used = 1.8683302402496338s
epoch 85: {'train_loss': '0.16096'}; time used = 1.7001497745513916s
epoch 90: {'train_loss': '0.49498'}; time used = 1.731919288635254s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.571778297424316.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01758'}; time used = 1.1744129657745361s
epoch 10: {'train_loss': '0.54809'}; time used = 0.9296514987945557s
epoch 15: {'train_loss': '0.36861'}; time used = 0.9081902503967285s
epoch 20: {'train_loss': '0.23929'}; time used = 0.9396276473999023s
epoch 25: {'train_loss': '0.16066'}; time used = 1.0343668460845947s
epoch 30: {'train_loss': '0.10263'}; time used = 0.9463679790496826s
epoch 35: {'train_loss': '0.06827'}; time used = 0.948174238204956s
epoch 40: {'train_loss': '0.05345'}; time used = 0.9399664402008057s
epoch 45: {'train_loss': '0.05501'}; time used = 0.9259476661682129s
epoch 50: {'train_loss': '0.04403'}; time used = 1.0669667720794678s
epoch 55: {'train_loss': '0.03117'}; time used = 0.9025015830993652s
epoch 60: {'train_loss': '0.02338'}; time used = 0.9632341861724854s
epoch 65: {'train_loss': '0.03157'}; time used = 0.8644928932189941s
epoch 70: {'train_loss': '0.02279'}; time used = 0.9156146049499512s
epoch 75: {'train_loss': '0.02282'}; time used = 1.8004302978515625s
epoch 80: {'train_loss': '0.01844'}; time used = 0.96645188331604s
epoch 85: {'train_loss': '0.02288'}; time used = 0.8859269618988037s
epoch 90: {'train_loss': '0.02672'}; time used = 0.9030807018280029s
epoch 95: {'train_loss': '0.03073'}; time used = 0.8672914505004883s
epoch 100: {'train_loss': '0.03475'}; time used = 0.8739681243896484s
epoch 105: {'train_loss': '0.01359'}; time used = 0.9217641353607178s
epoch 110: {'train_loss': '0.01412'}; time used = 0.865609884262085s
epoch 115: {'train_loss': '0.01942'}; time used = 0.8727400302886963s
epoch 120: {'train_loss': '0.02311'}; time used = 0.873483419418335s
epoch 125: {'train_loss': '0.02337'}; time used = 0.8678696155548096s
epoch 130: {'train_loss': '0.01344'}; time used = 0.8608534336090088s
epoch 135: {'train_loss': '0.01812'}; time used = 0.8770129680633545s
epoch 140: {'train_loss': '0.02845'}; time used = 0.8713984489440918s
epoch 145: {'train_loss': '0.01162'}; time used = 0.8608462810516357s
epoch 150: {'train_loss': '0.01255'}; time used = 0.9182698726654053s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.056050062179565.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.856386999244142, 'samples': 0.868421052631579, 'weighted': 0.8629510283645622, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03474'}; time used = 1.1605267524719238s
epoch 10: {'train_loss': '0.66138'}; time used = 0.9926939010620117s
epoch 15: {'train_loss': '0.43572'}; time used = 1.156583309173584s
epoch 20: {'train_loss': '0.31438'}; time used = 1.1243278980255127s
epoch 25: {'train_loss': '0.24237'}; time used = 1.152080774307251s
epoch 30: {'train_loss': '0.22469'}; time used = 1.1306893825531006s
epoch 35: {'train_loss': '0.25898'}; time used = 1.1810758113861084s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.363972425460815.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.12647'}; time used = 1.2389085292816162s
epoch 10: {'train_loss': '1.41218'}; time used = 1.1001465320587158s
epoch 15: {'train_loss': '0.67662'}; time used = 1.077350378036499s
epoch 20: {'train_loss': '0.57554'}; time used = 1.056753396987915s
epoch 25: {'train_loss': '0.03002'}; time used = 1.0568315982818604s
epoch 30: {'train_loss': '1.40775'}; time used = 1.0220904350280762s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.658221960067749.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36651'}; time used = 1.234189748764038s
epoch 10: {'train_loss': '1.32640'}; time used = 1.1426928043365479s
epoch 15: {'train_loss': '1.23521'}; time used = 1.1534905433654785s
epoch 20: {'train_loss': '1.20006'}; time used = 1.1363394260406494s
epoch 25: {'train_loss': '0.96273'}; time used = 1.1498088836669922s
epoch 30: {'train_loss': '0.88622'}; time used = 1.3069303035736084s
epoch 35: {'train_loss': '0.76291'}; time used = 1.1321625709533691s
epoch 40: {'train_loss': '0.93591'}; time used = 1.0920491218566895s
epoch 45: {'train_loss': '0.74931'}; time used = 1.0972840785980225s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.062886714935303.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.89908'}; time used = 1.087886095046997s
epoch 10: {'train_loss': '2.79037'}; time used = 1.2781667709350586s
epoch 15: {'train_loss': '2.77259'}; time used = 1.1009466648101807s
epoch 20: {'train_loss': '2.77928'}; time used = 1.0534310340881348s
epoch 25: {'train_loss': '2.77721'}; time used = 1.3862709999084473s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.096296548843384.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.87170'}; time used = 1.0264458656311035s
epoch 10: {'train_loss': '2.50567'}; time used = 0.8872265815734863s
epoch 15: {'train_loss': '2.51463'}; time used = 0.8680880069732666s
epoch 20: {'train_loss': '2.47565'}; time used = 0.8936333656311035s
epoch 25: {'train_loss': '2.43399'}; time used = 0.8763535022735596s
epoch 30: {'train_loss': '2.36053'}; time used = 0.8573575019836426s
epoch 35: {'train_loss': '2.30483'}; time used = 0.9636685848236084s
epoch 40: {'train_loss': '2.25163'}; time used = 0.950711727142334s
epoch 45: {'train_loss': '2.20466'}; time used = 0.9456937313079834s
epoch 50: {'train_loss': '2.17895'}; time used = 0.9938652515411377s
epoch 55: {'train_loss': '2.14776'}; time used = 1.067121982574463s
epoch 60: {'train_loss': '2.11888'}; time used = 0.9564001560211182s
epoch 65: {'train_loss': '2.12471'}; time used = 0.8898758888244629s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.40166687965393.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84685'}; time used = 2.298924446105957s
epoch 10: {'train_loss': '0.47913'}; time used = 2.167499303817749s
epoch 15: {'train_loss': '0.33065'}; time used = 2.230746269226074s
epoch 20: {'train_loss': '0.26141'}; time used = 2.1121232509613037s
epoch 25: {'train_loss': '0.30144'}; time used = 1.9515888690948486s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.417470216751099.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36988'}; time used = 1.0399811267852783s
epoch 10: {'train_loss': '1.35673'}; time used = 1.1481280326843262s
epoch 15: {'train_loss': '1.26974'}; time used = 0.9701316356658936s
epoch 20: {'train_loss': '1.32844'}; time used = 1.2751200199127197s
epoch 25: {'train_loss': '1.15661'}; time used = 0.9696471691131592s
epoch 30: {'train_loss': '1.27402'}; time used = 0.9623703956604004s
epoch 35: {'train_loss': '1.28551'}; time used = 0.9934625625610352s
epoch 40: {'train_loss': '1.22245'}; time used = 1.0590898990631104s
epoch 45: {'train_loss': '1.09085'}; time used = 1.0406455993652344s
epoch 50: {'train_loss': '1.13583'}; time used = 0.9632015228271484s
epoch 55: {'train_loss': '1.31007'}; time used = 0.9517922401428223s
epoch 60: {'train_loss': '1.25936'}; time used = 0.9372720718383789s
epoch 65: {'train_loss': '1.17574'}; time used = 1.0671639442443848s
epoch 70: {'train_loss': '1.24496'}; time used = 1.0242199897766113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.535967350006104.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33823'}; time used = 2.1535861492156982s
epoch 10: {'train_loss': '1.26824'}; time used = 2.087343215942383s
epoch 15: {'train_loss': '1.24846'}; time used = 2.2161834239959717s
epoch 20: {'train_loss': '1.20313'}; time used = 2.021279811859131s
epoch 25: {'train_loss': '1.02736'}; time used = 2.109884738922119s
epoch 30: {'train_loss': '0.80934'}; time used = 2.0157504081726074s
epoch 35: {'train_loss': '0.77247'}; time used = 2.1726953983306885s
epoch 40: {'train_loss': '0.67000'}; time used = 2.099756956100464s
epoch 45: {'train_loss': '0.54150'}; time used = 2.1562490463256836s
epoch 50: {'train_loss': '0.49412'}; time used = 2.1585023403167725s
epoch 55: {'train_loss': '0.42730'}; time used = 2.227926731109619s
epoch 60: {'train_loss': '0.29440'}; time used = 2.214578628540039s
epoch 65: {'train_loss': '0.20488'}; time used = 2.07696795463562s
epoch 70: {'train_loss': '0.30124'}; time used = 2.0786213874816895s
epoch 75: {'train_loss': '0.09957'}; time used = 2.1417534351348877s
epoch 80: {'train_loss': '0.04782'}; time used = 2.219329357147217s
epoch 85: {'train_loss': '0.09386'}; time used = 2.1629371643066406s
epoch 90: {'train_loss': '0.03068'}; time used = 2.0918214321136475s
epoch 95: {'train_loss': '0.04189'}; time used = 2.136951446533203s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.48519015312195.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78808'}; time used = 1.808755874633789s
epoch 10: {'train_loss': '2.76267'}; time used = 1.6972944736480713s
epoch 15: {'train_loss': '2.74237'}; time used = 2.307561159133911s
epoch 20: {'train_loss': '2.70808'}; time used = 3.1218101978302s
epoch 25: {'train_loss': '2.64571'}; time used = 3.0790505409240723s
epoch 30: {'train_loss': '2.60276'}; time used = 2.651820421218872s
epoch 35: {'train_loss': '2.54003'}; time used = 1.6349480152130127s
epoch 40: {'train_loss': '2.44892'}; time used = 1.7895588874816895s
epoch 45: {'train_loss': '2.57571'}; time used = 1.6142325401306152s
epoch 50: {'train_loss': '2.39375'}; time used = 1.839343786239624s
epoch 55: {'train_loss': '2.35093'}; time used = 1.6329646110534668s
epoch 60: {'train_loss': '2.31241'}; time used = 1.6054911613464355s
epoch 65: {'train_loss': '2.22386'}; time used = 1.6285316944122314s
epoch 70: {'train_loss': '2.15257'}; time used = 2.4265270233154297s
epoch 75: {'train_loss': '2.09349'}; time used = 2.4394633769989014s
epoch 80: {'train_loss': '2.03701'}; time used = 1.6637787818908691s
epoch 85: {'train_loss': '2.09166'}; time used = 1.637007474899292s
epoch 90: {'train_loss': '2.05201'}; time used = 1.6075284481048584s
epoch 95: {'train_loss': '1.95834'}; time used = 1.6625010967254639s
epoch 100: {'train_loss': '2.35791'}; time used = 1.5864779949188232s
epoch 105: {'train_loss': '2.08310'}; time used = 1.6672444343566895s
epoch 110: {'train_loss': '1.99281'}; time used = 1.7261476516723633s
epoch 115: {'train_loss': '1.89285'}; time used = 1.594670057296753s
epoch 120: {'train_loss': '1.85798'}; time used = 2.26461124420166s
epoch 125: {'train_loss': '1.80478'}; time used = 1.7123379707336426s
epoch 130: {'train_loss': '1.78863'}; time used = 1.5156455039978027s
epoch 135: {'train_loss': '1.87161'}; time used = 1.6846280097961426s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.677526235580444.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01930'}; time used = 2.922109842300415s
epoch 10: {'train_loss': '0.63757'}; time used = 3.74120831489563s
epoch 15: {'train_loss': '0.00940'}; time used = 3.6720855236053467s
epoch 20: {'train_loss': '0.00295'}; time used = 2.7712836265563965s
epoch 25: {'train_loss': '0.02243'}; time used = 1.7574820518493652s
epoch 30: {'train_loss': '0.07659'}; time used = 1.5805959701538086s
epoch 35: {'train_loss': '0.16376'}; time used = 1.777207374572754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.816306591033936.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6044973544973544, 'samples': 0.6231884057971014, 'weighted': 0.6107277049306035, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.35454'}; time used = 1.770707130432129s
epoch 10: {'train_loss': '2.82088'}; time used = 1.6883904933929443s
epoch 15: {'train_loss': '2.79223'}; time used = 1.63767409324646s
epoch 20: {'train_loss': '2.79377'}; time used = 1.7386937141418457s
epoch 25: {'train_loss': '2.79408'}; time used = 1.7520949840545654s
epoch 30: {'train_loss': '2.78720'}; time used = 1.791452169418335s
epoch 35: {'train_loss': '2.77577'}; time used = 1.9097394943237305s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.351207971572876.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6349206349206349, 'samples': 0.6376811594202898, 'weighted': 0.6372210720036807, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.91822'}; time used = 3.4982287883758545s
epoch 10: {'train_loss': '2.77436'}; time used = 5.025147438049316s
epoch 15: {'train_loss': '2.77274'}; time used = 4.9007487297058105s
epoch 20: {'train_loss': '2.77467'}; time used = 4.111190319061279s
epoch 25: {'train_loss': '2.77818'}; time used = 2.728200912475586s
epoch 30: {'train_loss': '2.77891'}; time used = 2.473862409591675s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.815948724746704.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05722'}; time used = 4.928306818008423s
epoch 10: {'train_loss': '2.78217'}; time used = 5.049354553222656s
epoch 15: {'train_loss': '2.79065'}; time used = 4.871928453445435s
epoch 20: {'train_loss': '2.79817'}; time used = 4.657776355743408s
epoch 25: {'train_loss': '2.77452'}; time used = 5.909095525741577s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.33771634101868.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049926248156204, 'samples': 0.705, 'weighted': 0.7050221255531389, 'accuracy': 0.705}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77233'}; time used = 2.8154778480529785s
epoch 10: {'train_loss': '2.76381'}; time used = 2.0504655838012695s
epoch 15: {'train_loss': '2.75679'}; time used = 1.7395999431610107s
epoch 20: {'train_loss': '2.72788'}; time used = 1.7357761859893799s
epoch 25: {'train_loss': '2.72497'}; time used = 1.95784330368042s
epoch 30: {'train_loss': '2.71437'}; time used = 1.851003646850586s
epoch 35: {'train_loss': '2.71373'}; time used = 1.734281063079834s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.26369380950928.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05399'}; time used = 1.3387997150421143s
epoch 10: {'train_loss': '2.79385'}; time used = 1.0936765670776367s
epoch 15: {'train_loss': '2.79020'}; time used = 1.0652356147766113s
epoch 20: {'train_loss': '2.79902'}; time used = 1.3316574096679688s
epoch 25: {'train_loss': '2.77259'}; time used = 1.1214163303375244s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.835812330245972.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.71615'}; time used = 1.780207872390747s
epoch 10: {'train_loss': '2.63748'}; time used = 1.6928796768188477s
epoch 15: {'train_loss': '2.62594'}; time used = 1.7027199268341064s
epoch 20: {'train_loss': '2.59395'}; time used = 1.679748296737671s
epoch 25: {'train_loss': '2.56984'}; time used = 1.7764184474945068s
epoch 30: {'train_loss': '2.54095'}; time used = 1.6980695724487305s
epoch 35: {'train_loss': '2.51397'}; time used = 1.7010612487792969s
epoch 40: {'train_loss': '2.48229'}; time used = 1.7539596557617188s
epoch 45: {'train_loss': '2.43822'}; time used = 2.1199183464050293s
epoch 50: {'train_loss': '2.46225'}; time used = 1.971048355102539s
epoch 55: {'train_loss': '2.38971'}; time used = 1.9881255626678467s
epoch 60: {'train_loss': '2.35322'}; time used = 1.8927552700042725s
epoch 65: {'train_loss': '2.31582'}; time used = 1.9296727180480957s
epoch 70: {'train_loss': '2.64635'}; time used = 3.2135422229766846s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.952425718307495.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.93013'}; time used = 1.8148269653320312s
epoch 10: {'train_loss': '2.80828'}; time used = 1.8114879131317139s
epoch 15: {'train_loss': '2.75989'}; time used = 1.6672708988189697s
epoch 20: {'train_loss': '2.70902'}; time used = 1.7322919368743896s
epoch 25: {'train_loss': '2.66062'}; time used = 1.7429101467132568s
epoch 30: {'train_loss': '2.62614'}; time used = 1.7852044105529785s
epoch 35: {'train_loss': '2.60620'}; time used = 1.91986083984375s
epoch 40: {'train_loss': '2.58780'}; time used = 1.7502646446228027s
epoch 45: {'train_loss': '2.55634'}; time used = 1.7042498588562012s
epoch 50: {'train_loss': '2.52055'}; time used = 1.8705291748046875s
epoch 55: {'train_loss': '2.53222'}; time used = 1.995612621307373s
epoch 60: {'train_loss': '2.52814'}; time used = 1.714329719543457s
epoch 65: {'train_loss': '2.50731'}; time used = 1.7727687358856201s
epoch 70: {'train_loss': '2.48182'}; time used = 1.9455409049987793s
epoch 75: {'train_loss': '2.45139'}; time used = 1.7418038845062256s
epoch 80: {'train_loss': '2.41219'}; time used = 1.7313117980957031s
epoch 85: {'train_loss': '2.41273'}; time used = 1.6773402690887451s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.724714279174805.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87376'}; time used = 2.0177090167999268s
epoch 10: {'train_loss': '2.79882'}; time used = 1.8488030433654785s
epoch 15: {'train_loss': '2.77755'}; time used = 2.16336989402771s
epoch 20: {'train_loss': '2.76976'}; time used = 2.033479928970337s
epoch 25: {'train_loss': '2.76565'}; time used = 2.6150574684143066s
epoch 30: {'train_loss': '2.76163'}; time used = 3.485229253768921s
epoch 35: {'train_loss': '2.75908'}; time used = 3.8203113079071045s
epoch 40: {'train_loss': '2.75657'}; time used = 3.8183460235595703s
epoch 45: {'train_loss': '2.75005'}; time used = 4.119286298751831s
epoch 50: {'train_loss': '2.74492'}; time used = 3.8707315921783447s
epoch 55: {'train_loss': '2.74669'}; time used = 3.3993687629699707s
epoch 60: {'train_loss': '2.73552'}; time used = 2.5893659591674805s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.59993863105774.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.41025641025641024, 'samples': 0.5217391304347826, 'weighted': 0.42883686361947226, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.13296'}; time used = 2.34424090385437s
epoch 10: {'train_loss': '2.79589'}; time used = 0.9978978633880615s
epoch 15: {'train_loss': '2.80005'}; time used = 0.9867291450500488s
epoch 20: {'train_loss': '2.79754'}; time used = 1.0583364963531494s
epoch 25: {'train_loss': '2.77560'}; time used = 0.9649872779846191s
epoch 30: {'train_loss': '2.78064'}; time used = 0.9775152206420898s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.389311790466309.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81358'}; time used = 3.7339794635772705s
epoch 10: {'train_loss': '2.76675'}; time used = 3.9142627716064453s
epoch 15: {'train_loss': '2.75564'}; time used = 3.405209541320801s
epoch 20: {'train_loss': '2.73463'}; time used = 2.514885425567627s
epoch 25: {'train_loss': '2.71587'}; time used = 2.5910847187042236s
epoch 30: {'train_loss': '2.69758'}; time used = 2.5648601055145264s
epoch 35: {'train_loss': '2.69150'}; time used = 3.7485666275024414s
epoch 40: {'train_loss': '2.69148'}; time used = 3.254692316055298s
epoch 45: {'train_loss': '2.68983'}; time used = 2.639512062072754s
epoch 50: {'train_loss': '2.68146'}; time used = 2.5075507164001465s
epoch 55: {'train_loss': '2.68986'}; time used = 2.462099313735962s
epoch 60: {'train_loss': '2.67447'}; time used = 2.5747220516204834s
epoch 65: {'train_loss': '2.68049'}; time used = 2.4380640983581543s
epoch 70: {'train_loss': '2.68687'}; time used = 2.414562702178955s
epoch 75: {'train_loss': '2.66486'}; time used = 2.5277140140533447s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.29055309295654.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4569444444444444, 'samples': 0.5072463768115942, 'weighted': 0.4689210950080515, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.40915'}; time used = 5.70487380027771s
epoch 10: {'train_loss': '2.81779'}; time used = 8.585208892822266s
epoch 15: {'train_loss': '2.82786'}; time used = 5.554495334625244s
epoch 20: {'train_loss': '2.84117'}; time used = 4.7273383140563965s
epoch 25: {'train_loss': '2.82683'}; time used = 5.222054481506348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.80109119415283.
Training classifier using 80.00% nodes...
{'micro': 0.7, 'macro': 0.6999699969997, 'samples': 0.7, 'weighted': 0.7000300030002999, 'accuracy': 0.7}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.35261'}; time used = 1.4037227630615234s
epoch 10: {'train_loss': '1.40139'}; time used = 0.9662446975708008s
epoch 15: {'train_loss': '1.34760'}; time used = 1.0437958240509033s
epoch 20: {'train_loss': '1.35908'}; time used = 0.9578044414520264s
epoch 25: {'train_loss': '1.29443'}; time used = 0.9422335624694824s
epoch 30: {'train_loss': '1.29899'}; time used = 1.108354091644287s
epoch 35: {'train_loss': '1.30113'}; time used = 0.9657492637634277s
epoch 40: {'train_loss': '1.23480'}; time used = 0.942786693572998s
epoch 45: {'train_loss': '1.10423'}; time used = 1.0788917541503906s
epoch 50: {'train_loss': '1.21131'}; time used = 0.9674246311187744s
epoch 55: {'train_loss': '1.19943'}; time used = 0.9693253040313721s
epoch 60: {'train_loss': '1.23258'}; time used = 1.0094506740570068s
epoch 65: {'train_loss': '1.04701'}; time used = 2.4136219024658203s
epoch 70: {'train_loss': '1.33287'}; time used = 2.279884099960327s
epoch 75: {'train_loss': '1.22671'}; time used = 2.3647007942199707s
epoch 80: {'train_loss': '1.07475'}; time used = 2.3701374530792236s
epoch 85: {'train_loss': '1.08850'}; time used = 1.9808809757232666s
epoch 90: {'train_loss': '1.06802'}; time used = 1.0465259552001953s
epoch 95: {'train_loss': '1.18963'}; time used = 0.9612886905670166s
epoch 100: {'train_loss': '1.14890'}; time used = 0.9594292640686035s
epoch 105: {'train_loss': '1.09855'}; time used = 0.9653804302215576s
epoch 110: {'train_loss': '1.18990'}; time used = 0.9752464294433594s
epoch 115: {'train_loss': '1.27460'}; time used = 1.1056230068206787s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.38577365875244.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.19739'}; time used = 1.194305181503296s
epoch 10: {'train_loss': '2.90032'}; time used = 1.144218921661377s
epoch 15: {'train_loss': '2.79471'}; time used = 1.0996201038360596s
epoch 20: {'train_loss': '2.77461'}; time used = 1.1741046905517578s
epoch 25: {'train_loss': '2.78370'}; time used = 1.1225130558013916s
epoch 30: {'train_loss': '2.77768'}; time used = 1.262375831604004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.598206996917725.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7840909090909092, 'samples': 0.7894736842105263, 'weighted': 0.7894736842105263, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87521'}; time used = 1.0768141746520996s
epoch 10: {'train_loss': '2.79443'}; time used = 0.9711887836456299s
epoch 15: {'train_loss': '2.77270'}; time used = 0.9657986164093018s
epoch 20: {'train_loss': '2.77897'}; time used = 1.0420794486999512s
epoch 25: {'train_loss': '2.77909'}; time used = 0.9957211017608643s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.07912278175354.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37694'}; time used = 2.6465134620666504s
epoch 10: {'train_loss': '1.30536'}; time used = 2.134758472442627s
epoch 15: {'train_loss': '1.20015'}; time used = 1.1030616760253906s
epoch 20: {'train_loss': '1.15275'}; time used = 1.0970697402954102s
epoch 25: {'train_loss': '0.89128'}; time used = 1.259568691253662s
epoch 30: {'train_loss': '1.06963'}; time used = 1.1634879112243652s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.422304391860962.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11988'}; time used = 1.2456128597259521s
epoch 10: {'train_loss': '2.81467'}; time used = 1.0515122413635254s
epoch 15: {'train_loss': '2.81679'}; time used = 1.6592638492584229s
epoch 20: {'train_loss': '2.80065'}; time used = 2.396484851837158s
epoch 25: {'train_loss': '2.78697'}; time used = 1.103564739227295s
epoch 30: {'train_loss': '2.78021'}; time used = 1.0752270221710205s
epoch 35: {'train_loss': '2.77682'}; time used = 1.1784923076629639s
epoch 40: {'train_loss': '2.77531'}; time used = 1.0449256896972656s
epoch 45: {'train_loss': '2.77483'}; time used = 2.142054796218872s
epoch 50: {'train_loss': '2.77420'}; time used = 1.0154061317443848s
epoch 55: {'train_loss': '2.77363'}; time used = 0.9852676391601562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.928820610046387.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.19739'}; time used = 1.203026533126831s
epoch 10: {'train_loss': '2.90032'}; time used = 1.090282678604126s
epoch 15: {'train_loss': '2.79471'}; time used = 1.2222561836242676s
epoch 20: {'train_loss': '2.77461'}; time used = 1.3050410747528076s
epoch 25: {'train_loss': '2.78370'}; time used = 1.191957950592041s
epoch 30: {'train_loss': '2.77768'}; time used = 1.3039393424987793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.56975269317627.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7840909090909092, 'samples': 0.7894736842105263, 'weighted': 0.7894736842105263, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.81658'}; time used = 5.171908140182495s
epoch 10: {'train_loss': '2.78092'}; time used = 5.148534774780273s
epoch 15: {'train_loss': '2.76087'}; time used = 4.231161594390869s
epoch 20: {'train_loss': '2.75167'}; time used = 3.1012909412384033s
epoch 25: {'train_loss': '2.74306'}; time used = 2.3778488636016846s
epoch 30: {'train_loss': '2.72554'}; time used = 2.0245490074157715s
epoch 35: {'train_loss': '2.71643'}; time used = 1.790088176727295s
epoch 40: {'train_loss': '2.70871'}; time used = 1.7898781299591064s
epoch 45: {'train_loss': '2.70224'}; time used = 1.8159081935882568s
epoch 50: {'train_loss': '2.69439'}; time used = 2.052518367767334s
epoch 55: {'train_loss': '2.69380'}; time used = 1.7547416687011719s
epoch 60: {'train_loss': '2.67553'}; time used = 1.81378173828125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.31384754180908.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.44084'}; time used = 1.187152624130249s
epoch 10: {'train_loss': '0.26903'}; time used = 1.0784852504730225s
epoch 15: {'train_loss': '0.28154'}; time used = 1.1936421394348145s
epoch 20: {'train_loss': '0.25562'}; time used = 1.140836477279663s
epoch 25: {'train_loss': '0.29112'}; time used = 0.9781975746154785s
epoch 30: {'train_loss': '0.24123'}; time used = 1.0939249992370605s
epoch 35: {'train_loss': '0.27526'}; time used = 1.0287821292877197s
epoch 40: {'train_loss': '0.21563'}; time used = 0.9941275119781494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.85095500946045.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91540'}; time used = 1.9124200344085693s
epoch 10: {'train_loss': '2.76849'}; time used = 1.831624984741211s
epoch 15: {'train_loss': '2.75950'}; time used = 1.7940824031829834s
epoch 20: {'train_loss': '2.74922'}; time used = 1.9256038665771484s
epoch 25: {'train_loss': '2.73317'}; time used = 1.9881927967071533s
epoch 30: {'train_loss': '2.71020'}; time used = 1.7898986339569092s
epoch 35: {'train_loss': '2.68103'}; time used = 1.8599591255187988s
epoch 40: {'train_loss': '2.63798'}; time used = 1.9214496612548828s
epoch 45: {'train_loss': '2.57399'}; time used = 1.875723123550415s
epoch 50: {'train_loss': '2.49128'}; time used = 1.740412712097168s
epoch 55: {'train_loss': '2.47790'}; time used = 1.8183073997497559s
epoch 60: {'train_loss': '2.45271'}; time used = 1.7571992874145508s
epoch 65: {'train_loss': '2.42852'}; time used = 1.7565593719482422s
epoch 70: {'train_loss': '2.39361'}; time used = 1.8318417072296143s
epoch 75: {'train_loss': '2.38480'}; time used = 1.8154687881469727s
epoch 80: {'train_loss': '2.35745'}; time used = 1.902637004852295s
epoch 85: {'train_loss': '2.35527'}; time used = 2.0949547290802s
epoch 90: {'train_loss': '2.37600'}; time used = 1.839829921722412s
epoch 95: {'train_loss': '2.36564'}; time used = 2.0129666328430176s
epoch 100: {'train_loss': '2.34596'}; time used = 3.402698040008545s
epoch 105: {'train_loss': '2.33653'}; time used = 2.355684518814087s
epoch 110: {'train_loss': '2.33554'}; time used = 1.8217718601226807s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.272342920303345.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.37422'}; time used = 4.228894472122192s
epoch 10: {'train_loss': '1.34491'}; time used = 1.9168589115142822s
epoch 15: {'train_loss': '1.37537'}; time used = 1.9050076007843018s
epoch 20: {'train_loss': '1.44505'}; time used = 1.8737666606903076s
epoch 25: {'train_loss': '1.40862'}; time used = 2.046438455581665s
epoch 30: {'train_loss': '1.35677'}; time used = 1.8384926319122314s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.358383178710938.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.47860'}; time used = 1.4158036708831787s
epoch 10: {'train_loss': '0.18238'}; time used = 1.2584307193756104s
epoch 15: {'train_loss': '0.13222'}; time used = 1.2774090766906738s
epoch 20: {'train_loss': '0.22015'}; time used = 1.2819883823394775s
epoch 25: {'train_loss': '0.15167'}; time used = 1.269880771636963s
epoch 30: {'train_loss': '0.13900'}; time used = 1.2850444316864014s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.906018018722534.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.10102'}; time used = 1.295483112335205s
epoch 10: {'train_loss': '0.82679'}; time used = 1.3526132106781006s
epoch 15: {'train_loss': '0.92952'}; time used = 1.05275559425354s
epoch 20: {'train_loss': '0.61140'}; time used = 1.0361366271972656s
epoch 25: {'train_loss': '0.57359'}; time used = 1.0146749019622803s
epoch 30: {'train_loss': '0.39605'}; time used = 1.0262293815612793s
epoch 35: {'train_loss': '0.24997'}; time used = 1.024559497833252s
epoch 40: {'train_loss': '0.12268'}; time used = 1.0738117694854736s
epoch 45: {'train_loss': '0.08469'}; time used = 1.206592082977295s
epoch 50: {'train_loss': '0.06182'}; time used = 1.2119450569152832s
epoch 55: {'train_loss': '0.04715'}; time used = 1.1885440349578857s
epoch 60: {'train_loss': '0.02086'}; time used = 1.3377902507781982s
epoch 65: {'train_loss': '0.03133'}; time used = 1.2045531272888184s
epoch 70: {'train_loss': '0.02705'}; time used = 1.2140820026397705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.908891916275024.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82570'}; time used = 2.6033551692962646s
epoch 10: {'train_loss': '2.78273'}; time used = 2.521246910095215s
epoch 15: {'train_loss': '2.77329'}; time used = 2.6851484775543213s
epoch 20: {'train_loss': '2.77776'}; time used = 2.804028272628784s
epoch 25: {'train_loss': '2.77458'}; time used = 2.684364080429077s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.388128995895386.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.38186'}; time used = 1.212174415588379s
epoch 10: {'train_loss': '1.38366'}; time used = 1.0503630638122559s
epoch 15: {'train_loss': '1.32687'}; time used = 1.0505118370056152s
epoch 20: {'train_loss': '1.32667'}; time used = 1.1828796863555908s
epoch 25: {'train_loss': '1.30081'}; time used = 1.073446273803711s
epoch 30: {'train_loss': '1.27598'}; time used = 1.0474534034729004s
epoch 35: {'train_loss': '1.28205'}; time used = 1.0542259216308594s
epoch 40: {'train_loss': '1.19843'}; time used = 1.0602138042449951s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.71647024154663.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.15375'}; time used = 1.18544602394104s
epoch 10: {'train_loss': '0.89878'}; time used = 0.9591591358184814s
epoch 15: {'train_loss': '0.75239'}; time used = 0.951775312423706s
epoch 20: {'train_loss': '0.61850'}; time used = 1.0836491584777832s
epoch 25: {'train_loss': '0.58617'}; time used = 0.9276385307312012s
epoch 30: {'train_loss': '0.43099'}; time used = 0.9348955154418945s
epoch 35: {'train_loss': '0.41200'}; time used = 1.0527513027191162s
epoch 40: {'train_loss': '0.36621'}; time used = 1.7630877494812012s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.715299606323242.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35993'}; time used = 3.001068353652954s
epoch 10: {'train_loss': '1.27301'}; time used = 2.8562138080596924s
epoch 15: {'train_loss': '1.29081'}; time used = 2.720071792602539s
epoch 20: {'train_loss': '1.33182'}; time used = 2.5676965713500977s
epoch 25: {'train_loss': '1.32013'}; time used = 2.620713949203491s
epoch 30: {'train_loss': '1.26861'}; time used = 2.455237627029419s
epoch 35: {'train_loss': '1.25042'}; time used = 2.475843667984009s
epoch 40: {'train_loss': '1.20564'}; time used = 2.4389591217041016s
epoch 45: {'train_loss': '1.26452'}; time used = 2.4235999584198s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.332824230194092.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5251942286348501, 'samples': 0.5507246376811594, 'weighted': 0.5331724814618218, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.88145'}; time used = 1.715116262435913s
epoch 10: {'train_loss': '2.79060'}; time used = 1.5953683853149414s
epoch 15: {'train_loss': '2.75718'}; time used = 1.600935459136963s
epoch 20: {'train_loss': '2.73178'}; time used = 1.6193122863769531s
epoch 25: {'train_loss': '2.70894'}; time used = 1.679887056350708s
epoch 30: {'train_loss': '2.68625'}; time used = 1.5944702625274658s
epoch 35: {'train_loss': '2.66978'}; time used = 1.7454395294189453s
epoch 40: {'train_loss': '2.64867'}; time used = 1.869271993637085s
epoch 45: {'train_loss': '2.62093'}; time used = 1.9189515113830566s
epoch 50: {'train_loss': '2.59382'}; time used = 1.6054885387420654s
epoch 55: {'train_loss': '2.59562'}; time used = 1.699695348739624s
epoch 60: {'train_loss': '2.58381'}; time used = 1.585693597793579s
epoch 65: {'train_loss': '2.56359'}; time used = 1.576486587524414s
epoch 70: {'train_loss': '2.53346'}; time used = 1.7729275226593018s
epoch 75: {'train_loss': '2.52353'}; time used = 1.6965668201446533s
epoch 80: {'train_loss': '2.50434'}; time used = 1.6575143337249756s
epoch 85: {'train_loss': '2.50399'}; time used = 1.6709318161010742s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.192766427993774.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89816'}; time used = 1.0589728355407715s
epoch 10: {'train_loss': '2.79906'}; time used = 1.0767419338226318s
epoch 15: {'train_loss': '2.78481'}; time used = 1.4591643810272217s
epoch 20: {'train_loss': '2.77927'}; time used = 1.241844892501831s
epoch 25: {'train_loss': '2.77498'}; time used = 1.3485107421875s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.449236869812012.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90107'}; time used = 1.5395159721374512s
epoch 10: {'train_loss': '2.79540'}; time used = 1.4655735492706299s
epoch 15: {'train_loss': '2.77236'}; time used = 1.379307508468628s
epoch 20: {'train_loss': '2.77833'}; time used = 1.4627363681793213s
epoch 25: {'train_loss': '2.77701'}; time used = 1.3863403797149658s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.4541335105896.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36879'}; time used = 3.7007930278778076s
epoch 10: {'train_loss': '1.31844'}; time used = 1.870464563369751s
epoch 15: {'train_loss': '1.28446'}; time used = 2.007805347442627s
epoch 20: {'train_loss': '1.28024'}; time used = 2.000110149383545s
epoch 25: {'train_loss': '1.12698'}; time used = 1.845548152923584s
epoch 30: {'train_loss': '0.90786'}; time used = 1.8222925662994385s
epoch 35: {'train_loss': '1.02106'}; time used = 1.8280916213989258s
epoch 40: {'train_loss': '0.83597'}; time used = 1.8333330154418945s
epoch 45: {'train_loss': '0.71130'}; time used = 1.9279677867889404s
epoch 50: {'train_loss': '0.70483'}; time used = 1.9286856651306152s
epoch 55: {'train_loss': '0.48304'}; time used = 1.75010085105896s
epoch 60: {'train_loss': '0.55060'}; time used = 2.794246196746826s
epoch 65: {'train_loss': '0.60769'}; time used = 1.790266752243042s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.05590486526489.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5527777777777778, 'samples': 0.5942028985507246, 'weighted': 0.5626409017713365, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.21824'}; time used = 1.6726164817810059s
epoch 10: {'train_loss': '0.83156'}; time used = 1.671823263168335s
epoch 15: {'train_loss': '0.18268'}; time used = 1.5928013324737549s
epoch 20: {'train_loss': '0.11607'}; time used = 1.806605577468872s
epoch 25: {'train_loss': '0.00037'}; time used = 2.109522819519043s
epoch 30: {'train_loss': '0.00042'}; time used = 1.9894068241119385s
epoch 35: {'train_loss': '0.00000'}; time used = 1.6813790798187256s
epoch 40: {'train_loss': '0.00004'}; time used = 1.5934221744537354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.499800205230713.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6373764977927264, 'samples': 0.6376811594202898, 'weighted': 0.6381381518616348, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.65811'}; time used = 1.1093883514404297s
epoch 10: {'train_loss': '2.58695'}; time used = 1.0029494762420654s
epoch 15: {'train_loss': '2.25646'}; time used = 1.056880235671997s
epoch 20: {'train_loss': '2.13339'}; time used = 1.0536730289459229s
epoch 25: {'train_loss': '2.07305'}; time used = 1.0466585159301758s
epoch 30: {'train_loss': '1.99645'}; time used = 1.074155330657959s
epoch 35: {'train_loss': '1.92759'}; time used = 1.0790526866912842s
epoch 40: {'train_loss': '1.89970'}; time used = 1.0833089351654053s
epoch 45: {'train_loss': '1.88881'}; time used = 1.1436197757720947s
epoch 50: {'train_loss': '1.87751'}; time used = 1.0178511142730713s
epoch 55: {'train_loss': '1.87424'}; time used = 0.9200661182403564s
epoch 60: {'train_loss': '1.96930'}; time used = 0.9626014232635498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.388016939163208.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.17664'}; time used = 1.7275006771087646s
epoch 10: {'train_loss': '1.10928'}; time used = 1.7002696990966797s
epoch 15: {'train_loss': '0.90439'}; time used = 1.7029619216918945s
epoch 20: {'train_loss': '0.80030'}; time used = 1.726086139678955s
epoch 25: {'train_loss': '0.53702'}; time used = 1.7968313694000244s
epoch 30: {'train_loss': '0.38720'}; time used = 1.9085664749145508s
epoch 35: {'train_loss': '0.29466'}; time used = 1.7266743183135986s
epoch 40: {'train_loss': '0.23322'}; time used = 1.7798824310302734s
epoch 45: {'train_loss': '0.13456'}; time used = 1.7801456451416016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.149216413497925.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.26939'}; time used = 1.0679612159729004s
epoch 10: {'train_loss': '1.39359'}; time used = 1.0235209465026855s
epoch 15: {'train_loss': '1.38421'}; time used = 0.9657509326934814s
epoch 20: {'train_loss': '1.38083'}; time used = 0.968590497970581s
epoch 25: {'train_loss': '1.35247'}; time used = 0.9590041637420654s
epoch 30: {'train_loss': '1.38256'}; time used = 1.05245041847229s
epoch 35: {'train_loss': '1.40194'}; time used = 0.9514391422271729s
epoch 40: {'train_loss': '1.37569'}; time used = 0.9666132926940918s
epoch 45: {'train_loss': '1.32547'}; time used = 1.7383191585540771s
epoch 50: {'train_loss': '1.40105'}; time used = 2.153398036956787s
epoch 55: {'train_loss': '1.37275'}; time used = 2.5811028480529785s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.46349024772644.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.92185'}; time used = 1.1580309867858887s
epoch 10: {'train_loss': '2.77940'}; time used = 1.0195233821868896s
epoch 15: {'train_loss': '2.66989'}; time used = 1.00925874710083s
epoch 20: {'train_loss': '2.56077'}; time used = 0.8895766735076904s
epoch 25: {'train_loss': '2.38954'}; time used = 0.9126932621002197s
epoch 30: {'train_loss': '2.14524'}; time used = 0.8976831436157227s
epoch 35: {'train_loss': '1.99034'}; time used = 0.9501476287841797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.61995005607605.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83280'}; time used = 4.7697436809539795s
epoch 10: {'train_loss': '2.80204'}; time used = 5.0262367725372314s
epoch 15: {'train_loss': '2.78791'}; time used = 5.142911911010742s
epoch 20: {'train_loss': '2.77982'}; time used = 5.197731971740723s
epoch 25: {'train_loss': '2.77455'}; time used = 5.356291770935059s
epoch 30: {'train_loss': '2.77194'}; time used = 5.224853277206421s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.826106548309326.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7048155096935584, 'samples': 0.705, 'weighted': 0.7046679174484052, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80477'}; time used = 1.7653295993804932s
epoch 10: {'train_loss': '2.89514'}; time used = 1.7419893741607666s
epoch 15: {'train_loss': '2.80707'}; time used = 1.6947574615478516s
epoch 20: {'train_loss': '2.77534'}; time used = 1.7642083168029785s
epoch 25: {'train_loss': '2.76846'}; time used = 1.844686508178711s
epoch 30: {'train_loss': '2.76808'}; time used = 1.680288314819336s
epoch 35: {'train_loss': '2.76868'}; time used = 1.7898085117340088s
epoch 40: {'train_loss': '2.76865'}; time used = 1.7961740493774414s
epoch 45: {'train_loss': '2.76169'}; time used = 1.6705882549285889s
epoch 50: {'train_loss': '2.75648'}; time used = 1.776458501815796s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.94072961807251.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5503468572629808, 'samples': 0.5507246376811594, 'weighted': 0.5512913083084272, 'accuracy': 0.5507246376811594}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.19582'}; time used = 2.253784418106079s
epoch 10: {'train_loss': '1.03213'}; time used = 1.6731369495391846s
epoch 15: {'train_loss': '0.93469'}; time used = 1.838937759399414s
epoch 20: {'train_loss': '0.77093'}; time used = 1.6324090957641602s
epoch 25: {'train_loss': '0.47799'}; time used = 1.866602897644043s
epoch 30: {'train_loss': '0.33788'}; time used = 1.6928892135620117s
epoch 35: {'train_loss': '0.18348'}; time used = 1.7173418998718262s
epoch 40: {'train_loss': '0.14824'}; time used = 1.7312648296356201s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.79411816596985.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.69 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78215'}; time used = 8.71616005897522s
epoch 10: {'train_loss': '2.78419'}; time used = 8.25595998764038s
epoch 15: {'train_loss': '2.77521'}; time used = 6.3336615562438965s
epoch 20: {'train_loss': '2.77260'}; time used = 6.514297008514404s
epoch 25: {'train_loss': '2.77374'}; time used = 6.065903186798096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.65463137626648.
Training classifier using 80.00% nodes...
{'micro': 0.44666666666666666, 'macro': 0.44224344712096536, 'samples': 0.44666666666666666, 'weighted': 0.4400209198267394, 'accuracy': 0.44666666666666666}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 9.278475046157837s
epoch 10: {'train_loss': '1.38629'}; time used = 7.238234519958496s
epoch 15: {'train_loss': '1.38629'}; time used = 7.8869829177856445s
epoch 20: {'train_loss': '1.38629'}; time used = 6.700286865234375s
epoch 25: {'train_loss': '1.38629'}; time used = 7.278418302536011s
epoch 30: {'train_loss': '1.38629'}; time used = 6.480421781539917s
epoch 35: {'train_loss': '1.38629'}; time used = 6.357027769088745s
epoch 40: {'train_loss': '1.38629'}; time used = 6.392234802246094s
epoch 45: {'train_loss': '1.38629'}; time used = 6.422844409942627s
epoch 50: {'train_loss': '1.38629'}; time used = 7.707534551620483s
epoch 55: {'train_loss': '1.38629'}; time used = 6.330953359603882s
epoch 60: {'train_loss': '1.38629'}; time used = 6.655164480209351s
epoch 65: {'train_loss': '1.38629'}; time used = 6.764177083969116s
epoch 70: {'train_loss': '1.38629'}; time used = 6.870707273483276s
epoch 75: {'train_loss': '1.38629'}; time used = 7.634730577468872s
epoch 80: {'train_loss': '1.38629'}; time used = 9.231092929840088s
epoch 85: {'train_loss': '1.38629'}; time used = 8.506899356842041s
epoch 90: {'train_loss': '1.38629'}; time used = 10.958228826522827s
epoch 95: {'train_loss': '1.38629'}; time used = 6.897777795791626s
epoch 100: {'train_loss': '1.38629'}; time used = 7.212238311767578s
epoch 105: {'train_loss': '1.38629'}; time used = 6.616745233535767s
epoch 110: {'train_loss': '1.38629'}; time used = 7.045702219009399s
epoch 115: {'train_loss': '1.38629'}; time used = 6.434053182601929s
epoch 120: {'train_loss': '1.38629'}; time used = 7.722099304199219s
epoch 125: {'train_loss': '1.38629'}; time used = 7.384723663330078s
epoch 130: {'train_loss': '1.38629'}; time used = 6.913455247879028s
epoch 135: {'train_loss': '1.38629'}; time used = 6.555834054946899s
epoch 140: {'train_loss': '1.38629'}; time used = 6.4117279052734375s
epoch 145: {'train_loss': '1.38629'}; time used = 6.265242576599121s
epoch 150: {'train_loss': '1.38629'}; time used = 7.228904962539673s
epoch 155: {'train_loss': '1.38629'}; time used = 6.6526384353637695s
epoch 160: {'train_loss': '1.38629'}; time used = 6.4296674728393555s
epoch 165: {'train_loss': '1.38629'}; time used = 6.512107849121094s
epoch 170: {'train_loss': '1.38629'}; time used = 6.337273120880127s
epoch 175: {'train_loss': '1.38629'}; time used = 6.6062703132629395s
epoch 180: {'train_loss': '1.38629'}; time used = 6.3647425174713135s
epoch 185: {'train_loss': '1.38629'}; time used = 6.4797563552856445s
epoch 190: {'train_loss': '1.38629'}; time used = 6.300524950027466s
epoch 195: {'train_loss': '1.38629'}; time used = 6.809892892837524s
epoch 200: {'train_loss': '1.38629'}; time used = 6.999649524688721s
epoch 205: {'train_loss': '1.38629'}; time used = 6.883552551269531s
epoch 210: {'train_loss': '1.38629'}; time used = 6.45064115524292s
epoch 215: {'train_loss': '1.38629'}; time used = 6.863505125045776s
epoch 220: {'train_loss': '1.38629'}; time used = 6.394114017486572s
epoch 225: {'train_loss': '1.38629'}; time used = 6.569040775299072s
epoch 230: {'train_loss': '1.38629'}; time used = 6.644446849822998s
epoch 235: {'train_loss': '1.38629'}; time used = 6.3043882846832275s
epoch 240: {'train_loss': '1.38629'}; time used = 6.3254053592681885s
epoch 245: {'train_loss': '1.38629'}; time used = 6.331458806991577s
epoch 250: {'train_loss': '1.38629'}; time used = 6.487257957458496s
epoch 255: {'train_loss': '1.38629'}; time used = 6.613252878189087s
epoch 260: {'train_loss': '1.38629'}; time used = 6.899487257003784s
epoch 265: {'train_loss': '1.38629'}; time used = 6.305021524429321s
epoch 270: {'train_loss': '1.38629'}; time used = 6.9089484214782715s
epoch 275: {'train_loss': '1.38629'}; time used = 6.775101661682129s
epoch 280: {'train_loss': '1.38629'}; time used = 6.3355889320373535s
epoch 285: {'train_loss': '1.38629'}; time used = 6.4926440715789795s
epoch 290: {'train_loss': '1.38629'}; time used = 6.246851921081543s
epoch 295: {'train_loss': '1.38629'}; time used = 6.808759450912476s
epoch 300: {'train_loss': '1.38629'}; time used = 6.787359237670898s
epoch 305: {'train_loss': '1.38629'}; time used = 6.8082664012908936s
epoch 310: {'train_loss': '1.38629'}; time used = 6.329235553741455s
epoch 315: {'train_loss': '1.38629'}; time used = 6.339410781860352s
epoch 320: {'train_loss': '1.38629'}; time used = 6.286175012588501s
epoch 325: {'train_loss': '1.38629'}; time used = 6.88793683052063s
epoch 330: {'train_loss': '1.38629'}; time used = 6.60681939125061s
epoch 335: {'train_loss': '1.38629'}; time used = 6.485495567321777s
epoch 340: {'train_loss': '1.38629'}; time used = 6.468260049819946s
epoch 345: {'train_loss': '1.38629'}; time used = 6.783221244812012s
epoch 350: {'train_loss': '1.38629'}; time used = 6.650117635726929s
epoch 355: {'train_loss': '1.38629'}; time used = 6.213351249694824s
epoch 360: {'train_loss': '1.38629'}; time used = 6.415221691131592s
epoch 365: {'train_loss': '1.38629'}; time used = 6.591440439224243s
epoch 370: {'train_loss': '1.38629'}; time used = 7.672593116760254s
epoch 375: {'train_loss': '1.38629'}; time used = 7.049335479736328s
epoch 380: {'train_loss': '1.38629'}; time used = 6.504940748214722s
epoch 385: {'train_loss': '1.38629'}; time used = 6.438334226608276s
epoch 390: {'train_loss': '1.38629'}; time used = 6.652785062789917s
epoch 395: {'train_loss': '1.38629'}; time used = 6.315789699554443s
epoch 400: {'train_loss': '1.38629'}; time used = 6.384643077850342s
epoch 405: {'train_loss': '1.38629'}; time used = 6.695799827575684s
epoch 410: {'train_loss': '1.38629'}; time used = 6.868446111679077s
epoch 415: {'train_loss': '1.38629'}; time used = 6.385624170303345s
epoch 420: {'train_loss': '1.38629'}; time used = 6.636097192764282s
epoch 425: {'train_loss': '1.38629'}; time used = 6.385601043701172s
epoch 430: {'train_loss': '1.38629'}; time used = 6.325969934463501s
epoch 435: {'train_loss': '1.38629'}; time used = 6.785985231399536s
epoch 440: {'train_loss': '1.38629'}; time used = 6.330363750457764s
epoch 445: {'train_loss': '1.38629'}; time used = 6.389507055282593s
epoch 450: {'train_loss': '1.38629'}; time used = 6.622503995895386s
epoch 455: {'train_loss': '1.38629'}; time used = 6.576689004898071s
epoch 460: {'train_loss': '1.38629'}; time used = 6.309058904647827s
epoch 465: {'train_loss': '1.38629'}; time used = 6.464728832244873s
epoch 470: {'train_loss': '1.38629'}; time used = 6.701897144317627s
epoch 475: {'train_loss': '1.38629'}; time used = 6.738229751586914s
epoch 480: {'train_loss': '1.38629'}; time used = 6.689481258392334s
epoch 485: {'train_loss': '1.38629'}; time used = 6.526404142379761s
epoch 490: {'train_loss': '1.38629'}; time used = 6.408794164657593s
epoch 495: {'train_loss': '1.38629'}; time used = 6.480876445770264s
epoch 500: {'train_loss': '1.38629'}; time used = 7.016624212265015s
Finished training. Time used = 685.2726452350616.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77240'}; time used = 1.880265235900879s
epoch 10: {'train_loss': '2.77057'}; time used = 1.8519623279571533s
epoch 15: {'train_loss': '2.77089'}; time used = 1.8530678749084473s
epoch 20: {'train_loss': '2.76823'}; time used = 1.9194166660308838s
epoch 25: {'train_loss': '2.76317'}; time used = 2.4502129554748535s
epoch 30: {'train_loss': '2.75861'}; time used = 2.2440009117126465s
epoch 35: {'train_loss': '2.75562'}; time used = 2.2986531257629395s
epoch 40: {'train_loss': '2.75505'}; time used = 2.1862025260925293s
epoch 45: {'train_loss': '2.75138'}; time used = 1.8306970596313477s
epoch 50: {'train_loss': '2.75082'}; time used = 2.033154010772705s
epoch 55: {'train_loss': '2.75291'}; time used = 1.8537626266479492s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.06641387939453.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36086'}; time used = 1.8167269229888916s
epoch 10: {'train_loss': '1.29498'}; time used = 1.7674691677093506s
epoch 15: {'train_loss': '1.29638'}; time used = 1.7742204666137695s
epoch 20: {'train_loss': '1.34745'}; time used = 1.7781708240509033s
epoch 25: {'train_loss': '1.30072'}; time used = 1.7879881858825684s
epoch 30: {'train_loss': '1.23062'}; time used = 1.6888535022735596s
epoch 35: {'train_loss': '1.21524'}; time used = 1.811107873916626s
epoch 40: {'train_loss': '1.17443'}; time used = 1.7038958072662354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.87371015548706.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30235'}; time used = 2.008960485458374s
epoch 10: {'train_loss': '1.15497'}; time used = 1.95216703414917s
epoch 15: {'train_loss': '1.04091'}; time used = 1.9256281852722168s
epoch 20: {'train_loss': '0.98998'}; time used = 1.9490559101104736s
epoch 25: {'train_loss': '0.92926'}; time used = 2.206322193145752s
epoch 30: {'train_loss': '0.87488'}; time used = 2.059440851211548s
epoch 35: {'train_loss': '0.85486'}; time used = 2.0056819915771484s
epoch 40: {'train_loss': '0.80617'}; time used = 2.0431649684906006s
epoch 45: {'train_loss': '0.79542'}; time used = 1.937767744064331s
epoch 50: {'train_loss': '0.70399'}; time used = 1.9266107082366943s
epoch 55: {'train_loss': '0.64107'}; time used = 2.0485966205596924s
epoch 60: {'train_loss': '0.56208'}; time used = 1.9814157485961914s
epoch 65: {'train_loss': '0.55983'}; time used = 2.0032429695129395s
epoch 70: {'train_loss': '0.43613'}; time used = 1.649115800857544s
epoch 75: {'train_loss': '0.08388'}; time used = 1.667935848236084s
epoch 80: {'train_loss': '0.03080'}; time used = 1.717846393585205s
epoch 85: {'train_loss': '0.01353'}; time used = 1.5458989143371582s
epoch 90: {'train_loss': '0.02204'}; time used = 1.6449332237243652s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.518107175827026.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.449072599411011s
epoch 10: {'train_loss': '1.38629'}; time used = 4.317686557769775s
epoch 15: {'train_loss': '1.38629'}; time used = 5.604651689529419s
epoch 20: {'train_loss': '1.38629'}; time used = 4.392344951629639s
epoch 25: {'train_loss': '1.38629'}; time used = 4.724720239639282s
epoch 30: {'train_loss': '1.38629'}; time used = 4.535787343978882s
epoch 35: {'train_loss': '1.38629'}; time used = 4.428296804428101s
epoch 40: {'train_loss': '1.38629'}; time used = 5.4191224575042725s
epoch 45: {'train_loss': '1.38629'}; time used = 5.317731618881226s
epoch 50: {'train_loss': '1.38629'}; time used = 4.485577583312988s
epoch 55: {'train_loss': '1.38629'}; time used = 4.34274697303772s
epoch 60: {'train_loss': '1.38629'}; time used = 4.551342248916626s
epoch 65: {'train_loss': '1.38629'}; time used = 7.313764810562134s
epoch 70: {'train_loss': '1.38629'}; time used = 10.017713785171509s
epoch 75: {'train_loss': '1.38629'}; time used = 7.476101636886597s
epoch 80: {'train_loss': '1.38629'}; time used = 4.868153095245361s
epoch 85: {'train_loss': '1.38629'}; time used = 4.690387725830078s
epoch 90: {'train_loss': '1.38629'}; time used = 4.69744610786438s
epoch 95: {'train_loss': '1.38629'}; time used = 5.599316358566284s
epoch 100: {'train_loss': '1.38629'}; time used = 4.377420663833618s
epoch 105: {'train_loss': '1.38629'}; time used = 4.590278387069702s
epoch 110: {'train_loss': '1.38629'}; time used = 4.637418270111084s
epoch 115: {'train_loss': '1.38629'}; time used = 4.583387851715088s
epoch 120: {'train_loss': '1.38629'}; time used = 6.621919393539429s
epoch 125: {'train_loss': '1.38629'}; time used = 8.771419048309326s
epoch 130: {'train_loss': '1.38629'}; time used = 7.363584041595459s
epoch 135: {'train_loss': '1.38629'}; time used = 4.908564805984497s
epoch 140: {'train_loss': '1.38629'}; time used = 4.466286659240723s
epoch 145: {'train_loss': '1.38629'}; time used = 4.439607620239258s
epoch 150: {'train_loss': '1.38629'}; time used = 4.762339353561401s
epoch 155: {'train_loss': '1.38629'}; time used = 5.023482084274292s
epoch 160: {'train_loss': '1.38629'}; time used = 4.81766152381897s
epoch 165: {'train_loss': '1.38629'}; time used = 5.2888689041137695s
epoch 170: {'train_loss': '1.38629'}; time used = 4.215118646621704s
epoch 175: {'train_loss': '1.38629'}; time used = 4.512705326080322s
epoch 180: {'train_loss': '1.38629'}; time used = 4.284603834152222s
epoch 185: {'train_loss': '1.38629'}; time used = 4.644171714782715s
epoch 190: {'train_loss': '1.38629'}; time used = 5.075006484985352s
epoch 195: {'train_loss': '1.38629'}; time used = 4.452306509017944s
epoch 200: {'train_loss': '1.38629'}; time used = 4.744095802307129s
epoch 205: {'train_loss': '1.38629'}; time used = 4.739731311798096s
epoch 210: {'train_loss': '1.38629'}; time used = 5.115776777267456s
epoch 215: {'train_loss': '1.38629'}; time used = 5.211272954940796s
epoch 220: {'train_loss': '1.38629'}; time used = 4.355003833770752s
epoch 225: {'train_loss': '1.38629'}; time used = 4.472225189208984s
epoch 230: {'train_loss': '1.38629'}; time used = 4.364637613296509s
epoch 235: {'train_loss': '1.38629'}; time used = 4.321043252944946s
epoch 240: {'train_loss': '1.38629'}; time used = 4.129539728164673s
epoch 245: {'train_loss': '1.38629'}; time used = 4.212390184402466s
epoch 250: {'train_loss': '1.38629'}; time used = 4.076464414596558s
epoch 255: {'train_loss': '1.38629'}; time used = 4.120742082595825s
epoch 260: {'train_loss': '1.38629'}; time used = 4.146331787109375s
epoch 265: {'train_loss': '1.38629'}; time used = 4.163135528564453s
epoch 270: {'train_loss': '1.38629'}; time used = 4.203168869018555s
epoch 275: {'train_loss': '1.38629'}; time used = 4.302783966064453s
epoch 280: {'train_loss': '1.38629'}; time used = 4.293163537979126s
epoch 285: {'train_loss': '1.38629'}; time used = 4.296654462814331s
epoch 290: {'train_loss': '1.38629'}; time used = 4.879964351654053s
epoch 295: {'train_loss': '1.38629'}; time used = 5.353701114654541s
epoch 300: {'train_loss': '1.38629'}; time used = 5.103957176208496s
epoch 305: {'train_loss': '1.38629'}; time used = 4.42165994644165s
epoch 310: {'train_loss': '1.38629'}; time used = 4.3447699546813965s
epoch 315: {'train_loss': '1.38629'}; time used = 5.937504529953003s
epoch 320: {'train_loss': '1.38629'}; time used = 7.065854787826538s
epoch 325: {'train_loss': '1.38629'}; time used = 5.692664384841919s
epoch 330: {'train_loss': '1.38629'}; time used = 7.270151853561401s
epoch 335: {'train_loss': '1.38629'}; time used = 4.798267602920532s
epoch 340: {'train_loss': '1.38629'}; time used = 4.352214574813843s
epoch 345: {'train_loss': '1.38629'}; time used = 5.565139293670654s
epoch 350: {'train_loss': '1.38629'}; time used = 9.216444730758667s
epoch 355: {'train_loss': '1.38629'}; time used = 9.29939603805542s
epoch 360: {'train_loss': '1.38629'}; time used = 7.312632322311401s
epoch 365: {'train_loss': '1.38629'}; time used = 4.480424165725708s
epoch 370: {'train_loss': '1.38629'}; time used = 4.865832805633545s
epoch 375: {'train_loss': '1.38629'}; time used = 4.258911609649658s
epoch 380: {'train_loss': '1.38629'}; time used = 4.258725166320801s
epoch 385: {'train_loss': '1.38629'}; time used = 4.266247749328613s
epoch 390: {'train_loss': '1.38629'}; time used = 4.358703851699829s
epoch 395: {'train_loss': '1.38629'}; time used = 4.365138053894043s
epoch 400: {'train_loss': '1.38629'}; time used = 4.460355997085571s
epoch 405: {'train_loss': '1.38629'}; time used = 4.252297639846802s
epoch 410: {'train_loss': '1.38629'}; time used = 4.2669291496276855s
epoch 415: {'train_loss': '1.38629'}; time used = 4.365999937057495s
epoch 420: {'train_loss': '1.38629'}; time used = 5.262024641036987s
epoch 425: {'train_loss': '1.38629'}; time used = 6.509268045425415s
epoch 430: {'train_loss': '1.38629'}; time used = 6.086867094039917s
epoch 435: {'train_loss': '1.38629'}; time used = 4.4144606590271s
epoch 440: {'train_loss': '1.38629'}; time used = 4.401715517044067s
epoch 445: {'train_loss': '1.38629'}; time used = 4.441748142242432s
epoch 450: {'train_loss': '1.38629'}; time used = 4.406342029571533s
epoch 455: {'train_loss': '1.38629'}; time used = 4.260183095932007s
epoch 460: {'train_loss': '1.38629'}; time used = 4.216314077377319s
epoch 465: {'train_loss': '1.38629'}; time used = 4.261494874954224s
epoch 470: {'train_loss': '1.38629'}; time used = 4.371378660202026s
epoch 475: {'train_loss': '1.38629'}; time used = 4.421501159667969s
epoch 480: {'train_loss': '1.38629'}; time used = 4.6139726638793945s
epoch 485: {'train_loss': '1.38629'}; time used = 4.305661201477051s
epoch 490: {'train_loss': '1.38629'}; time used = 4.126746416091919s
epoch 495: {'train_loss': '1.38629'}; time used = 4.1535890102386475s
epoch 500: {'train_loss': '1.38629'}; time used = 4.1459057331085205s
Finished training. Time used = 507.3119170665741.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79337'}; time used = 1.9182782173156738s
epoch 10: {'train_loss': '2.73387'}; time used = 2.3045663833618164s
epoch 15: {'train_loss': '2.70456'}; time used = 2.61572527885437s
epoch 20: {'train_loss': '2.69159'}; time used = 1.727066993713379s
epoch 25: {'train_loss': '2.66297'}; time used = 1.8449091911315918s
epoch 30: {'train_loss': '2.64691'}; time used = 1.6423146724700928s
epoch 35: {'train_loss': '2.64093'}; time used = 1.766641616821289s
epoch 40: {'train_loss': '2.64094'}; time used = 1.7164742946624756s
epoch 45: {'train_loss': '2.63649'}; time used = 2.67277193069458s
epoch 50: {'train_loss': '2.62501'}; time used = 3.044543981552124s
epoch 55: {'train_loss': '2.62540'}; time used = 3.0737781524658203s
epoch 60: {'train_loss': '2.63288'}; time used = 2.8521571159362793s
epoch 65: {'train_loss': '2.62569'}; time used = 1.7266616821289062s
epoch 70: {'train_loss': '2.61508'}; time used = 1.845179557800293s
epoch 75: {'train_loss': '2.60728'}; time used = 1.829218864440918s
epoch 80: {'train_loss': '2.60556'}; time used = 1.949150562286377s
epoch 85: {'train_loss': '2.60207'}; time used = 1.7272155284881592s
epoch 90: {'train_loss': '2.60719'}; time used = 1.7030813694000244s
epoch 95: {'train_loss': '2.60039'}; time used = 1.6339390277862549s
epoch 100: {'train_loss': '2.58023'}; time used = 1.831017017364502s
epoch 105: {'train_loss': '2.57818'}; time used = 1.7838478088378906s
epoch 110: {'train_loss': '2.56835'}; time used = 1.7084341049194336s
epoch 115: {'train_loss': '2.56859'}; time used = 1.8224735260009766s
epoch 120: {'train_loss': '2.56901'}; time used = 1.656381368637085s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.96399736404419.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37198'}; time used = 1.6468026638031006s
epoch 10: {'train_loss': '1.56281'}; time used = 1.3962538242340088s
epoch 15: {'train_loss': '1.41738'}; time used = 1.371640920639038s
epoch 20: {'train_loss': '1.30375'}; time used = 1.370039939880371s
epoch 25: {'train_loss': '1.39160'}; time used = 1.3552565574645996s
epoch 30: {'train_loss': '1.34575'}; time used = 1.3591809272766113s
epoch 35: {'train_loss': '1.38029'}; time used = 1.3676152229309082s
epoch 40: {'train_loss': '1.35413'}; time used = 1.3789191246032715s
epoch 45: {'train_loss': '1.39376'}; time used = 1.3803555965423584s
epoch 50: {'train_loss': '1.44929'}; time used = 1.3632409572601318s
epoch 55: {'train_loss': '1.35557'}; time used = 1.3642175197601318s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.687846422195435.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.98022'}; time used = 1.2604880332946777s
epoch 10: {'train_loss': '2.74124'}; time used = 1.063647985458374s
epoch 15: {'train_loss': '2.65612'}; time used = 1.1437034606933594s
epoch 20: {'train_loss': '2.61414'}; time used = 1.0376269817352295s
epoch 25: {'train_loss': '2.55627'}; time used = 1.6401622295379639s
epoch 30: {'train_loss': '2.43234'}; time used = 1.9274718761444092s
epoch 35: {'train_loss': '2.34765'}; time used = 1.7230165004730225s
epoch 40: {'train_loss': '2.30555'}; time used = 1.8356246948242188s
epoch 45: {'train_loss': '2.24173'}; time used = 1.839287281036377s
epoch 50: {'train_loss': '2.18326'}; time used = 1.7728488445281982s
epoch 55: {'train_loss': '2.13975'}; time used = 1.3304789066314697s
epoch 60: {'train_loss': '2.09065'}; time used = 1.1730093955993652s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.074133157730103.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.35454'}; time used = 1.845801830291748s
epoch 10: {'train_loss': '2.82088'}; time used = 1.8608920574188232s
epoch 15: {'train_loss': '2.79223'}; time used = 4.1421120166778564s
epoch 20: {'train_loss': '2.79377'}; time used = 1.872718334197998s
epoch 25: {'train_loss': '2.79408'}; time used = 1.920780897140503s
epoch 30: {'train_loss': '2.78720'}; time used = 1.8092446327209473s
epoch 35: {'train_loss': '2.77577'}; time used = 1.9886457920074463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.08336639404297.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6349206349206349, 'samples': 0.6376811594202898, 'weighted': 0.6372210720036807, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.08639'}; time used = 1.5681560039520264s
epoch 10: {'train_loss': '2.77580'}; time used = 1.4136781692504883s
epoch 15: {'train_loss': '2.77350'}; time used = 1.3671939373016357s
epoch 20: {'train_loss': '2.77530'}; time used = 1.545663833618164s
epoch 25: {'train_loss': '2.77796'}; time used = 1.4039313793182373s
epoch 30: {'train_loss': '2.77991'}; time used = 1.3616406917572021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.087033987045288.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77868'}; time used = 1.1678194999694824s
epoch 10: {'train_loss': '2.77378'}; time used = 1.0371508598327637s
epoch 15: {'train_loss': '2.78424'}; time used = 1.1693141460418701s
epoch 20: {'train_loss': '2.78060'}; time used = 1.092099905014038s
epoch 25: {'train_loss': '2.77204'}; time used = 1.0949463844299316s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.346810579299927.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78117'}; time used = 1.8608450889587402s
epoch 10: {'train_loss': '2.67588'}; time used = 1.2723588943481445s
epoch 15: {'train_loss': '2.52994'}; time used = 0.9965634346008301s
epoch 20: {'train_loss': '2.35026'}; time used = 1.0126376152038574s
epoch 25: {'train_loss': '2.23407'}; time used = 1.2293853759765625s
epoch 30: {'train_loss': '2.11276'}; time used = 1.0890779495239258s
epoch 35: {'train_loss': '2.05548'}; time used = 0.9917769432067871s
epoch 40: {'train_loss': '2.01871'}; time used = 0.9985830783843994s
epoch 45: {'train_loss': '2.02024'}; time used = 1.0044317245483398s
epoch 50: {'train_loss': '1.98256'}; time used = 1.0032930374145508s
epoch 55: {'train_loss': '1.95376'}; time used = 0.9720633029937744s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.37477731704712.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33063'}; time used = 2.093385934829712s
epoch 10: {'train_loss': '1.20836'}; time used = 2.074679136276245s
epoch 15: {'train_loss': '1.16185'}; time used = 2.1361443996429443s
epoch 20: {'train_loss': '1.16358'}; time used = 2.1394896507263184s
epoch 25: {'train_loss': '1.10681'}; time used = 2.1378252506256104s
epoch 30: {'train_loss': '0.97429'}; time used = 1.9969184398651123s
epoch 35: {'train_loss': '0.94885'}; time used = 3.614889621734619s
epoch 40: {'train_loss': '0.90713'}; time used = 3.7509491443634033s
epoch 45: {'train_loss': '0.87540'}; time used = 2.0277740955352783s
epoch 50: {'train_loss': '0.75571'}; time used = 2.4538512229919434s
epoch 55: {'train_loss': '0.67242'}; time used = 2.0808544158935547s
epoch 60: {'train_loss': '0.73403'}; time used = 2.012371063232422s
epoch 65: {'train_loss': '0.75023'}; time used = 2.1014795303344727s
epoch 70: {'train_loss': '0.77395'}; time used = 2.429211139678955s
epoch 75: {'train_loss': '0.80422'}; time used = 3.7208735942840576s
epoch 80: {'train_loss': '0.65437'}; time used = 3.377714157104492s
epoch 85: {'train_loss': '0.56897'}; time used = 3.2833898067474365s
epoch 90: {'train_loss': '0.63334'}; time used = 2.1451549530029297s
epoch 95: {'train_loss': '0.38572'}; time used = 2.0721518993377686s
epoch 100: {'train_loss': '0.50028'}; time used = 2.1105093955993652s
epoch 105: {'train_loss': '0.45354'}; time used = 2.0830769538879395s
epoch 110: {'train_loss': '0.31252'}; time used = 2.0139193534851074s
epoch 115: {'train_loss': '0.21396'}; time used = 2.072216033935547s
epoch 120: {'train_loss': '0.29497'}; time used = 1.959371566772461s
epoch 125: {'train_loss': '0.22044'}; time used = 1.9622280597686768s
epoch 130: {'train_loss': '0.15918'}; time used = 2.0437119007110596s
epoch 135: {'train_loss': '0.09609'}; time used = 1.9824559688568115s
epoch 140: {'train_loss': '0.31168'}; time used = 2.1056923866271973s
epoch 145: {'train_loss': '0.15039'}; time used = 2.1180226802825928s
epoch 150: {'train_loss': '0.28467'}; time used = 2.0111911296844482s
epoch 155: {'train_loss': '0.09091'}; time used = 2.0590708255767822s
epoch 160: {'train_loss': '0.12675'}; time used = 1.9601836204528809s
epoch 165: {'train_loss': '0.17353'}; time used = 2.1131348609924316s
epoch 170: {'train_loss': '0.25817'}; time used = 3.293687582015991s
epoch 175: {'train_loss': '0.08252'}; time used = 2.0420777797698975s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 87.96288228034973.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6360926393029123, 'samples': 0.6666666666666666, 'weighted': 0.6437361461438508, 'accuracy': 0.6666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.29775'}; time used = 1.923478603363037s
epoch 10: {'train_loss': '1.22153'}; time used = 1.8461148738861084s
epoch 15: {'train_loss': '1.16093'}; time used = 1.9469828605651855s
epoch 20: {'train_loss': '1.04539'}; time used = 2.096909523010254s
epoch 25: {'train_loss': '0.91993'}; time used = 2.084550142288208s
epoch 30: {'train_loss': '0.80606'}; time used = 2.1256155967712402s
epoch 35: {'train_loss': '0.69842'}; time used = 1.7210888862609863s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.45673894882202.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37489'}; time used = 1.8428330421447754s
epoch 10: {'train_loss': '1.03608'}; time used = 1.8066315650939941s
epoch 15: {'train_loss': '0.49307'}; time used = 1.8183414936065674s
epoch 20: {'train_loss': '0.36471'}; time used = 1.807215690612793s
epoch 25: {'train_loss': '0.12140'}; time used = 2.1224255561828613s
epoch 30: {'train_loss': '0.10259'}; time used = 2.0738863945007324s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.00219988822937.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5132275132275133, 'samples': 0.5362318840579711, 'weighted': 0.5208956368376658, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04752'}; time used = 8.027256965637207s
epoch 10: {'train_loss': '2.77762'}; time used = 6.602409839630127s
epoch 15: {'train_loss': '2.80961'}; time used = 5.69878888130188s
epoch 20: {'train_loss': '2.79435'}; time used = 5.413632869720459s
epoch 25: {'train_loss': '2.77230'}; time used = 7.094905614852905s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.42788887023926.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85316'}; time used = 1.5490186214447021s
epoch 10: {'train_loss': '2.77482'}; time used = 1.555898904800415s
epoch 15: {'train_loss': '2.77401'}; time used = 1.575732707977295s
epoch 20: {'train_loss': '2.77107'}; time used = 1.553086519241333s
epoch 25: {'train_loss': '2.77311'}; time used = 1.5274746417999268s
epoch 30: {'train_loss': '2.77268'}; time used = 1.733311653137207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.558948516845703.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.24884'}; time used = 1.3405826091766357s
epoch 10: {'train_loss': '0.12452'}; time used = 1.2207796573638916s
epoch 15: {'train_loss': '0.07164'}; time used = 1.2245924472808838s
epoch 20: {'train_loss': '0.06163'}; time used = 1.1099681854248047s
epoch 25: {'train_loss': '0.06148'}; time used = 1.1384096145629883s
epoch 30: {'train_loss': '0.07557'}; time used = 1.2881629467010498s
epoch 35: {'train_loss': '0.06850'}; time used = 1.1567158699035645s
epoch 40: {'train_loss': '0.05042'}; time used = 1.0696749687194824s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.834360122680664.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.61 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.64258'}; time used = 1.2564809322357178s
epoch 10: {'train_loss': '2.52905'}; time used = 1.0221130847930908s
epoch 15: {'train_loss': '2.46733'}; time used = 1.0677549839019775s
epoch 20: {'train_loss': '2.37819'}; time used = 1.073042869567871s
epoch 25: {'train_loss': '2.33950'}; time used = 1.1311752796173096s
epoch 30: {'train_loss': '2.28693'}; time used = 1.755976676940918s
epoch 35: {'train_loss': '2.25416'}; time used = 1.1688129901885986s
epoch 40: {'train_loss': '2.20756'}; time used = 1.0244686603546143s
epoch 45: {'train_loss': '2.17514'}; time used = 1.15486741065979s
epoch 50: {'train_loss': '2.16648'}; time used = 1.0644652843475342s
epoch 55: {'train_loss': '2.14001'}; time used = 1.0111713409423828s
epoch 60: {'train_loss': '2.11834'}; time used = 1.1383695602416992s
epoch 65: {'train_loss': '2.12035'}; time used = 0.9422659873962402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.619110584259033.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18774'}; time used = 1.1747949123382568s
epoch 10: {'train_loss': '0.07326'}; time used = 1.0911080837249756s
epoch 15: {'train_loss': '0.07764'}; time used = 1.0878324508666992s
epoch 20: {'train_loss': '0.04617'}; time used = 1.0789697170257568s
epoch 25: {'train_loss': '0.04662'}; time used = 1.0756702423095703s
epoch 30: {'train_loss': '0.02738'}; time used = 1.081120491027832s
epoch 35: {'train_loss': '0.01302'}; time used = 1.120082139968872s
epoch 40: {'train_loss': '0.02347'}; time used = 1.1370668411254883s
epoch 45: {'train_loss': '0.03261'}; time used = 1.019432783126831s
epoch 50: {'train_loss': '0.03228'}; time used = 1.1565427780151367s
epoch 55: {'train_loss': '0.01773'}; time used = 1.1060996055603027s
epoch 60: {'train_loss': '0.01031'}; time used = 1.0000739097595215s
epoch 65: {'train_loss': '0.02475'}; time used = 0.9622807502746582s
epoch 70: {'train_loss': '0.01766'}; time used = 0.9606144428253174s
epoch 75: {'train_loss': '0.01742'}; time used = 1.232011079788208s
epoch 80: {'train_loss': '0.01739'}; time used = 1.0493183135986328s
epoch 85: {'train_loss': '0.02138'}; time used = 1.0018634796142578s
epoch 90: {'train_loss': '0.02840'}; time used = 1.6286509037017822s
epoch 95: {'train_loss': '0.03182'}; time used = 2.704472541809082s
epoch 100: {'train_loss': '0.03544'}; time used = 2.238325595855713s
epoch 105: {'train_loss': '0.01005'}; time used = 1.1000943183898926s
epoch 110: {'train_loss': '0.01443'}; time used = 0.9567222595214844s
epoch 115: {'train_loss': '0.01734'}; time used = 1.0941476821899414s
epoch 120: {'train_loss': '0.02534'}; time used = 0.9992492198944092s
epoch 125: {'train_loss': '0.02457'}; time used = 1.1059677600860596s
epoch 130: {'train_loss': '0.01361'}; time used = 1.5959348678588867s
epoch 135: {'train_loss': '0.02074'}; time used = 0.9681692123413086s
epoch 140: {'train_loss': '0.03513'}; time used = 1.1001896858215332s
epoch 145: {'train_loss': '0.01703'}; time used = 1.0138862133026123s
epoch 150: {'train_loss': '0.01345'}; time used = 1.0536046028137207s
epoch 155: {'train_loss': '0.01715'}; time used = 1.053215503692627s
epoch 160: {'train_loss': '0.01005'}; time used = 0.9316809177398682s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.35495352745056.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02360'}; time used = 1.7635552883148193s
epoch 10: {'train_loss': '0.99432'}; time used = 1.7176244258880615s
epoch 15: {'train_loss': '1.00324'}; time used = 2.4007105827331543s
epoch 20: {'train_loss': '0.97274'}; time used = 2.1689486503601074s
epoch 25: {'train_loss': '0.86243'}; time used = 1.831960916519165s
epoch 30: {'train_loss': '0.86893'}; time used = 1.7036688327789307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.861074686050415.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.623109243697479, 'samples': 0.6231884057971014, 'weighted': 0.6227134331993668, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.99176'}; time used = 1.488807201385498s
epoch 10: {'train_loss': '2.85447'}; time used = 1.374159574508667s
epoch 15: {'train_loss': '2.82819'}; time used = 1.3654510974884033s
epoch 20: {'train_loss': '2.81435'}; time used = 1.3222465515136719s
epoch 25: {'train_loss': '2.79925'}; time used = 1.314065933227539s
epoch 30: {'train_loss': '2.80655'}; time used = 1.4491298198699951s
epoch 35: {'train_loss': '2.79467'}; time used = 1.3714673519134521s
epoch 40: {'train_loss': '2.79850'}; time used = 1.4173474311828613s
epoch 45: {'train_loss': '2.80079'}; time used = 1.3442251682281494s
epoch 50: {'train_loss': '2.79187'}; time used = 1.1677935123443604s
epoch 55: {'train_loss': '2.78929'}; time used = 1.4052338600158691s
epoch 60: {'train_loss': '2.78894'}; time used = 1.2023138999938965s
epoch 65: {'train_loss': '2.78551'}; time used = 1.1630797386169434s
epoch 70: {'train_loss': '2.77681'}; time used = 1.171619176864624s
epoch 75: {'train_loss': '2.78415'}; time used = 1.3648779392242432s
epoch 80: {'train_loss': '2.77929'}; time used = 1.1921758651733398s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.01906657218933.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.97059'}; time used = 1.8511817455291748s
epoch 10: {'train_loss': '0.16099'}; time used = 1.7540805339813232s
epoch 15: {'train_loss': '0.00000'}; time used = 1.8278851509094238s
epoch 20: {'train_loss': '0.15045'}; time used = 1.7885956764221191s
epoch 25: {'train_loss': '0.00014'}; time used = 1.9552080631256104s
epoch 30: {'train_loss': '0.00039'}; time used = 1.744323968887329s
epoch 35: {'train_loss': '0.00039'}; time used = 2.1244568824768066s
epoch 40: {'train_loss': '1.38610'}; time used = 1.9301671981811523s
epoch 45: {'train_loss': '0.00001'}; time used = 2.043234348297119s
epoch 50: {'train_loss': '0.00000'}; time used = 1.8612544536590576s
epoch 55: {'train_loss': '1.38628'}; time used = 1.8251490592956543s
epoch 60: {'train_loss': '0.00000'}; time used = 1.821929693222046s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.078511238098145.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78059'}; time used = 1.1596462726593018s
epoch 10: {'train_loss': '2.77592'}; time used = 1.041271448135376s
epoch 15: {'train_loss': '2.77567'}; time used = 1.0332176685333252s
epoch 20: {'train_loss': '2.77509'}; time used = 1.0473597049713135s
epoch 25: {'train_loss': '2.77211'}; time used = 1.0212438106536865s
epoch 30: {'train_loss': '2.77222'}; time used = 1.0339295864105225s
epoch 35: {'train_loss': '2.77001'}; time used = 1.1261537075042725s
epoch 40: {'train_loss': '2.77047'}; time used = 1.0160467624664307s
epoch 45: {'train_loss': '2.76958'}; time used = 1.134089469909668s
epoch 50: {'train_loss': '2.76775'}; time used = 1.0834236145019531s
epoch 55: {'train_loss': '2.76762'}; time used = 1.046865701675415s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.151447296142578.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5064935064935066, 'samples': 0.6052631578947368, 'weighted': 0.5413533834586466, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.69840'}; time used = 1.1335463523864746s
epoch 10: {'train_loss': '2.63170'}; time used = 1.068584680557251s
epoch 15: {'train_loss': '2.54245'}; time used = 0.9991810321807861s
epoch 20: {'train_loss': '2.47893'}; time used = 1.0041537284851074s
epoch 25: {'train_loss': '2.38261'}; time used = 1.1193175315856934s
epoch 30: {'train_loss': '2.29349'}; time used = 0.9821913242340088s
epoch 35: {'train_loss': '2.27132'}; time used = 0.9715533256530762s
epoch 40: {'train_loss': '2.22972'}; time used = 1.095170497894287s
epoch 45: {'train_loss': '2.18511'}; time used = 1.051604986190796s
epoch 50: {'train_loss': '2.17491'}; time used = 1.057072401046753s
epoch 55: {'train_loss': '2.24242'}; time used = 1.0366885662078857s
epoch 60: {'train_loss': '2.09117'}; time used = 1.2504169940948486s
epoch 65: {'train_loss': '2.04901'}; time used = 1.145254135131836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.995228052139282.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34731'}; time used = 5.361362934112549s
epoch 10: {'train_loss': '1.29989'}; time used = 5.335824728012085s
epoch 15: {'train_loss': '1.19635'}; time used = 5.406428098678589s
epoch 20: {'train_loss': '1.13176'}; time used = 4.972719430923462s
epoch 25: {'train_loss': '1.02228'}; time used = 5.124938726425171s
epoch 30: {'train_loss': '0.63209'}; time used = 6.021502256393433s
epoch 35: {'train_loss': '0.60894'}; time used = 7.442337512969971s
epoch 40: {'train_loss': '0.52547'}; time used = 6.956090927124023s
epoch 45: {'train_loss': '0.43099'}; time used = 5.9965856075286865s
epoch 50: {'train_loss': '0.94969'}; time used = 9.219461441040039s
epoch 55: {'train_loss': '0.52241'}; time used = 5.027070045471191s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 106.8452742099762.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77178'}; time used = 2.3627541065216064s
epoch 10: {'train_loss': '2.77034'}; time used = 2.1321706771850586s
epoch 15: {'train_loss': '2.76785'}; time used = 2.1679625511169434s
epoch 20: {'train_loss': '2.76370'}; time used = 1.8061656951904297s
epoch 25: {'train_loss': '2.76110'}; time used = 1.8847908973693848s
epoch 30: {'train_loss': '2.75552'}; time used = 1.6983928680419922s
epoch 35: {'train_loss': '2.75161'}; time used = 1.9274120330810547s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.147626399993896.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6166666666666667, 'samples': 0.6231884057971014, 'weighted': 0.6202898550724637, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87525'}; time used = 2.5688674449920654s
epoch 10: {'train_loss': '2.81846'}; time used = 1.8985869884490967s
epoch 15: {'train_loss': '2.80463'}; time used = 1.7525763511657715s
epoch 20: {'train_loss': '2.79125'}; time used = 1.8056988716125488s
epoch 25: {'train_loss': '2.78255'}; time used = 1.7616419792175293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.39412260055542.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36556'}; time used = 2.737020254135132s
epoch 10: {'train_loss': '1.21283'}; time used = 2.664818525314331s
epoch 15: {'train_loss': '1.04532'}; time used = 2.9610064029693604s
epoch 20: {'train_loss': '0.85109'}; time used = 2.990281105041504s
epoch 25: {'train_loss': '0.74009'}; time used = 4.158674001693726s
epoch 30: {'train_loss': '0.58724'}; time used = 3.241614580154419s
epoch 35: {'train_loss': '0.65857'}; time used = 2.4739301204681396s
epoch 40: {'train_loss': '0.54305'}; time used = 2.5428049564361572s
epoch 45: {'train_loss': '0.55863'}; time used = 2.4735426902770996s
epoch 50: {'train_loss': '0.54080'}; time used = 2.514735460281372s
epoch 55: {'train_loss': '0.28273'}; time used = 2.3818159103393555s
epoch 60: {'train_loss': '0.23922'}; time used = 3.9221994876861572s
epoch 65: {'train_loss': '0.26262'}; time used = 3.776728391647339s
epoch 70: {'train_loss': '0.39521'}; time used = 3.6171715259552s
epoch 75: {'train_loss': '0.20421'}; time used = 2.6288857460021973s
epoch 80: {'train_loss': '0.14976'}; time used = 2.4428422451019287s
epoch 85: {'train_loss': '0.19643'}; time used = 2.379375696182251s
epoch 90: {'train_loss': '0.02348'}; time used = 2.4648044109344482s
epoch 95: {'train_loss': '0.02461'}; time used = 3.316680908203125s
epoch 100: {'train_loss': '0.36901'}; time used = 4.13683819770813s
epoch 105: {'train_loss': '0.51155'}; time used = 3.900973320007324s
epoch 110: {'train_loss': '0.28326'}; time used = 2.6834876537323s
epoch 115: {'train_loss': '0.21155'}; time used = 2.4262163639068604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 74.7241222858429.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 34.67 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.633774757385254s
epoch 10: {'train_loss': '1.38629'}; time used = 4.738321542739868s
epoch 15: {'train_loss': '1.38629'}; time used = 4.933703184127808s
epoch 20: {'train_loss': '1.38629'}; time used = 4.950484037399292s
epoch 25: {'train_loss': '1.38629'}; time used = 4.5411083698272705s
epoch 30: {'train_loss': '1.38629'}; time used = 4.973247051239014s
epoch 35: {'train_loss': '1.38629'}; time used = 4.612891674041748s
epoch 40: {'train_loss': '1.38629'}; time used = 4.649139642715454s
epoch 45: {'train_loss': '1.38629'}; time used = 5.009962797164917s
epoch 50: {'train_loss': '1.38629'}; time used = 5.066278696060181s
epoch 55: {'train_loss': '1.38629'}; time used = 5.085819721221924s
epoch 60: {'train_loss': '1.38629'}; time used = 5.298815488815308s
epoch 65: {'train_loss': '1.38629'}; time used = 6.143038988113403s
epoch 70: {'train_loss': '1.38629'}; time used = 4.599428176879883s
epoch 75: {'train_loss': '1.38629'}; time used = 6.042971849441528s
epoch 80: {'train_loss': '1.38629'}; time used = 6.230500936508179s
epoch 85: {'train_loss': '1.38629'}; time used = 4.8740174770355225s
epoch 90: {'train_loss': '1.38629'}; time used = 4.928850889205933s
epoch 95: {'train_loss': '1.38629'}; time used = 4.902781963348389s
epoch 100: {'train_loss': '1.38629'}; time used = 5.667851448059082s
epoch 105: {'train_loss': '1.38629'}; time used = 4.805405855178833s
epoch 110: {'train_loss': '1.38629'}; time used = 5.019885540008545s
epoch 115: {'train_loss': '1.38629'}; time used = 6.387164115905762s
epoch 120: {'train_loss': '1.38629'}; time used = 6.906294584274292s
epoch 125: {'train_loss': '1.38629'}; time used = 4.712351322174072s
epoch 130: {'train_loss': '1.38629'}; time used = 4.589779615402222s
epoch 135: {'train_loss': '1.38629'}; time used = 4.987329959869385s
epoch 140: {'train_loss': '1.38629'}; time used = 5.501394033432007s
epoch 145: {'train_loss': '1.38629'}; time used = 4.258365154266357s
epoch 150: {'train_loss': '1.38629'}; time used = 5.568321704864502s
epoch 155: {'train_loss': '1.38629'}; time used = 6.503293037414551s
epoch 160: {'train_loss': '1.38629'}; time used = 4.306811094284058s
epoch 165: {'train_loss': '1.38629'}; time used = 4.505309104919434s
epoch 170: {'train_loss': '1.38629'}; time used = 4.3170166015625s
epoch 175: {'train_loss': '1.38629'}; time used = 6.803658485412598s
epoch 180: {'train_loss': '1.38629'}; time used = 6.079402446746826s
epoch 185: {'train_loss': '1.38629'}; time used = 4.279939651489258s
epoch 190: {'train_loss': '1.38629'}; time used = 7.209801435470581s
epoch 195: {'train_loss': '1.38629'}; time used = 5.641424655914307s
epoch 200: {'train_loss': '1.38629'}; time used = 4.4231109619140625s
epoch 205: {'train_loss': '1.38629'}; time used = 4.499594449996948s
epoch 210: {'train_loss': '1.38629'}; time used = 4.804286003112793s
epoch 215: {'train_loss': '1.38629'}; time used = 4.396039724349976s
epoch 220: {'train_loss': '1.38629'}; time used = 4.422621726989746s
epoch 225: {'train_loss': '1.38629'}; time used = 6.524017810821533s
epoch 230: {'train_loss': '1.38629'}; time used = 5.9258222579956055s
epoch 235: {'train_loss': '1.38629'}; time used = 4.551905393600464s
epoch 240: {'train_loss': '1.38629'}; time used = 5.507030248641968s
epoch 245: {'train_loss': '1.38629'}; time used = 8.599884748458862s
epoch 250: {'train_loss': '1.38629'}; time used = 8.442686080932617s
epoch 255: {'train_loss': '1.38629'}; time used = 7.726083517074585s
epoch 260: {'train_loss': '1.38629'}; time used = 4.760991334915161s
epoch 265: {'train_loss': '1.38629'}; time used = 4.525763034820557s
epoch 270: {'train_loss': '1.38629'}; time used = 4.304222822189331s
epoch 275: {'train_loss': '1.38629'}; time used = 4.374306678771973s
epoch 280: {'train_loss': '1.38629'}; time used = 4.880791664123535s
epoch 285: {'train_loss': '1.38629'}; time used = 4.327238082885742s
epoch 290: {'train_loss': '1.38629'}; time used = 4.782058238983154s
epoch 295: {'train_loss': '1.38629'}; time used = 4.73097038269043s
epoch 300: {'train_loss': '1.38629'}; time used = 4.96707558631897s
epoch 305: {'train_loss': '1.38629'}; time used = 4.417813062667847s
epoch 310: {'train_loss': '1.38629'}; time used = 4.652079343795776s
epoch 315: {'train_loss': '1.38629'}; time used = 4.396551847457886s
epoch 320: {'train_loss': '1.38629'}; time used = 4.272124767303467s
epoch 325: {'train_loss': '1.38629'}; time used = 4.148139238357544s
epoch 330: {'train_loss': '1.38629'}; time used = 4.063693046569824s
epoch 335: {'train_loss': '1.38629'}; time used = 4.163409233093262s
epoch 340: {'train_loss': '1.38629'}; time used = 4.317151308059692s
epoch 345: {'train_loss': '1.38629'}; time used = 4.370914936065674s
epoch 350: {'train_loss': '1.38629'}; time used = 4.259690046310425s
epoch 355: {'train_loss': '1.38629'}; time used = 4.173534631729126s
epoch 360: {'train_loss': '1.38629'}; time used = 4.2467591762542725s
epoch 365: {'train_loss': '1.38629'}; time used = 4.302409648895264s
epoch 370: {'train_loss': '1.38629'}; time used = 4.2650017738342285s
epoch 375: {'train_loss': '1.38629'}; time used = 5.043622255325317s
epoch 380: {'train_loss': '1.38629'}; time used = 7.467098712921143s
epoch 385: {'train_loss': '1.38629'}; time used = 4.712337493896484s
epoch 390: {'train_loss': '1.38629'}; time used = 5.179837226867676s
epoch 395: {'train_loss': '1.38629'}; time used = 4.148763418197632s
epoch 400: {'train_loss': '1.38629'}; time used = 4.3578526973724365s
epoch 405: {'train_loss': '1.38629'}; time used = 4.3332438468933105s
epoch 410: {'train_loss': '1.38629'}; time used = 4.225779294967651s
epoch 415: {'train_loss': '1.38629'}; time used = 4.28576922416687s
epoch 420: {'train_loss': '1.38629'}; time used = 4.253024578094482s
epoch 425: {'train_loss': '1.38629'}; time used = 4.215407133102417s
epoch 430: {'train_loss': '1.38629'}; time used = 4.354511260986328s
epoch 435: {'train_loss': '1.38629'}; time used = 4.291906833648682s
epoch 440: {'train_loss': '1.38629'}; time used = 5.307066917419434s
epoch 445: {'train_loss': '1.38629'}; time used = 7.052984952926636s
epoch 450: {'train_loss': '1.38629'}; time used = 6.928612470626831s
epoch 455: {'train_loss': '1.38629'}; time used = 5.968454599380493s
epoch 460: {'train_loss': '1.38629'}; time used = 4.705709934234619s
epoch 465: {'train_loss': '1.38629'}; time used = 4.542485952377319s
epoch 470: {'train_loss': '1.38629'}; time used = 4.487193822860718s
epoch 475: {'train_loss': '1.38629'}; time used = 4.113107204437256s
epoch 480: {'train_loss': '1.38629'}; time used = 4.383402585983276s
epoch 485: {'train_loss': '1.38629'}; time used = 5.2369444370269775s
epoch 490: {'train_loss': '1.38629'}; time used = 4.160574674606323s
epoch 495: {'train_loss': '1.38629'}; time used = 4.375982761383057s
epoch 500: {'train_loss': '1.38629'}; time used = 4.527001142501831s
Finished training. Time used = 511.28672647476196.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05462'}; time used = 2.591505527496338s
epoch 10: {'train_loss': '2.77691'}; time used = 2.322969675064087s
epoch 15: {'train_loss': '2.80957'}; time used = 2.082411527633667s
epoch 20: {'train_loss': '2.81197'}; time used = 2.1841771602630615s
epoch 25: {'train_loss': '2.77440'}; time used = 2.2116870880126953s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.094709634780884.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76703'}; time used = 2.1307480335235596s
epoch 10: {'train_loss': '2.76045'}; time used = 1.8241219520568848s
epoch 15: {'train_loss': '2.74929'}; time used = 1.8644764423370361s
epoch 20: {'train_loss': '2.72712'}; time used = 1.842264175415039s
epoch 25: {'train_loss': '2.68946'}; time used = 1.8543269634246826s
epoch 30: {'train_loss': '2.65566'}; time used = 1.9850819110870361s
epoch 35: {'train_loss': '2.60761'}; time used = 1.8161683082580566s
epoch 40: {'train_loss': '2.55366'}; time used = 1.7479369640350342s
epoch 45: {'train_loss': '2.50692'}; time used = 1.7504189014434814s
epoch 50: {'train_loss': '2.42731'}; time used = 1.7496271133422852s
epoch 55: {'train_loss': '2.43964'}; time used = 1.7984623908996582s
epoch 60: {'train_loss': '2.32725'}; time used = 1.8422296047210693s
epoch 65: {'train_loss': '2.38253'}; time used = 1.891796588897705s
epoch 70: {'train_loss': '2.40454'}; time used = 1.7650001049041748s
epoch 75: {'train_loss': '2.34320'}; time used = 1.8020260334014893s
epoch 80: {'train_loss': '2.26305'}; time used = 1.9606692790985107s
epoch 85: {'train_loss': '2.21036'}; time used = 1.7457926273345947s
epoch 90: {'train_loss': '2.16882'}; time used = 1.8092069625854492s
epoch 95: {'train_loss': '2.41297'}; time used = 1.7393114566802979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.38238334655762.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5114782235571765, 'samples': 0.5217391304347826, 'weighted': 0.5166086769959796, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34175'}; time used = 7.974914073944092s
epoch 10: {'train_loss': '1.31182'}; time used = 7.583212375640869s
epoch 15: {'train_loss': '1.22845'}; time used = 8.654073476791382s
epoch 20: {'train_loss': '1.16647'}; time used = 8.083537817001343s
epoch 25: {'train_loss': '0.99447'}; time used = 7.288573265075684s
epoch 30: {'train_loss': '0.92273'}; time used = 7.164657354354858s
epoch 35: {'train_loss': '0.65979'}; time used = 7.430422306060791s
epoch 40: {'train_loss': '0.65878'}; time used = 8.568384170532227s
epoch 45: {'train_loss': '0.77951'}; time used = 7.123425006866455s
epoch 50: {'train_loss': '0.74438'}; time used = 7.67484188079834s
epoch 55: {'train_loss': '0.70819'}; time used = 7.320518732070923s
epoch 60: {'train_loss': '0.57687'}; time used = 7.076183557510376s
epoch 65: {'train_loss': '0.56876'}; time used = 7.052700042724609s
epoch 70: {'train_loss': '0.40916'}; time used = 7.225602865219116s
epoch 75: {'train_loss': '0.33778'}; time used = 10.48409628868103s
epoch 80: {'train_loss': '0.37640'}; time used = 7.7254955768585205s
epoch 85: {'train_loss': '0.31902'}; time used = 11.008607387542725s
epoch 90: {'train_loss': '0.30754'}; time used = 7.9990739822387695s
epoch 95: {'train_loss': '0.22408'}; time used = 9.419684410095215s
epoch 100: {'train_loss': '0.29779'}; time used = 7.698409557342529s
epoch 105: {'train_loss': '0.20704'}; time used = 7.602825403213501s
epoch 110: {'train_loss': '0.20743'}; time used = 8.245314121246338s
epoch 115: {'train_loss': '0.19781'}; time used = 14.19547724723816s
epoch 120: {'train_loss': '0.09114'}; time used = 12.93858528137207s
epoch 125: {'train_loss': '0.08678'}; time used = 7.448021650314331s
epoch 130: {'train_loss': '0.08220'}; time used = 7.347594738006592s
epoch 135: {'train_loss': '0.15874'}; time used = 7.525954723358154s
epoch 140: {'train_loss': '0.41483'}; time used = 7.165410041809082s
epoch 145: {'train_loss': '0.24868'}; time used = 6.9875969886779785s
epoch 150: {'train_loss': '0.14059'}; time used = 7.222562551498413s
epoch 155: {'train_loss': '0.29933'}; time used = 8.852840662002563s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 277.42515230178833.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.41875076073007217, 'samples': 0.5066666666666667, 'weighted': 0.4072993490192811, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.09065'}; time used = 2.1721138954162598s
epoch 10: {'train_loss': '2.95774'}; time used = 2.4588959217071533s
epoch 15: {'train_loss': '2.87534'}; time used = 2.3076813220977783s
epoch 20: {'train_loss': '2.85091'}; time used = 1.927398443222046s
epoch 25: {'train_loss': '2.82017'}; time used = 2.0059468746185303s
epoch 30: {'train_loss': '2.80936'}; time used = 1.9314441680908203s
epoch 35: {'train_loss': '2.79942'}; time used = 2.2109930515289307s
epoch 40: {'train_loss': '2.79225'}; time used = 2.1701250076293945s
epoch 45: {'train_loss': '2.79101'}; time used = 2.347015380859375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.8885018825531.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36706'}; time used = 1.7200672626495361s
epoch 10: {'train_loss': '1.40237'}; time used = 1.7250218391418457s
epoch 15: {'train_loss': '1.42555'}; time used = 1.7848949432373047s
epoch 20: {'train_loss': '1.30991'}; time used = 1.6244256496429443s
epoch 25: {'train_loss': '1.38871'}; time used = 1.355872631072998s
epoch 30: {'train_loss': '1.35006'}; time used = 2.2213053703308105s
epoch 35: {'train_loss': '1.37837'}; time used = 1.4524405002593994s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.105656623840332.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.98509'}; time used = 1.0861473083496094s
epoch 10: {'train_loss': '2.82632'}; time used = 1.022061824798584s
epoch 15: {'train_loss': '2.80938'}; time used = 0.9754085540771484s
epoch 20: {'train_loss': '2.78889'}; time used = 1.0456926822662354s
epoch 25: {'train_loss': '2.77705'}; time used = 0.9983932971954346s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.927035808563232.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.64321'}; time used = 1.7949204444885254s
epoch 10: {'train_loss': '2.48884'}; time used = 1.658740520477295s
epoch 15: {'train_loss': '2.31156'}; time used = 1.740753173828125s
epoch 20: {'train_loss': '2.25897'}; time used = 1.831829309463501s
epoch 25: {'train_loss': '2.06666'}; time used = 1.752384901046753s
epoch 30: {'train_loss': '2.30994'}; time used = 1.2728118896484375s
epoch 35: {'train_loss': '1.80603'}; time used = 0.9458458423614502s
epoch 40: {'train_loss': '1.85011'}; time used = 0.985187292098999s
epoch 45: {'train_loss': '1.61844'}; time used = 0.9273381233215332s
epoch 50: {'train_loss': '1.60378'}; time used = 0.9314992427825928s
epoch 55: {'train_loss': '1.56232'}; time used = 0.9246177673339844s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.085418939590454.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7301136363636364, 'samples': 0.7368421052631579, 'weighted': 0.7368421052631579, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34760'}; time used = 1.7657475471496582s
epoch 10: {'train_loss': '1.24590'}; time used = 1.7830560207366943s
epoch 15: {'train_loss': '1.18222'}; time used = 1.8016514778137207s
epoch 20: {'train_loss': '0.70796'}; time used = 1.7550954818725586s
epoch 25: {'train_loss': '0.82051'}; time used = 1.7486271858215332s
epoch 30: {'train_loss': '0.79440'}; time used = 1.8155109882354736s
epoch 35: {'train_loss': '0.36407'}; time used = 1.874208927154541s
epoch 40: {'train_loss': '0.71880'}; time used = 1.7343053817749023s
epoch 45: {'train_loss': '0.70885'}; time used = 1.6879820823669434s
epoch 50: {'train_loss': '0.60804'}; time used = 1.7149465084075928s
epoch 55: {'train_loss': '0.54965'}; time used = 1.698117733001709s
epoch 60: {'train_loss': '0.48861'}; time used = 3.036308765411377s
epoch 65: {'train_loss': '0.47238'}; time used = 2.6549293994903564s
epoch 70: {'train_loss': '0.44477'}; time used = 1.659120798110962s
epoch 75: {'train_loss': '0.45366'}; time used = 1.767340898513794s
epoch 80: {'train_loss': '0.40533'}; time used = 1.6302344799041748s
epoch 85: {'train_loss': '0.39276'}; time used = 1.8268542289733887s
epoch 90: {'train_loss': '0.41059'}; time used = 1.8323731422424316s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.43120002746582.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.17175'}; time used = 1.3920905590057373s
epoch 10: {'train_loss': '1.05340'}; time used = 1.1862149238586426s
epoch 15: {'train_loss': '0.94216'}; time used = 1.1165337562561035s
epoch 20: {'train_loss': '0.77612'}; time used = 1.115034580230713s
epoch 25: {'train_loss': '0.58626'}; time used = 1.1803667545318604s
epoch 30: {'train_loss': '0.38781'}; time used = 1.1113030910491943s
epoch 35: {'train_loss': '0.32676'}; time used = 1.1018829345703125s
epoch 40: {'train_loss': '0.23214'}; time used = 1.1231248378753662s
epoch 45: {'train_loss': '0.18889'}; time used = 1.097231149673462s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.790151357650757.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13745'}; time used = 1.8714587688446045s
epoch 10: {'train_loss': '0.86063'}; time used = 3.6898763179779053s
epoch 15: {'train_loss': '0.34716'}; time used = 1.8645269870758057s
epoch 20: {'train_loss': '0.43251'}; time used = 2.2060770988464355s
epoch 25: {'train_loss': '0.43372'}; time used = 2.268165111541748s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.598984956741333.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85632'}; time used = 5.335392713546753s
epoch 10: {'train_loss': '2.78289'}; time used = 5.7205986976623535s
epoch 15: {'train_loss': '2.77433'}; time used = 5.473287343978882s
epoch 20: {'train_loss': '2.78284'}; time used = 5.990735054016113s
epoch 25: {'train_loss': '2.77537'}; time used = 5.1113152503967285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.10172128677368.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6948092557848655, 'samples': 0.695, 'weighted': 0.694656660412758, 'accuracy': 0.695}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.26285'}; time used = 7.6357855796813965s
epoch 10: {'train_loss': '0.98495'}; time used = 8.126103639602661s
epoch 15: {'train_loss': '0.49483'}; time used = 7.263129711151123s
epoch 20: {'train_loss': '0.21029'}; time used = 7.5566771030426025s
epoch 25: {'train_loss': '0.19382'}; time used = 7.115244388580322s
epoch 30: {'train_loss': '0.31061'}; time used = 7.486894369125366s
epoch 35: {'train_loss': '0.03786'}; time used = 7.429024934768677s
epoch 40: {'train_loss': '0.06400'}; time used = 7.82835841178894s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 100.50139307975769.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44062727286437714, 'samples': 0.5066666666666667, 'weighted': 0.43096777671234404, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23305'}; time used = 1.0916321277618408s
epoch 10: {'train_loss': '2.89471'}; time used = 1.1560726165771484s
epoch 15: {'train_loss': '2.77973'}; time used = 1.1324899196624756s
epoch 20: {'train_loss': '2.78881'}; time used = 1.1471507549285889s
epoch 25: {'train_loss': '2.78590'}; time used = 1.710273027420044s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.589864015579224.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10285'}; time used = 1.2705528736114502s
epoch 10: {'train_loss': '0.80594'}; time used = 1.406141996383667s
epoch 15: {'train_loss': '0.57705'}; time used = 1.3174262046813965s
epoch 20: {'train_loss': '0.39086'}; time used = 1.2917146682739258s
epoch 25: {'train_loss': '0.49325'}; time used = 1.3066351413726807s
epoch 30: {'train_loss': '0.33047'}; time used = 2.0672898292541504s
epoch 35: {'train_loss': '0.21421'}; time used = 1.971860408782959s
epoch 40: {'train_loss': '0.17163'}; time used = 2.1350760459899902s
epoch 45: {'train_loss': '0.20450'}; time used = 2.197784423828125s
epoch 50: {'train_loss': '0.17911'}; time used = 1.4708194732666016s
epoch 55: {'train_loss': '0.18867'}; time used = 1.1902222633361816s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.528064727783203.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94342'}; time used = 2.783996820449829s
epoch 10: {'train_loss': '2.74617'}; time used = 2.6140522956848145s
epoch 15: {'train_loss': '2.75338'}; time used = 2.5824453830718994s
epoch 20: {'train_loss': '2.73613'}; time used = 2.5260348320007324s
epoch 25: {'train_loss': '2.71606'}; time used = 2.528270959854126s
epoch 30: {'train_loss': '2.68986'}; time used = 2.429645538330078s
epoch 35: {'train_loss': '2.64638'}; time used = 2.3842926025390625s
epoch 40: {'train_loss': '2.60254'}; time used = 2.4622833728790283s
epoch 45: {'train_loss': '2.52798'}; time used = 2.4489998817443848s
epoch 50: {'train_loss': '2.52045'}; time used = 2.4541547298431396s
epoch 55: {'train_loss': '2.49521'}; time used = 2.439601182937622s
epoch 60: {'train_loss': '2.48324'}; time used = 2.3869504928588867s
epoch 65: {'train_loss': '2.45464'}; time used = 2.4431207180023193s
epoch 70: {'train_loss': '2.41445'}; time used = 2.584404468536377s
epoch 75: {'train_loss': '2.41576'}; time used = 2.513150453567505s
epoch 80: {'train_loss': '2.39347'}; time used = 2.577038288116455s
epoch 85: {'train_loss': '2.40620'}; time used = 2.7457773685455322s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.08013653755188.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.50682261208577, 'samples': 0.5217391304347826, 'weighted': 0.5130378280645252, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.90202'}; time used = 3.557788372039795s
epoch 10: {'train_loss': '2.79912'}; time used = 3.4724488258361816s
epoch 15: {'train_loss': '2.78539'}; time used = 2.5183520317077637s
epoch 20: {'train_loss': '2.78118'}; time used = 1.8641853332519531s
epoch 25: {'train_loss': '2.77795'}; time used = 1.9739353656768799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.40447449684143.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87376'}; time used = 2.2822680473327637s
epoch 10: {'train_loss': '2.79882'}; time used = 1.8338708877563477s
epoch 15: {'train_loss': '2.77755'}; time used = 2.0331435203552246s
epoch 20: {'train_loss': '2.76976'}; time used = 1.7931098937988281s
epoch 25: {'train_loss': '2.76565'}; time used = 1.832923173904419s
epoch 30: {'train_loss': '2.76163'}; time used = 1.7923965454101562s
epoch 35: {'train_loss': '2.75908'}; time used = 1.8515114784240723s
epoch 40: {'train_loss': '2.75657'}; time used = 1.8709001541137695s
epoch 45: {'train_loss': '2.75005'}; time used = 1.852660894393921s
epoch 50: {'train_loss': '2.74492'}; time used = 2.0899341106414795s
epoch 55: {'train_loss': '2.74669'}; time used = 2.3097665309906006s
epoch 60: {'train_loss': '2.73552'}; time used = 2.0315496921539307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.934059381484985.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.41025641025641024, 'samples': 0.5217391304347826, 'weighted': 0.42883686361947226, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.01487'}; time used = 1.3813433647155762s
epoch 10: {'train_loss': '0.74837'}; time used = 1.2197754383087158s
epoch 15: {'train_loss': '0.57779'}; time used = 1.2233107089996338s
epoch 20: {'train_loss': '0.41068'}; time used = 1.181121826171875s
epoch 25: {'train_loss': '0.33535'}; time used = 1.1793928146362305s
epoch 30: {'train_loss': '0.27436'}; time used = 1.1677484512329102s
epoch 35: {'train_loss': '0.21921'}; time used = 1.1905219554901123s
epoch 40: {'train_loss': '0.14885'}; time used = 1.5124197006225586s
epoch 45: {'train_loss': '0.11962'}; time used = 1.7130544185638428s
epoch 50: {'train_loss': '0.11518'}; time used = 1.1009714603424072s
epoch 55: {'train_loss': '0.08739'}; time used = 1.1351583003997803s
epoch 60: {'train_loss': '0.07642'}; time used = 1.3334410190582275s
epoch 65: {'train_loss': '0.07390'}; time used = 1.6066207885742188s
epoch 70: {'train_loss': '0.07510'}; time used = 0.9908134937286377s
epoch 75: {'train_loss': '0.06226'}; time used = 1.0175323486328125s
epoch 80: {'train_loss': '0.04740'}; time used = 0.9383797645568848s
epoch 85: {'train_loss': '0.07005'}; time used = 0.9665360450744629s
epoch 90: {'train_loss': '0.06089'}; time used = 0.9655673503875732s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.0420184135437.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.17 GiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.64 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.32191'}; time used = 2.6680171489715576s
epoch 10: {'train_loss': '1.24575'}; time used = 3.1663124561309814s
epoch 15: {'train_loss': '1.24732'}; time used = 3.291137456893921s
epoch 20: {'train_loss': '1.19618'}; time used = 3.0021467208862305s
epoch 25: {'train_loss': '1.08388'}; time used = 2.167734146118164s
epoch 30: {'train_loss': '0.88538'}; time used = 2.87819504737854s
epoch 35: {'train_loss': '0.88929'}; time used = 3.310490608215332s
epoch 40: {'train_loss': '0.81404'}; time used = 3.2617762088775635s
epoch 45: {'train_loss': '0.73100'}; time used = 2.9217689037323s
epoch 50: {'train_loss': '0.72745'}; time used = 1.9714465141296387s
epoch 55: {'train_loss': '0.71098'}; time used = 2.028277635574341s
epoch 60: {'train_loss': '0.66401'}; time used = 1.9605257511138916s
epoch 65: {'train_loss': '0.75578'}; time used = 1.9380836486816406s
epoch 70: {'train_loss': '0.64243'}; time used = 1.9403424263000488s
epoch 75: {'train_loss': '0.68221'}; time used = 2.0058488845825195s
epoch 80: {'train_loss': '0.55431'}; time used = 2.013988971710205s
epoch 85: {'train_loss': '0.53745'}; time used = 2.068746328353882s
epoch 90: {'train_loss': '0.59420'}; time used = 2.07728910446167s
epoch 95: {'train_loss': '0.59050'}; time used = 1.9819586277008057s
epoch 100: {'train_loss': '0.52672'}; time used = 1.9608025550842285s
epoch 105: {'train_loss': '0.51208'}; time used = 2.027986526489258s
epoch 110: {'train_loss': '0.54958'}; time used = 1.9663939476013184s
epoch 115: {'train_loss': '0.56540'}; time used = 2.0568201541900635s
epoch 120: {'train_loss': '0.51807'}; time used = 1.9729697704315186s
epoch 125: {'train_loss': '0.51671'}; time used = 1.965592622756958s
epoch 130: {'train_loss': '0.53921'}; time used = 1.9312281608581543s
epoch 135: {'train_loss': '0.60638'}; time used = 2.001450300216675s
epoch 140: {'train_loss': '0.57184'}; time used = 2.1939079761505127s
epoch 145: {'train_loss': '0.42829'}; time used = 2.172597885131836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 71.37408971786499.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5108695652173914, 'samples': 0.5652173913043478, 'weighted': 0.5226843100189036, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.27971'}; time used = 2.1446046829223633s
epoch 10: {'train_loss': '1.18899'}; time used = 2.015899896621704s
epoch 15: {'train_loss': '1.12310'}; time used = 2.0451648235321045s
epoch 20: {'train_loss': '1.11898'}; time used = 2.3213229179382324s
epoch 25: {'train_loss': '1.03041'}; time used = 2.1839053630828857s
epoch 30: {'train_loss': '0.86407'}; time used = 2.469496250152588s
epoch 35: {'train_loss': '0.93068'}; time used = 2.1739590167999268s
epoch 40: {'train_loss': '0.75308'}; time used = 2.0953617095947266s
epoch 45: {'train_loss': '0.76075'}; time used = 2.1644928455352783s
epoch 50: {'train_loss': '0.68938'}; time used = 3.1394739151000977s
epoch 55: {'train_loss': '0.44588'}; time used = 5.045562267303467s
epoch 60: {'train_loss': '0.46566'}; time used = 2.3722872734069824s
epoch 65: {'train_loss': '0.54749'}; time used = 2.0944676399230957s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.34229254722595.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6805555555555556, 'samples': 0.6811594202898551, 'weighted': 0.6815619967793881, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82160'}; time used = 4.112473726272583s
epoch 10: {'train_loss': '2.78956'}; time used = 2.732612371444702s
epoch 15: {'train_loss': '2.77277'}; time used = 2.6881306171417236s
epoch 20: {'train_loss': '2.77946'}; time used = 2.5802555084228516s
epoch 25: {'train_loss': '2.77310'}; time used = 2.122770071029663s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.803558826446533.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.566247582205029, 'samples': 0.6231884057971014, 'weighted': 0.5776357469234434, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.25518'}; time used = 3.236952781677246s
epoch 10: {'train_loss': '1.14682'}; time used = 2.2508625984191895s
epoch 15: {'train_loss': '0.97169'}; time used = 2.1106255054473877s
epoch 20: {'train_loss': '0.81072'}; time used = 2.091708183288574s
epoch 25: {'train_loss': '0.69000'}; time used = 1.9880187511444092s
epoch 30: {'train_loss': '0.57310'}; time used = 2.0447678565979004s
epoch 35: {'train_loss': '0.63225'}; time used = 2.017324924468994s
epoch 40: {'train_loss': '0.50945'}; time used = 2.8513343334198s
epoch 45: {'train_loss': '0.54666'}; time used = 3.1942121982574463s
epoch 50: {'train_loss': '0.57402'}; time used = 3.1858789920806885s
epoch 55: {'train_loss': '0.55216'}; time used = 3.179933786392212s
epoch 60: {'train_loss': '0.49726'}; time used = 1.9755713939666748s
epoch 65: {'train_loss': '0.49893'}; time used = 1.908503532409668s
epoch 70: {'train_loss': '0.49235'}; time used = 1.9217414855957031s
epoch 75: {'train_loss': '0.37285'}; time used = 1.9172890186309814s
epoch 80: {'train_loss': '0.41104'}; time used = 2.1031389236450195s
epoch 85: {'train_loss': '0.42804'}; time used = 1.9373290538787842s
epoch 90: {'train_loss': '0.35262'}; time used = 1.9851396083831787s
epoch 95: {'train_loss': '0.41648'}; time used = 2.0249814987182617s
epoch 100: {'train_loss': '0.33132'}; time used = 2.031912326812744s
epoch 105: {'train_loss': '0.38710'}; time used = 2.687896251678467s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.013938426971436.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84502'}; time used = 7.599055767059326s
epoch 10: {'train_loss': '2.77480'}; time used = 7.11515736579895s
epoch 15: {'train_loss': '2.77599'}; time used = 10.08832573890686s
epoch 20: {'train_loss': '2.77202'}; time used = 9.111133575439453s
epoch 25: {'train_loss': '2.76328'}; time used = 8.425008535385132s
epoch 30: {'train_loss': '2.76123'}; time used = 7.420171022415161s
epoch 35: {'train_loss': '2.74770'}; time used = 8.208734035491943s
epoch 40: {'train_loss': '2.73678'}; time used = 15.018353462219238s
epoch 45: {'train_loss': '2.72918'}; time used = 10.82972002029419s
epoch 50: {'train_loss': '2.72638'}; time used = 7.209675073623657s
epoch 55: {'train_loss': '2.72266'}; time used = 7.29975700378418s
epoch 60: {'train_loss': '2.72151'}; time used = 7.011981964111328s
epoch 65: {'train_loss': '2.71312'}; time used = 7.00170636177063s
epoch 70: {'train_loss': '2.71466'}; time used = 6.989619255065918s
epoch 75: {'train_loss': '2.70950'}; time used = 7.3328917026519775s
epoch 80: {'train_loss': '2.71387'}; time used = 7.048013210296631s
epoch 85: {'train_loss': '2.70812'}; time used = 7.835104703903198s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 169.79124069213867.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.44913711583924343, 'samples': 0.5033333333333333, 'weighted': 0.44046300236406616, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.07507'}; time used = 1.2714056968688965s
epoch 10: {'train_loss': '2.70367'}; time used = 1.2717766761779785s
epoch 15: {'train_loss': '2.66740'}; time used = 1.3541250228881836s
epoch 20: {'train_loss': '2.61790'}; time used = 1.0831913948059082s
epoch 25: {'train_loss': '2.56119'}; time used = 1.073721170425415s
epoch 30: {'train_loss': '2.42707'}; time used = 1.5470294952392578s
epoch 35: {'train_loss': '2.36218'}; time used = 2.1093924045562744s
epoch 40: {'train_loss': '2.32251'}; time used = 1.820779800415039s
epoch 45: {'train_loss': '2.27099'}; time used = 2.032090663909912s
epoch 50: {'train_loss': '2.21910'}; time used = 1.9879741668701172s
epoch 55: {'train_loss': '2.18030'}; time used = 1.8322772979736328s
epoch 60: {'train_loss': '2.14738'}; time used = 1.2096569538116455s
epoch 65: {'train_loss': '2.10051'}; time used = 1.0718693733215332s
epoch 70: {'train_loss': '2.11110'}; time used = 1.3164033889770508s
epoch 75: {'train_loss': '2.08441'}; time used = 2.3861448764801025s
epoch 80: {'train_loss': '2.08385'}; time used = 1.419287919998169s
epoch 85: {'train_loss': '2.11614'}; time used = 1.0374960899353027s
epoch 90: {'train_loss': '2.07030'}; time used = 1.0697193145751953s
epoch 95: {'train_loss': '1.99726'}; time used = 1.216904640197754s
epoch 100: {'train_loss': '2.01075'}; time used = 1.0579886436462402s
epoch 105: {'train_loss': '2.11942'}; time used = 1.0751659870147705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.01186990737915.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5064935064935066, 'samples': 0.6052631578947368, 'weighted': 0.5413533834586466, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.86818790435791s
epoch 10: {'train_loss': '1.38629'}; time used = 4.864804983139038s
epoch 15: {'train_loss': '1.38629'}; time used = 5.012948036193848s
epoch 20: {'train_loss': '1.38629'}; time used = 5.608118295669556s
epoch 25: {'train_loss': '1.38629'}; time used = 8.803215742111206s
epoch 30: {'train_loss': '1.38629'}; time used = 9.246671199798584s
epoch 35: {'train_loss': '1.38629'}; time used = 9.109314441680908s
epoch 40: {'train_loss': '1.38629'}; time used = 4.849990129470825s
epoch 45: {'train_loss': '1.38629'}; time used = 4.91244649887085s
epoch 50: {'train_loss': '1.38629'}; time used = 4.704760789871216s
epoch 55: {'train_loss': '1.38629'}; time used = 4.698360919952393s
epoch 60: {'train_loss': '1.38629'}; time used = 5.00410008430481s
epoch 65: {'train_loss': '1.38629'}; time used = 5.672384977340698s
epoch 70: {'train_loss': '1.38629'}; time used = 7.84188985824585s
epoch 75: {'train_loss': '1.38629'}; time used = 5.119125843048096s
epoch 80: {'train_loss': '1.38629'}; time used = 4.655343532562256s
epoch 85: {'train_loss': '1.38629'}; time used = 5.042491674423218s
epoch 90: {'train_loss': '1.38629'}; time used = 4.76023006439209s
epoch 95: {'train_loss': '1.38629'}; time used = 4.628734588623047s
epoch 100: {'train_loss': '1.38629'}; time used = 4.722047567367554s
epoch 105: {'train_loss': '1.38629'}; time used = 4.854672193527222s
epoch 110: {'train_loss': '1.38629'}; time used = 4.950530290603638s
epoch 115: {'train_loss': '1.38629'}; time used = 4.817830801010132s
epoch 120: {'train_loss': '1.38629'}; time used = 4.64434814453125s
epoch 125: {'train_loss': '1.38629'}; time used = 4.517031908035278s
epoch 130: {'train_loss': '1.38629'}; time used = 4.611656188964844s
epoch 135: {'train_loss': '1.38629'}; time used = 4.7500550746917725s
epoch 140: {'train_loss': '1.38629'}; time used = 4.795468807220459s
epoch 145: {'train_loss': '1.38629'}; time used = 4.820483922958374s
epoch 150: {'train_loss': '1.38629'}; time used = 4.829324245452881s
epoch 155: {'train_loss': '1.38629'}; time used = 5.023848295211792s
epoch 160: {'train_loss': '1.38629'}; time used = 4.72708797454834s
epoch 165: {'train_loss': '1.38629'}; time used = 6.766284227371216s
epoch 170: {'train_loss': '1.38629'}; time used = 7.002439022064209s
epoch 175: {'train_loss': '1.38629'}; time used = 5.036407709121704s
epoch 180: {'train_loss': '1.38629'}; time used = 4.67841100692749s
epoch 185: {'train_loss': '1.38629'}; time used = 5.262449264526367s
epoch 190: {'train_loss': '1.38629'}; time used = 4.887748956680298s
epoch 195: {'train_loss': '1.38629'}; time used = 5.3619585037231445s
epoch 200: {'train_loss': '1.38629'}; time used = 4.896444082260132s
epoch 205: {'train_loss': '1.38629'}; time used = 4.842038869857788s
epoch 210: {'train_loss': '1.38629'}; time used = 4.639456510543823s
epoch 215: {'train_loss': '1.38629'}; time used = 4.932464122772217s
epoch 220: {'train_loss': '1.38629'}; time used = 4.775287866592407s
epoch 225: {'train_loss': '1.38629'}; time used = 6.6214988231658936s
epoch 230: {'train_loss': '1.38629'}; time used = 7.3238441944122314s
epoch 235: {'train_loss': '1.38629'}; time used = 4.889781713485718s
epoch 240: {'train_loss': '1.38629'}; time used = 6.9883811473846436s
epoch 245: {'train_loss': '1.38629'}; time used = 6.142118215560913s
epoch 250: {'train_loss': '1.38629'}; time used = 4.637176752090454s
epoch 255: {'train_loss': '1.38629'}; time used = 5.205437421798706s
epoch 260: {'train_loss': '1.38629'}; time used = 4.789041042327881s
epoch 265: {'train_loss': '1.38629'}; time used = 4.5120697021484375s
epoch 270: {'train_loss': '1.38629'}; time used = 4.568657398223877s
epoch 275: {'train_loss': '1.38629'}; time used = 4.661419630050659s
epoch 280: {'train_loss': '1.38629'}; time used = 5.929020166397095s
epoch 285: {'train_loss': '1.38629'}; time used = 4.761402130126953s
epoch 290: {'train_loss': '1.38629'}; time used = 4.466387510299683s
epoch 295: {'train_loss': '1.38629'}; time used = 7.06477165222168s
epoch 300: {'train_loss': '1.38629'}; time used = 5.385588645935059s
epoch 305: {'train_loss': '1.38629'}; time used = 7.008813858032227s
epoch 310: {'train_loss': '1.38629'}; time used = 4.580899715423584s
epoch 315: {'train_loss': '1.38629'}; time used = 4.556526184082031s
epoch 320: {'train_loss': '1.38629'}; time used = 4.581773042678833s
epoch 325: {'train_loss': '1.38629'}; time used = 4.546774625778198s
epoch 330: {'train_loss': '1.38629'}; time used = 4.6769750118255615s
epoch 335: {'train_loss': '1.38629'}; time used = 4.666597366333008s
epoch 340: {'train_loss': '1.38629'}; time used = 4.500744581222534s
epoch 345: {'train_loss': '1.38629'}; time used = 4.715588808059692s
epoch 350: {'train_loss': '1.38629'}; time used = 4.628352165222168s
epoch 355: {'train_loss': '1.38629'}; time used = 4.560944318771362s
epoch 360: {'train_loss': '1.38629'}; time used = 4.505014657974243s
epoch 365: {'train_loss': '1.38629'}; time used = 4.577258586883545s
epoch 370: {'train_loss': '1.38629'}; time used = 8.569161653518677s
epoch 375: {'train_loss': '1.38629'}; time used = 9.457496643066406s
epoch 380: {'train_loss': '1.38629'}; time used = 8.656567811965942s
epoch 385: {'train_loss': '1.38629'}; time used = 5.390186309814453s
epoch 390: {'train_loss': '1.38629'}; time used = 4.627368927001953s
epoch 395: {'train_loss': '1.38629'}; time used = 4.772578477859497s
epoch 400: {'train_loss': '1.38629'}; time used = 7.639356851577759s
epoch 405: {'train_loss': '1.38629'}; time used = 5.9036595821380615s
epoch 410: {'train_loss': '1.38629'}; time used = 5.327145576477051s
epoch 415: {'train_loss': '1.38629'}; time used = 5.245343208312988s
epoch 420: {'train_loss': '1.38629'}; time used = 5.082410573959351s
epoch 425: {'train_loss': '1.38629'}; time used = 4.403102159500122s
epoch 430: {'train_loss': '1.38629'}; time used = 4.6626927852630615s
epoch 435: {'train_loss': '1.38629'}; time used = 4.785458564758301s
epoch 440: {'train_loss': '1.38629'}; time used = 4.713231563568115s
epoch 445: {'train_loss': '1.38629'}; time used = 4.734344959259033s
epoch 450: {'train_loss': '1.38629'}; time used = 4.546332359313965s
epoch 455: {'train_loss': '1.38629'}; time used = 6.040728330612183s
epoch 460: {'train_loss': '1.38629'}; time used = 6.668710470199585s
epoch 465: {'train_loss': '1.38629'}; time used = 4.565330982208252s
epoch 470: {'train_loss': '1.38629'}; time used = 4.718472242355347s
epoch 475: {'train_loss': '1.38629'}; time used = 4.652637958526611s
epoch 480: {'train_loss': '1.38629'}; time used = 4.4772422313690186s
epoch 485: {'train_loss': '1.38629'}; time used = 4.498671770095825s
epoch 490: {'train_loss': '1.38629'}; time used = 4.467365026473999s
epoch 495: {'train_loss': '1.38629'}; time used = 4.727036237716675s
epoch 500: {'train_loss': '1.38629'}; time used = 6.688654184341431s
Finished training. Time used = 542.3670411109924.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37058'}; time used = 1.960010051727295s
epoch 10: {'train_loss': '1.27608'}; time used = 1.7603015899658203s
epoch 15: {'train_loss': '1.01308'}; time used = 1.9379839897155762s
epoch 20: {'train_loss': '0.53765'}; time used = 1.8375766277313232s
epoch 25: {'train_loss': '0.45308'}; time used = 1.919018268585205s
epoch 30: {'train_loss': '0.16255'}; time used = 1.826874017715454s
epoch 35: {'train_loss': '0.55047'}; time used = 1.8219413757324219s
epoch 40: {'train_loss': '0.21324'}; time used = 1.9076032638549805s
epoch 45: {'train_loss': '0.37178'}; time used = 2.1591897010803223s
epoch 50: {'train_loss': '0.25055'}; time used = 2.054727554321289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.032910346984863.
Training classifier using 80.00% nodes...
{'micro': 0.7101449275362319, 'macro': 0.7086148648648649, 'samples': 0.7101449275362319, 'weighted': 0.7101449275362319, 'accuracy': 0.7101449275362319}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.77681'}; time used = 1.8486247062683105s
epoch 10: {'train_loss': '2.90036'}; time used = 1.87105393409729s
epoch 15: {'train_loss': '2.81773'}; time used = 1.716020107269287s
epoch 20: {'train_loss': '2.77059'}; time used = 1.826263189315796s
epoch 25: {'train_loss': '2.75568'}; time used = 1.7991547584533691s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.946844100952148.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5152224824355972, 'samples': 0.5217391304347826, 'weighted': 0.5192953874350881, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.99176'}; time used = 1.3583216667175293s
epoch 10: {'train_loss': '2.85447'}; time used = 1.1209869384765625s
epoch 15: {'train_loss': '2.82819'}; time used = 1.1123597621917725s
epoch 20: {'train_loss': '2.81435'}; time used = 1.106919527053833s
epoch 25: {'train_loss': '2.79925'}; time used = 1.1309502124786377s
epoch 30: {'train_loss': '2.80655'}; time used = 1.123924970626831s
epoch 35: {'train_loss': '2.79467'}; time used = 1.1319849491119385s
epoch 40: {'train_loss': '2.79850'}; time used = 1.1914584636688232s
epoch 45: {'train_loss': '2.80079'}; time used = 1.1274538040161133s
epoch 50: {'train_loss': '2.79187'}; time used = 1.128126859664917s
epoch 55: {'train_loss': '2.78929'}; time used = 1.3851280212402344s
epoch 60: {'train_loss': '2.78894'}; time used = 1.1690752506256104s
epoch 65: {'train_loss': '2.78551'}; time used = 1.2633929252624512s
epoch 70: {'train_loss': '2.77681'}; time used = 1.2857816219329834s
epoch 75: {'train_loss': '2.78415'}; time used = 1.427185297012329s
epoch 80: {'train_loss': '2.77929'}; time used = 2.1045732498168945s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.81787919998169.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.99836'}; time used = 1.0910921096801758s
epoch 10: {'train_loss': '2.64606'}; time used = 1.0835893154144287s
epoch 15: {'train_loss': '2.55235'}; time used = 0.9888591766357422s
epoch 20: {'train_loss': '2.48735'}; time used = 0.9910056591033936s
epoch 25: {'train_loss': '2.46509'}; time used = 1.251070261001587s
epoch 30: {'train_loss': '2.36834'}; time used = 0.9789202213287354s
epoch 35: {'train_loss': '2.29552'}; time used = 0.9756882190704346s
epoch 40: {'train_loss': '2.19426'}; time used = 1.0665898323059082s
epoch 45: {'train_loss': '2.14451'}; time used = 1.0673894882202148s
epoch 50: {'train_loss': '2.15310'}; time used = 1.0062148571014404s
epoch 55: {'train_loss': '2.13352'}; time used = 1.2305586338043213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.730381488800049.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79890'}; time used = 2.0285096168518066s
epoch 10: {'train_loss': '2.78345'}; time used = 1.9147741794586182s
epoch 15: {'train_loss': '2.76976'}; time used = 1.859964370727539s
epoch 20: {'train_loss': '2.76589'}; time used = 1.9316608905792236s
epoch 25: {'train_loss': '2.75757'}; time used = 2.0543859004974365s
epoch 30: {'train_loss': '2.74804'}; time used = 1.8254284858703613s
epoch 35: {'train_loss': '2.74654'}; time used = 1.9106998443603516s
epoch 40: {'train_loss': '2.74255'}; time used = 1.9912965297698975s
epoch 45: {'train_loss': '2.73926'}; time used = 1.97711181640625s
epoch 50: {'train_loss': '2.73425'}; time used = 1.930992603302002s
epoch 55: {'train_loss': '2.73393'}; time used = 1.909353494644165s
epoch 60: {'train_loss': '2.72278'}; time used = 1.9207091331481934s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.524043798446655.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36076'}; time used = 1.8600988388061523s
epoch 10: {'train_loss': '1.30063'}; time used = 1.8474602699279785s
epoch 15: {'train_loss': '1.24125'}; time used = 1.813828945159912s
epoch 20: {'train_loss': '1.14359'}; time used = 1.9002363681793213s
epoch 25: {'train_loss': '0.91346'}; time used = 1.885085105895996s
epoch 30: {'train_loss': '0.75315'}; time used = 1.870138168334961s
epoch 35: {'train_loss': '0.53139'}; time used = 1.8114023208618164s
epoch 40: {'train_loss': '0.48088'}; time used = 1.8260607719421387s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.576529264450073.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.62762'}; time used = 1.0580592155456543s
epoch 10: {'train_loss': '0.69476'}; time used = 0.9768097400665283s
epoch 15: {'train_loss': '0.48198'}; time used = 1.0272102355957031s
epoch 20: {'train_loss': '0.35423'}; time used = 0.9230468273162842s
epoch 25: {'train_loss': '0.29696'}; time used = 0.8884034156799316s
epoch 30: {'train_loss': '0.17945'}; time used = 1.0081801414489746s
epoch 35: {'train_loss': '0.06090'}; time used = 0.8765923976898193s
epoch 40: {'train_loss': '0.14367'}; time used = 0.8858044147491455s
epoch 45: {'train_loss': '0.12563'}; time used = 0.8847413063049316s
epoch 50: {'train_loss': '0.14268'}; time used = 1.0292234420776367s
epoch 55: {'train_loss': '0.20790'}; time used = 0.8889479637145996s
epoch 60: {'train_loss': '0.12044'}; time used = 0.9763092994689941s
epoch 65: {'train_loss': '0.10281'}; time used = 0.9059889316558838s
epoch 70: {'train_loss': '0.12464'}; time used = 0.9578490257263184s
epoch 75: {'train_loss': '0.11743'}; time used = 0.973970890045166s
epoch 80: {'train_loss': '0.18700'}; time used = 0.9783351421356201s
epoch 85: {'train_loss': '0.19934'}; time used = 1.109497308731079s
epoch 90: {'train_loss': '0.02922'}; time used = 0.9329931735992432s
epoch 95: {'train_loss': '0.02426'}; time used = 0.938232421875s
epoch 100: {'train_loss': '0.22078'}; time used = 1.0818073749542236s
epoch 105: {'train_loss': '0.15510'}; time used = 0.9575843811035156s
epoch 110: {'train_loss': '0.15592'}; time used = 0.9296376705169678s
epoch 115: {'train_loss': '0.12253'}; time used = 1.0245234966278076s
epoch 120: {'train_loss': '0.08450'}; time used = 0.9565167427062988s
epoch 125: {'train_loss': '0.07659'}; time used = 0.9074647426605225s
epoch 130: {'train_loss': '0.07586'}; time used = 0.9007453918457031s
epoch 135: {'train_loss': '0.04628'}; time used = 0.8923859596252441s
epoch 140: {'train_loss': '0.11686'}; time used = 0.9421801567077637s
epoch 145: {'train_loss': '0.11002'}; time used = 0.9664056301116943s
epoch 150: {'train_loss': '0.07479'}; time used = 0.989574670791626s
epoch 155: {'train_loss': '0.08599'}; time used = 0.9319164752960205s
epoch 160: {'train_loss': '0.05629'}; time used = 0.9103186130523682s
epoch 165: {'train_loss': '0.10085'}; time used = 0.981848955154419s
epoch 170: {'train_loss': '0.08676'}; time used = 0.9072797298431396s
epoch 175: {'train_loss': '0.07425'}; time used = 0.9731626510620117s
epoch 180: {'train_loss': '0.01197'}; time used = 1.009000301361084s
epoch 185: {'train_loss': '0.04662'}; time used = 1.132561445236206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.71331834793091.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01568'}; time used = 1.6696562767028809s
epoch 10: {'train_loss': '0.60216'}; time used = 2.034846305847168s
epoch 15: {'train_loss': '0.27461'}; time used = 1.1618142127990723s
epoch 20: {'train_loss': '0.14891'}; time used = 0.9279289245605469s
epoch 25: {'train_loss': '0.08477'}; time used = 0.9465532302856445s
epoch 30: {'train_loss': '0.04558'}; time used = 0.9131402969360352s
epoch 35: {'train_loss': '0.03274'}; time used = 0.9481234550476074s
epoch 40: {'train_loss': '0.02288'}; time used = 1.0027387142181396s
epoch 45: {'train_loss': '0.01998'}; time used = 0.9593966007232666s
epoch 50: {'train_loss': '0.01007'}; time used = 1.0034444332122803s
epoch 55: {'train_loss': '0.00813'}; time used = 0.9449009895324707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.123255968093872.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8246153846153846, 'samples': 0.8421052631578947, 'weighted': 0.8333603238866396, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.27677'}; time used = 1.7401437759399414s
epoch 10: {'train_loss': '1.18280'}; time used = 1.8194732666015625s
epoch 15: {'train_loss': '0.98631'}; time used = 1.708437442779541s
epoch 20: {'train_loss': '0.83711'}; time used = 1.8269741535186768s
epoch 25: {'train_loss': '0.77361'}; time used = 3.152913808822632s
epoch 30: {'train_loss': '0.75863'}; time used = 2.857853889465332s
epoch 35: {'train_loss': '0.70148'}; time used = 3.0474743843078613s
epoch 40: {'train_loss': '0.69888'}; time used = 2.664264678955078s
epoch 45: {'train_loss': '0.67435'}; time used = 1.7861833572387695s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.38404154777527.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.47787204769548264, 'samples': 0.5217391304347826, 'weighted': 0.4888388183803076, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72530'}; time used = 1.4585978984832764s
epoch 10: {'train_loss': '2.69580'}; time used = 1.2674498558044434s
epoch 15: {'train_loss': '2.42230'}; time used = 1.2633593082427979s
epoch 20: {'train_loss': '2.28408'}; time used = 1.2637035846710205s
epoch 25: {'train_loss': '2.09291'}; time used = 1.2654101848602295s
epoch 30: {'train_loss': '2.12543'}; time used = 1.2612807750701904s
epoch 35: {'train_loss': '1.93091'}; time used = 1.2822554111480713s
epoch 40: {'train_loss': '1.94897'}; time used = 1.264894723892212s
epoch 45: {'train_loss': '1.93974'}; time used = 1.3415515422821045s
epoch 50: {'train_loss': '1.93183'}; time used = 1.360466718673706s
epoch 55: {'train_loss': '1.83947'}; time used = 1.4006893634796143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.12277603149414.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01149'}; time used = 2.581914186477661s
epoch 10: {'train_loss': '0.16410'}; time used = 2.3804843425750732s
epoch 15: {'train_loss': '0.34324'}; time used = 2.281559705734253s
epoch 20: {'train_loss': '0.00025'}; time used = 2.352428913116455s
epoch 25: {'train_loss': '0.11045'}; time used = 2.5093250274658203s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.6902973651886.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78059'}; time used = 1.1526126861572266s
epoch 10: {'train_loss': '2.77964'}; time used = 1.0203142166137695s
epoch 15: {'train_loss': '2.77958'}; time used = 0.993241548538208s
epoch 20: {'train_loss': '2.77487'}; time used = 1.0101711750030518s
epoch 25: {'train_loss': '2.77245'}; time used = 1.0187408924102783s
epoch 30: {'train_loss': '2.77301'}; time used = 1.2550561428070068s
epoch 35: {'train_loss': '2.77362'}; time used = 0.9870202541351318s
epoch 40: {'train_loss': '2.77244'}; time used = 1.065514087677002s
epoch 45: {'train_loss': '2.77292'}; time used = 0.9772129058837891s
epoch 50: {'train_loss': '2.77126'}; time used = 0.9958999156951904s
epoch 55: {'train_loss': '2.77147'}; time used = 0.990985631942749s
epoch 60: {'train_loss': '2.77144'}; time used = 1.0610570907592773s
epoch 65: {'train_loss': '2.77021'}; time used = 1.1017656326293945s
epoch 70: {'train_loss': '2.76924'}; time used = 1.010301113128662s
epoch 75: {'train_loss': '2.76904'}; time used = 0.9976415634155273s
epoch 80: {'train_loss': '2.76791'}; time used = 0.9838981628417969s
epoch 85: {'train_loss': '2.76681'}; time used = 0.9861924648284912s
epoch 90: {'train_loss': '2.76518'}; time used = 1.0273466110229492s
epoch 95: {'train_loss': '2.76535'}; time used = 1.0575978755950928s
epoch 100: {'train_loss': '2.76466'}; time used = 1.1115503311157227s
epoch 105: {'train_loss': '2.76308'}; time used = 0.9952793121337891s
epoch 110: {'train_loss': '2.76391'}; time used = 1.0327632427215576s
epoch 115: {'train_loss': '2.76122'}; time used = 1.0617315769195557s
epoch 120: {'train_loss': '2.76258'}; time used = 1.0310633182525635s
epoch 125: {'train_loss': '2.76317'}; time used = 1.047358512878418s
epoch 130: {'train_loss': '2.76128'}; time used = 1.1334049701690674s
epoch 135: {'train_loss': '2.76196'}; time used = 1.125169277191162s
epoch 140: {'train_loss': '2.76357'}; time used = 1.0987138748168945s
epoch 145: {'train_loss': '2.75953'}; time used = 0.9256830215454102s
epoch 150: {'train_loss': '2.76283'}; time used = 1.016798734664917s
epoch 155: {'train_loss': '2.75903'}; time used = 0.9715824127197266s
epoch 160: {'train_loss': '2.75971'}; time used = 0.9853405952453613s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.429238080978394.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14969'}; time used = 2.721741199493408s
epoch 10: {'train_loss': '0.73417'}; time used = 2.5351321697235107s
epoch 15: {'train_loss': '0.51183'}; time used = 2.626281976699829s
epoch 20: {'train_loss': '0.40390'}; time used = 2.4282279014587402s
epoch 25: {'train_loss': '0.36348'}; time used = 2.5136559009552s
epoch 30: {'train_loss': '0.49621'}; time used = 2.3749632835388184s
epoch 35: {'train_loss': '0.36511'}; time used = 2.4647879600524902s
epoch 40: {'train_loss': '0.32575'}; time used = 2.4268805980682373s
epoch 45: {'train_loss': '0.34850'}; time used = 2.423017740249634s
epoch 50: {'train_loss': '0.28859'}; time used = 2.3847413063049316s
epoch 55: {'train_loss': '0.37172'}; time used = 2.4465701580047607s
epoch 60: {'train_loss': '0.37404'}; time used = 2.458540916442871s
epoch 65: {'train_loss': '0.38428'}; time used = 2.425497531890869s
epoch 70: {'train_loss': '0.29556'}; time used = 2.4425244331359863s
epoch 75: {'train_loss': '0.27442'}; time used = 2.404872417449951s
epoch 80: {'train_loss': '0.36197'}; time used = 2.480010509490967s
epoch 85: {'train_loss': '0.34263'}; time used = 2.486889123916626s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.13777565956116.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39678'}; time used = 1.202589511871338s
epoch 10: {'train_loss': '1.38447'}; time used = 1.0059633255004883s
epoch 15: {'train_loss': '1.28681'}; time used = 1.0026278495788574s
epoch 20: {'train_loss': '1.34577'}; time used = 1.0007171630859375s
epoch 25: {'train_loss': '1.25756'}; time used = 1.8460841178894043s
epoch 30: {'train_loss': '1.20619'}; time used = 2.302680015563965s
epoch 35: {'train_loss': '1.29419'}; time used = 2.2215771675109863s
epoch 40: {'train_loss': '1.21670'}; time used = 2.3761167526245117s
epoch 45: {'train_loss': '1.11731'}; time used = 2.421342611312866s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.517516374588013.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.63465'}; time used = 1.366175651550293s
epoch 10: {'train_loss': '2.27186'}; time used = 1.1146531105041504s
epoch 15: {'train_loss': '1.96565'}; time used = 1.116051197052002s
epoch 20: {'train_loss': '1.79182'}; time used = 0.8467543125152588s
epoch 25: {'train_loss': '1.68618'}; time used = 0.9167990684509277s
epoch 30: {'train_loss': '1.65829'}; time used = 1.0996763706207275s
epoch 35: {'train_loss': '1.51617'}; time used = 0.9877617359161377s
epoch 40: {'train_loss': '1.61335'}; time used = 0.8978872299194336s
epoch 45: {'train_loss': '1.48660'}; time used = 0.9778118133544922s
epoch 50: {'train_loss': '1.44854'}; time used = 0.933035135269165s
epoch 55: {'train_loss': '1.44780'}; time used = 1.0934371948242188s
epoch 60: {'train_loss': '1.42332'}; time used = 1.008619785308838s
epoch 65: {'train_loss': '1.41516'}; time used = 1.0335667133331299s
epoch 70: {'train_loss': '1.36192'}; time used = 0.966702938079834s
epoch 75: {'train_loss': '1.41409'}; time used = 0.9727516174316406s
epoch 80: {'train_loss': '1.38059'}; time used = 0.9987211227416992s
epoch 85: {'train_loss': '1.43355'}; time used = 1.0544612407684326s
epoch 90: {'train_loss': '1.39682'}; time used = 1.0286204814910889s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.085793018341064.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.61304'}; time used = 1.0770225524902344s
epoch 10: {'train_loss': '2.32147'}; time used = 0.9308516979217529s
epoch 15: {'train_loss': '2.03068'}; time used = 0.931316614151001s
epoch 20: {'train_loss': '1.86913'}; time used = 0.9140636920928955s
epoch 25: {'train_loss': '1.75363'}; time used = 0.8957295417785645s
epoch 30: {'train_loss': '1.62754'}; time used = 0.9117550849914551s
epoch 35: {'train_loss': '1.52439'}; time used = 1.0324296951293945s
epoch 40: {'train_loss': '1.62605'}; time used = 1.0630488395690918s
epoch 45: {'train_loss': '1.68388'}; time used = 0.9219686985015869s
epoch 50: {'train_loss': '1.58861'}; time used = 0.9480159282684326s
epoch 55: {'train_loss': '1.53955'}; time used = 1.0037133693695068s
epoch 60: {'train_loss': '1.47287'}; time used = 1.0086100101470947s
epoch 65: {'train_loss': '1.42168'}; time used = 0.922621488571167s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.841001033782959.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35729'}; time used = 1.1265537738800049s
epoch 10: {'train_loss': '1.68775'}; time used = 1.0116524696350098s
epoch 15: {'train_loss': '1.38657'}; time used = 1.1016061305999756s
epoch 20: {'train_loss': '1.38396'}; time used = 0.9964442253112793s
epoch 25: {'train_loss': '1.38993'}; time used = 0.9807920455932617s
epoch 30: {'train_loss': '1.37829'}; time used = 1.0667428970336914s
epoch 35: {'train_loss': '1.37760'}; time used = 0.9939219951629639s
epoch 40: {'train_loss': '1.34778'}; time used = 0.9549181461334229s
epoch 45: {'train_loss': '1.33500'}; time used = 1.0083367824554443s
epoch 50: {'train_loss': '1.38359'}; time used = 1.0495193004608154s
epoch 55: {'train_loss': '1.31134'}; time used = 1.0019910335540771s
epoch 60: {'train_loss': '1.24316'}; time used = 1.0117645263671875s
epoch 65: {'train_loss': '0.97195'}; time used = 1.067643404006958s
epoch 70: {'train_loss': '1.13277'}; time used = 0.9854385852813721s
epoch 75: {'train_loss': '0.99758'}; time used = 1.0782146453857422s
epoch 80: {'train_loss': '0.84725'}; time used = 1.0481557846069336s
epoch 85: {'train_loss': '0.61167'}; time used = 0.9870302677154541s
epoch 90: {'train_loss': '0.48067'}; time used = 1.3793082237243652s
epoch 95: {'train_loss': '0.38014'}; time used = 1.923649787902832s
epoch 100: {'train_loss': '0.37390'}; time used = 1.019096851348877s
epoch 105: {'train_loss': '0.77549'}; time used = 1.1427335739135742s
epoch 110: {'train_loss': '0.02075'}; time used = 0.9872808456420898s
epoch 115: {'train_loss': '0.91975'}; time used = 0.9997830390930176s
epoch 120: {'train_loss': '0.68285'}; time used = 0.9338428974151611s
epoch 125: {'train_loss': '0.29290'}; time used = 0.9495151042938232s
epoch 130: {'train_loss': '0.27525'}; time used = 0.9603183269500732s
epoch 135: {'train_loss': '0.04144'}; time used = 1.1229655742645264s
epoch 140: {'train_loss': '0.23655'}; time used = 0.9612910747528076s
epoch 145: {'train_loss': '0.01143'}; time used = 0.9766819477081299s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.00973320007324.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.64 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.09874'}; time used = 1.139007568359375s
epoch 10: {'train_loss': '0.82119'}; time used = 1.0350677967071533s
epoch 15: {'train_loss': '0.70543'}; time used = 1.003399133682251s
epoch 20: {'train_loss': '0.58400'}; time used = 1.1124541759490967s
epoch 25: {'train_loss': '0.54342'}; time used = 1.2738664150238037s
epoch 30: {'train_loss': '0.30791'}; time used = 1.2301044464111328s
epoch 35: {'train_loss': '0.15539'}; time used = 1.8828153610229492s
epoch 40: {'train_loss': '0.08669'}; time used = 1.9775042533874512s
epoch 45: {'train_loss': '0.07028'}; time used = 1.1381025314331055s
epoch 50: {'train_loss': '0.05826'}; time used = 1.0770292282104492s
epoch 55: {'train_loss': '0.04968'}; time used = 1.01505446434021s
epoch 60: {'train_loss': '0.02340'}; time used = 1.204564094543457s
epoch 65: {'train_loss': '0.02842'}; time used = 1.1006395816802979s
epoch 70: {'train_loss': '0.02942'}; time used = 1.1868641376495361s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.03305697441101.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.88829'}; time used = 1.5559844970703125s
epoch 10: {'train_loss': '2.80343'}; time used = 1.131241798400879s
epoch 15: {'train_loss': '2.76009'}; time used = 1.1165404319763184s
epoch 20: {'train_loss': '2.72996'}; time used = 1.1043288707733154s
epoch 25: {'train_loss': '2.67484'}; time used = 1.120952844619751s
epoch 30: {'train_loss': '2.52745'}; time used = 1.1065759658813477s
epoch 35: {'train_loss': '2.31511'}; time used = 1.076951026916504s
epoch 40: {'train_loss': '2.39001'}; time used = 1.3185596466064453s
epoch 45: {'train_loss': '2.27762'}; time used = 1.1559443473815918s
epoch 50: {'train_loss': '2.24621'}; time used = 1.155968189239502s
epoch 55: {'train_loss': '2.19691'}; time used = 1.1805109977722168s
epoch 60: {'train_loss': '2.18709'}; time used = 1.9419121742248535s
epoch 65: {'train_loss': '2.16003'}; time used = 1.2568087577819824s
epoch 70: {'train_loss': '2.17505'}; time used = 1.1348304748535156s
epoch 75: {'train_loss': '2.10819'}; time used = 1.1288678646087646s
epoch 80: {'train_loss': '2.09634'}; time used = 1.2617003917694092s
epoch 85: {'train_loss': '2.12113'}; time used = 1.0840497016906738s
epoch 90: {'train_loss': '2.09013'}; time used = 1.1119158267974854s
epoch 95: {'train_loss': '2.13115'}; time used = 1.1079754829406738s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.6700222492218.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37178'}; time used = 2.078701972961426s
epoch 10: {'train_loss': '1.28211'}; time used = 2.060544729232788s
epoch 15: {'train_loss': '1.04731'}; time used = 2.0272457599639893s
epoch 20: {'train_loss': '0.71877'}; time used = 2.0613791942596436s
epoch 25: {'train_loss': '0.29404'}; time used = 2.0385069847106934s
epoch 30: {'train_loss': '0.20968'}; time used = 1.8754539489746094s
epoch 35: {'train_loss': '0.48877'}; time used = 1.6453173160552979s
epoch 40: {'train_loss': '0.23870'}; time used = 2.1084351539611816s
epoch 45: {'train_loss': '0.40210'}; time used = 2.4464330673217773s
epoch 50: {'train_loss': '0.11104'}; time used = 1.8099453449249268s
epoch 55: {'train_loss': '0.01336'}; time used = 2.066103458404541s
epoch 60: {'train_loss': '0.17405'}; time used = 3.4743332862854004s
epoch 65: {'train_loss': '0.23126'}; time used = 3.3579490184783936s
epoch 70: {'train_loss': '0.12578'}; time used = 3.4120047092437744s
epoch 75: {'train_loss': '0.23170'}; time used = 2.5240278244018555s
epoch 80: {'train_loss': '0.45521'}; time used = 1.6876168251037598s
epoch 85: {'train_loss': '0.01548'}; time used = 1.7198007106781006s
epoch 90: {'train_loss': '0.01160'}; time used = 1.6947154998779297s
epoch 95: {'train_loss': '0.40801'}; time used = 1.8269639015197754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.3005850315094.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5213369770863989, 'samples': 0.5217391304347826, 'weighted': 0.522342360457358, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.02308'}; time used = 1.3116447925567627s
epoch 10: {'train_loss': '0.61294'}; time used = 1.013798475265503s
epoch 15: {'train_loss': '0.30175'}; time used = 0.9719905853271484s
epoch 20: {'train_loss': '0.14656'}; time used = 0.9738540649414062s
epoch 25: {'train_loss': '0.08023'}; time used = 0.9579489231109619s
epoch 30: {'train_loss': '0.04313'}; time used = 0.9711380004882812s
epoch 35: {'train_loss': '0.03389'}; time used = 0.9843080043792725s
epoch 40: {'train_loss': '0.02394'}; time used = 1.111037254333496s
epoch 45: {'train_loss': '0.02215'}; time used = 1.027907133102417s
epoch 50: {'train_loss': '0.01268'}; time used = 0.9629220962524414s
epoch 55: {'train_loss': '0.00969'}; time used = 1.062117338180542s
epoch 60: {'train_loss': '0.00892'}; time used = 1.0747778415679932s
epoch 65: {'train_loss': '0.01232'}; time used = 0.9617722034454346s
epoch 70: {'train_loss': '0.27417'}; time used = 1.0554516315460205s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.20478868484497.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.55091'}; time used = 1.3856735229492188s
epoch 10: {'train_loss': '0.38419'}; time used = 1.261204481124878s
epoch 15: {'train_loss': '0.25673'}; time used = 1.2146899700164795s
epoch 20: {'train_loss': '0.20653'}; time used = 1.3077385425567627s
epoch 25: {'train_loss': '0.24312'}; time used = 1.9929089546203613s
epoch 30: {'train_loss': '0.16407'}; time used = 1.9319088459014893s
epoch 35: {'train_loss': '0.14953'}; time used = 1.8634412288665771s
epoch 40: {'train_loss': '0.02996'}; time used = 1.9203426837921143s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.99692153930664.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77200'}; time used = 1.1746125221252441s
epoch 10: {'train_loss': '2.77446'}; time used = 1.2382497787475586s
epoch 15: {'train_loss': '2.77858'}; time used = 1.1164708137512207s
epoch 20: {'train_loss': '2.77494'}; time used = 1.1054234504699707s
epoch 25: {'train_loss': '2.77232'}; time used = 1.1039268970489502s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.925394773483276.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37314'}; time used = 1.7761287689208984s
epoch 10: {'train_loss': '1.30546'}; time used = 2.0044264793395996s
epoch 15: {'train_loss': '1.23502'}; time used = 1.834496021270752s
epoch 20: {'train_loss': '1.26545'}; time used = 2.208336353302002s
epoch 25: {'train_loss': '1.13468'}; time used = 1.976064682006836s
epoch 30: {'train_loss': '1.06352'}; time used = 1.8986129760742188s
epoch 35: {'train_loss': '1.05287'}; time used = 1.7144029140472412s
epoch 40: {'train_loss': '0.96755'}; time used = 1.7896592617034912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.004260540008545.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.66571'}; time used = 1.049478530883789s
epoch 10: {'train_loss': '2.39960'}; time used = 0.9062612056732178s
epoch 15: {'train_loss': '2.09224'}; time used = 0.8949978351593018s
epoch 20: {'train_loss': '1.79857'}; time used = 1.0918192863464355s
epoch 25: {'train_loss': '1.76446'}; time used = 1.1398823261260986s
epoch 30: {'train_loss': '1.67559'}; time used = 1.2870278358459473s
epoch 35: {'train_loss': '1.60687'}; time used = 0.944951057434082s
epoch 40: {'train_loss': '1.61908'}; time used = 0.8942561149597168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.801884889602661.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.6041666666666666, 'samples': 0.631578947368421, 'weighted': 0.6206140350877193, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.89187'}; time used = 1.6469345092773438s
epoch 10: {'train_loss': '2.86210'}; time used = 1.5438683032989502s
epoch 15: {'train_loss': '2.79200'}; time used = 1.5161595344543457s
epoch 20: {'train_loss': '2.74933'}; time used = 1.550684928894043s
epoch 25: {'train_loss': '2.70896'}; time used = 1.6493182182312012s
epoch 30: {'train_loss': '2.67821'}; time used = 1.5396842956542969s
epoch 35: {'train_loss': '2.63987'}; time used = 1.5682227611541748s
epoch 40: {'train_loss': '2.60326'}; time used = 1.5235965251922607s
epoch 45: {'train_loss': '2.56205'}; time used = 1.6257297992706299s
epoch 50: {'train_loss': '2.49487'}; time used = 1.572608470916748s
epoch 55: {'train_loss': '2.46625'}; time used = 1.6659295558929443s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.51373815536499.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4772727272727273, 'samples': 0.4782608695652174, 'weighted': 0.47891963109354413, 'accuracy': 0.4782608695652174}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04815'}; time used = 6.463062047958374s
epoch 10: {'train_loss': '2.77770'}; time used = 9.70823884010315s
epoch 15: {'train_loss': '2.80981'}; time used = 6.804395437240601s
epoch 20: {'train_loss': '2.79534'}; time used = 8.609883785247803s
epoch 25: {'train_loss': '2.77468'}; time used = 7.487309694290161s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.07290601730347.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44062727286437714, 'samples': 0.5066666666666667, 'weighted': 0.43096777671234404, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.96942'}; time used = 1.1583247184753418s
epoch 10: {'train_loss': '2.84475'}; time used = 1.0289397239685059s
epoch 15: {'train_loss': '2.80572'}; time used = 1.0347051620483398s
epoch 20: {'train_loss': '2.77845'}; time used = 1.14878249168396s
epoch 25: {'train_loss': '2.77285'}; time used = 1.0786197185516357s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.373446464538574.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93528'}; time used = 1.33967924118042s
epoch 10: {'train_loss': '2.88355'}; time used = 1.1420702934265137s
epoch 15: {'train_loss': '2.84000'}; time used = 1.14967942237854s
epoch 20: {'train_loss': '2.80943'}; time used = 1.1478009223937988s
epoch 25: {'train_loss': '2.79588'}; time used = 1.2416181564331055s
epoch 30: {'train_loss': '2.79957'}; time used = 1.1331193447113037s
epoch 35: {'train_loss': '2.78982'}; time used = 1.1529607772827148s
epoch 40: {'train_loss': '2.79187'}; time used = 1.1388680934906006s
epoch 45: {'train_loss': '2.79128'}; time used = 1.1436843872070312s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.656441450119019.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.13121'}; time used = 2.0207936763763428s
epoch 10: {'train_loss': '0.21210'}; time used = 1.7823803424835205s
epoch 15: {'train_loss': '0.01252'}; time used = 2.110048770904541s
epoch 20: {'train_loss': '0.00300'}; time used = 2.077910900115967s
epoch 25: {'train_loss': '0.00943'}; time used = 2.1079461574554443s
epoch 30: {'train_loss': '0.00011'}; time used = 2.0307159423828125s
epoch 35: {'train_loss': '0.00000'}; time used = 2.105451822280884s
epoch 40: {'train_loss': '0.13260'}; time used = 1.7238829135894775s
epoch 45: {'train_loss': '0.00000'}; time used = 1.944211483001709s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.964996099472046.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.65672'}; time used = 1.2571938037872314s
epoch 10: {'train_loss': '0.46598'}; time used = 0.99820876121521s
epoch 15: {'train_loss': '0.37160'}; time used = 1.0879528522491455s
epoch 20: {'train_loss': '0.26078'}; time used = 0.9960596561431885s
epoch 25: {'train_loss': '0.09226'}; time used = 0.9816458225250244s
epoch 30: {'train_loss': '0.05083'}; time used = 0.9514133930206299s
epoch 35: {'train_loss': '0.05566'}; time used = 0.968085765838623s
epoch 40: {'train_loss': '0.06130'}; time used = 0.9711973667144775s
epoch 45: {'train_loss': '0.06182'}; time used = 0.9827990531921387s
epoch 50: {'train_loss': '0.05372'}; time used = 0.9442107677459717s
epoch 55: {'train_loss': '0.05670'}; time used = 1.0615286827087402s
epoch 60: {'train_loss': '0.07880'}; time used = 1.1295149326324463s
epoch 65: {'train_loss': '0.10650'}; time used = 1.1644840240478516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.872934818267822.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.94665'}; time used = 1.6809649467468262s
epoch 10: {'train_loss': '2.82925'}; time used = 1.6256210803985596s
epoch 15: {'train_loss': '2.79916'}; time used = 1.6227433681488037s
epoch 20: {'train_loss': '2.77263'}; time used = 1.6332612037658691s
epoch 25: {'train_loss': '2.75581'}; time used = 1.7488682270050049s
epoch 30: {'train_loss': '2.74422'}; time used = 1.6195087432861328s
epoch 35: {'train_loss': '2.72838'}; time used = 1.606703281402588s
epoch 40: {'train_loss': '2.70558'}; time used = 1.9519824981689453s
epoch 45: {'train_loss': '2.68108'}; time used = 1.8014633655548096s
epoch 50: {'train_loss': '2.65452'}; time used = 2.102341651916504s
epoch 55: {'train_loss': '2.63715'}; time used = 1.6834664344787598s
epoch 60: {'train_loss': '2.59949'}; time used = 1.7637841701507568s
epoch 65: {'train_loss': '2.56642'}; time used = 1.7198328971862793s
epoch 70: {'train_loss': '2.55732'}; time used = 1.669935941696167s
epoch 75: {'train_loss': '2.49074'}; time used = 1.8110778331756592s
epoch 80: {'train_loss': '2.48163'}; time used = 1.7130465507507324s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.553903341293335.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.21 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37180'}; time used = 1.7315094470977783s
epoch 10: {'train_loss': '1.27734'}; time used = 1.7647860050201416s
epoch 15: {'train_loss': '1.20037'}; time used = 1.7844934463500977s
epoch 20: {'train_loss': '1.14062'}; time used = 1.7659602165222168s
epoch 25: {'train_loss': '0.85176'}; time used = 1.845764398574829s
epoch 30: {'train_loss': '0.81649'}; time used = 1.8537826538085938s
epoch 35: {'train_loss': '0.88333'}; time used = 1.8728010654449463s
epoch 40: {'train_loss': '0.71303'}; time used = 1.6910128593444824s
epoch 45: {'train_loss': '0.54915'}; time used = 1.6954951286315918s
epoch 50: {'train_loss': '0.66397'}; time used = 3.562349557876587s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.11562943458557.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.5016562938690186s
epoch 10: {'train_loss': '1.38629'}; time used = 6.7003493309021s
epoch 15: {'train_loss': '1.38629'}; time used = 6.800767183303833s
epoch 20: {'train_loss': '1.38629'}; time used = 6.921073913574219s
epoch 25: {'train_loss': '1.38629'}; time used = 7.027207136154175s
epoch 30: {'train_loss': '1.38629'}; time used = 6.859246253967285s
epoch 35: {'train_loss': '1.38629'}; time used = 6.762074708938599s
epoch 40: {'train_loss': '1.38629'}; time used = 6.784501075744629s
epoch 45: {'train_loss': '1.38629'}; time used = 6.795599937438965s
epoch 50: {'train_loss': '1.38629'}; time used = 6.525870323181152s
epoch 55: {'train_loss': '1.38629'}; time used = 6.544313430786133s
epoch 60: {'train_loss': '1.38629'}; time used = 6.691595077514648s
epoch 65: {'train_loss': '1.38629'}; time used = 7.248349905014038s
epoch 70: {'train_loss': '1.38629'}; time used = 9.930527925491333s
epoch 75: {'train_loss': '1.38629'}; time used = 6.776103973388672s
epoch 80: {'train_loss': '1.38629'}; time used = 6.644244194030762s
epoch 85: {'train_loss': '1.38629'}; time used = 6.948851585388184s
epoch 90: {'train_loss': '1.38629'}; time used = 7.270460605621338s
epoch 95: {'train_loss': '1.38629'}; time used = 6.823769807815552s
epoch 100: {'train_loss': '1.38629'}; time used = 6.748811960220337s
epoch 105: {'train_loss': '1.38629'}; time used = 6.556678295135498s
epoch 110: {'train_loss': '1.38629'}; time used = 6.93673849105835s
epoch 115: {'train_loss': '1.38629'}; time used = 6.761955499649048s
epoch 120: {'train_loss': '1.38629'}; time used = 7.10006308555603s
epoch 125: {'train_loss': '1.38629'}; time used = 6.334211349487305s
epoch 130: {'train_loss': '1.38629'}; time used = 6.86743950843811s
epoch 135: {'train_loss': '1.38629'}; time used = 11.087628841400146s
epoch 140: {'train_loss': '1.38629'}; time used = 7.041639566421509s
epoch 145: {'train_loss': '1.38629'}; time used = 6.738196134567261s
epoch 150: {'train_loss': '1.38629'}; time used = 6.73967981338501s
epoch 155: {'train_loss': '1.38629'}; time used = 6.5915141105651855s
epoch 160: {'train_loss': '1.38629'}; time used = 7.684644460678101s
epoch 165: {'train_loss': '1.38629'}; time used = 7.651782989501953s
epoch 170: {'train_loss': '1.38629'}; time used = 7.215928554534912s
epoch 175: {'train_loss': '1.38629'}; time used = 6.510420322418213s
epoch 180: {'train_loss': '1.38629'}; time used = 7.525369167327881s
epoch 185: {'train_loss': '1.38629'}; time used = 6.606902837753296s
epoch 190: {'train_loss': '1.38629'}; time used = 10.541432857513428s
epoch 195: {'train_loss': '1.38629'}; time used = 7.8188300132751465s
epoch 200: {'train_loss': '1.38629'}; time used = 11.844107151031494s
epoch 205: {'train_loss': '1.38629'}; time used = 9.494994163513184s
epoch 210: {'train_loss': '1.38629'}; time used = 6.833875417709351s
epoch 215: {'train_loss': '1.38629'}; time used = 6.588406562805176s
epoch 220: {'train_loss': '1.38629'}; time used = 6.576017379760742s
epoch 225: {'train_loss': '1.38629'}; time used = 6.553001403808594s
epoch 230: {'train_loss': '1.38629'}; time used = 6.808220148086548s
epoch 235: {'train_loss': '1.38629'}; time used = 6.675037384033203s
epoch 240: {'train_loss': '1.38629'}; time used = 6.999269008636475s
epoch 245: {'train_loss': '1.38629'}; time used = 6.9485390186309814s
epoch 250: {'train_loss': '1.38629'}; time used = 6.549209833145142s
epoch 255: {'train_loss': '1.38629'}; time used = 6.639513254165649s
epoch 260: {'train_loss': '1.38629'}; time used = 7.002812147140503s
epoch 265: {'train_loss': '1.38629'}; time used = 6.888974189758301s
epoch 270: {'train_loss': '1.38629'}; time used = 8.010798692703247s
epoch 275: {'train_loss': '1.38629'}; time used = 11.112261295318604s
epoch 280: {'train_loss': '1.38629'}; time used = 9.568110942840576s
epoch 285: {'train_loss': '1.38629'}; time used = 9.180906295776367s
epoch 290: {'train_loss': '1.38629'}; time used = 6.424496173858643s
epoch 295: {'train_loss': '1.38629'}; time used = 7.214129209518433s
epoch 300: {'train_loss': '1.38629'}; time used = 6.667194843292236s
epoch 305: {'train_loss': '1.38629'}; time used = 6.61118483543396s
epoch 310: {'train_loss': '1.38629'}; time used = 6.515862464904785s
epoch 315: {'train_loss': '1.38629'}; time used = 6.436020612716675s
epoch 320: {'train_loss': '1.38629'}; time used = 7.120282888412476s
epoch 325: {'train_loss': '1.38629'}; time used = 7.08550500869751s
epoch 330: {'train_loss': '1.38629'}; time used = 8.279070854187012s
epoch 335: {'train_loss': '1.38629'}; time used = 6.252346038818359s
epoch 340: {'train_loss': '1.38629'}; time used = 8.375547647476196s
epoch 345: {'train_loss': '1.38629'}; time used = 7.940454959869385s
epoch 350: {'train_loss': '1.38629'}; time used = 6.47062349319458s
epoch 355: {'train_loss': '1.38629'}; time used = 6.314915895462036s
epoch 360: {'train_loss': '1.38629'}; time used = 6.269838094711304s
epoch 365: {'train_loss': '1.38629'}; time used = 6.355649948120117s
epoch 370: {'train_loss': '1.38629'}; time used = 6.539386510848999s
epoch 375: {'train_loss': '1.38629'}; time used = 6.4654717445373535s
epoch 380: {'train_loss': '1.38629'}; time used = 6.411128997802734s
epoch 385: {'train_loss': '1.38629'}; time used = 6.554591178894043s
epoch 390: {'train_loss': '1.38629'}; time used = 6.831669569015503s
epoch 395: {'train_loss': '1.38629'}; time used = 9.893688917160034s
epoch 400: {'train_loss': '1.38629'}; time used = 6.5331573486328125s
epoch 405: {'train_loss': '1.38629'}; time used = 6.6030189990997314s
epoch 410: {'train_loss': '1.38629'}; time used = 9.038586854934692s
epoch 415: {'train_loss': '1.38629'}; time used = 7.934136390686035s
epoch 420: {'train_loss': '1.38629'}; time used = 7.248169898986816s
epoch 425: {'train_loss': '1.38629'}; time used = 7.423702955245972s
epoch 430: {'train_loss': '1.38629'}; time used = 7.419780969619751s
epoch 435: {'train_loss': '1.38629'}; time used = 7.8502326011657715s
epoch 440: {'train_loss': '1.38629'}; time used = 7.355940818786621s
epoch 445: {'train_loss': '1.38629'}; time used = 7.25260066986084s
epoch 450: {'train_loss': '1.38629'}; time used = 7.246443033218384s
epoch 455: {'train_loss': '1.38629'}; time used = 7.1826910972595215s
epoch 460: {'train_loss': '1.38629'}; time used = 6.524440765380859s
epoch 465: {'train_loss': '1.38629'}; time used = 6.4960949420928955s
epoch 470: {'train_loss': '1.38629'}; time used = 9.914814472198486s
epoch 475: {'train_loss': '1.38629'}; time used = 7.096560716629028s
epoch 480: {'train_loss': '1.38629'}; time used = 11.992451429367065s
epoch 485: {'train_loss': '1.38629'}; time used = 10.890083074569702s
epoch 490: {'train_loss': '1.38629'}; time used = 6.732213258743286s
epoch 495: {'train_loss': '1.38629'}; time used = 6.4011828899383545s
epoch 500: {'train_loss': '1.38629'}; time used = 6.589627027511597s
Finished training. Time used = 742.362895488739.
Training classifier using 80.00% nodes...
{'micro': 0.41999999999999993, 'macro': 0.3393353394833341, 'samples': 0.42, 'weighted': 0.3291552792988341, 'accuracy': 0.42}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.36122'}; time used = 1.791398048400879s
epoch 10: {'train_loss': '1.30033'}; time used = 1.7602176666259766s
epoch 15: {'train_loss': '1.33895'}; time used = 1.714585781097412s
epoch 20: {'train_loss': '1.37711'}; time used = 1.7297821044921875s
epoch 25: {'train_loss': '1.28491'}; time used = 1.905684232711792s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.967723369598389.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5446029380455609, 'samples': 0.5507246376811594, 'weighted': 0.5484290003178098, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92585'}; time used = 2.2719576358795166s
epoch 10: {'train_loss': '2.80833'}; time used = 2.0481274127960205s
epoch 15: {'train_loss': '2.78952'}; time used = 2.035658121109009s
epoch 20: {'train_loss': '2.77763'}; time used = 2.1970326900482178s
epoch 25: {'train_loss': '2.76432'}; time used = 2.127095937728882s
epoch 30: {'train_loss': '2.75096'}; time used = 1.9797217845916748s
epoch 35: {'train_loss': '2.74012'}; time used = 2.03844952583313s
epoch 40: {'train_loss': '2.72527'}; time used = 2.101797580718994s
epoch 45: {'train_loss': '2.71027'}; time used = 1.9840850830078125s
epoch 50: {'train_loss': '2.69108'}; time used = 2.1180572509765625s
epoch 55: {'train_loss': '2.69006'}; time used = 2.2276477813720703s
epoch 60: {'train_loss': '2.65320'}; time used = 3.5149621963500977s
epoch 65: {'train_loss': '2.62162'}; time used = 4.130884885787964s
epoch 70: {'train_loss': '2.61333'}; time used = 4.356117248535156s
epoch 75: {'train_loss': '2.55375'}; time used = 4.372685194015503s
epoch 80: {'train_loss': '2.56149'}; time used = 4.433555603027344s
epoch 85: {'train_loss': '2.58841'}; time used = 4.088958501815796s
epoch 90: {'train_loss': '2.52337'}; time used = 2.8579599857330322s
epoch 95: {'train_loss': '2.52868'}; time used = 2.0771842002868652s
epoch 100: {'train_loss': '2.51159'}; time used = 2.0380876064300537s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.56212759017944.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83767'}; time used = 2.1862714290618896s
epoch 10: {'train_loss': '2.77224'}; time used = 2.067336320877075s
epoch 15: {'train_loss': '2.79451'}; time used = 2.054957628250122s
epoch 20: {'train_loss': '2.78205'}; time used = 1.9190800189971924s
epoch 25: {'train_loss': '2.77104'}; time used = 2.3301148414611816s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.618672370910645.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.600300364728599, 'samples': 0.6086956521739131, 'weighted': 0.6044980084512561, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.26486'}; time used = 1.259474277496338s
epoch 10: {'train_loss': '2.76476'}; time used = 0.9354283809661865s
epoch 15: {'train_loss': '2.75326'}; time used = 0.9688107967376709s
epoch 20: {'train_loss': '2.73155'}; time used = 1.0765230655670166s
epoch 25: {'train_loss': '2.63140'}; time used = 1.0154237747192383s
epoch 30: {'train_loss': '2.03148'}; time used = 0.9951155185699463s
epoch 35: {'train_loss': '1.45903'}; time used = 1.1489386558532715s
epoch 40: {'train_loss': '1.41015'}; time used = 1.2093086242675781s
epoch 45: {'train_loss': '1.40616'}; time used = 1.1635565757751465s
epoch 50: {'train_loss': '1.27451'}; time used = 1.1898322105407715s
epoch 55: {'train_loss': '1.25089'}; time used = 1.9262003898620605s
epoch 60: {'train_loss': '1.16905'}; time used = 1.9918100833892822s
epoch 65: {'train_loss': '1.13405'}; time used = 1.9079644680023193s
epoch 70: {'train_loss': '1.06602'}; time used = 1.8837320804595947s
epoch 75: {'train_loss': '1.02535'}; time used = 1.5787158012390137s
epoch 80: {'train_loss': '1.05882'}; time used = 1.0764970779418945s
epoch 85: {'train_loss': '1.06306'}; time used = 1.0957350730895996s
epoch 90: {'train_loss': '1.00745'}; time used = 1.0595920085906982s
epoch 95: {'train_loss': '1.07633'}; time used = 0.934434175491333s
epoch 100: {'train_loss': '1.03113'}; time used = 0.9556574821472168s
epoch 105: {'train_loss': '0.96096'}; time used = 1.0772316455841064s
epoch 110: {'train_loss': '0.91438'}; time used = 1.0741958618164062s
epoch 115: {'train_loss': '0.90911'}; time used = 1.0002624988555908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.7217960357666.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85544'}; time used = 3.339901924133301s
epoch 10: {'train_loss': '2.78723'}; time used = 3.481837511062622s
epoch 15: {'train_loss': '2.77278'}; time used = 3.1882576942443848s
epoch 20: {'train_loss': '2.77549'}; time used = 3.2678475379943848s
epoch 25: {'train_loss': '2.77695'}; time used = 2.2449913024902344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.852050304412842.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8920454545454546, 'samples': 0.8947368421052632, 'weighted': 0.8947368421052632, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84823'}; time used = 6.630407333374023s
epoch 10: {'train_loss': '2.77736'}; time used = 7.350545644760132s
epoch 15: {'train_loss': '2.78156'}; time used = 7.462227821350098s
epoch 20: {'train_loss': '2.77758'}; time used = 6.4942145347595215s
epoch 25: {'train_loss': '2.77369'}; time used = 6.779362440109253s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.47028994560242.
Training classifier using 80.00% nodes...
{'micro': 0.5, 'macro': 0.43165824164932104, 'samples': 0.5, 'weighted': 0.42178541747676446, 'accuracy': 0.5}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.48258'}; time used = 1.5010972023010254s
epoch 10: {'train_loss': '0.25099'}; time used = 1.3265631198883057s
epoch 15: {'train_loss': '0.25567'}; time used = 1.2431697845458984s
epoch 20: {'train_loss': '0.15116'}; time used = 1.2410776615142822s
epoch 25: {'train_loss': '0.18497'}; time used = 1.2271509170532227s
epoch 30: {'train_loss': '0.18789'}; time used = 1.2575526237487793s
epoch 35: {'train_loss': '0.17837'}; time used = 1.211585283279419s
epoch 40: {'train_loss': '0.10940'}; time used = 1.2025730609893799s
epoch 45: {'train_loss': '0.09890'}; time used = 1.2588891983032227s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.87312626838684.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30284'}; time used = 1.8029229640960693s
epoch 10: {'train_loss': '1.13240'}; time used = 1.683743953704834s
epoch 15: {'train_loss': '1.12517'}; time used = 1.7169246673583984s
epoch 20: {'train_loss': '1.00317'}; time used = 1.6948633193969727s
epoch 25: {'train_loss': '0.95582'}; time used = 1.7249062061309814s
epoch 30: {'train_loss': '0.90895'}; time used = 1.695164680480957s
epoch 35: {'train_loss': '0.88641'}; time used = 1.6945252418518066s
epoch 40: {'train_loss': '0.83676'}; time used = 1.6927943229675293s
epoch 45: {'train_loss': '0.83432'}; time used = 1.7623040676116943s
epoch 50: {'train_loss': '0.73790'}; time used = 1.7464048862457275s
epoch 55: {'train_loss': '0.72119'}; time used = 1.7844243049621582s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.32728385925293.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5108695652173914, 'samples': 0.5652173913043478, 'weighted': 0.5226843100189036, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77183'}; time used = 1.8420345783233643s
epoch 10: {'train_loss': '2.65710'}; time used = 1.7523562908172607s
epoch 15: {'train_loss': '2.63921'}; time used = 1.744840145111084s
epoch 20: {'train_loss': '2.61901'}; time used = 1.7669601440429688s
epoch 25: {'train_loss': '2.59203'}; time used = 1.8880529403686523s
epoch 30: {'train_loss': '2.56402'}; time used = 1.7611198425292969s
epoch 35: {'train_loss': '2.53371'}; time used = 1.782402515411377s
epoch 40: {'train_loss': '2.50340'}; time used = 1.6964771747589111s
epoch 45: {'train_loss': '2.46987'}; time used = 1.7022442817687988s
epoch 50: {'train_loss': '2.39211'}; time used = 1.8186659812927246s
epoch 55: {'train_loss': '2.40998'}; time used = 1.7772600650787354s
epoch 60: {'train_loss': '2.38585'}; time used = 1.7141201496124268s
epoch 65: {'train_loss': '2.34720'}; time used = 1.714634895324707s
epoch 70: {'train_loss': '2.29869'}; time used = 1.7228367328643799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.325324296951294.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4828042328042328, 'samples': 0.5072463768115942, 'weighted': 0.4909516141400199, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.34072'}; time used = 1.757035493850708s
epoch 10: {'train_loss': '1.10729'}; time used = 1.870997667312622s
epoch 15: {'train_loss': '0.88148'}; time used = 1.8259270191192627s
epoch 20: {'train_loss': '0.74760'}; time used = 2.0623178482055664s
epoch 25: {'train_loss': '0.57400'}; time used = 2.3130531311035156s
epoch 30: {'train_loss': '0.06545'}; time used = 3.8490800857543945s
epoch 35: {'train_loss': '0.16783'}; time used = 3.6545543670654297s
epoch 40: {'train_loss': '0.02555'}; time used = 3.392529010772705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.94587731361389.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.19285'}; time used = 1.3177149295806885s
epoch 10: {'train_loss': '0.84649'}; time used = 1.213181495666504s
epoch 15: {'train_loss': '0.67418'}; time used = 1.2590696811676025s
epoch 20: {'train_loss': '0.56706'}; time used = 1.0877056121826172s
epoch 25: {'train_loss': '0.49009'}; time used = 1.0782499313354492s
epoch 30: {'train_loss': '0.35345'}; time used = 1.049607753753662s
epoch 35: {'train_loss': '0.32647'}; time used = 1.156437635421753s
epoch 40: {'train_loss': '0.33299'}; time used = 1.1377971172332764s
epoch 45: {'train_loss': '0.27156'}; time used = 1.1368217468261719s
epoch 50: {'train_loss': '0.28564'}; time used = 1.0877516269683838s
epoch 55: {'train_loss': '0.27093'}; time used = 1.0766167640686035s
epoch 60: {'train_loss': '0.21144'}; time used = 1.138824462890625s
epoch 65: {'train_loss': '0.22270'}; time used = 1.0498378276824951s
epoch 70: {'train_loss': '0.20588'}; time used = 1.0551183223724365s
epoch 75: {'train_loss': '0.24618'}; time used = 1.083078145980835s
epoch 80: {'train_loss': '0.21618'}; time used = 1.0553345680236816s
epoch 85: {'train_loss': '0.22021'}; time used = 1.1579008102416992s
epoch 90: {'train_loss': '0.20973'}; time used = 1.115973711013794s
epoch 95: {'train_loss': '0.28098'}; time used = 1.0950541496276855s
epoch 100: {'train_loss': '0.23545'}; time used = 1.104154348373413s
epoch 105: {'train_loss': '0.22068'}; time used = 1.111337661743164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.573089838027954.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35397'}; time used = 2.2447450160980225s
epoch 10: {'train_loss': '1.44870'}; time used = 1.0330193042755127s
epoch 15: {'train_loss': '0.61945'}; time used = 1.5501503944396973s
epoch 20: {'train_loss': '0.28518'}; time used = 2.17144513130188s
epoch 25: {'train_loss': '0.02500'}; time used = 2.4580326080322266s
epoch 30: {'train_loss': '0.07708'}; time used = 2.4232521057128906s
epoch 35: {'train_loss': '0.02118'}; time used = 2.088230848312378s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.931519031524658.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.27972'}; time used = 2.508284568786621s
epoch 10: {'train_loss': '1.07342'}; time used = 1.775406837463379s
epoch 15: {'train_loss': '0.98309'}; time used = 1.7410221099853516s
epoch 20: {'train_loss': '0.89340'}; time used = 1.7504677772521973s
epoch 25: {'train_loss': '0.69903'}; time used = 1.875373363494873s
epoch 30: {'train_loss': '0.40496'}; time used = 1.7511234283447266s
epoch 35: {'train_loss': '0.19222'}; time used = 1.815622091293335s
epoch 40: {'train_loss': '0.21150'}; time used = 1.769545078277588s
epoch 45: {'train_loss': '0.27263'}; time used = 1.9774789810180664s
epoch 50: {'train_loss': '0.19283'}; time used = 2.047935724258423s
epoch 55: {'train_loss': '0.32562'}; time used = 2.006026268005371s
epoch 60: {'train_loss': '0.24371'}; time used = 1.8714830875396729s
epoch 65: {'train_loss': '0.13592'}; time used = 1.8705730438232422s
epoch 70: {'train_loss': '0.03174'}; time used = 1.939711332321167s
epoch 75: {'train_loss': '0.00776'}; time used = 1.8498375415802002s
epoch 80: {'train_loss': '0.08554'}; time used = 1.9456617832183838s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.84533762931824.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.48187084316670237, 'samples': 0.4927536231884058, 'weighted': 0.48731223317755407, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80301'}; time used = 1.7198200225830078s
epoch 10: {'train_loss': '2.70298'}; time used = 1.6013805866241455s
epoch 15: {'train_loss': '2.66593'}; time used = 1.6330416202545166s
epoch 20: {'train_loss': '2.65977'}; time used = 1.6752703189849854s
epoch 25: {'train_loss': '2.65161'}; time used = 1.8367931842803955s
epoch 30: {'train_loss': '2.63348'}; time used = 1.5957629680633545s
epoch 35: {'train_loss': '2.62881'}; time used = 1.5975687503814697s
epoch 40: {'train_loss': '2.62712'}; time used = 1.575200080871582s
epoch 45: {'train_loss': '2.61866'}; time used = 1.5809624195098877s
epoch 50: {'train_loss': '2.60256'}; time used = 1.6995465755462646s
epoch 55: {'train_loss': '2.59804'}; time used = 1.6351056098937988s
epoch 60: {'train_loss': '2.60034'}; time used = 1.565431833267212s
epoch 65: {'train_loss': '2.58557'}; time used = 1.5550291538238525s
epoch 70: {'train_loss': '2.57511'}; time used = 1.9312245845794678s
epoch 75: {'train_loss': '2.56169'}; time used = 1.5514278411865234s
epoch 80: {'train_loss': '2.56260'}; time used = 1.8104722499847412s
epoch 85: {'train_loss': '2.56420'}; time used = 1.7251198291778564s
epoch 90: {'train_loss': '2.57282'}; time used = 1.8857948780059814s
epoch 95: {'train_loss': '2.56999'}; time used = 1.6141326427459717s
epoch 100: {'train_loss': '2.55879'}; time used = 1.7304720878601074s
epoch 105: {'train_loss': '2.56123'}; time used = 1.6316678524017334s
epoch 110: {'train_loss': '2.56153'}; time used = 1.7051050662994385s
epoch 115: {'train_loss': '2.55700'}; time used = 1.63055419921875s
epoch 120: {'train_loss': '2.56133'}; time used = 1.6555955410003662s
epoch 125: {'train_loss': '2.55480'}; time used = 1.7048203945159912s
epoch 130: {'train_loss': '2.56025'}; time used = 1.6088368892669678s
epoch 135: {'train_loss': '2.55932'}; time used = 1.6313552856445312s
epoch 140: {'train_loss': '2.55754'}; time used = 1.5918374061584473s
epoch 145: {'train_loss': '2.55121'}; time used = 1.6200406551361084s
epoch 150: {'train_loss': '2.55651'}; time used = 1.565584659576416s
epoch 155: {'train_loss': '2.55399'}; time used = 1.5528278350830078s
epoch 160: {'train_loss': '2.56198'}; time used = 1.6226539611816406s
epoch 165: {'train_loss': '2.54729'}; time used = 1.7403151988983154s
epoch 170: {'train_loss': '2.55519'}; time used = 1.8152999877929688s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.11747479438782.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09309'}; time used = 1.7787423133850098s
epoch 10: {'train_loss': '2.84954'}; time used = 1.696556568145752s
epoch 15: {'train_loss': '2.77885'}; time used = 1.9863221645355225s
epoch 20: {'train_loss': '2.78103'}; time used = 1.7281997203826904s
epoch 25: {'train_loss': '2.78165'}; time used = 1.8238189220428467s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.659797430038452.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29328'}; time used = 1.9528179168701172s
epoch 10: {'train_loss': '1.19164'}; time used = 1.964695692062378s
epoch 15: {'train_loss': '1.02558'}; time used = 1.9595587253570557s
epoch 20: {'train_loss': '0.69132'}; time used = 1.8355836868286133s
epoch 25: {'train_loss': '0.65252'}; time used = 2.027830123901367s
epoch 30: {'train_loss': '0.33506'}; time used = 1.9166653156280518s
epoch 35: {'train_loss': '0.28902'}; time used = 1.8882391452789307s
epoch 40: {'train_loss': '0.06831'}; time used = 1.916088581085205s
epoch 45: {'train_loss': '0.09289'}; time used = 1.9399020671844482s
epoch 50: {'train_loss': '0.03978'}; time used = 1.9681141376495361s
epoch 55: {'train_loss': '0.02387'}; time used = 2.0258078575134277s
epoch 60: {'train_loss': '0.02264'}; time used = 1.9074158668518066s
epoch 65: {'train_loss': '0.01579'}; time used = 1.9917881488800049s
epoch 70: {'train_loss': '0.01555'}; time used = 1.985846757888794s
epoch 75: {'train_loss': '0.01028'}; time used = 1.9259400367736816s
epoch 80: {'train_loss': '0.07829'}; time used = 2.6653823852539062s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.011478900909424.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5740740740740741, 'samples': 0.5942028985507246, 'weighted': 0.5807836822329576, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.41188'}; time used = 6.985752820968628s
epoch 10: {'train_loss': '2.81930'}; time used = 6.926724433898926s
epoch 15: {'train_loss': '2.82479'}; time used = 8.480599164962769s
epoch 20: {'train_loss': '2.83732'}; time used = 8.40182375907898s
epoch 25: {'train_loss': '2.82707'}; time used = 7.949023962020874s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.81735062599182.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.44913711583924343, 'samples': 0.5033333333333333, 'weighted': 0.44046300236406616, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.30969'}; time used = 1.8437118530273438s
epoch 10: {'train_loss': '0.33798'}; time used = 1.7079668045043945s
epoch 15: {'train_loss': '0.15200'}; time used = 1.7353615760803223s
epoch 20: {'train_loss': '0.09520'}; time used = 1.6850640773773193s
epoch 25: {'train_loss': '0.12461'}; time used = 1.7252116203308105s
epoch 30: {'train_loss': '0.08897'}; time used = 1.6738815307617188s
epoch 35: {'train_loss': '0.08576'}; time used = 1.7120544910430908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.236144542694092.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85458'}; time used = 6.0765464305877686s
epoch 10: {'train_loss': '2.78031'}; time used = 6.229851722717285s
epoch 15: {'train_loss': '2.77649'}; time used = 6.776444435119629s
epoch 20: {'train_loss': '2.78483'}; time used = 6.3105385303497314s
epoch 25: {'train_loss': '2.77488'}; time used = 7.22940731048584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.835020780563354.
Training classifier using 80.00% nodes...
{'micro': 0.4766666666666667, 'macro': 0.3865399104728981, 'samples': 0.4766666666666667, 'weighted': 0.37494371315871117, 'accuracy': 0.4766666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.32305'}; time used = 5.3221917152404785s
epoch 10: {'train_loss': '1.34799'}; time used = 5.079431533813477s
epoch 15: {'train_loss': '1.33491'}; time used = 5.214860200881958s
epoch 20: {'train_loss': '1.33815'}; time used = 5.525461196899414s
epoch 25: {'train_loss': '1.31748'}; time used = 6.569254398345947s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.4363169670105.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.72997299729973, 'samples': 0.73, 'weighted': 0.72991899189919, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.72092'}; time used = 1.1416285037994385s
epoch 10: {'train_loss': '2.65284'}; time used = 1.0098495483398438s
epoch 15: {'train_loss': '2.61787'}; time used = 1.11016845703125s
epoch 20: {'train_loss': '2.56962'}; time used = 1.0969407558441162s
epoch 25: {'train_loss': '2.51554'}; time used = 1.1061532497406006s
epoch 30: {'train_loss': '2.44188'}; time used = 1.1725797653198242s
epoch 35: {'train_loss': '2.36151'}; time used = 1.033125638961792s
epoch 40: {'train_loss': '2.31265'}; time used = 0.971398115158081s
epoch 45: {'train_loss': '2.25703'}; time used = 0.9805459976196289s
epoch 50: {'train_loss': '2.22169'}; time used = 0.9770760536193848s
epoch 55: {'train_loss': '2.20609'}; time used = 0.9785094261169434s
epoch 60: {'train_loss': '2.14797'}; time used = 1.0848374366760254s
epoch 65: {'train_loss': '2.14105'}; time used = 1.121541976928711s
epoch 70: {'train_loss': '2.15541'}; time used = 1.182328462600708s
epoch 75: {'train_loss': '2.11169'}; time used = 2.5004994869232178s
epoch 80: {'train_loss': '2.15854'}; time used = 2.545539617538452s
epoch 85: {'train_loss': '2.17807'}; time used = 2.2307891845703125s
epoch 90: {'train_loss': '2.13507'}; time used = 1.02284836769104s
epoch 95: {'train_loss': '2.08357'}; time used = 0.9535565376281738s
epoch 100: {'train_loss': '2.07646'}; time used = 0.9419925212860107s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.37061071395874.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.93812'}; time used = 1.1538946628570557s
epoch 10: {'train_loss': '2.80744'}; time used = 1.0502400398254395s
epoch 15: {'train_loss': '2.77881'}; time used = 1.0453355312347412s
epoch 20: {'train_loss': '2.77289'}; time used = 1.0843322277069092s
epoch 25: {'train_loss': '2.77627'}; time used = 0.9739270210266113s
epoch 30: {'train_loss': '2.77159'}; time used = 1.0404012203216553s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.156819105148315.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34119'}; time used = 1.9738216400146484s
epoch 10: {'train_loss': '1.26717'}; time used = 1.885371208190918s
epoch 15: {'train_loss': '1.25854'}; time used = 1.8345296382904053s
epoch 20: {'train_loss': '1.29315'}; time used = 1.793118953704834s
epoch 25: {'train_loss': '1.25898'}; time used = 1.8580193519592285s
epoch 30: {'train_loss': '1.15552'}; time used = 1.7963757514953613s
epoch 35: {'train_loss': '1.16592'}; time used = 1.8973805904388428s
epoch 40: {'train_loss': '1.12841'}; time used = 1.8847079277038574s
epoch 45: {'train_loss': '1.14841'}; time used = 1.92484712600708s
epoch 50: {'train_loss': '0.99460'}; time used = 1.9938461780548096s
epoch 55: {'train_loss': '0.95038'}; time used = 1.8409180641174316s
epoch 60: {'train_loss': '0.77475'}; time used = 1.9309089183807373s
epoch 65: {'train_loss': '0.86181'}; time used = 1.9766225814819336s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.65761375427246.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.56159'}; time used = 1.1532368659973145s
epoch 10: {'train_loss': '0.38356'}; time used = 0.9777584075927734s
epoch 15: {'train_loss': '0.22925'}; time used = 1.0602128505706787s
epoch 20: {'train_loss': '0.11452'}; time used = 0.9673566818237305s
epoch 25: {'train_loss': '0.12714'}; time used = 0.9817109107971191s
epoch 30: {'train_loss': '0.07333'}; time used = 0.9861273765563965s
epoch 35: {'train_loss': '0.06975'}; time used = 0.9892802238464355s
epoch 40: {'train_loss': '0.07280'}; time used = 0.9736261367797852s
epoch 45: {'train_loss': '0.05595'}; time used = 0.9812912940979004s
epoch 50: {'train_loss': '0.05480'}; time used = 0.997298002243042s
epoch 55: {'train_loss': '0.03306'}; time used = 1.0222654342651367s
epoch 60: {'train_loss': '0.00931'}; time used = 1.0739269256591797s
epoch 65: {'train_loss': '0.02619'}; time used = 0.9749109745025635s
epoch 70: {'train_loss': '0.01868'}; time used = 1.0506901741027832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.83120822906494.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.08639'}; time used = 1.1217379570007324s
epoch 10: {'train_loss': '0.42005'}; time used = 0.8980276584625244s
epoch 15: {'train_loss': '0.34355'}; time used = 0.9063818454742432s
epoch 20: {'train_loss': '0.30984'}; time used = 0.9101369380950928s
epoch 25: {'train_loss': '0.35629'}; time used = 0.9018197059631348s
epoch 30: {'train_loss': '0.28549'}; time used = 0.892026424407959s
epoch 35: {'train_loss': '0.31699'}; time used = 0.8957996368408203s
epoch 40: {'train_loss': '0.28446'}; time used = 0.8918137550354004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.575657844543457.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37982'}; time used = 1.8998486995697021s
epoch 10: {'train_loss': '1.29813'}; time used = 1.9639592170715332s
epoch 15: {'train_loss': '1.19775'}; time used = 1.9356915950775146s
epoch 20: {'train_loss': '1.34117'}; time used = 1.8261544704437256s
epoch 25: {'train_loss': '1.22284'}; time used = 2.0275685787200928s
epoch 30: {'train_loss': '1.13617'}; time used = 1.7715437412261963s
epoch 35: {'train_loss': '1.20656'}; time used = 2.0031380653381348s
epoch 40: {'train_loss': '1.20413'}; time used = 1.8447000980377197s
epoch 45: {'train_loss': '1.21715'}; time used = 1.8845934867858887s
epoch 50: {'train_loss': '1.17920'}; time used = 1.825026512145996s
epoch 55: {'train_loss': '1.00206'}; time used = 1.7749786376953125s
epoch 60: {'train_loss': '1.07508'}; time used = 1.7774488925933838s
epoch 65: {'train_loss': '1.20622'}; time used = 1.7584524154663086s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.34266948699951.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10285'}; time used = 1.1876435279846191s
epoch 10: {'train_loss': '0.80594'}; time used = 1.0477802753448486s
epoch 15: {'train_loss': '0.57705'}; time used = 1.056236743927002s
epoch 20: {'train_loss': '0.39086'}; time used = 1.0862102508544922s
epoch 25: {'train_loss': '0.49325'}; time used = 1.0708682537078857s
epoch 30: {'train_loss': '0.33047'}; time used = 1.0730030536651611s
epoch 35: {'train_loss': '0.21421'}; time used = 1.0653295516967773s
epoch 40: {'train_loss': '0.17163'}; time used = 1.1498231887817383s
epoch 45: {'train_loss': '0.20450'}; time used = 1.087184190750122s
epoch 50: {'train_loss': '0.17911'}; time used = 1.0784220695495605s
epoch 55: {'train_loss': '0.18867'}; time used = 1.2677569389343262s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.1338369846344.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5324036095159967, 'samples': 0.6052631578947368, 'weighted': 0.5615474288674926, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.22332'}; time used = 1.783031940460205s
epoch 10: {'train_loss': '3.08184'}; time used = 1.8709030151367188s
epoch 15: {'train_loss': '2.93734'}; time used = 1.830801010131836s
epoch 20: {'train_loss': '2.82886'}; time used = 1.7335708141326904s
epoch 25: {'train_loss': '2.75491'}; time used = 1.898792028427124s
epoch 30: {'train_loss': '2.69459'}; time used = 2.319983959197998s
epoch 35: {'train_loss': '2.66039'}; time used = 1.6988334655761719s
epoch 40: {'train_loss': '2.60799'}; time used = 1.6576790809631348s
epoch 45: {'train_loss': '2.56905'}; time used = 1.6498322486877441s
epoch 50: {'train_loss': '2.52276'}; time used = 1.6533715724945068s
epoch 55: {'train_loss': '2.51252'}; time used = 1.7531745433807373s
epoch 60: {'train_loss': '2.49985'}; time used = 1.7176225185394287s
epoch 65: {'train_loss': '2.47811'}; time used = 1.6578993797302246s
epoch 70: {'train_loss': '2.46197'}; time used = 1.6718764305114746s
epoch 75: {'train_loss': '2.46734'}; time used = 1.7063112258911133s
epoch 80: {'train_loss': '2.43961'}; time used = 1.8061673641204834s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.80210208892822.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01149'}; time used = 2.381873607635498s
epoch 10: {'train_loss': '0.16410'}; time used = 2.8528475761413574s
epoch 15: {'train_loss': '0.34324'}; time used = 2.7802348136901855s
epoch 20: {'train_loss': '0.00025'}; time used = 2.4577906131744385s
epoch 25: {'train_loss': '0.11045'}; time used = 2.3422977924346924s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.129576683044434.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39816'}; time used = 2.840467929840088s
epoch 10: {'train_loss': '1.40364'}; time used = 2.339540958404541s
epoch 15: {'train_loss': '1.37862'}; time used = 1.8212170600891113s
epoch 20: {'train_loss': '1.38296'}; time used = 1.4035582542419434s
epoch 25: {'train_loss': '1.28959'}; time used = 1.3600902557373047s
epoch 30: {'train_loss': '1.21164'}; time used = 1.340148687362671s
epoch 35: {'train_loss': '1.16347'}; time used = 1.4442930221557617s
epoch 40: {'train_loss': '1.15998'}; time used = 2.168405771255493s
epoch 45: {'train_loss': '0.89572'}; time used = 1.333092451095581s
epoch 50: {'train_loss': '0.89264'}; time used = 1.3658156394958496s
epoch 55: {'train_loss': '1.00669'}; time used = 1.3685057163238525s
epoch 60: {'train_loss': '0.94340'}; time used = 1.3097355365753174s
epoch 65: {'train_loss': '0.66588'}; time used = 1.3229703903198242s
epoch 70: {'train_loss': '0.80883'}; time used = 1.328104019165039s
epoch 75: {'train_loss': '0.76771'}; time used = 1.3423020839691162s
epoch 80: {'train_loss': '0.68454'}; time used = 1.4395694732666016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.05000376701355.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5529411764705883, 'samples': 0.6052631578947368, 'weighted': 0.5770897832817338, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.55377'}; time used = 1.444572925567627s
epoch 10: {'train_loss': '0.32714'}; time used = 1.094989538192749s
epoch 15: {'train_loss': '0.19876'}; time used = 0.9700441360473633s
epoch 20: {'train_loss': '0.15353'}; time used = 1.091418981552124s
epoch 25: {'train_loss': '0.21343'}; time used = 0.9324784278869629s
epoch 30: {'train_loss': '0.13208'}; time used = 0.933201789855957s
epoch 35: {'train_loss': '0.14723'}; time used = 0.9525210857391357s
epoch 40: {'train_loss': '0.18601'}; time used = 0.9875242710113525s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.489810228347778.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.24884'}; time used = 1.0855364799499512s
epoch 10: {'train_loss': '0.12452'}; time used = 1.0374071598052979s
epoch 15: {'train_loss': '0.07164'}; time used = 1.0352370738983154s
epoch 20: {'train_loss': '0.06163'}; time used = 1.0294742584228516s
epoch 25: {'train_loss': '0.06148'}; time used = 1.2206523418426514s
epoch 30: {'train_loss': '0.07557'}; time used = 0.9984920024871826s
epoch 35: {'train_loss': '0.06850'}; time used = 0.893364429473877s
epoch 40: {'train_loss': '0.05042'}; time used = 0.9193291664123535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.409235715866089.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.04890'}; time used = 1.132021427154541s
epoch 10: {'train_loss': '0.87197'}; time used = 1.0569603443145752s
epoch 15: {'train_loss': '0.70545'}; time used = 1.0826101303100586s
epoch 20: {'train_loss': '0.51253'}; time used = 1.0682077407836914s
epoch 25: {'train_loss': '0.39394'}; time used = 1.0671122074127197s
epoch 30: {'train_loss': '0.30200'}; time used = 1.0624465942382812s
epoch 35: {'train_loss': '0.23035'}; time used = 1.0635247230529785s
epoch 40: {'train_loss': '0.22397'}; time used = 1.0639193058013916s
epoch 45: {'train_loss': '0.27883'}; time used = 0.9746956825256348s
epoch 50: {'train_loss': '0.25362'}; time used = 0.8710529804229736s
epoch 55: {'train_loss': '0.22925'}; time used = 1.1774890422821045s
epoch 60: {'train_loss': '0.19392'}; time used = 1.108534574508667s
epoch 65: {'train_loss': '0.23543'}; time used = 0.8916592597961426s
epoch 70: {'train_loss': '0.20325'}; time used = 1.006394624710083s
epoch 75: {'train_loss': '0.09906'}; time used = 1.0519967079162598s
epoch 80: {'train_loss': '0.13897'}; time used = 0.8947992324829102s
epoch 85: {'train_loss': '0.15078'}; time used = 0.8801777362823486s
epoch 90: {'train_loss': '0.10974'}; time used = 0.9843542575836182s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.77471947669983.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.28662'}; time used = 1.0924947261810303s
epoch 10: {'train_loss': '1.47609'}; time used = 0.9921483993530273s
epoch 15: {'train_loss': '0.88482'}; time used = 1.080367088317871s
epoch 20: {'train_loss': '0.73272'}; time used = 1.027177095413208s
epoch 25: {'train_loss': '0.13307'}; time used = 0.9979429244995117s
epoch 30: {'train_loss': '0.24087'}; time used = 0.9681243896484375s
epoch 35: {'train_loss': '0.18772'}; time used = 1.0017547607421875s
epoch 40: {'train_loss': '0.16412'}; time used = 1.0247747898101807s
epoch 45: {'train_loss': '0.04465'}; time used = 1.000368356704712s
epoch 50: {'train_loss': '0.04283'}; time used = 1.0141873359680176s
epoch 55: {'train_loss': '0.00667'}; time used = 0.9518945217132568s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.440508842468262.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.33645'}; time used = 1.7828593254089355s
epoch 10: {'train_loss': '1.26823'}; time used = 1.6949806213378906s
epoch 15: {'train_loss': '1.25424'}; time used = 1.7848029136657715s
epoch 20: {'train_loss': '1.30088'}; time used = 1.7380588054656982s
epoch 25: {'train_loss': '1.26472'}; time used = 1.8104159832000732s
epoch 30: {'train_loss': '1.18485'}; time used = 1.7183127403259277s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.05008554458618.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.04058'}; time used = 1.4577741622924805s
epoch 10: {'train_loss': '0.65607'}; time used = 1.2843513488769531s
epoch 15: {'train_loss': '0.42071'}; time used = 1.4352715015411377s
epoch 20: {'train_loss': '0.30596'}; time used = 1.3725149631500244s
epoch 25: {'train_loss': '0.21425'}; time used = 1.2924134731292725s
epoch 30: {'train_loss': '0.28246'}; time used = 1.2878947257995605s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.50272512435913.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12898'}; time used = 1.6409330368041992s
epoch 10: {'train_loss': '0.89692'}; time used = 1.5788745880126953s
epoch 15: {'train_loss': '0.56407'}; time used = 1.5822269916534424s
epoch 20: {'train_loss': '0.34944'}; time used = 1.5580577850341797s
epoch 25: {'train_loss': '0.19119'}; time used = 1.6008319854736328s
epoch 30: {'train_loss': '0.11576'}; time used = 1.5573642253875732s
epoch 35: {'train_loss': '0.04176'}; time used = 1.5694050788879395s
epoch 40: {'train_loss': '0.08083'}; time used = 1.6027638912200928s
epoch 45: {'train_loss': '0.01409'}; time used = 1.5794720649719238s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.165233850479126.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36644'}; time used = 1.4719791412353516s
epoch 10: {'train_loss': '1.27584'}; time used = 1.3966279029846191s
epoch 15: {'train_loss': '0.29215'}; time used = 1.389986515045166s
epoch 20: {'train_loss': '0.26542'}; time used = 1.407280445098877s
epoch 25: {'train_loss': '0.14040'}; time used = 1.4024238586425781s
epoch 30: {'train_loss': '0.03495'}; time used = 1.3761529922485352s
epoch 35: {'train_loss': '0.06233'}; time used = 2.3254051208496094s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.509854793548584.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.700358422939068, 'samples': 0.7105263157894737, 'weighted': 0.709073759667987, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.30983'}; time used = 2.6291322708129883s
epoch 10: {'train_loss': '1.23540'}; time used = 2.3911726474761963s
epoch 15: {'train_loss': '1.21180'}; time used = 2.5456559658050537s
epoch 20: {'train_loss': '1.34377'}; time used = 2.5447590351104736s
epoch 25: {'train_loss': '1.26128'}; time used = 2.5584380626678467s
epoch 30: {'train_loss': '1.14590'}; time used = 2.459834575653076s
epoch 35: {'train_loss': '1.29171'}; time used = 2.464893102645874s
epoch 40: {'train_loss': '1.19194'}; time used = 2.449983835220337s
epoch 45: {'train_loss': '1.26582'}; time used = 2.465989828109741s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.96749448776245.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.15663'}; time used = 2.190800428390503s
epoch 10: {'train_loss': '0.13600'}; time used = 1.8934428691864014s
epoch 15: {'train_loss': '0.11868'}; time used = 2.31536865234375s
epoch 20: {'train_loss': '0.01069'}; time used = 2.8576653003692627s
epoch 25: {'train_loss': '0.03482'}; time used = 3.257495403289795s
epoch 30: {'train_loss': '0.02647'}; time used = 1.6983904838562012s
epoch 35: {'train_loss': '0.10356'}; time used = 1.6457936763763428s
epoch 40: {'train_loss': '0.00549'}; time used = 1.6115407943725586s
epoch 45: {'train_loss': '0.00410'}; time used = 1.6134109497070312s
epoch 50: {'train_loss': '0.03864'}; time used = 1.617987871170044s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.91688323020935.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.39937'}; time used = 1.323498249053955s
epoch 10: {'train_loss': '2.86339'}; time used = 1.1497905254364014s
epoch 15: {'train_loss': '2.83209'}; time used = 1.1530113220214844s
epoch 20: {'train_loss': '2.82442'}; time used = 1.1874675750732422s
epoch 25: {'train_loss': '2.81090'}; time used = 1.1334304809570312s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.611462831497192.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6266061980347695, 'samples': 0.6578947368421053, 'weighted': 0.6436726737478617, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.01487'}; time used = 1.0699734687805176s
epoch 10: {'train_loss': '0.74837'}; time used = 0.8872473239898682s
epoch 15: {'train_loss': '0.57779'}; time used = 0.8817014694213867s
epoch 20: {'train_loss': '0.41068'}; time used = 0.8926975727081299s
epoch 25: {'train_loss': '0.33535'}; time used = 0.8948075771331787s
epoch 30: {'train_loss': '0.27436'}; time used = 0.86686110496521s
epoch 35: {'train_loss': '0.21921'}; time used = 0.9103591442108154s
epoch 40: {'train_loss': '0.14885'}; time used = 0.912144660949707s
epoch 45: {'train_loss': '0.11962'}; time used = 0.8902208805084229s
epoch 50: {'train_loss': '0.11518'}; time used = 0.9144690036773682s
epoch 55: {'train_loss': '0.08739'}; time used = 0.9114022254943848s
epoch 60: {'train_loss': '0.07642'}; time used = 0.9710073471069336s
epoch 65: {'train_loss': '0.07390'}; time used = 0.9368855953216553s
epoch 70: {'train_loss': '0.07510'}; time used = 0.923943281173706s
epoch 75: {'train_loss': '0.06226'}; time used = 0.8868064880371094s
epoch 80: {'train_loss': '0.04740'}; time used = 0.9068267345428467s
epoch 85: {'train_loss': '0.07005'}; time used = 0.9164772033691406s
epoch 90: {'train_loss': '0.06089'}; time used = 0.9179551601409912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.962559461593628.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7246376811594202, 'samples': 0.7368421052631579, 'weighted': 0.7337909992372235, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.36379'}; time used = 2.1799535751342773s
epoch 10: {'train_loss': '2.98142'}; time used = 1.909834861755371s
epoch 15: {'train_loss': '2.88265'}; time used = 2.0205390453338623s
epoch 20: {'train_loss': '2.85455'}; time used = 1.9034340381622314s
epoch 25: {'train_loss': '2.82615'}; time used = 2.036113977432251s
epoch 30: {'train_loss': '2.81429'}; time used = 1.9681739807128906s
epoch 35: {'train_loss': '2.80618'}; time used = 1.8955698013305664s
epoch 40: {'train_loss': '2.79989'}; time used = 1.9174749851226807s
epoch 45: {'train_loss': '2.80167'}; time used = 1.9106435775756836s
epoch 50: {'train_loss': '2.79249'}; time used = 1.9267644882202148s
epoch 55: {'train_loss': '2.79203'}; time used = 1.9911494255065918s
epoch 60: {'train_loss': '2.78476'}; time used = 1.8779377937316895s
epoch 65: {'train_loss': '2.77144'}; time used = 1.8974907398223877s
epoch 70: {'train_loss': '2.76116'}; time used = 1.9303898811340332s
epoch 75: {'train_loss': '2.73755'}; time used = 2.031414747238159s
epoch 80: {'train_loss': '2.70898'}; time used = 2.1272735595703125s
epoch 85: {'train_loss': '2.67832'}; time used = 1.9248745441436768s
epoch 90: {'train_loss': '2.65871'}; time used = 1.9202909469604492s
epoch 95: {'train_loss': '2.63411'}; time used = 1.9590234756469727s
epoch 100: {'train_loss': '2.58161'}; time used = 1.9042394161224365s
epoch 105: {'train_loss': '2.60065'}; time used = 1.9424877166748047s
epoch 110: {'train_loss': '2.61380'}; time used = 1.911609411239624s
epoch 115: {'train_loss': '2.57346'}; time used = 1.9055490493774414s
epoch 120: {'train_loss': '2.58234'}; time used = 1.918487787246704s
epoch 125: {'train_loss': '2.56983'}; time used = 1.9114248752593994s
epoch 130: {'train_loss': '2.56873'}; time used = 1.9839982986450195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 57.03918385505676.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86588'}; time used = 0.9967169761657715s
epoch 10: {'train_loss': '2.79278'}; time used = 0.8575608730316162s
epoch 15: {'train_loss': '2.74842'}; time used = 0.8797924518585205s
epoch 20: {'train_loss': '2.68022'}; time used = 0.8670773506164551s
epoch 25: {'train_loss': '2.48655'}; time used = 0.8576779365539551s
epoch 30: {'train_loss': '2.15914'}; time used = 0.8640344142913818s
epoch 35: {'train_loss': '1.96053'}; time used = 0.8634037971496582s
epoch 40: {'train_loss': '1.99792'}; time used = 0.8772799968719482s
epoch 45: {'train_loss': '1.92937'}; time used = 0.8729164600372314s
epoch 50: {'train_loss': '1.91208'}; time used = 0.8549273014068604s
epoch 55: {'train_loss': '1.86081'}; time used = 0.8540940284729004s
epoch 60: {'train_loss': '1.80543'}; time used = 0.9400577545166016s
epoch 65: {'train_loss': '1.82500'}; time used = 0.861257791519165s
epoch 70: {'train_loss': '1.81948'}; time used = 0.8811643123626709s
epoch 75: {'train_loss': '1.74290'}; time used = 1.0051522254943848s
epoch 80: {'train_loss': '1.88006'}; time used = 0.9297199249267578s
epoch 85: {'train_loss': '1.81912'}; time used = 1.0105104446411133s
epoch 90: {'train_loss': '1.76650'}; time used = 0.9436280727386475s
epoch 95: {'train_loss': '1.76523'}; time used = 0.8128900527954102s
epoch 100: {'train_loss': '1.75478'}; time used = 0.8339755535125732s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.961904287338257.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10432'}; time used = 2.3850810527801514s
epoch 10: {'train_loss': '0.27804'}; time used = 2.3615496158599854s
epoch 15: {'train_loss': '0.14590'}; time used = 2.461156129837036s
epoch 20: {'train_loss': '0.10129'}; time used = 2.2891204357147217s
epoch 25: {'train_loss': '0.08266'}; time used = 2.491037368774414s
epoch 30: {'train_loss': '0.07366'}; time used = 2.364100694656372s
epoch 35: {'train_loss': '0.06917'}; time used = 2.9547531604766846s
epoch 40: {'train_loss': '0.04853'}; time used = 3.364290714263916s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.369933605194092.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4462279293739968, 'samples': 0.4927536231884058, 'weighted': 0.4578593528275991, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.22062'}; time used = 1.2135119438171387s
epoch 10: {'train_loss': '1.41185'}; time used = 1.0558457374572754s
epoch 15: {'train_loss': '1.38374'}; time used = 1.1078834533691406s
epoch 20: {'train_loss': '1.39511'}; time used = 1.0351006984710693s
epoch 25: {'train_loss': '1.37327'}; time used = 1.0438458919525146s
epoch 30: {'train_loss': '1.36379'}; time used = 1.0155596733093262s
epoch 35: {'train_loss': '1.36588'}; time used = 1.0214364528656006s
epoch 40: {'train_loss': '1.33426'}; time used = 1.2142152786254883s
epoch 45: {'train_loss': '1.28418'}; time used = 1.0542473793029785s
epoch 50: {'train_loss': '1.35363'}; time used = 1.0761864185333252s
epoch 55: {'train_loss': '1.31395'}; time used = 1.0809075832366943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.922254085540771.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86588'}; time used = 1.076247215270996s
epoch 10: {'train_loss': '2.79278'}; time used = 0.9536871910095215s
epoch 15: {'train_loss': '2.74842'}; time used = 0.9348583221435547s
epoch 20: {'train_loss': '2.68022'}; time used = 0.9464380741119385s
epoch 25: {'train_loss': '2.48655'}; time used = 0.9632508754730225s
epoch 30: {'train_loss': '2.15914'}; time used = 1.0327363014221191s
epoch 35: {'train_loss': '1.96053'}; time used = 1.0863068103790283s
epoch 40: {'train_loss': '1.99792'}; time used = 1.0164167881011963s
epoch 45: {'train_loss': '1.92937'}; time used = 0.9842219352722168s
epoch 50: {'train_loss': '1.91208'}; time used = 1.1087682247161865s
epoch 55: {'train_loss': '1.86081'}; time used = 1.0825684070587158s
epoch 60: {'train_loss': '1.80543'}; time used = 1.0355312824249268s
epoch 65: {'train_loss': '1.82500'}; time used = 0.9797394275665283s
epoch 70: {'train_loss': '1.81948'}; time used = 0.9836554527282715s
epoch 75: {'train_loss': '1.74290'}; time used = 0.978360652923584s
epoch 80: {'train_loss': '1.88006'}; time used = 0.9578626155853271s
epoch 85: {'train_loss': '1.81912'}; time used = 0.9550278186798096s
epoch 90: {'train_loss': '1.76650'}; time used = 0.9518980979919434s
epoch 95: {'train_loss': '1.76523'}; time used = 1.6788437366485596s
epoch 100: {'train_loss': '1.75478'}; time used = 1.958937644958496s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.890414237976074.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.22257'}; time used = 0.9675633907318115s
epoch 10: {'train_loss': '0.11871'}; time used = 0.9205291271209717s
epoch 15: {'train_loss': '0.06507'}; time used = 0.9104032516479492s
epoch 20: {'train_loss': '0.06154'}; time used = 0.9510636329650879s
epoch 25: {'train_loss': '0.06153'}; time used = 0.914602518081665s
epoch 30: {'train_loss': '0.07574'}; time used = 0.9009959697723389s
epoch 35: {'train_loss': '0.06866'}; time used = 0.9084033966064453s
epoch 40: {'train_loss': '0.05081'}; time used = 0.9383869171142578s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.713487386703491.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.48961'}; time used = 1.5075294971466064s
epoch 10: {'train_loss': '0.17070'}; time used = 1.2728896141052246s
epoch 15: {'train_loss': '0.15241'}; time used = 1.2573843002319336s
epoch 20: {'train_loss': '0.13385'}; time used = 1.2636191844940186s
epoch 25: {'train_loss': '0.07042'}; time used = 1.2645483016967773s
epoch 30: {'train_loss': '0.30253'}; time used = 1.2529370784759521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.586832761764526.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36449'}; time used = 1.7709581851959229s
epoch 10: {'train_loss': '1.24413'}; time used = 1.7464885711669922s
epoch 15: {'train_loss': '1.04565'}; time used = 1.8137335777282715s
epoch 20: {'train_loss': '0.87695'}; time used = 1.757906198501587s
epoch 25: {'train_loss': '0.19016'}; time used = 2.064976692199707s
epoch 30: {'train_loss': '0.49479'}; time used = 1.699350357055664s
epoch 35: {'train_loss': '0.19481'}; time used = 1.7130210399627686s
epoch 40: {'train_loss': '0.02337'}; time used = 1.8857643604278564s
epoch 45: {'train_loss': '0.14986'}; time used = 1.7812719345092773s
epoch 50: {'train_loss': '0.24452'}; time used = 1.9402070045471191s
epoch 55: {'train_loss': '0.15197'}; time used = 1.6940219402313232s
epoch 60: {'train_loss': '0.06605'}; time used = 1.717059850692749s
epoch 65: {'train_loss': '0.09237'}; time used = 1.9112253189086914s
epoch 70: {'train_loss': '0.05704'}; time used = 1.773209571838379s
epoch 75: {'train_loss': '0.03630'}; time used = 2.848053216934204s
epoch 80: {'train_loss': '0.01551'}; time used = 3.4454972743988037s
epoch 85: {'train_loss': '0.01252'}; time used = 3.3286638259887695s
epoch 90: {'train_loss': '0.00696'}; time used = 1.781296730041504s
epoch 95: {'train_loss': '0.01058'}; time used = 1.7595977783203125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.26341128349304.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5367121507472385, 'samples': 0.5507246376811594, 'weighted': 0.5425506869697055, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94043'}; time used = 1.7164762020111084s
epoch 10: {'train_loss': '2.79125'}; time used = 1.6598472595214844s
epoch 15: {'train_loss': '2.79407'}; time used = 1.7627766132354736s
epoch 20: {'train_loss': '2.78495'}; time used = 1.914355754852295s
epoch 25: {'train_loss': '2.77842'}; time used = 1.801891565322876s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.97824740409851.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.16183'}; time used = 1.6207804679870605s
epoch 10: {'train_loss': '0.01436'}; time used = 1.5348572731018066s
epoch 15: {'train_loss': '0.04782'}; time used = 1.5580167770385742s
epoch 20: {'train_loss': '0.00085'}; time used = 1.5502192974090576s
epoch 25: {'train_loss': '0.01799'}; time used = 1.6563541889190674s
epoch 30: {'train_loss': '0.00014'}; time used = 1.5699076652526855s
epoch 35: {'train_loss': '0.11317'}; time used = 1.6507048606872559s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.444368600845337.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5208333333333334, 'samples': 0.5652173913043478, 'weighted': 0.5314009661835749, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01844'}; time used = 1.256009817123413s
epoch 10: {'train_loss': '0.52292'}; time used = 0.8952467441558838s
epoch 15: {'train_loss': '0.34858'}; time used = 1.0164802074432373s
epoch 20: {'train_loss': '0.29309'}; time used = 0.9236831665039062s
epoch 25: {'train_loss': '0.19221'}; time used = 0.9054069519042969s
epoch 30: {'train_loss': '0.13123'}; time used = 0.9186716079711914s
epoch 35: {'train_loss': '0.07608'}; time used = 0.9969260692596436s
epoch 40: {'train_loss': '0.05291'}; time used = 0.9022552967071533s
epoch 45: {'train_loss': '0.03781'}; time used = 0.8924531936645508s
epoch 50: {'train_loss': '0.02895'}; time used = 0.9278173446655273s
epoch 55: {'train_loss': '0.01644'}; time used = 0.9222884178161621s
epoch 60: {'train_loss': '0.01774'}; time used = 1.0111887454986572s
epoch 65: {'train_loss': '0.01958'}; time used = 0.9843728542327881s
epoch 70: {'train_loss': '0.01209'}; time used = 0.917182445526123s
epoch 75: {'train_loss': '0.00924'}; time used = 0.9302592277526855s
epoch 80: {'train_loss': '0.01468'}; time used = 0.9709696769714355s
epoch 85: {'train_loss': '0.02336'}; time used = 0.922771692276001s
epoch 90: {'train_loss': '0.02308'}; time used = 0.9171712398529053s
epoch 95: {'train_loss': '0.01578'}; time used = 0.8977706432342529s
epoch 100: {'train_loss': '0.02084'}; time used = 0.8946869373321533s
epoch 105: {'train_loss': '0.01202'}; time used = 0.9565417766571045s
epoch 110: {'train_loss': '0.00983'}; time used = 0.8870458602905273s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.574134349822998.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.26340'}; time used = 2.613471746444702s
epoch 10: {'train_loss': '1.18190'}; time used = 2.572082996368408s
epoch 15: {'train_loss': '1.12383'}; time used = 2.722928524017334s
epoch 20: {'train_loss': '1.03138'}; time used = 2.782726287841797s
epoch 25: {'train_loss': '0.81402'}; time used = 2.736459970474243s
epoch 30: {'train_loss': '0.58427'}; time used = 2.5910305976867676s
epoch 35: {'train_loss': '0.32831'}; time used = 2.560894727706909s
epoch 40: {'train_loss': '0.16146'}; time used = 2.5514378547668457s
epoch 45: {'train_loss': '0.11171'}; time used = 2.4871859550476074s
epoch 50: {'train_loss': '0.10329'}; time used = 2.4341654777526855s
epoch 55: {'train_loss': '0.11212'}; time used = 2.508249521255493s
epoch 60: {'train_loss': '0.04495'}; time used = 2.3816030025482178s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.80720806121826.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.4559139784946237, 'samples': 0.5217391304347826, 'weighted': 0.46962755181549015, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.97617'}; time used = 1.6581902503967285s
epoch 10: {'train_loss': '2.81092'}; time used = 1.6085712909698486s
epoch 15: {'train_loss': '2.81442'}; time used = 1.623227834701538s
epoch 20: {'train_loss': '2.79567'}; time used = 1.7039706707000732s
epoch 25: {'train_loss': '2.77935'}; time used = 1.7703442573547363s
epoch 30: {'train_loss': '2.76147'}; time used = 1.6323742866516113s
epoch 35: {'train_loss': '2.72718'}; time used = 1.6238939762115479s
epoch 40: {'train_loss': '2.66107'}; time used = 1.6267263889312744s
epoch 45: {'train_loss': '2.59866'}; time used = 1.6739468574523926s
epoch 50: {'train_loss': '2.54052'}; time used = 1.6065483093261719s
epoch 55: {'train_loss': '2.49920'}; time used = 1.7406859397888184s
epoch 60: {'train_loss': '2.44508'}; time used = 1.7569098472595215s
epoch 65: {'train_loss': '2.30585'}; time used = 1.6036367416381836s
epoch 70: {'train_loss': '2.28413'}; time used = 1.676387071609497s
epoch 75: {'train_loss': '2.16943'}; time used = 1.5836520195007324s
epoch 80: {'train_loss': '2.11720'}; time used = 1.6593194007873535s
epoch 85: {'train_loss': '2.07543'}; time used = 1.6823101043701172s
epoch 90: {'train_loss': '2.04735'}; time used = 1.6811697483062744s
epoch 95: {'train_loss': '2.02675'}; time used = 1.6125578880310059s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.531090259552.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5527777777777778, 'samples': 0.5942028985507246, 'weighted': 0.5626409017713365, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79791'}; time used = 2.5125844478607178s
epoch 10: {'train_loss': '2.77335'}; time used = 2.531780242919922s
epoch 15: {'train_loss': '2.78522'}; time used = 2.560757637023926s
epoch 20: {'train_loss': '2.78396'}; time used = 2.41945219039917s
epoch 25: {'train_loss': '2.77314'}; time used = 2.384162187576294s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.888198852539062.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79102'}; time used = 1.829416275024414s
epoch 10: {'train_loss': '2.89206'}; time used = 1.7339541912078857s
epoch 15: {'train_loss': '2.80853'}; time used = 1.7559778690338135s
epoch 20: {'train_loss': '2.77795'}; time used = 1.7756342887878418s
epoch 25: {'train_loss': '2.76984'}; time used = 1.8210327625274658s
epoch 30: {'train_loss': '2.76829'}; time used = 1.6416542530059814s
epoch 35: {'train_loss': '2.76940'}; time used = 1.6364998817443848s
epoch 40: {'train_loss': '2.76972'}; time used = 1.6448259353637695s
epoch 45: {'train_loss': '2.76704'}; time used = 1.6528420448303223s
epoch 50: {'train_loss': '2.76368'}; time used = 1.710188865661621s
epoch 55: {'train_loss': '2.76360'}; time used = 1.650026798248291s
epoch 60: {'train_loss': '2.75601'}; time used = 1.6189756393432617s
epoch 65: {'train_loss': '2.75219'}; time used = 1.6088659763336182s
epoch 70: {'train_loss': '2.75363'}; time used = 1.6197304725646973s
epoch 75: {'train_loss': '2.74528'}; time used = 1.7098042964935303s
epoch 80: {'train_loss': '2.75005'}; time used = 1.7110376358032227s
epoch 85: {'train_loss': '2.74942'}; time used = 1.6471972465515137s
epoch 90: {'train_loss': '2.74016'}; time used = 1.5911190509796143s
epoch 95: {'train_loss': '2.74095'}; time used = 2.498809576034546s
epoch 100: {'train_loss': '2.74274'}; time used = 1.7493846416473389s
epoch 105: {'train_loss': '2.73485'}; time used = 1.6613829135894775s
epoch 110: {'train_loss': '2.73735'}; time used = 1.7086021900177002s
epoch 115: {'train_loss': '2.72493'}; time used = 1.661076545715332s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.364826679229736.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.21 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.48961'}; time used = 1.394982099533081s
epoch 10: {'train_loss': '0.17070'}; time used = 1.389148235321045s
epoch 15: {'train_loss': '0.15241'}; time used = 1.2963600158691406s
epoch 20: {'train_loss': '0.13385'}; time used = 1.296422004699707s
epoch 25: {'train_loss': '0.07042'}; time used = 2.2639060020446777s
epoch 30: {'train_loss': '0.30253'}; time used = 2.044156074523926s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.681976795196533.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 7; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.44557'}; time used = 1.5075860023498535s
epoch 10: {'train_loss': '0.15774'}; time used = 1.353745460510254s
epoch 15: {'train_loss': '0.05582'}; time used = 1.4061791896820068s
epoch 20: {'train_loss': '0.14414'}; time used = 1.4017951488494873s
epoch 25: {'train_loss': '0.21284'}; time used = 1.4489803314208984s
epoch 30: {'train_loss': '0.10733'}; time used = 1.3795185089111328s
epoch 35: {'train_loss': '0.05907'}; time used = 1.3941116333007812s
epoch 40: {'train_loss': '0.02978'}; time used = 1.3848896026611328s
epoch 45: {'train_loss': '0.01118'}; time used = 1.3768012523651123s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.825327634811401.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84084'}; time used = 2.1831603050231934s
epoch 10: {'train_loss': '2.77302'}; time used = 2.087681293487549s
epoch 15: {'train_loss': '2.79580'}; time used = 2.083021402359009s
epoch 20: {'train_loss': '2.78337'}; time used = 2.24745512008667s
epoch 25: {'train_loss': '2.77323'}; time used = 2.3057360649108887s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.257245302200317.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.90970'}; time used = 1.8220436573028564s
epoch 10: {'train_loss': '2.78845'}; time used = 2.1626853942871094s
epoch 15: {'train_loss': '2.75968'}; time used = 3.5522778034210205s
epoch 20: {'train_loss': '2.75066'}; time used = 3.5734641551971436s
epoch 25: {'train_loss': '2.75043'}; time used = 1.9326555728912354s
epoch 30: {'train_loss': '2.74069'}; time used = 1.851597547531128s
epoch 35: {'train_loss': '2.73466'}; time used = 1.7084765434265137s
epoch 40: {'train_loss': '2.73046'}; time used = 1.7344748973846436s
epoch 45: {'train_loss': '2.72147'}; time used = 1.7524521350860596s
epoch 50: {'train_loss': '2.71490'}; time used = 1.8484172821044922s
epoch 55: {'train_loss': '2.71171'}; time used = 1.7380850315093994s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.6018328666687.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.16427'}; time used = 1.9023444652557373s
epoch 10: {'train_loss': '1.09456'}; time used = 1.8521435260772705s
epoch 15: {'train_loss': '0.89598'}; time used = 1.7684733867645264s
epoch 20: {'train_loss': '0.68501'}; time used = 1.8256819248199463s
epoch 25: {'train_loss': '0.46956'}; time used = 1.8870315551757812s
epoch 30: {'train_loss': '0.26857'}; time used = 2.003887891769409s
epoch 35: {'train_loss': '0.21162'}; time used = 2.7063302993774414s
epoch 40: {'train_loss': '0.19386'}; time used = 1.5466783046722412s
epoch 45: {'train_loss': '0.08907'}; time used = 1.497647762298584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.174299240112305.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.46392896781354054, 'samples': 0.4927536231884058, 'weighted': 0.4729366726181859, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36773'}; time used = 5.403487682342529s
epoch 10: {'train_loss': '1.39112'}; time used = 5.418607711791992s
epoch 15: {'train_loss': '1.37926'}; time used = 5.4699766635894775s
epoch 20: {'train_loss': '1.33100'}; time used = 5.163333892822266s
epoch 25: {'train_loss': '1.19198'}; time used = 5.446778774261475s
epoch 30: {'train_loss': '1.12837'}; time used = 5.353726625442505s
epoch 35: {'train_loss': '0.87719'}; time used = 5.465036630630493s
epoch 40: {'train_loss': '1.17020'}; time used = 4.857656002044678s
epoch 45: {'train_loss': '0.60790'}; time used = 5.472651481628418s
epoch 50: {'train_loss': '0.69062'}; time used = 5.340082883834839s
epoch 55: {'train_loss': '0.61240'}; time used = 4.897014617919922s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 79.23863220214844.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6949923748093703, 'samples': 0.695, 'weighted': 0.6949618740468512, 'accuracy': 0.695}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 7; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [7], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88558'}; time used = 1.1154906749725342s
epoch 10: {'train_loss': '2.80446'}; time used = 1.0096964836120605s
epoch 15: {'train_loss': '2.79240'}; time used = 1.0024762153625488s
epoch 20: {'train_loss': '2.78357'}; time used = 1.012061595916748s
epoch 25: {'train_loss': '2.77748'}; time used = 1.0212483406066895s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.473814725875854.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
